# Comparing `tmp/mindtorch-0.2.1.tar.gz` & `tmp/mindtorch-0.3.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "mindtorch-0.2.1.tar", last modified: Thu Feb  1 07:56:59 2024, max compression
+gzip compressed data, was "mindtorch-0.3.0.tar", last modified: Mon Apr 29 01:30:08 2024, max compression
```

## Comparing `mindtorch-0.2.1.tar` & `mindtorch-0.3.0.tar`

### file list

```diff
@@ -1,468 +1,748 @@
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.313028 mindtorch-0.2.1/
--rw-------   0 root         (0) root         (0)    11438 2024-02-01 07:54:56.000000 mindtorch-0.2.1/LICENSE
--rw-r--r--   0 root         (0) root         (0)     4147 2024-02-01 07:56:59.313028 mindtorch-0.2.1/PKG-INFO
--rw-------   0 root         (0) root         (0)     3156 2024-02-01 07:54:56.000000 mindtorch-0.2.1/README.rst
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.145025 mindtorch-0.2.1/mindtorch/
--rw-------   0 root         (0) root         (0)      209 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/__init__.py
--rw-------   0 root         (0) root         (0)      285 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/package_info.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.149025 mindtorch-0.2.1/mindtorch/tools/
--rw-------   0 root         (0) root         (0)      172 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/tools/__init__.py
--rw-------   0 root         (0) root         (0)     3004 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/tools/convert_tensor.py
--rw-------   0 root         (0) root         (0)     5424 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/tools/debug_layer_info.py
--rw-------   0 root         (0) root         (0)     1197 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/tools/pth2ckpt.py
--rw-------   0 root         (0) root         (0)    16214 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/tools/support_wrap_ops.yaml
--rw-------   0 root         (0) root         (0)      732 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/tools/utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.153025 mindtorch-0.2.1/mindtorch/torch/
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.153025 mindtorch-0.2.1/mindtorch/torch/_C/
--rw-------   0 root         (0) root         (0)     2606 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_C/Generator.py
--rw-------   0 root         (0) root         (0)      478 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/_C/__init__.py
--rw-------   0 root         (0) root         (0)     3606 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/__init__.py
--rw-------   0 root         (0) root         (0)     1233 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/_default_dtype.py
--rw-------   0 root         (0) root         (0)     9049 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_export_func_to_root.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.157025 mindtorch-0.2.1/mindtorch/torch/_ref/
--rw-------   0 root         (0) root         (0)      595 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_ref/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.157025 mindtorch-0.2.1/mindtorch/torch/_register/
--rw-------   0 root         (0) root         (0)     2939 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_register/__init__.py
--rw-------   0 root         (0) root         (0)     1522 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_register/getitem_impl.py
--rw-------   0 root         (0) root         (0)     6761 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_register/register_multitype_ops.py
--rw-------   0 root         (0) root         (0)     2618 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_register/register_standard_method.py
--rw-------   0 root         (0) root         (0)     8241 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_register/register_utils.py
--rw-------   0 root         (0) root         (0)     7521 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/_register_numpy_primitive.py
--rw-------   0 root         (0) root         (0)       30 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_six.py
--rw-------   0 root         (0) root         (0)     4820 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/_utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.157025 mindtorch-0.2.1/mindtorch/torch/amp/
--rw-------   0 root         (0) root         (0)     2884 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/amp/__init__.py
--rw-------   0 root         (0) root         (0)      897 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/amp/autocast_mode.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.157025 mindtorch-0.2.1/mindtorch/torch/autograd/
--rw-------   0 root         (0) root         (0)      372 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/autograd/__init__.py
--rw-------   0 root         (0) root         (0)     1568 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/autograd/function.py
--rw-------   0 root         (0) root         (0)     3019 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/autograd/functional.py
--rw-------   0 root         (0) root         (0)     3396 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/autograd/grad_mode.py
--rw-------   0 root         (0) root         (0)      526 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/autograd/variable.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/backends/
--rw-------   0 root         (0) root         (0)     1577 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/backends/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/backends/cuda/
--rw-------   0 root         (0) root         (0)      692 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/backends/cuda/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/backends/cudnn/
--rw-------   0 root         (0) root         (0)     3065 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/backends/cudnn/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/backends/mkl/
--rw-------   0 root         (0) root         (0)      155 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/backends/mkl/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/backends/mkldnn/
--rw-------   0 root         (0) root         (0)      159 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/backends/mkldnn/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/backends/mps/
--rw-------   0 root         (0) root         (0)      313 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/backends/mps/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/backends/openmp/
--rw-------   0 root         (0) root         (0)      170 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/backends/openmp/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/common/
--rw-------   0 root         (0) root         (0)      611 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/common/__init__.py
--rw-------   0 root         (0) root         (0)     5443 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/common/_inner.py
--rw-------   0 root         (0) root         (0)     7663 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/common/dtype.py
--rw-------   0 root         (0) root         (0)     1607 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/conflict_functional.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/cpu/
--rw-------   0 root         (0) root         (0)       84 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/cpu/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.161025 mindtorch-0.2.1/mindtorch/torch/cpu/amp/
--rw-------   0 root         (0) root         (0)       82 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/cpu/amp/__init__.py
--rw-------   0 root         (0) root         (0)      364 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/cpu/amp/autocast_mode.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.165025 mindtorch-0.2.1/mindtorch/torch/cuda/
--rw-------   0 root         (0) root         (0)     1263 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/cuda/__init__.py
--rw-------   0 root         (0) root         (0)      840 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/cuda/_utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.165025 mindtorch-0.2.1/mindtorch/torch/cuda/amp/
--rw-------   0 root         (0) root         (0)      143 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/cuda/amp/__init__.py
--rw-------   0 root         (0) root         (0)     1331 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/cuda/amp/autocast_mode.py
--rw-------   0 root         (0) root         (0)    10658 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/cuda/amp/grad_scaler.py
--rw-------   0 root         (0) root         (0)      454 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/cuda/random.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.165025 mindtorch-0.2.1/mindtorch/torch/distributed/
--rw-------   0 root         (0) root         (0)      598 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/distributed/__init__.py
--rw-------   0 root         (0) root         (0)     8710 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/distributed/distributed_c10d.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.165025 mindtorch-0.2.1/mindtorch/torch/fft/
--rw-------   0 root         (0) root         (0)      104 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/fft/__init__.py
--rw-------   0 root         (0) root         (0)      685 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/fft/fft.py
--rw-------   0 root         (0) root         (0)   117816 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/functional.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.165025 mindtorch-0.2.1/mindtorch/torch/fx/
--rw-------   0 root         (0) root         (0)       71 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/fx/__init__.py
--rw-------   0 root         (0) root         (0)      523 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/fx/proxy.py
--rw-------   0 root         (0) root         (0)     9655 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/hub.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.169025 mindtorch-0.2.1/mindtorch/torch/jit/
--rw-------   0 root         (0) root         (0)     1269 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/jit/__init__.py
--rw-------   0 root         (0) root         (0)      306 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/jit/_jit_internal.py
--rw-------   0 root         (0) root         (0)      936 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/library.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.169025 mindtorch-0.2.1/mindtorch/torch/linalg/
--rw-------   0 root         (0) root         (0)      635 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/linalg/__init__.py
--rw-------   0 root         (0) root         (0)    12833 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/linalg/linalg.py
--rw-------   0 root         (0) root         (0)     2085 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/logging.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.169025 mindtorch-0.2.1/mindtorch/torch/multiprocessing/
--rw-------   0 root         (0) root         (0)     1230 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/multiprocessing/__init__.py
--rw-------   0 root         (0) root         (0)     7099 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/multiprocessing/spawn.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.169025 mindtorch-0.2.1/mindtorch/torch/nn/
--rw-------   0 root         (0) root         (0)      230 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/__init__.py
--rw-------   0 root         (0) root         (0)   111207 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/functional.py
--rw-------   0 root         (0) root         (0)     6588 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/init.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.177025 mindtorch-0.2.1/mindtorch/torch/nn/modules/
--rw-------   0 root         (0) root         (0)     3412 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/__init__.py
--rw-------   0 root         (0) root         (0)    21631 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/activation.py
--rw-------   0 root         (0) root         (0)     6875 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/adaptive.py
--rw-------   0 root         (0) root         (0)    14388 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/batchnorm.py
--rw-------   0 root         (0) root         (0)     1735 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/channelshuffle.py
--rw-------   0 root         (0) root         (0)    37856 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/container.py
--rw-------   0 root         (0) root         (0)    25245 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/conv.py
--rw-------   0 root         (0) root         (0)      802 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/distance.py
--rw-------   0 root         (0) root         (0)     7483 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/dropout.py
--rw-------   0 root         (0) root         (0)     1106 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/flatten.py
--rw-------   0 root         (0) root         (0)     1424 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/fold.py
--rw-------   0 root         (0) root         (0)     2697 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/instancenorm.py
--rw-------   0 root         (0) root         (0)     5597 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/linear.py
--rw-------   0 root         (0) root         (0)    11018 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/loss.py
--rw-------   0 root         (0) root         (0)    35829 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/module.py
--rw-------   0 root         (0) root         (0)     5200 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/normalization.py
--rw-------   0 root         (0) root         (0)    11325 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/padding.py
--rw-------   0 root         (0) root         (0)      878 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/pixelshuffle.py
--rw-------   0 root         (0) root         (0)     8778 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/pooling.py
--rw-------   0 root         (0) root         (0)    37702 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/rnn.py
--rw-------   0 root         (0) root         (0)     3574 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/sparse.py
--rw-------   0 root         (0) root         (0)    12766 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/transformer.py
--rw-------   0 root         (0) root         (0)     1348 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/unpooling.py
--rw-------   0 root         (0) root         (0)     3407 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/upsampling.py
--rw-------   0 root         (0) root         (0)     3362 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/modules/utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.181025 mindtorch-0.2.1/mindtorch/torch/nn/parallel/
--rw-------   0 root         (0) root         (0)      154 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/parallel/__init__.py
--rw-------   0 root         (0) root         (0)      365 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/parallel/_functions.py
--rw-------   0 root         (0) root         (0)      447 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/parallel/data_parallel.py
--rw-------   0 root         (0) root         (0)     3145 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/parallel/distributed.py
--rw-------   0 root         (0) root         (0)     8601 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/parameter.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.181025 mindtorch-0.2.1/mindtorch/torch/nn/quantized/
--rw-------   0 root         (0) root         (0)       23 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/quantized/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.181025 mindtorch-0.2.1/mindtorch/torch/nn/quantized/modules/
--rw-------   0 root         (0) root         (0)       67 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/quantized/modules/__init__.py
--rw-------   0 root         (0) root         (0)     2203 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/quantized/modules/functional_modules.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.181025 mindtorch-0.2.1/mindtorch/torch/nn/utils/
--rw-------   0 root         (0) root         (0)      125 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/utils/__init__.py
--rw-------   0 root         (0) root         (0)     4005 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/utils/clip_grad.py
--rw-------   0 root         (0) root         (0)     2068 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/nn/utils/convert_parameters.py
--rw-------   0 root         (0) root         (0)    11863 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/nn/utils/rnn.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.185025 mindtorch-0.2.1/mindtorch/torch/optim/
--rw-------   0 root         (0) root         (0)      328 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/optim/__init__.py
--rw-------   0 root         (0) root         (0)     1076 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/optim/adam.py
--rw-------   0 root         (0) root         (0)     1081 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/optim/adamw.py
--rw-------   0 root         (0) root         (0)    19505 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/optim/lr_scheduler.py
--rw-------   0 root         (0) root         (0)    10888 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/optim/optimizer.py
--rw-------   0 root         (0) root         (0)     1484 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/optim/sgd.py
--rw-------   0 root         (0) root         (0)      147 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/overrides.py
--rw-------   0 root         (0) root         (0)      246 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/random.py
--rw-------   0 root         (0) root         (0)    15570 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/serialization.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.185025 mindtorch-0.2.1/mindtorch/torch/special/
--rw-------   0 root         (0) root         (0)      351 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/special/__init__.py
--rw-------   0 root         (0) root         (0)    27718 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/storage.py
--rw-------   0 root         (0) root         (0)   175242 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/tensor.py
--rw-------   0 root         (0) root         (0)      243 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/tensor_type.py
--rw-------   0 root         (0) root         (0)      959 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/torch_version.py
--rw-------   0 root         (0) root         (0)     3442 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/types.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.185025 mindtorch-0.2.1/mindtorch/torch/utils/
--rw-------   0 root         (0) root         (0)      174 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/utils/__init__.py
--rw-------   0 root         (0) root         (0)     6353 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/_pytree.py
--rw-------   0 root         (0) root         (0)     1677 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/checkpoint.py
--rw-------   0 root         (0) root         (0)      649 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/cpp_extension.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.189025 mindtorch-0.2.1/mindtorch/torch/utils/data/
--rw-------   0 root         (0) root         (0)     1762 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.189025 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/
--rw-------   0 root         (0) root         (0)     1829 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/__init__.py
--rw-------   0 root         (0) root         (0)    16397 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/collate.py
--rw-------   0 root         (0) root         (0)     1926 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/fetch.py
--rw-------   0 root         (0) root         (0)     2765 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/pin_memory.py
--rw-------   0 root         (0) root         (0)     8705 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/queue.py
--rw-------   0 root         (0) root         (0)      435 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/serialization.py
--rw-------   0 root         (0) root         (0)     3601 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/signal_handling.py
--rw-------   0 root         (0) root         (0)    13620 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/worker.py
--rw-------   0 root         (0) root         (0)      230 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/backward_compatibility.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.193026 mindtorch-0.2.1/mindtorch/torch/utils/data/communication/
--rw-------   0 root         (0) root         (0)      127 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/communication/__init__.py
--rw-------   0 root         (0) root         (0)     2788 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/communication/eventloop.py
--rw-------   0 root         (0) root         (0)     6575 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/communication/iter.py
--rw-------   0 root         (0) root         (0)     6112 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/communication/map.py
--rw-------   0 root         (0) root         (0)     1171 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/communication/messages.py
--rw-------   0 root         (0) root         (0)     8308 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/communication/protocol.py
--rw-------   0 root         (0) root         (0)     1401 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/communication/queue.py
--rw-------   0 root         (0) root         (0)    54729 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/dataloader.py
--rw-------   0 root         (0) root         (0)     7174 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/dataloader_experimental.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.193026 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/
--rw-------   0 root         (0) root         (0)       61 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/__init__.py
--rw-------   0 root         (0) root         (0)     7739 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/_decorator.py
--rw-------   0 root         (0) root         (0)    24732 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/_typing.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.197026 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/dataframe/
--rw-------   0 root         (0) root         (0)      355 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/dataframe/__init__.py
--rw-------   0 root         (0) root         (0)     2883 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/dataframe/dataframe_wrapper.py
--rw-------   0 root         (0) root         (0)     8818 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/dataframe/dataframes.py
--rw-------   0 root         (0) root         (0)     4342 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/dataframe/datapipes.py
--rw-------   0 root         (0) root         (0)      550 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/dataframe/structures.py
--rw-------   0 root         (0) root         (0)    15596 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/datapipe.py
--rw-------   0 root         (0) root         (0)     9923 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/gen_pyi.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.201026 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/
--rw-------   0 root         (0) root         (0)     2052 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/__init__.py
--rw-------   0 root         (0) root         (0)     6454 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/callable.py
--rw-------   0 root         (0) root         (0)     6321 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/combinatorics.py
--rw-------   0 root         (0) root         (0)    22292 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/combining.py
--rw-------   0 root         (0) root         (0)     2496 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/filelister.py
--rw-------   0 root         (0) root         (0)     3328 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/fileopener.py
--rw-------   0 root         (0) root         (0)    12607 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/grouping.py
--rw-------   0 root         (0) root         (0)     2770 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/routeddecoder.py
--rw-------   0 root         (0) root         (0)     3814 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/selecting.py
--rw-------   0 root         (0) root         (0)     1356 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/streamreader.py
--rw-------   0 root         (0) root         (0)     1786 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/iter/utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.205026 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/map/
--rw-------   0 root         (0) root         (0)      705 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/map/__init__.py
--rw-------   0 root         (0) root         (0)     1816 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/map/callable.py
--rw-------   0 root         (0) root         (0)     2382 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/map/combinatorics.py
--rw-------   0 root         (0) root         (0)     3749 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/map/combining.py
--rw-------   0 root         (0) root         (0)     2584 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/map/grouping.py
--rw-------   0 root         (0) root         (0)     1527 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/map/utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.209026 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/utils/
--rw-------   0 root         (0) root         (0)        0 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/utils/__init__.py
--rw-------   0 root         (0) root         (0)     8042 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/utils/common.py
--rw-------   0 root         (0) root         (0)    11024 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/datapipes/utils/decoder.py
--rw-------   0 root         (0) root         (0)    13820 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/dataset.py
--rw-------   0 root         (0) root         (0)     6318 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/distributed.py
--rw-------   0 root         (0) root         (0)     3141 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/graph.py
--rw-------   0 root         (0) root         (0)     2679 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/graph_settings.py
--rw-------   0 root         (0) root         (0)    10759 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/data/sampler.py
--rw-------   0 root         (0) root         (0)      121 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torch/utils/model_zoo.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.209026 mindtorch-0.2.1/mindtorch/torchaudio/
--rw-------   0 root         (0) root         (0)      655 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/__init__.py
--rw-------   0 root         (0) root         (0)     3745 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/_extension.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.213026 mindtorch-0.2.1/mindtorch/torchaudio/_internal/
--rw-------   0 root         (0) root         (0)      131 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/_internal/__init__.py
--rw-------   0 root         (0) root         (0)     4178 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/_internal/module_utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.217026 mindtorch-0.2.1/mindtorch/torchaudio/backend/
--rw-------   0 root         (0) root         (0)      112 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/backend/__init__.py
--rw-------   0 root         (0) root         (0)     1896 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/backend/common.py
--rw-------   0 root         (0) root         (0)      721 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/backend/no_backend.py
--rw-------   0 root         (0) root         (0)    16736 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/backend/soundfile_backend.py
--rw-------   0 root         (0) root         (0)    14497 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/backend/sox_io_backend.py
--rw-------   0 root         (0) root         (0)     2659 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/backend/utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.217026 mindtorch-0.2.1/mindtorch/torchaudio/compliance/
--rw-------   0 root         (0) root         (0)       48 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/compliance/__init__.py
--rw-------   0 root         (0) root         (0)    38330 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/compliance/kaldi.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.233026 mindtorch-0.2.1/mindtorch/torchaudio/datasets/
--rw-------   0 root         (0) root         (0)      757 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/__init__.py
--rw-------   0 root         (0) root         (0)     7043 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/cmuarctic.py
--rw-------   0 root         (0) root         (0)     6207 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/cmudict.py
--rw-------   0 root         (0) root         (0)     2523 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/commonvoice.py
--rw-------   0 root         (0) root         (0)     4212 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/dr_vctk.py
--rw-------   0 root         (0) root         (0)    24156 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/gtzan.py
--rw-------   0 root         (0) root         (0)     3623 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/librilight_limited.py
--rw-------   0 root         (0) root         (0)     3546 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/librimix.py
--rw-------   0 root         (0) root         (0)     5304 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/librispeech.py
--rw-------   0 root         (0) root         (0)     5752 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/libritts.py
--rw-------   0 root         (0) root         (0)     3452 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/ljspeech.py
--rw-------   0 root         (0) root         (0)     3778 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/quesst14.py
--rw-------   0 root         (0) root         (0)     6653 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/speechcommands.py
--rw-------   0 root         (0) root         (0)     8578 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/tedlium.py
--rw-------   0 root         (0) root         (0)     6779 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/utils.py
--rw-------   0 root         (0) root         (0)     5624 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/vctk.py
--rw-------   0 root         (0) root         (0)     2998 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/datasets/yesno.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.233026 mindtorch-0.2.1/mindtorch/torchaudio/functional/
--rw-------   0 root         (0) root         (0)     2026 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/functional/__init__.py
--rw-------   0 root         (0) root         (0)    64313 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/functional/filtering.py
--rw-------   0 root         (0) root         (0)    86495 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/functional/functional.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.237027 mindtorch-0.2.1/mindtorch/torchaudio/io/
--rw-------   0 root         (0) root         (0)      641 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/io/__init__.py
--rw-------   0 root         (0) root         (0)     3637 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/io/_compat.py
--rw-------   0 root         (0) root         (0)    25906 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/io/_stream_reader.py
--rw-------   0 root         (0) root         (0)     5222 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/kaldi_io.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.245027 mindtorch-0.2.1/mindtorch/torchaudio/models/
--rw-------   0 root         (0) root         (0)     1327 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/__init__.py
--rw-------   0 root         (0) root         (0)    10605 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/conformer.py
--rw-------   0 root         (0) root         (0)    12208 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/conv_tasnet.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.245027 mindtorch-0.2.1/mindtorch/torchaudio/models/decoder/
--rw-------   0 root         (0) root         (0)      995 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/decoder/__init__.py
--rw-------   0 root         (0) root         (0)    12886 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/decoder/_ctc_decoder.py
--rw-------   0 root         (0) root         (0)     2914 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/deepspeech.py
--rw-------   0 root         (0) root         (0)    39064 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/emformer.py
--rw-------   0 root         (0) root         (0)    36957 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/rnnt.py
--rw-------   0 root         (0) root         (0)    13413 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/rnnt_decoder.py
--rw-------   0 root         (0) root         (0)    47711 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/tacotron2.py
--rw-------   0 root         (0) root         (0)     3386 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2letter.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.249027 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/
--rw-------   0 root         (0) root         (0)      744 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/__init__.py
--rw-------   0 root         (0) root         (0)    43518 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/components.py
--rw-------   0 root         (0) root         (0)    52285 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/model.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.253027 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/utils/
--rw-------   0 root         (0) root         (0)      194 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/utils/__init__.py
--rw-------   0 root         (0) root         (0)     9764 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/utils/import_fairseq.py
--rw-------   0 root         (0) root         (0)     3231 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/utils/import_huggingface.py
--rw-------   0 root         (0) root         (0)    15831 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/models/wavernn.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.253027 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/
--rw-------   0 root         (0) root         (0)     2068 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/__init__.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.257027 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_tts/
--rw-------   0 root         (0) root         (0)      456 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_tts/__init__.py
--rw-------   0 root         (0) root         (0)    16367 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_tts/impl.py
--rw-------   0 root         (0) root         (0)    11677 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_tts/interface.py
--rw-------   0 root         (0) root         (0)     5055 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_tts/utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.257027 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_wav2vec2/
--rw-------   0 root         (0) root         (0)        0 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_wav2vec2/__init__.py
--rw-------   0 root         (0) root         (0)    49158 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_wav2vec2/impl.py
--rw-------   0 root         (0) root         (0)     3310 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_wav2vec2/utils.py
--rw-------   0 root         (0) root         (0)    14313 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/pipelines/rnnt_pipeline.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.261027 mindtorch-0.2.1/mindtorch/torchaudio/sox_effects/
--rw-------   0 root         (0) root         (0)      510 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/sox_effects/__init__.py
--rw-------   0 root         (0) root         (0)    12395 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/sox_effects/sox_effects.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.261027 mindtorch-0.2.1/mindtorch/torchaudio/transforms/
--rw-------   0 root         (0) root         (0)      966 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/transforms/__init__.py
--rw-------   0 root         (0) root         (0)    22249 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/transforms/_multi_channel.py
--rw-------   0 root         (0) root         (0)    89668 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/transforms/_transforms.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.265027 mindtorch-0.2.1/mindtorch/torchaudio/utils/
--rw-------   0 root         (0) root         (0)      299 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/utils/__init__.py
--rw-------   0 root         (0) root         (0)     2997 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/utils/download.py
--rw-------   0 root         (0) root         (0)     1788 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/utils/ffmpeg_utils.py
--rw-------   0 root         (0) root         (0)     2821 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchaudio/utils/sox_utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.269027 mindtorch-0.2.1/mindtorch/torchvision/
--rw-------   0 root         (0) root         (0)     2832 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/__init__.py
--rw-------   0 root         (0) root         (0)     2063 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/_internally_replaced_utils.py
--rw-------   0 root         (0) root         (0)      934 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/_utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.285027 mindtorch-0.2.1/mindtorch/torchvision/datasets/
--rw-------   0 root         (0) root         (0)     2554 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/__init__.py
--rw-------   0 root         (0) root         (0)    18841 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/_optical_flow.py
--rw-------   0 root         (0) root         (0)     9296 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/caltech.py
--rw-------   0 root         (0) root         (0)     9630 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/celeba.py
--rw-------   0 root         (0) root         (0)     5851 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/cifar.py
--rw-------   0 root         (0) root         (0)    10237 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/cityscapes.py
--rw-------   0 root         (0) root         (0)     3416 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/clevr.py
--rw-------   0 root         (0) root         (0)     3972 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/coco.py
--rw-------   0 root         (0) root         (0)     2408 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/country211.py
--rw-------   0 root         (0) root         (0)     3939 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/dtd.py
--rw-------   0 root         (0) root         (0)     2053 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/eurosat.py
--rw-------   0 root         (0) root         (0)     2606 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/fakedata.py
--rw-------   0 root         (0) root         (0)     2781 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/fer2013.py
--rw-------   0 root         (0) root         (0)     4561 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/fgvc_aircraft.py
--rw-------   0 root         (0) root         (0)     5339 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/flickr.py
--rw-------   0 root         (0) root         (0)     4600 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/flowers102.py
--rw-------   0 root         (0) root         (0)    11938 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/folder.py
--rw-------   0 root         (0) root         (0)     3713 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/food101.py
--rw-------   0 root         (0) root         (0)     3742 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/gtsrb.py
--rw-------   0 root         (0) root         (0)     5855 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/hmdb51.py
--rw-------   0 root         (0) root         (0)     8449 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/imagenet.py
--rw-------   0 root         (0) root         (0)    10107 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/inaturalist.py
--rw-------   0 root         (0) root         (0)    13406 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/kinetics.py
--rw-------   0 root         (0) root         (0)     5600 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/kitti.py
--rw-------   0 root         (0) root         (0)    10282 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/lfw.py
--rw-------   0 root         (0) root         (0)     5675 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/lsun.py
--rw-------   0 root         (0) root         (0)    21322 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/mnist.py
--rw-------   0 root         (0) root         (0)     4091 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/omniglot.py
--rw-------   0 root         (0) root         (0)     5071 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/oxford_iiit_pet.py
--rw-------   0 root         (0) root         (0)     5385 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/pcam.py
--rw-------   0 root         (0) root         (0)     8279 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/phototour.py
--rw-------   0 root         (0) root         (0)     7201 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/places365.py
--rw-------   0 root         (0) root         (0)     3557 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/rendered_sst2.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.289028 mindtorch-0.2.1/mindtorch/torchvision/datasets/samplers/
--rw-------   0 root         (0) root         (0)      161 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/samplers/__init__.py
--rw-------   0 root         (0) root         (0)     6528 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/samplers/clip_sampler.py
--rw-------   0 root         (0) root         (0)     5202 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/sbd.py
--rw-------   0 root         (0) root         (0)     4203 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/sbu.py
--rw-------   0 root         (0) root         (0)     3088 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/semeion.py
--rw-------   0 root         (0) root         (0)     4843 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/stanford_cars.py
--rw-------   0 root         (0) root         (0)     7294 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/stl10.py
--rw-------   0 root         (0) root         (0)     2743 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/sun397.py
--rw-------   0 root         (0) root         (0)     4766 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/svhn.py
--rw-------   0 root         (0) root         (0)     5417 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/ucf101.py
--rw-------   0 root         (0) root         (0)     3440 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/usps.py
--rw-------   0 root         (0) root         (0)    17257 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/utils.py
--rw-------   0 root         (0) root         (0)    17193 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/video_utils.py
--rw-------   0 root         (0) root         (0)     4216 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/vision.py
--rw-------   0 root         (0) root         (0)     9343 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/voc.py
--rw-------   0 root         (0) root         (0)     8307 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/datasets/widerface.py
--rw-------   0 root         (0) root         (0)     3198 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/extension.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.289028 mindtorch-0.2.1/mindtorch/torchvision/io/
--rw-------   0 root         (0) root         (0)     1568 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/io/__init__.py
--rw-------   0 root         (0) root         (0)      216 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/io/_load_gpu_decoder.py
--rw-------   0 root         (0) root         (0)    19782 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/io/_video_opt.py
--rw-------   0 root         (0) root         (0)     9944 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/io/image.py
--rw-------   0 root         (0) root         (0)    15420 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/io/video.py
--rw-------   0 root         (0) root         (0)     6934 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/io/video_reader.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.293027 mindtorch-0.2.1/mindtorch/torchvision/models/
--rw-------   0 root         (0) root         (0)      449 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/__init__.py
--rw-------   0 root         (0) root         (0)     2894 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/_utils.py
--rw-------   0 root         (0) root         (0)     2265 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/alexnet.py
--rw-------   0 root         (0) root         (0)    12717 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/densenet.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.297028 mindtorch-0.2.1/mindtorch/torchvision/models/detection/
--rw-------   0 root         (0) root         (0)      148 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/__init__.py
--rw-------   0 root         (0) root         (0)    16290 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/_utils.py
--rw-------   0 root         (0) root         (0)    11633 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/anchor_utils.py
--rw-------   0 root         (0) root         (0)     7825 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/backbone_utils.py
--rw-------   0 root         (0) root         (0)    23562 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/faster_rcnn.py
--rw-------   0 root         (0) root         (0)     4565 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/generalized_rcnn.py
--rw-------   0 root         (0) root         (0)      771 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/image_list.py
--rw-------   0 root         (0) root         (0)    19266 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/keypoint_rcnn.py
--rw-------   0 root         (0) root         (0)    19017 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/mask_rcnn.py
--rw-------   0 root         (0) root         (0)    27844 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/retinanet.py
--rw-------   0 root         (0) root         (0)    35169 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/roi_heads.py
--rw-------   0 root         (0) root         (0)    15405 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/rpn.py
--rw-------   0 root         (0) root         (0)    27129 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/ssd.py
--rw-------   0 root         (0) root         (0)    10477 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/ssdlite.py
--rw-------   0 root         (0) root         (0)    12393 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/detection/transform.py
--rw-------   0 root         (0) root         (0)    11719 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/googlenet.py
--rw-------   0 root         (0) root         (0)    17246 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/inception.py
--rw-------   0 root         (0) root         (0)    11473 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/mnasnet.py
--rw-------   0 root         (0) root         (0)      196 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/mobilenet.py
--rw-------   0 root         (0) root         (0)     7983 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/mobilenetv2.py
--rw-------   0 root         (0) root         (0)    12069 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/mobilenetv3.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.301028 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/
--rw-------   0 root         (0) root         (0)      125 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/__init__.py
--rw-------   0 root         (0) root         (0)      292 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/googlenet.py
--rw-------   0 root         (0) root         (0)      310 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/inception.py
--rw-------   0 root         (0) root         (0)      199 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/mobilenet.py
--rw-------   0 root         (0) root         (0)      301 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/mobilenetv2.py
--rw-------   0 root         (0) root         (0)      314 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/mobilenetv3.py
--rw-------   0 root         (0) root         (0)      529 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/resnet.py
--rw-------   0 root         (0) root         (0)      713 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/quantization/shufflenetv2.py
--rw-------   0 root         (0) root         (0)    15407 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/resnet.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.301028 mindtorch-0.2.1/mindtorch/torchvision/models/segmentation/
--rw-------   0 root         (0) root         (0)       94 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/segmentation/__init__.py
--rw-------   0 root         (0) root         (0)     1047 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/segmentation/_utils.py
--rw-------   0 root         (0) root         (0)     3032 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/segmentation/deeplabv3.py
--rw-------   0 root         (0) root         (0)     1169 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/segmentation/fcn.py
--rw-------   0 root         (0) root         (0)     2511 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/segmentation/lraspp.py
--rw-------   0 root         (0) root         (0)     8968 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/segmentation/segmentation.py
--rw-------   0 root         (0) root         (0)     8536 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/shufflenetv2.py
--rw-------   0 root         (0) root         (0)     5841 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/squeezenet.py
--rw-------   0 root         (0) root         (0)     6814 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/utils.py
--rw-------   0 root         (0) root         (0)     7771 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/vgg.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.305028 mindtorch-0.2.1/mindtorch/torchvision/models/video/
--rw-------   0 root         (0) root         (0)       22 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/video/__init__.py
--rw-------   0 root         (0) root         (0)    11072 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/models/video/resnet.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.309028 mindtorch-0.2.1/mindtorch/torchvision/ops/
--rw-------   0 root         (0) root         (0)     1896 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/__init__.py
--rw-------   0 root         (0) root         (0)     2436 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/_box_convert.py
--rw-------   0 root         (0) root         (0)     3996 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/_utils.py
--rw-------   0 root         (0) root         (0)    15504 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/boxes.py
--rw-------   0 root         (0) root         (0)     2678 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/ciou_loss.py
--rw-------   0 root         (0) root         (0)     7977 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/deform_conv.py
--rw-------   0 root         (0) root         (0)     3100 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/diou_loss.py
--rw-------   0 root         (0) root         (0)     6024 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/drop_block.py
--rw-------   0 root         (0) root         (0)     8551 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/feature_pyramid_network.py
--rw-------   0 root         (0) root         (0)     1992 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/focal_loss.py
--rw-------   0 root         (0) root         (0)     2435 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/giou_loss.py
--rw-------   0 root         (0) root         (0)    12092 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/misc.py
--rw-------   0 root         (0) root         (0)    11954 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/poolers.py
--rw-------   0 root         (0) root         (0)     3378 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/ps_roi_align.py
--rw-------   0 root         (0) root         (0)     3068 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/ps_roi_pool.py
--rw-------   0 root         (0) root         (0)     5012 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/roi_align.py
--rw-------   0 root         (0) root         (0)     2576 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/roi_pool.py
--rw-------   0 root         (0) root         (0)     2024 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/ops/stochastic_depth.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.313028 mindtorch-0.2.1/mindtorch/torchvision/transforms/
--rw-------   0 root         (0) root         (0)       53 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/__init__.py
--rw-------   0 root         (0) root         (0)     4005 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/_functional_video.py
--rw-------   0 root         (0) root         (0)      818 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/_pil_constants.py
--rw-------   0 root         (0) root         (0)     8082 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/_presets.py
--rw-------   0 root         (0) root         (0)     5101 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/_transforms_video.py
--rw-------   0 root         (0) root         (0)    29394 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/autoaugment.py
--rw-------   0 root         (0) root         (0)    67471 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/functional.py
--rw-------   0 root         (0) root         (0)    13228 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/functional_pil.py
--rw-------   0 root         (0) root         (0)    37528 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/functional_tensor.py
--rw-------   0 root         (0) root         (0)    95842 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/torchvision/transforms/transforms.py
--rw-------   0 root         (0) root         (0)    20468 2024-02-01 07:54:56.000000 mindtorch-0.2.1/mindtorch/torchvision/utils.py
--rw-------   0 root         (0) root         (0)     6312 2024-02-01 07:56:16.000000 mindtorch-0.2.1/mindtorch/utils.py
-drwx------   0 root         (0) root         (0)        0 2024-02-01 07:56:59.145025 mindtorch-0.2.1/mindtorch.egg-info/
--rw-r--r--   0 root         (0) root         (0)     4147 2024-02-01 07:56:59.000000 mindtorch-0.2.1/mindtorch.egg-info/PKG-INFO
--rw-------   0 root         (0) root         (0)    16594 2024-02-01 07:56:59.000000 mindtorch-0.2.1/mindtorch.egg-info/SOURCES.txt
--rw-------   0 root         (0) root         (0)        1 2024-02-01 07:56:59.000000 mindtorch-0.2.1/mindtorch.egg-info/dependency_links.txt
--rw-------   0 root         (0) root         (0)       10 2024-02-01 07:56:59.000000 mindtorch-0.2.1/mindtorch.egg-info/top_level.txt
--rw-------   0 root         (0) root         (0)       38 2024-02-01 07:56:59.313028 mindtorch-0.2.1/setup.cfg
--rw-------   0 root         (0) root         (0)     3161 2024-02-01 07:56:16.000000 mindtorch-0.2.1/setup.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.538154 mindtorch-0.3.0/
+-rw-------   0 root         (0) root         (0)    11438 2024-04-29 00:52:43.000000 mindtorch-0.3.0/LICENSE
+-rw-r--r--   0 root         (0) root         (0)     4028 2024-04-29 01:30:08.538154 mindtorch-0.3.0/PKG-INFO
+-rw-------   0 root         (0) root         (0)     2845 2024-04-29 00:52:43.000000 mindtorch-0.3.0/README.rst
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.338152 mindtorch-0.3.0/mindtorch/
+-rw-------   0 root         (0) root         (0)      449 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/__init__.py
+-rw-------   0 root         (0) root         (0)     6786 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/module_hooker.py
+-rw-------   0 root         (0) root         (0)      285 2024-04-29 00:54:02.000000 mindtorch-0.3.0/mindtorch/package_info.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.342151 mindtorch-0.3.0/mindtorch/tools/
+-rw-------   0 root         (0) root         (0)      173 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/tools/__init__.py
+-rw-------   0 root         (0) root         (0)     3281 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/tools/convert_tensor.py
+-rw-------   0 root         (0) root         (0)     5672 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/tools/debug_layer_info.py
+-rw-------   0 root         (0) root         (0)       68 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/tools/mstorch_enable.py
+-rw-------   0 root         (0) root         (0)     1293 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/tools/pth2ckpt.py
+-rw-------   0 root         (0) root         (0)       66 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/tools/pytorch_enable.py
+-rw-------   0 root         (0) root         (0)    16214 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/tools/support_wrap_ops.yaml
+-rw-------   0 root         (0) root         (0)      734 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/tools/utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.350152 mindtorch-0.3.0/mindtorch/torch/
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.350152 mindtorch-0.3.0/mindtorch/torch/_C/
+-rw-------   0 root         (0) root         (0)     2606 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_C/Generator.py
+-rw-------   0 root         (0) root         (0)      603 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_C/Size.py
+-rw-------   0 root         (0) root         (0)     1749 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_C/__init__.py
+-rw-------   0 root         (0) root         (0)     3629 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/__init__.py
+-rw-------   0 root         (0) root         (0)     1234 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_default_dtype.py
+-rw-------   0 root         (0) root         (0)     9049 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_export_func_to_root.py
+-rw-------   0 root         (0) root         (0)     1105 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_patch_func.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.350152 mindtorch-0.3.0/mindtorch/torch/_ref/
+-rw-------   0 root         (0) root         (0)      595 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_ref/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/_register/
+-rw-------   0 root         (0) root         (0)     4005 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_register/__init__.py
+-rw-------   0 root         (0) root         (0)     1522 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_register/getitem_impl.py
+-rw-------   0 root         (0) root         (0)     6761 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_register/register_multitype_ops.py
+-rw-------   0 root         (0) root         (0)     4804 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_register/register_standard_method.py
+-rw-------   0 root         (0) root         (0)     8241 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_register/register_utils.py
+-rw-------   0 root         (0) root         (0)     7554 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_register_numpy_primitive.py
+-rw-------   0 root         (0) root         (0)       30 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_six.py
+-rw-------   0 root         (0) root         (0)      717 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_tensor.py
+-rw-------   0 root         (0) root         (0)     7965 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/_utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/amp/
+-rw-------   0 root         (0) root         (0)     3850 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/amp/__init__.py
+-rw-------   0 root         (0) root         (0)      925 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/amp/autocast_mode.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/autograd/
+-rw-------   0 root         (0) root         (0)      372 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/autograd/__init__.py
+-rw-------   0 root         (0) root         (0)     4641 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/autograd/function.py
+-rw-------   0 root         (0) root         (0)     3019 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/autograd/functional.py
+-rw-------   0 root         (0) root         (0)     3396 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/autograd/grad_mode.py
+-rw-------   0 root         (0) root         (0)      810 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/autograd/variable.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/backends/
+-rw-------   0 root         (0) root         (0)     1577 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/backends/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/backends/cuda/
+-rw-------   0 root         (0) root         (0)      692 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/backends/cuda/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/backends/cudnn/
+-rw-------   0 root         (0) root         (0)     3065 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/backends/cudnn/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/backends/mkl/
+-rw-------   0 root         (0) root         (0)      155 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/backends/mkl/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/backends/mkldnn/
+-rw-------   0 root         (0) root         (0)      159 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/backends/mkldnn/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.354152 mindtorch-0.3.0/mindtorch/torch/backends/mps/
+-rw-------   0 root         (0) root         (0)      313 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/backends/mps/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.358152 mindtorch-0.3.0/mindtorch/torch/backends/openmp/
+-rw-------   0 root         (0) root         (0)      170 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/backends/openmp/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.358152 mindtorch-0.3.0/mindtorch/torch/common/
+-rw-------   0 root         (0) root         (0)      611 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/common/__init__.py
+-rw-------   0 root         (0) root         (0)     6295 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/common/_inner.py
+-rw-------   0 root         (0) root         (0)     8127 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/common/dtype.py
+-rw-------   0 root         (0) root         (0)     1565 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/conflict_functional.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.358152 mindtorch-0.3.0/mindtorch/torch/cpu/
+-rw-------   0 root         (0) root         (0)       84 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cpu/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.358152 mindtorch-0.3.0/mindtorch/torch/cpu/amp/
+-rw-------   0 root         (0) root         (0)       82 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cpu/amp/__init__.py
+-rw-------   0 root         (0) root         (0)      364 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cpu/amp/autocast_mode.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.358152 mindtorch-0.3.0/mindtorch/torch/cuda/
+-rw-------   0 root         (0) root         (0)     6071 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cuda/__init__.py
+-rw-------   0 root         (0) root         (0)      838 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cuda/_utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.362152 mindtorch-0.3.0/mindtorch/torch/cuda/amp/
+-rw-------   0 root         (0) root         (0)      143 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cuda/amp/__init__.py
+-rw-------   0 root         (0) root         (0)     1389 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cuda/amp/autocast_mode.py
+-rw-------   0 root         (0) root         (0)    11966 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cuda/amp/grad_scaler.py
+-rw-------   0 root         (0) root         (0)     1878 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cuda/memory.py
+-rw-------   0 root         (0) root         (0)      454 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cuda/random.py
+-rw-------   0 root         (0) root         (0)     1471 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/cuda/streams.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.362152 mindtorch-0.3.0/mindtorch/torch/distributed/
+-rw-------   0 root         (0) root         (0)      185 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/__init__.py
+-rw-------   0 root         (0) root         (0)    14286 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/_distributed_c10d.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.362152 mindtorch-0.3.0/mindtorch/torch/distributed/_tensor/
+-rw-------   0 root         (0) root         (0)       36 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/_tensor/__init__.py
+-rw-------   0 root         (0) root         (0)     8125 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/_tensor/device_mesh.py
+-rw-------   0 root         (0) root         (0)    10111 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/_tensor/placement_type.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.362152 mindtorch-0.3.0/mindtorch/torch/distributed/algorithms/
+-rw-------   0 root         (0) root         (0)       77 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/algorithms/__init__.py
+-rw-------   0 root         (0) root         (0)     1575 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/algorithms/join.py
+-rw-------   0 root         (0) root         (0)    33990 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/distributed_c10d.py
+-rw-------   0 root         (0) root         (0)     1089 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/distributed/utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.362152 mindtorch-0.3.0/mindtorch/torch/fft/
+-rw-------   0 root         (0) root         (0)      104 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/fft/__init__.py
+-rw-------   0 root         (0) root         (0)      685 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/fft/fft.py
+-rw-------   0 root         (0) root         (0)   122122 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/functional.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.366152 mindtorch-0.3.0/mindtorch/torch/fx/
+-rw-------   0 root         (0) root         (0)       71 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/fx/__init__.py
+-rw-------   0 root         (0) root         (0)      523 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/fx/proxy.py
+-rw-------   0 root         (0) root         (0)    17935 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/hub.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.366152 mindtorch-0.3.0/mindtorch/torch/jit/
+-rw-------   0 root         (0) root         (0)     1270 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/jit/__init__.py
+-rw-------   0 root         (0) root         (0)      306 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/jit/_jit_internal.py
+-rw-------   0 root         (0) root         (0)      936 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/library.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.366152 mindtorch-0.3.0/mindtorch/torch/linalg/
+-rw-------   0 root         (0) root         (0)      635 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/linalg/__init__.py
+-rw-------   0 root         (0) root         (0)    13092 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/linalg/linalg.py
+-rw-------   0 root         (0) root         (0)     2211 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/logging.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.366152 mindtorch-0.3.0/mindtorch/torch/multiprocessing/
+-rw-------   0 root         (0) root         (0)     1393 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/multiprocessing/__init__.py
+-rw-------   0 root         (0) root         (0)     7099 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/multiprocessing/spawn.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.366152 mindtorch-0.3.0/mindtorch/torch/nn/
+-rw-------   0 root         (0) root         (0)      275 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/__init__.py
+-rw-------   0 root         (0) root         (0)   111177 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/functional.py
+-rw-------   0 root         (0) root         (0)     8254 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/init.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.378152 mindtorch-0.3.0/mindtorch/torch/nn/modules/
+-rw-------   0 root         (0) root         (0)     3714 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/__init__.py
+-rw-------   0 root         (0) root         (0)    21586 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/activation.py
+-rw-------   0 root         (0) root         (0)     6875 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/adaptive.py
+-rw-------   0 root         (0) root         (0)    17050 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/batchnorm.py
+-rw-------   0 root         (0) root         (0)     1735 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/channelshuffle.py
+-rw-------   0 root         (0) root         (0)    37856 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/container.py
+-rw-------   0 root         (0) root         (0)    33867 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/conv.py
+-rw-------   0 root         (0) root         (0)      802 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/distance.py
+-rw-------   0 root         (0) root         (0)     7483 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/dropout.py
+-rw-------   0 root         (0) root         (0)     1106 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/flatten.py
+-rw-------   0 root         (0) root         (0)     1424 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/fold.py
+-rw-------   0 root         (0) root         (0)     3824 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/instancenorm.py
+-rw-------   0 root         (0) root         (0)     4000 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/lazy.py
+-rw-------   0 root         (0) root         (0)     6721 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/linear.py
+-rw-------   0 root         (0) root         (0)    11068 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/loss.py
+-rw-------   0 root         (0) root         (0)    44980 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/module.py
+-rw-------   0 root         (0) root         (0)     5200 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/normalization.py
+-rw-------   0 root         (0) root         (0)    11325 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/padding.py
+-rw-------   0 root         (0) root         (0)      878 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/pixelshuffle.py
+-rw-------   0 root         (0) root         (0)     8778 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/pooling.py
+-rw-------   0 root         (0) root         (0)    37705 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/rnn.py
+-rw-------   0 root         (0) root         (0)     3574 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/sparse.py
+-rw-------   0 root         (0) root         (0)    12766 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/transformer.py
+-rw-------   0 root         (0) root         (0)     1348 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/unpooling.py
+-rw-------   0 root         (0) root         (0)     3407 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/upsampling.py
+-rw-------   0 root         (0) root         (0)     3362 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/modules/utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.378152 mindtorch-0.3.0/mindtorch/torch/nn/parallel/
+-rw-------   0 root         (0) root         (0)      154 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/parallel/__init__.py
+-rw-------   0 root         (0) root         (0)      365 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/parallel/_functions.py
+-rw-------   0 root         (0) root         (0)      447 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/parallel/data_parallel.py
+-rw-------   0 root         (0) root         (0)     4245 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/parallel/distributed.py
+-rw-------   0 root         (0) root         (0)    13749 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/parameter.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.378152 mindtorch-0.3.0/mindtorch/torch/nn/quantized/
+-rw-------   0 root         (0) root         (0)       23 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/quantized/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.378152 mindtorch-0.3.0/mindtorch/torch/nn/quantized/modules/
+-rw-------   0 root         (0) root         (0)       67 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/quantized/modules/__init__.py
+-rw-------   0 root         (0) root         (0)     2203 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/quantized/modules/functional_modules.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.382152 mindtorch-0.3.0/mindtorch/torch/nn/utils/
+-rw-------   0 root         (0) root         (0)      328 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/__init__.py
+-rw-------   0 root         (0) root         (0)     5246 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/clip_grad.py
+-rw-------   0 root         (0) root         (0)     2068 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/convert_parameters.py
+-rw-------   0 root         (0) root         (0)      517 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/init.py
+-rw-------   0 root         (0) root         (0)     9660 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/parametrizations.py
+-rw-------   0 root         (0) root         (0)    16335 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/parametrize.py
+-rw-------   0 root         (0) root         (0)    11913 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/rnn.py
+-rw-------   0 root         (0) root         (0)     7641 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/spectral_norm.py
+-rw-------   0 root         (0) root         (0)     3138 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/stateless.py
+-rw-------   0 root         (0) root         (0)     3379 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/nn/utils/weight_norm.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.386152 mindtorch-0.3.0/mindtorch/torch/optim/
+-rw-------   0 root         (0) root         (0)      864 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/__init__.py
+-rw-------   0 root         (0) root         (0)     5208 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/_adamw.py
+-rw-------   0 root         (0) root         (0)      874 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/adadelta.py
+-rw-------   0 root         (0) root         (0)      945 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/adagrad.py
+-rw-------   0 root         (0) root         (0)     1136 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/adam.py
+-rw-------   0 root         (0) root         (0)      971 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/adamax.py
+-rw-------   0 root         (0) root         (0)     1110 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/adamw.py
+-rw-------   0 root         (0) root         (0)      974 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/asgd.py
+-rw-------   0 root         (0) root         (0)    23643 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/lr_scheduler.py
+-rw-------   0 root         (0) root         (0)      974 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/nadam.py
+-rw-------   0 root         (0) root         (0)    13405 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/optimizer.py
+-rw-------   0 root         (0) root         (0)      898 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/radam.py
+-rw-------   0 root         (0) root         (0)     1022 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/rmsprop.py
+-rw-------   0 root         (0) root         (0)      903 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/rprop.py
+-rw-------   0 root         (0) root         (0)     1612 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/optim/sgd.py
+-rw-------   0 root         (0) root         (0)      147 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/overrides.py
+-rw-------   0 root         (0) root         (0)      246 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/random.py
+-rw-------   0 root         (0) root         (0)    32320 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/serialization.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.386152 mindtorch-0.3.0/mindtorch/torch/special/
+-rw-------   0 root         (0) root         (0)      351 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/special/__init__.py
+-rw-------   0 root         (0) root         (0)    32055 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/storage.py
+-rw-------   0 root         (0) root         (0)   179875 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/tensor.py
+-rw-------   0 root         (0) root         (0)      243 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/tensor_type.py
+-rw-------   0 root         (0) root         (0)      959 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/torch_version.py
+-rw-------   0 root         (0) root         (0)     2542 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/types.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.390152 mindtorch-0.3.0/mindtorch/torch/utils/
+-rw-------   0 root         (0) root         (0)       90 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/__init__.py
+-rw-------   0 root         (0) root         (0)     6353 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/_pytree.py
+-rw-------   0 root         (0) root         (0)     2217 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/checkpoint.py
+-rw-------   0 root         (0) root         (0)      649 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/cpp_extension.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.390152 mindtorch-0.3.0/mindtorch/torch/utils/data/
+-rw-------   0 root         (0) root         (0)     1762 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.394152 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/
+-rw-------   0 root         (0) root         (0)     1829 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/__init__.py
+-rw-------   0 root         (0) root         (0)    16397 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/collate.py
+-rw-------   0 root         (0) root         (0)     1926 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/fetch.py
+-rw-------   0 root         (0) root         (0)     2701 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/pin_memory.py
+-rw-------   0 root         (0) root         (0)     8691 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/queue.py
+-rw-------   0 root         (0) root         (0)      435 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/serialization.py
+-rw-------   0 root         (0) root         (0)     3601 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/signal_handling.py
+-rw-------   0 root         (0) root         (0)    13620 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/worker.py
+-rw-------   0 root         (0) root         (0)      230 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/backward_compatibility.py
+-rw-------   0 root         (0) root         (0)    54845 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/dataloader.py
+-rw-------   0 root         (0) root         (0)     7174 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/dataloader_experimental.py
+-rw-------   0 root         (0) root         (0)    13820 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/dataset.py
+-rw-------   0 root         (0) root         (0)     6318 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/distributed.py
+-rw-------   0 root         (0) root         (0)     3141 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/graph.py
+-rw-------   0 root         (0) root         (0)     2679 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/graph_settings.py
+-rw-------   0 root         (0) root         (0)    10759 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/data/sampler.py
+-rw-------   0 root         (0) root         (0)     7301 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/hooks.py
+-rw-------   0 root         (0) root         (0)      121 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torch/utils/model_zoo.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.394152 mindtorch-0.3.0/mindtorch/torchaudio/
+-rw-------   0 root         (0) root         (0)      655 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/__init__.py
+-rw-------   0 root         (0) root         (0)     3745 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/_extension.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.394152 mindtorch-0.3.0/mindtorch/torchaudio/_internal/
+-rw-------   0 root         (0) root         (0)      131 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/_internal/__init__.py
+-rw-------   0 root         (0) root         (0)     4178 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/_internal/module_utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.398152 mindtorch-0.3.0/mindtorch/torchaudio/backend/
+-rw-------   0 root         (0) root         (0)      112 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/backend/__init__.py
+-rw-------   0 root         (0) root         (0)     1896 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/backend/common.py
+-rw-------   0 root         (0) root         (0)      721 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/backend/no_backend.py
+-rw-------   0 root         (0) root         (0)    16736 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/backend/soundfile_backend.py
+-rw-------   0 root         (0) root         (0)    14497 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/backend/sox_io_backend.py
+-rw-------   0 root         (0) root         (0)     2659 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/backend/utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.398152 mindtorch-0.3.0/mindtorch/torchaudio/compliance/
+-rw-------   0 root         (0) root         (0)       48 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/compliance/__init__.py
+-rw-------   0 root         (0) root         (0)    38330 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/compliance/kaldi.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.402152 mindtorch-0.3.0/mindtorch/torchaudio/datasets/
+-rw-------   0 root         (0) root         (0)      757 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/__init__.py
+-rw-------   0 root         (0) root         (0)     7043 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/cmuarctic.py
+-rw-------   0 root         (0) root         (0)     6207 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/cmudict.py
+-rw-------   0 root         (0) root         (0)     2523 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/commonvoice.py
+-rw-------   0 root         (0) root         (0)     4212 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/dr_vctk.py
+-rw-------   0 root         (0) root         (0)    24156 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/gtzan.py
+-rw-------   0 root         (0) root         (0)     3623 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/librilight_limited.py
+-rw-------   0 root         (0) root         (0)     3546 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/librimix.py
+-rw-------   0 root         (0) root         (0)     5304 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/librispeech.py
+-rw-------   0 root         (0) root         (0)     5752 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/libritts.py
+-rw-------   0 root         (0) root         (0)     3452 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/ljspeech.py
+-rw-------   0 root         (0) root         (0)     3778 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/quesst14.py
+-rw-------   0 root         (0) root         (0)     6653 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/speechcommands.py
+-rw-------   0 root         (0) root         (0)     8578 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/tedlium.py
+-rw-------   0 root         (0) root         (0)     6779 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/utils.py
+-rw-------   0 root         (0) root         (0)     5624 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/vctk.py
+-rw-------   0 root         (0) root         (0)     2998 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/datasets/yesno.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.406153 mindtorch-0.3.0/mindtorch/torchaudio/functional/
+-rw-------   0 root         (0) root         (0)     2026 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/functional/__init__.py
+-rw-------   0 root         (0) root         (0)    64313 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/functional/filtering.py
+-rw-------   0 root         (0) root         (0)    86495 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/functional/functional.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.406153 mindtorch-0.3.0/mindtorch/torchaudio/io/
+-rw-------   0 root         (0) root         (0)      641 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/io/__init__.py
+-rw-------   0 root         (0) root         (0)     3637 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/io/_compat.py
+-rw-------   0 root         (0) root         (0)    25906 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/io/_stream_reader.py
+-rw-------   0 root         (0) root         (0)     5222 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/kaldi_io.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.410153 mindtorch-0.3.0/mindtorch/torchaudio/models/
+-rw-------   0 root         (0) root         (0)     1327 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/__init__.py
+-rw-------   0 root         (0) root         (0)    10605 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/conformer.py
+-rw-------   0 root         (0) root         (0)    12208 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/conv_tasnet.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.410153 mindtorch-0.3.0/mindtorch/torchaudio/models/decoder/
+-rw-------   0 root         (0) root         (0)      995 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/decoder/__init__.py
+-rw-------   0 root         (0) root         (0)    12886 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/decoder/_ctc_decoder.py
+-rw-------   0 root         (0) root         (0)     2914 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/deepspeech.py
+-rw-------   0 root         (0) root         (0)    39064 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/emformer.py
+-rw-------   0 root         (0) root         (0)    36957 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/rnnt.py
+-rw-------   0 root         (0) root         (0)    13413 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/rnnt_decoder.py
+-rw-------   0 root         (0) root         (0)    47711 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/tacotron2.py
+-rw-------   0 root         (0) root         (0)     3386 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2letter.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.410153 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/
+-rw-------   0 root         (0) root         (0)      744 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/__init__.py
+-rw-------   0 root         (0) root         (0)    43518 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/components.py
+-rw-------   0 root         (0) root         (0)    52285 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/model.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.410153 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/utils/
+-rw-------   0 root         (0) root         (0)      194 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/utils/__init__.py
+-rw-------   0 root         (0) root         (0)     9764 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/utils/import_fairseq.py
+-rw-------   0 root         (0) root         (0)     3231 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/utils/import_huggingface.py
+-rw-------   0 root         (0) root         (0)    15831 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/models/wavernn.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.410153 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/
+-rw-------   0 root         (0) root         (0)     2068 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.414153 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_tts/
+-rw-------   0 root         (0) root         (0)      456 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_tts/__init__.py
+-rw-------   0 root         (0) root         (0)    16367 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_tts/impl.py
+-rw-------   0 root         (0) root         (0)    11677 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_tts/interface.py
+-rw-------   0 root         (0) root         (0)     5055 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_tts/utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.414153 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_wav2vec2/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_wav2vec2/__init__.py
+-rw-------   0 root         (0) root         (0)    49158 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_wav2vec2/impl.py
+-rw-------   0 root         (0) root         (0)     3310 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_wav2vec2/utils.py
+-rw-------   0 root         (0) root         (0)    14313 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/pipelines/rnnt_pipeline.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.414153 mindtorch-0.3.0/mindtorch/torchaudio/sox_effects/
+-rw-------   0 root         (0) root         (0)      510 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/sox_effects/__init__.py
+-rw-------   0 root         (0) root         (0)    12395 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/sox_effects/sox_effects.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.414153 mindtorch-0.3.0/mindtorch/torchaudio/transforms/
+-rw-------   0 root         (0) root         (0)      966 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/transforms/__init__.py
+-rw-------   0 root         (0) root         (0)    22249 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/transforms/_multi_channel.py
+-rw-------   0 root         (0) root         (0)    89668 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/transforms/_transforms.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.418153 mindtorch-0.3.0/mindtorch/torchaudio/utils/
+-rw-------   0 root         (0) root         (0)      299 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/utils/__init__.py
+-rw-------   0 root         (0) root         (0)     2997 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/utils/download.py
+-rw-------   0 root         (0) root         (0)     1788 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/utils/ffmpeg_utils.py
+-rw-------   0 root         (0) root         (0)     2821 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchaudio/utils/sox_utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.418153 mindtorch-0.3.0/mindtorch/torchvision/
+-rw-------   0 root         (0) root         (0)     2832 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/__init__.py
+-rw-------   0 root         (0) root         (0)     2063 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/_internally_replaced_utils.py
+-rw-------   0 root         (0) root         (0)      934 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/_utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.430153 mindtorch-0.3.0/mindtorch/torchvision/datasets/
+-rw-------   0 root         (0) root         (0)     2554 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/__init__.py
+-rw-------   0 root         (0) root         (0)    18841 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/_optical_flow.py
+-rw-------   0 root         (0) root         (0)     9296 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/caltech.py
+-rw-------   0 root         (0) root         (0)     9630 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/celeba.py
+-rw-------   0 root         (0) root         (0)     5851 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/cifar.py
+-rw-------   0 root         (0) root         (0)    10237 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/cityscapes.py
+-rw-------   0 root         (0) root         (0)     3416 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/clevr.py
+-rw-------   0 root         (0) root         (0)     3972 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/coco.py
+-rw-------   0 root         (0) root         (0)     2408 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/country211.py
+-rw-------   0 root         (0) root         (0)     3939 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/dtd.py
+-rw-------   0 root         (0) root         (0)     2053 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/eurosat.py
+-rw-------   0 root         (0) root         (0)     2606 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/fakedata.py
+-rw-------   0 root         (0) root         (0)     2781 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/fer2013.py
+-rw-------   0 root         (0) root         (0)     4561 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/fgvc_aircraft.py
+-rw-------   0 root         (0) root         (0)     5339 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/flickr.py
+-rw-------   0 root         (0) root         (0)     4600 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/flowers102.py
+-rw-------   0 root         (0) root         (0)    11938 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/folder.py
+-rw-------   0 root         (0) root         (0)     3713 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/food101.py
+-rw-------   0 root         (0) root         (0)     3742 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/gtsrb.py
+-rw-------   0 root         (0) root         (0)     5855 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/hmdb51.py
+-rw-------   0 root         (0) root         (0)     8449 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/imagenet.py
+-rw-------   0 root         (0) root         (0)    10107 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/inaturalist.py
+-rw-------   0 root         (0) root         (0)    13406 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/kinetics.py
+-rw-------   0 root         (0) root         (0)     5600 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/kitti.py
+-rw-------   0 root         (0) root         (0)    10282 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/lfw.py
+-rw-------   0 root         (0) root         (0)     5675 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/lsun.py
+-rw-------   0 root         (0) root         (0)    21322 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/mnist.py
+-rw-------   0 root         (0) root         (0)     4091 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/omniglot.py
+-rw-------   0 root         (0) root         (0)     5071 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/oxford_iiit_pet.py
+-rw-------   0 root         (0) root         (0)     5385 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/pcam.py
+-rw-------   0 root         (0) root         (0)     8279 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/phototour.py
+-rw-------   0 root         (0) root         (0)     7201 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/places365.py
+-rw-------   0 root         (0) root         (0)     3557 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/rendered_sst2.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.434153 mindtorch-0.3.0/mindtorch/torchvision/datasets/samplers/
+-rw-------   0 root         (0) root         (0)      161 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/samplers/__init__.py
+-rw-------   0 root         (0) root         (0)     6528 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/samplers/clip_sampler.py
+-rw-------   0 root         (0) root         (0)     5202 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/sbd.py
+-rw-------   0 root         (0) root         (0)     4203 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/sbu.py
+-rw-------   0 root         (0) root         (0)     3088 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/semeion.py
+-rw-------   0 root         (0) root         (0)     4843 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/stanford_cars.py
+-rw-------   0 root         (0) root         (0)     7294 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/stl10.py
+-rw-------   0 root         (0) root         (0)     2743 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/sun397.py
+-rw-------   0 root         (0) root         (0)     4766 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/svhn.py
+-rw-------   0 root         (0) root         (0)     5417 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/ucf101.py
+-rw-------   0 root         (0) root         (0)     3440 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/usps.py
+-rw-------   0 root         (0) root         (0)    17257 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/utils.py
+-rw-------   0 root         (0) root         (0)    17193 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/video_utils.py
+-rw-------   0 root         (0) root         (0)     4216 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/vision.py
+-rw-------   0 root         (0) root         (0)     9343 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/voc.py
+-rw-------   0 root         (0) root         (0)     8307 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/datasets/widerface.py
+-rw-------   0 root         (0) root         (0)     3198 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/extension.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.434153 mindtorch-0.3.0/mindtorch/torchvision/io/
+-rw-------   0 root         (0) root         (0)     1568 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/io/__init__.py
+-rw-------   0 root         (0) root         (0)      216 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/io/_load_gpu_decoder.py
+-rw-------   0 root         (0) root         (0)    19782 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/io/_video_opt.py
+-rw-------   0 root         (0) root         (0)     9944 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/io/image.py
+-rw-------   0 root         (0) root         (0)    15420 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/io/video.py
+-rw-------   0 root         (0) root         (0)     6934 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/io/video_reader.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.442153 mindtorch-0.3.0/mindtorch/torchvision/models/
+-rw-------   0 root         (0) root         (0)      581 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/__init__.py
+-rw-------   0 root         (0) root         (0)     3260 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/_api.py
+-rw-------   0 root         (0) root         (0)    28875 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/_meta.py
+-rw-------   0 root         (0) root         (0)    10865 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/_utils.py
+-rw-------   0 root         (0) root         (0)     4642 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/alexnet.py
+-rw-------   0 root         (0) root         (0)    15012 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/convnext.py
+-rw-------   0 root         (0) root         (0)    16963 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/densenet.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.446153 mindtorch-0.3.0/mindtorch/torchvision/models/detection/
+-rw-------   0 root         (0) root         (0)      168 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/__init__.py
+-rw-------   0 root         (0) root         (0)    22084 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/_utils.py
+-rw-------   0 root         (0) root         (0)    11851 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/anchor_utils.py
+-rw-------   0 root         (0) root         (0)    10494 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/backbone_utils.py
+-rw-------   0 root         (0) root         (0)    36683 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/faster_rcnn.py
+-rw-------   0 root         (0) root         (0)    34370 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/fcos.py
+-rw-------   0 root         (0) root         (0)     4772 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/generalized_rcnn.py
+-rw-------   0 root         (0) root         (0)      812 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/image_list.py
+-rw-------   0 root         (0) root         (0)    22041 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/keypoint_rcnn.py
+-rw-------   0 root         (0) root         (0)    26358 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/mask_rcnn.py
+-rw-------   0 root         (0) root         (0)    36894 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/retinanet.py
+-rw-------   0 root         (0) root         (0)    33945 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/roi_heads.py
+-rw-------   0 root         (0) root         (0)    15877 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/rpn.py
+-rw-------   0 root         (0) root         (0)    29553 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/ssd.py
+-rw-------   0 root         (0) root         (0)    13299 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/ssdlite.py
+-rw-------   0 root         (0) root         (0)    12029 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/detection/transform.py
+-rw-------   0 root         (0) root         (0)    42918 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/efficientnet.py
+-rw-------   0 root         (0) root         (0)    12904 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/googlenet.py
+-rw-------   0 root         (0) root         (0)    18951 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/inception.py
+-rw-------   0 root         (0) root         (0)    17215 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/mnasnet.py
+-rw-------   0 root         (0) root         (0)      210 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/mobilenet.py
+-rw-------   0 root         (0) root         (0)    10417 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/mobilenetv2.py
+-rw-------   0 root         (0) root         (0)    16899 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/mobilenetv3.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.446153 mindtorch-0.3.0/mindtorch/torchvision/models/optical_flow/
+-rw-------   0 root         (0) root         (0)       20 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/optical_flow/__init__.py
+-rw-------   0 root         (0) root         (0)     1837 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/optical_flow/_utils.py
+-rw-------   0 root         (0) root         (0)    38258 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/optical_flow/raft.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.450153 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/
+-rw-------   0 root         (0) root         (0)      125 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/__init__.py
+-rw-------   0 root         (0) root         (0)     1552 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/googlenet.py
+-rw-------   0 root         (0) root         (0)     1600 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/inception.py
+-rw-------   0 root         (0) root         (0)      211 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/mobilenet.py
+-rw-------   0 root         (0) root         (0)     1567 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/mobilenetv2.py
+-rw-------   0 root         (0) root         (0)     1609 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/mobilenetv3.py
+-rw-------   0 root         (0) root         (0)     5080 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/resnet.py
+-rw-------   0 root         (0) root         (0)     4276 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/quantization/shufflenetv2.py
+-rw-------   0 root         (0) root         (0)    63119 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/regnet.py
+-rw-------   0 root         (0) root         (0)    38294 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/resnet.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.450153 mindtorch-0.3.0/mindtorch/torchvision/models/segmentation/
+-rw-------   0 root         (0) root         (0)       65 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/segmentation/__init__.py
+-rw-------   0 root         (0) root         (0)     1141 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/segmentation/_utils.py
+-rw-------   0 root         (0) root         (0)    15066 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/segmentation/deeplabv3.py
+-rw-------   0 root         (0) root         (0)     9036 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/segmentation/fcn.py
+-rw-------   0 root         (0) root         (0)     7729 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/segmentation/lraspp.py
+-rw-------   0 root         (0) root         (0)      293 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/segmentation/segmentation.py
+-rw-------   0 root         (0) root         (0)    15438 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/shufflenetv2.py
+-rw-------   0 root         (0) root         (0)     8837 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/squeezenet.py
+-rw-------   0 root         (0) root         (0)    23259 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/swin_transformer.py
+-rw-------   0 root         (0) root         (0)    19029 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/vgg.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.454153 mindtorch-0.3.0/mindtorch/torchvision/models/video/
+-rw-------   0 root         (0) root         (0)       22 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/video/__init__.py
+-rw-------   0 root         (0) root         (0)    16406 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/video/resnet.py
+-rw-------   0 root         (0) root         (0)    31593 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/models/vision_transformer.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.458153 mindtorch-0.3.0/mindtorch/torchvision/ops/
+-rw-------   0 root         (0) root         (0)     1896 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/__init__.py
+-rw-------   0 root         (0) root         (0)     2436 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/_box_convert.py
+-rw-------   0 root         (0) root         (0)     3996 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/_utils.py
+-rw-------   0 root         (0) root         (0)    15504 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/boxes.py
+-rw-------   0 root         (0) root         (0)     2678 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/ciou_loss.py
+-rw-------   0 root         (0) root         (0)     7939 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/deform_conv.py
+-rw-------   0 root         (0) root         (0)     3100 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/diou_loss.py
+-rw-------   0 root         (0) root         (0)     6024 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/drop_block.py
+-rw-------   0 root         (0) root         (0)     8551 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/feature_pyramid_network.py
+-rw-------   0 root         (0) root         (0)     1992 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/focal_loss.py
+-rw-------   0 root         (0) root         (0)     2435 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/giou_loss.py
+-rw-------   0 root         (0) root         (0)    12092 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/misc.py
+-rw-------   0 root         (0) root         (0)    11954 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/poolers.py
+-rw-------   0 root         (0) root         (0)     3378 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/ps_roi_align.py
+-rw-------   0 root         (0) root         (0)     3068 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/ps_roi_pool.py
+-rw-------   0 root         (0) root         (0)     5012 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/roi_align.py
+-rw-------   0 root         (0) root         (0)     2576 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/roi_pool.py
+-rw-------   0 root         (0) root         (0)     2024 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/ops/stochastic_depth.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.462153 mindtorch-0.3.0/mindtorch/torchvision/transforms/
+-rw-------   0 root         (0) root         (0)       53 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/__init__.py
+-rw-------   0 root         (0) root         (0)     4005 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/_functional_video.py
+-rw-------   0 root         (0) root         (0)      818 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/_pil_constants.py
+-rw-------   0 root         (0) root         (0)     8082 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/_presets.py
+-rw-------   0 root         (0) root         (0)     5101 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/_transforms_video.py
+-rw-------   0 root         (0) root         (0)    29394 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/autoaugment.py
+-rw-------   0 root         (0) root         (0)    67471 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/functional.py
+-rw-------   0 root         (0) root         (0)    13228 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/functional_pil.py
+-rw-------   0 root         (0) root         (0)    37528 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/functional_tensor.py
+-rw-------   0 root         (0) root         (0)    95846 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/transforms/transforms.py
+-rw-------   0 root         (0) root         (0)    21829 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/torchvision/utils.py
+-rw-------   0 root         (0) root         (0)     7154 2024-04-29 00:52:43.000000 mindtorch-0.3.0/mindtorch/utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.342151 mindtorch-0.3.0/mindtorch.egg-info/
+-rw-r--r--   0 root         (0) root         (0)     4028 2024-04-29 01:30:08.000000 mindtorch-0.3.0/mindtorch.egg-info/PKG-INFO
+-rw-------   0 root         (0) root         (0)    27656 2024-04-29 01:30:08.000000 mindtorch-0.3.0/mindtorch.egg-info/SOURCES.txt
+-rw-------   0 root         (0) root         (0)        1 2024-04-29 01:30:08.000000 mindtorch-0.3.0/mindtorch.egg-info/dependency_links.txt
+-rw-------   0 root         (0) root         (0)      102 2024-04-29 01:30:08.000000 mindtorch-0.3.0/mindtorch.egg-info/requires.txt
+-rw-------   0 root         (0) root         (0)       18 2024-04-29 01:30:08.000000 mindtorch-0.3.0/mindtorch.egg-info/top_level.txt
+-rw-------   0 root         (0) root         (0)       38 2024-04-29 01:30:08.538154 mindtorch-0.3.0/setup.cfg
+-rw-------   0 root         (0) root         (0)     3161 2024-04-29 00:54:02.000000 mindtorch-0.3.0/setup.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.462153 mindtorch-0.3.0/testing/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.462153 mindtorch-0.3.0/testing/st/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.462153 mindtorch-0.3.0/testing/st/pytorch/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.474154 mindtorch-0.3.0/testing/st/pytorch/distributed/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/__init__.py
+-rw-------   0 root         (0) root         (0)      871 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/all_gather_2_group_impl.py
+-rw-------   0 root         (0) root         (0)     1039 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/all_gather_grad_impl.py
+-rw-------   0 root         (0) root         (0)      793 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/all_gather_impl.py
+-rw-------   0 root         (0) root         (0)      782 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/all_gather_into_tensor_2_group_impl.py
+-rw-------   0 root         (0) root         (0)     1052 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/all_gather_into_tensor_impl.py
+-rw-------   0 root         (0) root         (0)     1121 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/all_reduce_dtype_impl.py
+-rw-------   0 root         (0) root         (0)      791 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/all_to_all_impl.py
+-rw-------   0 root         (0) root         (0)      595 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/all_to_all_single_impl.py
+-rw-------   0 root         (0) root         (0)     1280 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/allreduce_2_group_impl.py
+-rw-------   0 root         (0) root         (0)     1425 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/allreduce_grad_impl.py
+-rw-------   0 root         (0) root         (0)      842 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/allreduce_impl.py
+-rw-------   0 root         (0) root         (0)      458 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/barrier_impl.py
+-rw-------   0 root         (0) root         (0)      657 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/broadcast_2_group_impl.py
+-rw-------   0 root         (0) root         (0)      875 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/broadcast_grad_impl.py
+-rw-------   0 root         (0) root         (0)      518 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/broadcast_impl.py
+-rw-------   0 root         (0) root         (0)      836 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/broadcast_impl_ascend_cast_and_async_impl.py
+-rw-------   0 root         (0) root         (0)     1459 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/ddp_impl_ascend.py
+-rw-------   0 root         (0) root         (0)     1459 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/ddp_impl_gpu.py
+-rw-------   0 root         (0) root         (0)      401 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/destroy_process_group_impl.py
+-rw-------   0 root         (0) root         (0)    35276 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/from_torch_c10d_nccl_impl.py
+-rw-------   0 root         (0) root         (0)    31820 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/from_torch_common_impl.py
+-rw-------   0 root         (0) root         (0)     9649 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/from_torch_pg_wrapper_impl.py
+-rw-------   0 root         (0) root         (0)      808 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/gather_2_group_impl.py
+-rw-------   0 root         (0) root         (0)     1086 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/gather_grad_impl.py
+-rw-------   0 root         (0) root         (0)      755 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/gather_impl.py
+-rw-------   0 root         (0) root         (0)      446 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/get_global_rank_impl.py
+-rw-------   0 root         (0) root         (0)      607 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/reduce_impl.py
+-rw-------   0 root         (0) root         (0)      856 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/reduce_scatter_2_group_impl.py
+-rw-------   0 root         (0) root         (0)     1370 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/reduce_scatter_grad_impl.py
+-rw-------   0 root         (0) root         (0)      803 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/reduce_scatter_impl.py
+-rw-------   0 root         (0) root         (0)      775 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/reduce_scatter_tensor_impl.py
+-rw-------   0 root         (0) root         (0)      722 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/scatter_impl.py
+-rw-------   0 root         (0) root         (0)      555 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/send_recv_2_group_impl.py
+-rw-------   0 root         (0) root         (0)      756 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/send_recv_2_tag_impl.py
+-rw-------   0 root         (0) root         (0)      843 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/send_recv_grad_impl.py
+-rw-------   0 root         (0) root         (0)      488 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/send_recv_impl.py
+-rw-------   0 root         (0) root         (0)      828 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/simple_interface_impl.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.474154 mindtorch-0.3.0/testing/st/pytorch/distributed/tensor/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/tensor/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.474154 mindtorch-0.3.0/testing/st/pytorch/distributed/tensor/parallel/
+-rw-------   0 root         (0) root         (0)    18066 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/tensor/parallel/2d_parallel_impl.py
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/tensor/parallel/__init__.py
+-rw-------   0 root         (0) root         (0)      744 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/tensor/parallel/test_tensor_parallel.py
+-rw-------   0 root         (0) root         (0)     1330 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/test_ddp.py
+-rw-------   0 root         (0) root         (0)    17687 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/pytorch/distributed/test_dist_interface.py
+-rw-------   0 root         (0) root         (0)    11563 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/st/test_troubleshooter_api_dump.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.474154 mindtorch-0.3.0/testing/ut/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.474154 mindtorch-0.3.0/testing/ut/pytorch/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.478154 mindtorch-0.3.0/testing/ut/pytorch/amp/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/amp/__init__.py
+-rw-------   0 root         (0) root         (0)     2324 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/amp/test_autocast.py
+-rw-------   0 root         (0) root         (0)     4884 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/amp/test_clip_grad.py
+-rw-------   0 root         (0) root         (0)    15987 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/amp/test_grad_scaler.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.478154 mindtorch-0.3.0/testing/ut/pytorch/autograd/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/autograd/__init__.py
+-rw-------   0 root         (0) root         (0)     4429 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/autograd/test_autograd.py
+-rw-------   0 root         (0) root         (0)     7706 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/autograd/test_autograd_function.py
+-rw-------   0 root         (0) root         (0)     2086 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/autograd/test_backward.py
+-rw-------   0 root         (0) root         (0)    11436 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/autograd/test_functional.py
+-rw-------   0 root         (0) root         (0)    11138 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/autograd/test_grad_mode.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.482154 mindtorch-0.3.0/testing/ut/pytorch/common/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/common/__init__.py
+-rw-------   0 root         (0) root         (0)     1022 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/common/test_checkpoint.py
+-rw-------   0 root         (0) root         (0)     1130 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/common/test_device.py
+-rw-------   0 root         (0) root         (0)      290 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/common/test_dtype.py
+-rw-------   0 root         (0) root         (0)     1473 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/common/test_inplace.py
+-rw-------   0 root         (0) root         (0)     1781 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/common/test_inplace_graph.py
+-rw-------   0 root         (0) root         (0)     4017 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/common/test_lru_cache.py
+-rw-------   0 root         (0) root         (0)     1780 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/common/test_utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.482154 mindtorch-0.3.0/testing/ut/pytorch/cuda/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/cuda/__init__.py
+-rw-------   0 root         (0) root         (0)     1690 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/cuda/test_device.py
+-rw-------   0 root         (0) root         (0)     2955 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/cuda/test_event.py
+-rw-------   0 root         (0) root         (0)    10790 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/cuda/test_stream.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.482154 mindtorch-0.3.0/testing/ut/pytorch/data/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/data/__init__.py
+-rw-------   0 root         (0) root         (0)    52982 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/data/test_dataloader.py
+-rw-------   0 root         (0) root         (0)     3449 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/data/test_dataloader_userdefine.py
+-rw-------   0 root         (0) root         (0)     3008 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/data/test_sampler.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.482154 mindtorch-0.3.0/testing/ut/pytorch/distributed/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/distributed/__init__.py
+-rw-------   0 root         (0) root         (0)     1484 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/distributed/dist_impl_ascend.py
+-rw-------   0 root         (0) root         (0)     1450 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/distributed/dist_impl_gpu.py
+-rw-------   0 root         (0) root         (0)     1361 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/distributed/test_dist.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.498154 mindtorch-0.3.0/testing/ut/pytorch/functional/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/__init__.py
+-rw-------   0 root         (0) root         (0)     9600 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_activation.py
+-rw-------   0 root         (0) root         (0)     2053 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_arange.py
+-rw-------   0 root         (0) root         (0)     3328 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_cat.py
+-rw-------   0 root         (0) root         (0)      692 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_chunk.py
+-rw-------   0 root         (0) root         (0)     9710 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_compare.py
+-rw-------   0 root         (0) root         (0)     2034 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_corrcoef.py
+-rw-------   0 root         (0) root         (0)     2484 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_cov.py
+-rw-------   0 root         (0) root         (0)     1403 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_cross.py
+-rw-------   0 root         (0) root         (0)     2877 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_cummax.py
+-rw-------   0 root         (0) root         (0)     2639 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_cummin.py
+-rw-------   0 root         (0) root         (0)     1523 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_cumprod.py
+-rw-------   0 root         (0) root         (0)     1961 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_cumsum.py
+-rw-------   0 root         (0) root         (0)     3281 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_diag.py
+-rw-------   0 root         (0) root         (0)     2804 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_diagflat.py
+-rw-------   0 root         (0) root         (0)     3309 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_diff.py
+-rw-------   0 root         (0) root         (0)     3878 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_dist.py
+-rw-------   0 root         (0) root         (0)     3731 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_div.py
+-rw-------   0 root         (0) root         (0)     2870 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_empty.py
+-rw-------   0 root         (0) root         (0)      695 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_eye.py
+-rw-------   0 root         (0) root         (0)     1289 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_flatten.py
+-rw-------   0 root         (0) root         (0)     2450 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_flip.py
+-rw-------   0 root         (0) root         (0)   129402 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_function.py
+-rw-------   0 root         (0) root         (0)     2486 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_gather.py
+-rw-------   0 root         (0) root         (0)    37367 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_linalg.py
+-rw-------   0 root         (0) root         (0)      686 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_log.py
+-rw-------   0 root         (0) root         (0)     1130 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_mask.py
+-rw-------   0 root         (0) root         (0)   117513 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_math.py
+-rw-------   0 root         (0) root         (0)     2897 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_matmul.py
+-rw-------   0 root         (0) root         (0)     3084 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_meshgrid.py
+-rw-------   0 root         (0) root         (0)     1881 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_mm.py
+-rw-------   0 root         (0) root         (0)     7310 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_other.py
+-rw-------   0 root         (0) root         (0)      652 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_permute.py
+-rw-------   0 root         (0) root         (0)    13756 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_reduction.py
+-rw-------   0 root         (0) root         (0)     1210 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_reshape.py
+-rw-------   0 root         (0) root         (0)     1287 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_softmax.py
+-rw-------   0 root         (0) root         (0)     1594 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_sort.py
+-rw-------   0 root         (0) root         (0)     5480 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_split.py
+-rw-------   0 root         (0) root         (0)     1417 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_sqrt.py
+-rw-------   0 root         (0) root         (0)     1250 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_squeeze.py
+-rw-------   0 root         (0) root         (0)     1565 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_stack.py
+-rw-------   0 root         (0) root         (0)     4157 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_stft.py
+-rw-------   0 root         (0) root         (0)      881 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_t.py
+-rw-------   0 root         (0) root         (0)     2344 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_transpose.py
+-rw-------   0 root         (0) root         (0)      676 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_unbind.py
+-rw-------   0 root         (0) root         (0)      628 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_unsqueeze.py
+-rw-------   0 root         (0) root         (0)     1912 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_var.py
+-rw-------   0 root         (0) root         (0)     1047 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/functional/test_zeros.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.498154 mindtorch-0.3.0/testing/ut/pytorch/fx/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/fx/__init__.py
+-rw-------   0 root         (0) root         (0)      419 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/fx/test_fx.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.498154 mindtorch-0.3.0/testing/ut/pytorch/jit/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/jit/__init__.py
+-rw-------   0 root         (0) root         (0)     1087 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/jit/test_jit.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.510154 mindtorch-0.3.0/testing/ut/pytorch/nn/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/__init__.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.518154 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/__init__.py
+-rw-------   0 root         (0) root         (0)    14884 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_avg_pooling.py
+-rw-------   0 root         (0) root         (0)    14401 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_batch_norm.py
+-rw-------   0 root         (0) root         (0)    14012 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_conv.py
+-rw-------   0 root         (0) root         (0)     8225 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_conv_transpose1d.py
+-rw-------   0 root         (0) root         (0)     7444 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_conv_transpose2d.py
+-rw-------   0 root         (0) root         (0)     4646 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_conv_transpose3d.py
+-rw-------   0 root         (0) root         (0)    10751 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_dropout.py
+-rw-------   0 root         (0) root         (0)    22470 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_functional.py
+-rw-------   0 root         (0) root         (0)     3447 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_grid_sample.py
+-rw-------   0 root         (0) root         (0)     3983 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_group_norm.py
+-rw-------   0 root         (0) root         (0)      819 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_gumbelsoftmax.py
+-rw-------   0 root         (0) root         (0)     1314 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_hardsigmoid.py
+-rw-------   0 root         (0) root         (0)    11196 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_instance_norm.py
+-rw-------   0 root         (0) root         (0)     8185 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_layer_norm.py
+-rw-------   0 root         (0) root         (0)     2526 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_linear.py
+-rw-------   0 root         (0) root         (0)     2416 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_log_softmax.py
+-rw-------   0 root         (0) root         (0)    17306 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_loss.py
+-rw-------   0 root         (0) root         (0)    13250 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_max_pooling.py
+-rw-------   0 root         (0) root         (0)    12013 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_maxunpool.py
+-rw-------   0 root         (0) root         (0)     2169 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_normalize.py
+-rw-------   0 root         (0) root         (0)     1006 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_one_hot.py
+-rw-------   0 root         (0) root         (0)    11314 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_pad.py
+-rw-------   0 root         (0) root         (0)      986 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_pdist.py
+-rw-------   0 root         (0) root         (0)     3017 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_prompt_flash_attention.py
+-rw-------   0 root         (0) root         (0)      696 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_relu.py
+-rw-------   0 root         (0) root         (0)     2175 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_scaled_dot_product_attention.py
+-rw-------   0 root         (0) root         (0)      760 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_sigmoid.py
+-rw-------   0 root         (0) root         (0)     1299 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_silu.py
+-rw-------   0 root         (0) root         (0)     2176 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_softplus.py
+-rw-------   0 root         (0) root         (0)     3080 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_upsample.py
+-rw-------   0 root         (0) root         (0)     2073 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/functional/test_vision.py
+-rw-------   0 root         (0) root         (0)    44173 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_activation.py
+-rw-------   0 root         (0) root         (0)     2926 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_adaptive.py
+-rw-------   0 root         (0) root         (0)    13919 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_adaptivepool.py
+-rw-------   0 root         (0) root         (0)    21522 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_batchnorm.py
+-rw-------   0 root         (0) root         (0)      905 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_channelshuffle.py
+-rw-------   0 root         (0) root         (0)    22547 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_container.py
+-rw-------   0 root         (0) root         (0)    46599 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_conv.py
+-rw-------   0 root         (0) root         (0)     2113 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_convert_param.py
+-rw-------   0 root         (0) root         (0)     4698 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_distance.py
+-rw-------   0 root         (0) root         (0)     7706 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_dropout.py
+-rw-------   0 root         (0) root         (0)     2235 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_flatten.py
+-rw-------   0 root         (0) root         (0)     1850 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_fold.py
+-rw-------   0 root         (0) root         (0)     9591 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_hooks.py
+-rw-------   0 root         (0) root         (0)     4516 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_init.py
+-rw-------   0 root         (0) root         (0)     5970 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_lazy.py
+-rw-------   0 root         (0) root         (0)     3902 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_linear.py
+-rw-------   0 root         (0) root         (0)    33763 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_loss.py
+-rw-------   0 root         (0) root         (0)    62480 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_module.py
+-rw-------   0 root         (0) root         (0)     5282 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_normalization.py
+-rw-------   0 root         (0) root         (0)    15547 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_packedsequence.py
+-rw-------   0 root         (0) root         (0)     9037 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_padding.py
+-rw-------   0 root         (0) root         (0)     9027 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_parameter.py
+-rw-------   0 root         (0) root         (0)     1033 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_pixelshuffle.py
+-rw-------   0 root         (0) root         (0)    29451 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_pooling.py
+-rw-------   0 root         (0) root         (0)     1042 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_quantized.py
+-rw-------   0 root         (0) root         (0)    37301 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_rnn.py
+-rw-------   0 root         (0) root         (0)     1142 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_sequential.py
+-rw-------   0 root         (0) root         (0)     7830 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_sparse.py
+-rw-------   0 root         (0) root         (0)    68186 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_transformer.py
+-rw-------   0 root         (0) root         (0)     4940 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_unpooling.py
+-rw-------   0 root         (0) root         (0)     2229 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/test_upsampling.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.522154 mindtorch-0.3.0/testing/ut/pytorch/nn/utils/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/utils/__init__.py
+-rw-------   0 root         (0) root         (0)    12348 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/utils/test_parametrizations.py
+-rw-------   0 root         (0) root         (0)      713 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/utils/test_skip_init.py
+-rw-------   0 root         (0) root         (0)     3220 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/utils/test_spectral_norm.py
+-rw-------   0 root         (0) root         (0)     1133 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/utils/test_stateless.py
+-rw-------   0 root         (0) root         (0)     1455 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/nn/utils/test_weight_norm.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.522154 mindtorch-0.3.0/testing/ut/pytorch/optim/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/optim/__init__.py
+-rw-------   0 root         (0) root         (0)    30099 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/optim/test_lr_scheduler.py
+-rw-------   0 root         (0) root         (0)    56884 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/optim/test_optim.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.522154 mindtorch-0.3.0/testing/ut/pytorch/special/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/special/__init__.py
+-rw-------   0 root         (0) root         (0)      423 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/special/test_special.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.526154 mindtorch-0.3.0/testing/ut/pytorch/tensor/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/__init__.py
+-rw-------   0 root         (0) root         (0)    15069 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/test_magic_methods.py
+-rw-------   0 root         (0) root         (0)     1780 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/test_size.py
+-rw-------   0 root         (0) root         (0)    10779 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/test_storage.py
+-rw-------   0 root         (0) root         (0)   247115 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/test_tensor.py
+-rw-------   0 root         (0) root         (0)    31024 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/test_tensor2.py
+-rw-------   0 root         (0) root         (0)     6605 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/test_tensor_compare.py
+-rw-------   0 root         (0) root         (0)    13319 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/test_triangle_func.py
+-rw-------   0 root         (0) root         (0)     3467 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/tensor/test_type.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.530154 mindtorch-0.3.0/testing/ut/pytorch/torch/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/__init__.py
+-rw-------   0 root         (0) root         (0)     1892 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_assert.py
+-rw-------   0 root         (0) root         (0)     5346 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_default_type.py
+-rw-------   0 root         (0) root         (0)     1757 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_dtype.py
+-rw-------   0 root         (0) root         (0)      738 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_export_nn_func.py
+-rw-------   0 root         (0) root         (0)     1343 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_export_tensor_func.py
+-rw-------   0 root         (0) root         (0)      963 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_hub.py
+-rw-------   0 root         (0) root         (0)      368 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_import.py
+-rw-------   0 root         (0) root         (0)     1886 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_info.py
+-rw-------   0 root         (0) root         (0)     1458 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_multinomial.py
+-rw-------   0 root         (0) root         (0)      874 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_ones.py
+-rw-------   0 root         (0) root         (0)     1821 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_randint.py
+-rw-------   0 root         (0) root         (0)      648 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_randn.py
+-rw-------   0 root         (0) root         (0)      768 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_randperm.py
+-rw-------   0 root         (0) root         (0)    16338 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_serialization.py
+-rw-------   0 root         (0) root         (0)      934 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/pytorch/torch/test_version.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.534155 mindtorch-0.3.0/testing/ut/torchvision/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/__init__.py
+-rw-------   0 root         (0) root         (0)     7804 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/common_utils.py
+-rw-------   0 root         (0) root         (0)      346 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/conftest.py
+-rw-------   0 root         (0) root         (0)    37287 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/datasets_utils.py
+drwx------   0 root         (0) root         (0)        0 2024-04-29 01:30:08.534155 mindtorch-0.3.0/testing/ut/torchvision/models/
+-rw-------   0 root         (0) root         (0)        0 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/models/__init__.py
+-rw-------   0 root         (0) root         (0)     2148 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/models/test_load_save.py
+-rw-------   0 root         (0) root         (0)    28882 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/models/test_models.py
+-rw-------   0 root         (0) root         (0)   103895 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_datasets.py
+-rw-------   0 root         (0) root         (0)     4027 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_datasets_samplers.py
+-rw-------   0 root         (0) root         (0)     8807 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_datasets_utils.py
+-rw-------   0 root         (0) root         (0)     4308 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_datasets_video_utils.py
+-rw-------   0 root         (0) root         (0)    52071 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_functional_tensor.py
+-rw-------   0 root         (0) root         (0)    59383 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_ops.py
+-rw-------   0 root         (0) root         (0)     1099 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_torchvision_ci.py
+-rw-------   0 root         (0) root         (0)    86319 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_transforms.py
+-rw-------   0 root         (0) root         (0)    86320 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_transforms_numpy.py
+-rw-------   0 root         (0) root         (0)     7317 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_transforms_video.py
+-rw-------   0 root         (0) root         (0)    14125 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/torchvision/test_utils.py
+-rw-------   0 root         (0) root         (0)     4493 2024-04-29 00:52:43.000000 mindtorch-0.3.0/testing/ut/utils.py
```

### Comparing `mindtorch-0.2.1/LICENSE` & `mindtorch-0.3.0/LICENSE`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/PKG-INFO` & `mindtorch-0.3.0/PKG-INFO`

 * *Files 23% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mindtorch
-Version: 0.2.1
+Version: 0.3.0
 Summary: MindTorch is a toolkit for support the PyTorch model running on Ascend.
 Home-page: https://openi.pcl.ac.cn/OpenI/MSAdapter 
 Author: Peng Cheng Lab, HUAWEI
 Author-email: pcl.openi@pcl.ac.cn
 License: Apache 2.0
 Classifier: Development Status :: 3 - Alpha
 Classifier: Programming Language :: Python :: 3 :: Only
@@ -16,14 +16,20 @@
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Software Development :: Libraries
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: Operating System :: OS Independent
 Description-Content-Type: text/plain
 License-File: LICENSE
+Requires-Dist: ml_dtypes==0.2.0
+Requires-Dist: numpy<1.24.0,>=1.21.0
+Requires-Dist: numba==0.56.4
+Requires-Dist: scikit-learn==1.0.2
+Requires-Dist: librosa==0.10.1
+Requires-Dist: tqdm==4.65.0
 
 Introduction
 =============
 MindTorch is MindSpore tool for adapting the PyTorch interface, which is designed to make PyTorch code perform efficiently on Ascend without changing the habits of the original PyTorch users.
 
 |MindTorch-architecture|
 
@@ -44,76 +50,60 @@
 
 .. code:: bash
 
     pip3 install git+https://openi.pcl.ac.cn/OpenI/MSAdapter.git
 
 User guide
 ===========
-For data processing and model building, MindTorch can be used in the same way as PyTorch, while the model training part of the code needs to be customized, as shown in the following example.
+You can start using it straight away, for example:
 
-1. Data processing (only modify the import package)
+Import mstorch_enable in the main program of the code file to adapt PyTorch code to MindTorch
 
 .. code:: python
 
-    from mindtorch.torch.utils.data import DataLoader
-    from mindtorch.torchvision import datasets, transforms
+    from mindtorch.tools import mstorch_enable   # It needs to be used before importing torch related modules in the main program
 
-    transform = transforms.Compose([transforms.Resize((224, 224), interpolation=InterpolationMode.BICUBIC),
-                                    transforms.ToTensor(),
-                                    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.2435, 0.2616])
-                                   ])
-    train_images = datasets.CIFAR10('./', train=True, download=True, transform=transform)
-    train_data = DataLoader(train_images, batch_size=128, shuffle=True, num_workers=2, drop_last=True)
+    import torch
+    import torch.nn as nn
+    import torch.nn.functional as F
+    from torchvision import datasets, transforms
 
-2. Model construction (modify import package only)
-
-.. code:: python
-
-    from mindtorch.torch.nn import Module, Linear, Flatten
-
-    class MLP(Module):
+    class LeNet(nn.Module):
         def __init__(self):
-            super(MLP, self).__init__()
-            self.flatten = Flatten()
-            self.line1 = Linear(in_features=1024, out_features=64)
-            self.line2 = Linear(in_features=64, out_features=128, bias=False)
-            self.line3 = Linear(in_features=128, out_features=10)
-
-        def forward(self, inputs):
-            x = self.flatten(inputs)
-            x = self.line1(x)
-            x = self.line2(x)
-            x = self.line3(x)
+            super(LeNet, self).__init__()
+            self.conv1 = nn.Conv2d(3, 16, 5)
+            self.pool1 = nn.MaxPool2d(2, 2)
+            self.conv2 = nn.Conv2d(16, 32, 5)
+            self.pool2 = nn.MaxPool2d(2, 2)
+            self.fc1 = nn.Linear(32*5*5, 120)
+            self.fc2 = nn.Linear(120, 84)
+            self.fc3 = nn.Linear(84, 10)
+
+        def forward(self, x):
+            x = F.relu(self.conv1(x))
+            x = self.pool1(x)
+            x = F.relu(self.conv2(x))
+            x = self.pool2(x)
+            x = x.view(-1, 32*5*5)
+            x = F.relu(self.fc1(x))
+            x = F.relu(self.fc2(x))
+            x = self.fc3(x)
             return x
 
-3.Model training (custom training)
+    criterion = nn.CrossEntropyLoss()
 
-.. code:: python
+    transform = transforms.Compose(
+        [transforms.ToTensor(),
+         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
 
-    import mindtorch.torch as torch
-    import mindtorch.torch.nn as nn
-    import mindspore as ms
-
-    net = MLP()
-    net.train()
-    epochs = 500
-    criterion = nn.CrossEntropyLoss()
-    optimizer = ms.nn.SGD(net.trainable_params(), learning_rate=0.01, momentum=0.9, weight_decay=0.0005)
+    train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
+    train_data = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2, drop_last=True)
 
-    # Define the training process
-    loss_net = ms.nn.WithLossCell(net, criterion)
-    train_net = ms.nn.TrainOneStepCell(loss_net, optimizer)
-
-    for i in range(epochs):
-        for X, y in train_data:
-            res = train_net(X, y)
-            print("epoch:{}, loss:{:.6f}".format(i, res.asnumpy()))
-    # Save model
-    ms.save_checkpoint(net, "save_path.ckpt")
+After importing mstorch_enable, the imported module with the same name of torch will be automatically converted to the corresponding module of mindtorch when the code is executed (currently supports automatic conversion of torch, torchvision, torchaudio related modules), and then execute the .py file of the main program. For more information on how to use it, please refer to User's Guide.
 
 
 License
 =======
 
 MindTorch is released under the Apache 2.0 license.
 
-.. |MindTorch-architecture| image:: https://openi.pcl.ac.cn/laich/pose_data/raw/branch/master/MSA_F.png
+.. |MindTorch-architecture| image:: https://openi.pcl.ac.cn/OpenI/MSAdapter/raw/branch/master/doc/readthedocs/source_zh/docs/pic/MSA_F.png
```

### Comparing `mindtorch-0.2.1/README.rst` & `mindtorch-0.3.0/README.rst`

 * *Files 18% similar despite different names*

```diff
@@ -21,76 +21,60 @@
 
 .. code:: bash
 
     pip3 install git+https://openi.pcl.ac.cn/OpenI/MSAdapter.git
 
 User guide
 ===========
-For data processing and model building, MindTorch can be used in the same way as PyTorch, while the model training part of the code needs to be customized, as shown in the following example.
+You can start using it straight away, for example:
 
-1. Data processing (only modify the import package)
+Import mstorch_enable in the main program of the code file to adapt PyTorch code to MindTorch
 
 .. code:: python
 
-    from mindtorch.torch.utils.data import DataLoader
-    from mindtorch.torchvision import datasets, transforms
+    from mindtorch.tools import mstorch_enable   # It needs to be used before importing torch related modules in the main program
 
-    transform = transforms.Compose([transforms.Resize((224, 224), interpolation=InterpolationMode.BICUBIC),
-                                    transforms.ToTensor(),
-                                    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.2435, 0.2616])
-                                   ])
-    train_images = datasets.CIFAR10('./', train=True, download=True, transform=transform)
-    train_data = DataLoader(train_images, batch_size=128, shuffle=True, num_workers=2, drop_last=True)
+    import torch
+    import torch.nn as nn
+    import torch.nn.functional as F
+    from torchvision import datasets, transforms
 
-2. Model construction (modify import package only)
-
-.. code:: python
-
-    from mindtorch.torch.nn import Module, Linear, Flatten
-
-    class MLP(Module):
+    class LeNet(nn.Module):
         def __init__(self):
-            super(MLP, self).__init__()
-            self.flatten = Flatten()
-            self.line1 = Linear(in_features=1024, out_features=64)
-            self.line2 = Linear(in_features=64, out_features=128, bias=False)
-            self.line3 = Linear(in_features=128, out_features=10)
-
-        def forward(self, inputs):
-            x = self.flatten(inputs)
-            x = self.line1(x)
-            x = self.line2(x)
-            x = self.line3(x)
+            super(LeNet, self).__init__()
+            self.conv1 = nn.Conv2d(3, 16, 5)
+            self.pool1 = nn.MaxPool2d(2, 2)
+            self.conv2 = nn.Conv2d(16, 32, 5)
+            self.pool2 = nn.MaxPool2d(2, 2)
+            self.fc1 = nn.Linear(32*5*5, 120)
+            self.fc2 = nn.Linear(120, 84)
+            self.fc3 = nn.Linear(84, 10)
+
+        def forward(self, x):
+            x = F.relu(self.conv1(x))
+            x = self.pool1(x)
+            x = F.relu(self.conv2(x))
+            x = self.pool2(x)
+            x = x.view(-1, 32*5*5)
+            x = F.relu(self.fc1(x))
+            x = F.relu(self.fc2(x))
+            x = self.fc3(x)
             return x
 
-3.Model training (custom training)
+    criterion = nn.CrossEntropyLoss()
 
-.. code:: python
+    transform = transforms.Compose(
+        [transforms.ToTensor(),
+         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
 
-    import mindtorch.torch as torch
-    import mindtorch.torch.nn as nn
-    import mindspore as ms
-
-    net = MLP()
-    net.train()
-    epochs = 500
-    criterion = nn.CrossEntropyLoss()
-    optimizer = ms.nn.SGD(net.trainable_params(), learning_rate=0.01, momentum=0.9, weight_decay=0.0005)
+    train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
+    train_data = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2, drop_last=True)
 
-    # Define the training process
-    loss_net = ms.nn.WithLossCell(net, criterion)
-    train_net = ms.nn.TrainOneStepCell(loss_net, optimizer)
-
-    for i in range(epochs):
-        for X, y in train_data:
-            res = train_net(X, y)
-            print("epoch:{}, loss:{:.6f}".format(i, res.asnumpy()))
-    # Save model
-    ms.save_checkpoint(net, "save_path.ckpt")
+After importing mstorch_enable, the imported module with the same name of torch will be automatically converted to the corresponding module of mindtorch when the code is executed (currently supports automatic conversion of torch, torchvision, torchaudio related modules), and then execute the .py file of the main program. For more information on how to use it, please refer to User's Guide.
 
 
 License
 =======
 
 MindTorch is released under the Apache 2.0 license.
 
-.. |MindTorch-architecture| image:: https://openi.pcl.ac.cn/laich/pose_data/raw/branch/master/MSA_F.png
+.. |MindTorch-architecture| image:: https://openi.pcl.ac.cn/OpenI/MSAdapter/raw/branch/master/doc/readthedocs/source_zh/docs/pic/MSA_F.png
```

### Comparing `mindtorch-0.2.1/mindtorch/tools/convert_tensor.py` & `mindtorch-0.3.0/mindtorch/tools/convert_tensor.py`

 * *Files 8% similar despite different names*

```diff
@@ -2,22 +2,23 @@
 # -*- coding: utf-8 -*-
 import re
 from collections.abc import Mapping, Sequence
 from mindtorch.tools.utils import try_import
 import mindspore as ms
 from mindspore.common import dtype as mstype
 from mindtorch.torch.tensor import Tensor
+from mindtorch.module_hooker import torch_enable, torch_pop
 
 string_classes = (str, bytes)
 np_str_obj_array_pattern = re.compile(r'[SaUO]')
 
 def convert_to_ms_tensor(data):
-
+    torch_enable()
     torch = try_import("torch")
-
+    torch_pop()
     _dtypeConvertor = {
         torch.float16: mstype.float16,
         torch.float32: mstype.float32,
         torch.float64: mstype.float64,
         torch.int8: mstype.int8,
         torch.int16: mstype.int16,
         torch.int32: mstype.int32,
@@ -34,22 +35,26 @@
         mstype.int8: mstype.int8,
         mstype.int16: mstype.int16,
         mstype.int32: mstype.int32,
         mstype.int64: mstype.int64,
         mstype.uint8: mstype.uint8,
         mstype.complex64: mstype.complex64,
         mstype.complex128: mstype.complex128,
-        mstype.bfloat16: mstype.float16,
+        mstype.bfloat16: mstype.bfloat16,
     }
 
     elem_type = type(data)
     if isinstance(data, torch.Tensor):
         origin_dtype = data.dtype
         origin_dtype = _dtypeConvertor[origin_dtype]
-        data = data.numpy()
+        if origin_dtype == mstype.bfloat16:
+            # numpy not support bfloat16 dtype, so need to transfer to float32.
+            data = data.float().numpy()
+        else:
+            data = data.numpy()
         return Tensor(data, dtype=origin_dtype)
     elif elem_type.__module__ == 'numpy' and elem_type.__name__ != 'str_' \
             and elem_type.__name__ != 'string_':
             if elem_type.__name__ == 'ndarray' \
                 and np_str_obj_array_pattern.search(data.dtype.str) is not None:
                 return data
             return Tensor(data)
@@ -72,8 +77,8 @@
         except TypeError:
             return [convert_to_ms_tensor(d) for d in data]
     elif isinstance(data, string_classes):
         return data
     elif isinstance(data, ms.Tensor):
         return data
     else:
-        raise TypeError("data must be tensor, numpy arrays, numbers, dicts or lists; but got {}".format(elem_type))
+        raise TypeError("data must be tensor, numpy arrays, numbers, dicts or lists; but got {}".format(elem_type))
```

### Comparing `mindtorch-0.2.1/mindtorch/tools/debug_layer_info.py` & `mindtorch-0.3.0/mindtorch/tools/debug_layer_info.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,21 +1,24 @@
 import os
 import warnings
 import numpy as np
 
 from mindtorch.torch.logging import _setup_logger
 from mindtorch.torch.tensor import cast_to_adapter_tensor
+from mindtorch.module_hooker import torch_enable, torch_pop
 import mindspore as ms
 
 adapter_print_header = True
 torch_print_header = True
 
 def hook_func(frame, type_info, tensor_info, name=None):
     if frame == "pytorch":
+        torch_enable()
         import torch
+        torch_pop()
     else:
         import mindtorch.torch as torch
 
     def tensor_basic_info(x, prefix):
         # all adapter tensors are converted to mindspore._c_expression.Tensor by HookBackward in this func
         input = x
         if frame == "mindtorch":
@@ -86,25 +89,29 @@
                         return output
 
         return output_tensor_reg_hook(outputs, 0)
 
     return hook_function
 
 def params_basic_info(parameter, name):
-    print(f"'{name}' with shape: {parameter.cpu().detach().numpy().shape}, "
-          f"and type: {parameter.cpu().detach().numpy().dtype}.")
+    param_np = parameter.cpu().detach().numpy()
+    print(f"'{name}' with shape: param_np.shape, "
+          f"and type: {param_np.dtype}.")
     if parameter.ndim == 0:
         print(f"{name} is {parameter}.")
-    else:
+    # ms min/max op unsupport complex64/complex128
+    elif param_np.dtype not in (np.complex64, np.complex128):
         print(f"The max value in '{name}' is {parameter.max():.4f}, min value is {parameter.min():.4f}, "
               f"mean value is {parameter.float().mean():.4f}.")
 
 def debug_layer_info(model, frame="mindtorch", type_info=False, tensor_info=True, params_info=True):
     if frame == "pytorch":
+        torch_enable()
         import torch
+        torch_pop()
     else:
         import mindtorch.torch as torch
         os.environ['MSA_LOG'] = '2'
         _setup_logger()
 
     if not isinstance(model, torch.nn.Module):
         raise ValueError(f"For debug_layer_info, `model` must be a nn.Module, but get a {type(model)} type.")
@@ -120,8 +127,8 @@
     # TODO: wrap non-nn APIs
     # from mindtorch.tools.wrap_tensor import initialize_hook
     # hook_func_partial = functools.partial(hook_func, frame, type_info, tensor_info)
     # initialize_hook(hook_func_partial)
 
     for name, module in model.named_modules():
         if module is not None:
-            module.register_forward_hook(hook_func(frame, type_info, tensor_info, name))
+            module.register_forward_hook(hook_func(frame, type_info, tensor_info, name))
```

### Comparing `mindtorch-0.2.1/mindtorch/tools/pth2ckpt.py` & `mindtorch-0.3.0/mindtorch/tools/pth2ckpt.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,16 +1,19 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 import sys
 from mindtorch.tools.utils import try_import
 from mindspore import Tensor, save_checkpoint
+from mindtorch.module_hooker import torch_enable, torch_pop
 
 def pth2ckpt(path):
+    torch_enable()
     torch = try_import('torch')
     torch_dict = torch.load(path, map_location='cpu')
+    torch_pop()
     ms_params = []
     for name, value in torch_dict.items():
         if isinstance(value, dict):
             for k, v in value.items():
                 param_dict = {}
                 param_dict['name'] = k
                 if isinstance(v, torch.Tensor):
@@ -29,8 +32,8 @@
             ms_params.append(param_dict)
 
     save_checkpoint(ms_params, path[:-3] + "ckpt")
     print("convert ckpt finish.")
 
 if __name__=="__main__":
     pth_file = sys.argc[1]
-    pth2ckpt(pth_file)
+    pth2ckpt(pth_file)
```

### Comparing `mindtorch-0.2.1/mindtorch/tools/support_wrap_ops.yaml` & `mindtorch-0.3.0/mindtorch/tools/support_wrap_ops.yaml`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/tools/utils.py` & `mindtorch-0.3.0/mindtorch/tools/utils.py`

 * *Files 24% similar despite different names*

```diff
@@ -11,12 +11,12 @@
         install_name = module_name.split('.')[0]
 
     try:
         mod = importlib.import_module(module_name)
         return mod
     except ImportError:
         err_msg = (
-            "Failed importing {}. This likely means that some pytorch modules "
+            "Failed importing {}. This likely means that some mindtorch modules "
             "require additional dependencies that have to be "
             "manually installed (usually with `pip install {}`). ").format(
                 module_name, install_name)
         raise ImportError(err_msg)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/_C/Generator.py` & `mindtorch-0.3.0/mindtorch/torch/_C/Generator.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -26,28 +26,28 @@
 from mindtorch.torch.autograd import (
     no_grad, enable_grad, set_grad_enabled, is_grad_enabled, inference_mode, is_inference_mode_enabled)
 from mindtorch.torch.random import *
 from mindtorch.torch.storage import *
 from mindtorch.torch.serialization import *
 import mindtorch.torch.linalg as linalg
 from mindtorch.torch.common.dtype import ms_dtype as dtype
-import mindtorch.torch.amp as amp
+from mindtorch.torch.amp import autocast, auto_mixed_precision
 import mindtorch.torch.cpu as cpu
 import mindtorch.torch.library as library
 from mindtorch.torch import hub
 from mindtorch.torch.logging import debug, info, warning, error, critical
 from mindtorch.torch.torch_version import __version__
 from mindtorch.torch import jit
 from mindtorch.torch import fx
 from mindtorch.torch._export_func_to_root import _export_func_to_root
 from mindtorch.torch.storage import _StorageBase, _TypedStorage, _LegacyStorage, _UntypedStorage, DoubleStorage, \
     FloatStorage, LongStorage, IntStorage, ShortStorage, CharStorage, ByteStorage, HalfStorage, \
     BoolStorage, BFloat16Storage, ComplexFloatStorage, ComplexDoubleStorage
 from mindtorch.torch._default_dtype import set_default_dtype, get_default_dtype, set_default_tensor_type
-
+from mindtorch.torch._patch_func import _patch_func_ms
 
 def _assert(condition, message):
     assert condition, message
 
 def is_tensor(obj):
     r"""Returns True if `obj` is a mindtorch.torch tensor.
 
@@ -60,32 +60,29 @@
 
 def is_floating_point(obj):
     if not is_tensor(obj):
         raise TypeError("is_floating_point(): argument 'input' (position 1) must be Tensor, not {}.".format(type(obj)))
 
     return obj.is_floating_point()
 
-class Size(tuple):
-    def __new__(cls, shape):
-        if isinstance(shape, Tensor):
-            _shape = shape.tolist()
-        else:
-            _shape = shape
-        if not isinstance(_shape, (tuple, list)):
-            raise TypeError("{} object is not supportted.".format(type(shape)))
-
-        return tuple.__new__(Size, _shape)
-strided = False
 
 def is_storage(obj):
     return type(obj) in _storage_classes
 
 _storage_classes = {
     _UntypedStorage, DoubleStorage, FloatStorage, LongStorage, IntStorage,
     ShortStorage, CharStorage, ByteStorage, HalfStorage, BoolStorage,
     BFloat16Storage, ComplexFloatStorage, ComplexDoubleStorage, _TypedStorage,
     # TODO:The quantized dtype is not supported
     # QUInt8Storage, QInt8Storage, QInt32Storage, , QUInt4x2Storage, QUInt2x4Storage,
 }
 
+def set_default_device(device):
+    unsupported_attr(device)
+    warning("`set_default_device` can not actually take effect. "
+            "Please try use mindspore.set_context('device_target') to specify the target device.")
+
 # export tensor.xxx and nn.functional.xxx to the current directory
 _export_func_to_root()
+
+# replace fun to adapt to old version mindspore
+_patch_func_ms()
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/_default_dtype.py` & `mindtorch-0.3.0/mindtorch/torch/_default_dtype.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 #!/usr/bin/env python
 import mindspore as ms
 from mindspore.ops.primitive import _primexpr
 from mindtorch.torch.common.dtype import all_float_type, float32, _get_dtype_from_type
 
+
 __all__ = ['set_default_dtype', 'get_default_dtype', 'set_default_tensor_type']
 
 
 @ms.jit_class
 class TypeHelperBase:
     # global dtype
     _float_dtype = float32
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/_export_func_to_root.py` & `mindtorch-0.3.0/mindtorch/torch/_export_func_to_root.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/_ref/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/_ref/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/_register/getitem_impl.py` & `mindtorch-0.3.0/mindtorch/torch/_register/getitem_impl.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/_register/register_multitype_ops.py` & `mindtorch-0.3.0/mindtorch/torch/_register/register_multitype_ops.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/_register/register_utils.py` & `mindtorch-0.3.0/mindtorch/torch/_register/register_utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/_register_numpy_primitive.py` & `mindtorch-0.3.0/mindtorch/torch/_register_numpy_primitive.py`

 * *Files 2% similar despite different names*

```diff
@@ -31,18 +31,18 @@
         super().__init__()
         self.op_name = op_name
         self.rcond = rcond
     def construct(self, a, b):
         a = a.asnumpy()
         b = b.asnumpy()
         output = np.linalg.lstsq(a, b, rcond=self.rcond)
-        x = ms.Tensor(output[0])
-        residuals = ms.Tensor(output[1])
+        x = ms.Tensor.from_numpy(output[0])
+        residuals = ms.Tensor.from_numpy(output[1])
         rank = ms.Tensor(output[2])
-        s = ms.Tensor(output[3])
+        s = ms.Tensor.from_numpy(output[3])
         return x, residuals, rank, s
     def bprop(self, a, b, out, dout):
         raise RuntimeError(_error_msg.format(self.op_name))
 
 class NumpyEigvals(NumpyCommon):
     def construct(self, A):
         A_np = A.asnumpy()
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/amp/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/amp/__init__.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 import sys
+import os
 import mindspore as ms
 import mindtorch.torch.nn as nn
 from mindtorch.torch.nn import Module, Sequential
 from mindtorch.torch.tensor import cast_to_adapter_tensor
 from mindtorch.torch.amp.autocast_mode import autocast
 
 all = [
@@ -41,41 +42,53 @@
             raise ValueError("Level `auto` only support when `device_target` is GPU or Ascend.")
 
     amp_net = ms.amp.auto_mixed_precision(network, amp_level)
     return _CastToAdapter(amp_net)
 
 
 # for mindspore auto mixed precision
-ms.rewrite.symbol_tree_builder.SymbolTreeBuilder.entry_function = "forward"
-ms.rewrite.parsers.class_def_parser.ClassDefParser.entry_function = "forward"
-ms.rewrite.parsers.assign_parser.AssignParser.types_for_cell_container.append(Sequential)
-
-class ToDtype(Module):
-    def __init__(self):
-        super(ToDtype, self).__init__()
-
-    def forward(self, x, dtype):
-        return x.to(dtype)
-
-nn_modules_list = [ToDtype]
-nn_modules = sys.modules['mindtorch.torch.nn']
-nn_modules_dir = dir(nn_modules)
-for module_name in nn_modules_dir:
-    module_obj = getattr(nn_modules, module_name)
-    if isinstance(module_obj, type) and issubclass(module_obj, Module):
-        nn_modules_list.append(module_obj)
-
-ms.rewrite.namespace._subtree_black_list.extend(nn_modules_list)
-ms.train.amp._config_amp(enable_rewrite=True, cast_op=ToDtype)
-
-ms.train.amp.AMP_WHITE_LIST.extend([nn.Conv1d,
-                                    nn.Conv2d,
-                                    nn.Conv3d,
-                                    nn.Linear,
-                                    nn.LSTMCell,
-                                    nn.RNNCell,
-                                    nn.GRUCell])
-
-ms.train.amp.AMP_BLACK_LIST.extend([nn.BatchNorm1d,
-                                    nn.BatchNorm2d,
-                                    nn.BatchNorm3d,
-                                    nn.LayerNorm])
+try:
+    # [adapt old version ms] use 'try import' to suit mindspore 2.2
+    ms.rewrite.symbol_tree_builder.SymbolTreeBuilder.entry_function = "forward"
+    ms.rewrite.parsers.class_def_parser.ClassDefParser.entry_function = "forward"
+    ms.rewrite.parsers.assign_parser.AssignParser.types_for_cell_container.append(Sequential)
+
+    class ToDtype(Module):
+        def __init__(self):
+            super(ToDtype, self).__init__()
+
+        def forward(self, x, dtype):
+            return x.to(dtype)
+
+    nn_modules_list = [ToDtype]
+    nn_modules = sys.modules['mindtorch.torch.nn']
+    nn_modules_dir = dir(nn_modules)
+    for module_name in nn_modules_dir:
+        module_obj = getattr(nn_modules, module_name)
+        if isinstance(module_obj, type) and issubclass(module_obj, Module):
+            nn_modules_list.append(module_obj)
+
+    ms.rewrite.namespace._subtree_black_list.extend(nn_modules_list)
+    ms.train.amp._config_amp(enable_rewrite=True, cast_op=ToDtype)
+
+    ms.train.amp.AMP_WHITE_LIST.extend([nn.Conv1d,
+                                        nn.Conv2d,
+                                        nn.Conv3d,
+                                        nn.Linear,
+                                        nn.LSTMCell,
+                                        nn.RNNCell,
+                                        nn.GRUCell])
+
+    ms.train.amp.AMP_BLACK_LIST.extend([nn.BatchNorm1d,
+                                        nn.BatchNorm2d,
+                                        nn.BatchNorm3d,
+                                        nn.LayerNorm])
+except AttributeError:
+    ms.rewrite.symbol_tree.symbol_tree_builder.SymbolTreeBuilder.entry_functions.append("forward")
+    ms.rewrite.parsers.class_def_parser.ClassDefParser.entry_functions.append("forward")
+    ms.rewrite.parsers.class_def_parser.ClassDefParser.final_networks.append(Module)
+    ms.rewrite.parsers.assign_parser.AssignParser.types_for_cell_container.append(Sequential)
+    ms.rewrite.common.namespace._ignore_third_party_paths.append(
+        os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
+    ms.train.amp._config_amp(enable_rewrite=True)
+    ms.train.amp._INNER_AMP_BLACK_LIST.extend([ms.ops.operations._inner_ops.ConvertToMsTensor,
+                                               ms.ops.operations._inner_ops.ConvertToAdapterTensor])
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/amp/autocast_mode.py` & `mindtorch-0.3.0/mindtorch/torch/amp/autocast_mode.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 from mindtorch.torch.common.dtype import float16
 from mindtorch.utils import unsupported_attr
+from mindtorch.torch.logging import warning
 
 class autocast():
     def __init__(self, device_type, enabled=True, dtype=float16, cache_enabled=True):
         unsupported_attr(device_type)
         unsupported_attr(enabled)
         unsupported_attr(dtype)
         unsupported_attr(cache_enabled)
-        raise NotImplementedError("The use of `with autocast` is not currently supported, "
-                                  "please use `mindspore.amp.auto_mixed_precision()` instead. "
-                                  "Please refer to examples: "
-                                  "https://openi.pcl.ac.cn/OpenI/MSAdapter/src/branch/master/USER_GUIDE.md")
+        warning("The use of `with autocast` is not currently supported, "
+                "please use `mindspore.amp.auto_mixed_precision()` instead. "
+                "Please refer to examples: "
+                "https://openi.pcl.ac.cn/OpenI/MSAdapter/src/branch/master/doc/"
+                "readthedocs/source_zh/docs/User_Guide_Mixed.md")
 
     def __enter__(self):
         pass
 
     def __exit__(self, exc_type, exc_val, exc_tb):
         pass
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/autograd/functional.py` & `mindtorch-0.3.0/mindtorch/torch/autograd/functional.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/autograd/grad_mode.py` & `mindtorch-0.3.0/mindtorch/torch/autograd/grad_mode.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/backends/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/backends/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/backends/cuda/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/backends/cuda/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/backends/cudnn/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/backends/cudnn/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/common/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/common/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/common/dtype.py` & `mindtorch-0.3.0/mindtorch/torch/common/dtype.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 
 import numpy as np
+from ml_dtypes import bfloat16 as np_bfloat16
 import mindspore as ms
 from mindspore import dtype as mstype
 from mindspore.ops.primitive import _primexpr
 from mindspore._c_expression import typing
 from mindtorch.torch.logging import warning
 
 MS_Bool = typing.Bool
@@ -156,19 +157,23 @@
 all_float_type = (float16, float32, float64, bfloat16)
 all_complex_type = (complex64, complex128, )
 all_float_and_complex_type = (float16, float32, float64, bfloat16, complex64, complex128, )
 
 _TypeDict = {float16: np.float16,
              float32: np.float32,
              float64: np.float64,
+             bfloat16: np_bfloat16,
              int8: np.int8,
              int16: np.int16,
              int32: np.int32,
              int64: np.int64,
-             uint8: np.uint8}
+             uint8: np.uint8,
+             bool: np.bool_,
+             complex64: np.complex64,
+             complex128: np.complex128}
 
 _msdtype2typeDict = {'Bool': bool,
                      'Int8': int8,
                      'Int16': int16,
                      'Int32': int32,
                      'Int64': int64,
                      'Uint8': uint8,
@@ -187,18 +192,27 @@
             self.bits = np_iinfo.bits
             self.max = np_iinfo.max
             self.min = np_iinfo.min
         else:
             raise ValueError("iinfo currently only supports torch.uint8/torch.int8/torch.int16/torch.int32/"
                              "torch.int64 as the input, but get a", dtype)
 
+
 @ms.jit_class
 class finfo:
     def __init__(self, dtype):
-        if dtype in all_float_type and dtype != bfloat16:
+        if dtype == bfloat16:
+            self.bits = 16
+            self.eps = 0.0078125
+            self.max = 3.38953e+38
+            self.min = -3.38953e+38
+            self.tiny = 1.17549e-38
+            self.smallest_normal = 1.17549e-38
+            self.resolution = 0.01
+        elif dtype in all_float_type:
             np_finfo = np.finfo(_TypeDict[dtype])
             self.bits = np_finfo.bits
             self.eps = np_finfo.eps.item()
             self.max = np_finfo.max.item()
             self.min = np_finfo.min.item()
             self.tiny = np_finfo.tiny.item()
             # smallest_normal for NumPy was added in 1.23.0
@@ -206,15 +220,15 @@
                 self.smallest_normal = np_finfo.smallest_normal.item()
             else:
                 warning("If you want to obtain `smallest_normal` in finfo, " \
                         "NumPy version must be greater or equal 1.23.0.")
             self.resolution = np_finfo.resolution.item()
         else:
             raise ValueError("finfo currently only supports torch.float16/torch.float32/"
-                             "torch.float64 as the input, but get a", dtype)
+                             "torch.float64/torch.bfloat16 as the input, but get a", dtype)
 
 
 _dtype2typeDict = {
     'float32': 'FloatTensor',
     'float': 'FloatTensor',
     'float64': 'DoubleTensor',
     'double': 'DoubleTensor',
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/conflict_functional.py` & `mindtorch-0.3.0/mindtorch/torch/conflict_functional.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,34 +6,32 @@
 from mindtorch.torch.common._inner import _out_inplace_assign
 from mindtorch.torch.tensor import cast_to_ms_tensor
 from mindtorch.torch._default_dtype import get_default_dtype, all_float_type
 
 def range(start, end, step=1, *, out=None, dtype=None, layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     if dtype is None:
         dtype = get_default_dtype()
     start = ms.Tensor(start, dtype=dtype)
     end = ms.Tensor(end+0.001, dtype=dtype)
     # TODO This function is deprecated and will be removed in a future release
     # because its behavior is inconsistent with Pythons range builtin. Instead, use torch.arange(),
     # which produces values in [start, end).
     step = ms.Tensor(step, dtype=dtype)
     output = ms.ops.range(start, end, step)
-    return _out_inplace_assign(out, output, "range")
+    return _out_inplace_assign(out, output, "range", requires_grad)
 
 
 def arange(start, end=None, step=1, *, out=None, dtype=None,
         layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     start = cast_to_ms_tensor(start)
     end = cast_to_ms_tensor(end)
     step = cast_to_ms_tensor(step)
     output =  ms.ops.arange(start=start, end=end, step=step, dtype=dtype)
     if dtype is None and output.dtype in all_float_type:
         default_dtype = get_default_dtype()
         output = output.astype(default_dtype)
 
-    return _out_inplace_assign(out, output, "arange")
+    return _out_inplace_assign(out, output, "arange", requires_grad)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/cuda/_utils.py` & `mindtorch-0.3.0/mindtorch/torch/cuda/_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -10,8 +10,8 @@
             if device.type.lower() not in ['cuda', 'cpu', 'ascend']:
                 raise ValueError('Expected a cuda or cpu device, but got: {}'.format(device))
         elif device.type.lower() != 'cuda' and device.type.lower() != 'ascend':
             raise ValueError('Expected a cuda or ascend device, but got: {}'.format(device))
         return device.index
     if isinstance(device, int):
         return device
-    raise ValueError("The inputdevice of _get_device_index is abnormal, please check.")
+    raise ValueError("The input device of _get_device_index is abnormal, please check.")
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/cuda/amp/autocast_mode.py` & `mindtorch-0.3.0/mindtorch/torch/cuda/amp/autocast_mode.py`

 * *Files 17% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 def custom_fwd(fwd=None, *, cast_inputs=None):
     unsupported_attr(fwd)
     unsupported_attr(cast_inputs)
     raise NotImplementedError("The use of `@custom_fwd` is not currently supported, please use "
                               "`mindspore.amp.auto_mixed_precision()` or `tensor.astype(ms.float16)' instead."
                               "Please refer to examples: https://openi.pcl.ac.cn/OpenI/MSAdapter/src/branch/"
-                              "master/doc/torch/USER_GUIDE.md")
+                              "master/doc/readthedocs/source_zh/docs/User_Guide_Adapter.md")
 
 def custom_bwd(bwd):
     unsupported_attr(bwd)
     raise NotImplementedError("The use of `@custom_bwd` is not currently supported, please use "
                               "`mindspore.amp.auto_mixed_precision()` or `tensor.astype(ms.float16)' instead."
                               "Please refer to examples: https://openi.pcl.ac.cn/OpenI/MSAdapter/src/branch/"
-                              "master/doc/torch/USER_GUIDE.md")
+                              "master/doc/readthedocs/source_zh/docs/User_Guide_Adapter.md")
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/cuda/amp/grad_scaler.py` & `mindtorch-0.3.0/mindtorch/torch/cuda/amp/grad_scaler.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 import inspect
 from collections import defaultdict
 from enum import Enum
 import mindspore as ms
 from mindspore.amp import DynamicLossScaler, all_finite
 import mindspore.ops as ops
+from mindspore.common import mutable
 from mindtorch.torch.nn.parameter import Parameter
-from mindtorch.torch.tensor import tensor
+from mindtorch.torch.tensor import tensor, cast_to_ms_tensor
 from  mindtorch.torch.common.dtype import float32, int32
 from mindtorch.torch.logging import warning
 from mindtorch.utils import graph_mode_condition
 
 class OptState(Enum):
     READY = 0
     UNSCALED = 1
@@ -18,15 +19,15 @@
 def _refresh_per_optimizer_state():
     return {"stage": OptState.READY, "found_inf_per_device": {}}
 
 def _assign(x1, x2):
     return x1.assign_value(x2)
 
 _hypermap = ops.HyperMap()
-
+_partial = ops.Partial()
 class GradScaler(DynamicLossScaler):
     def __init__(self,
                  init_scale=2.**16,
                  growth_factor=2.0,
                  backoff_factor=0.5,
                  growth_interval=2000,
                  enabled=True):
@@ -57,55 +58,75 @@
             # for mindspore
             self.counter = Parameter(tensor(0, dtype=int32), name="counter", requires_grad=False)
             self._per_optimizer_states = defaultdict(_refresh_per_optimizer_state)
 
     def _check_inf(self, grads):
         return {'all': ms.ops.logical_not(all_finite(grads))}
 
+    def _loss_scale(self, scale, loss):
+        return loss * scale.astype(loss.dtype)
+
+    def _loss_scale_map(self, scale_value, inputs):
+        return _hypermap(_partial(self._loss_scale, scale_value), inputs)
+
     def scale(self, outputs):
         if not self._enabled:
             return outputs
-        return DynamicLossScaler.scale(self, outputs)
+        outputs = mutable(outputs)
+        return self._loss_scale_map(self.scale_value, outputs)
 
-    def unscale_(self, optimizer, grads):
+    def unscale_(self, optimizer, grads=None):
         if not self._enabled:
             return
 
+        if graph_mode_condition():
+            raise RuntimeError("Under graph mode, GradScalar not support unscale_(), please use unscale(). "
+                               "Example: change 'scaler.unscale_(optimizer)' to "
+                               "'grads = scaler.unscale(optimizer, grads)'")
+
         optimizer_state = self._per_optimizer_states[id(optimizer)]
         if optimizer_state["stage"] is OptState.UNSCALED:
             raise RuntimeError("unscale_() has already been called on this optimizer since the last update().")
         elif optimizer_state["stage"] is OptState.STEPPED:
             raise RuntimeError("unscale_() is being called after step().")
 
+        if grads is None:
+            grads = [cast_to_ms_tensor(p.grad) for p in optimizer.parameters if p.grad is not None]
+            if len(grads) == 0:
+                return
+            grads = tuple(grads)
+            optimizer_state['found_inf_per_device'] = self._check_inf(grads)
+            new_grads = DynamicLossScaler.unscale(self, grads)
+            for i, p in enumerate(optimizer.parameters):
+                if p.grad is not None:
+                    p.grad = new_grads[i]
+            return
+
         optimizer_state['found_inf_per_device'] = self._check_inf(grads)
-        if graph_mode_condition():
-            raise RuntimeError("Under graph mode, GradScalar not support unscale_(), please use unscale(). "
-                               "Example: change 'scaler.unscale_(optimizer, grads)' to "
-                               "'grads = scaler.unscale(optimizer, grads)'")
         _hypermap(_assign, grads, DynamicLossScaler.unscale(self, grads))
         optimizer_state["stage"] = OptState.UNSCALED
 
     def unscale(self, optimizer, grads):
         if not self._enabled:
             return grads
 
         optimizer_state = self._per_optimizer_states[id(optimizer)]
         optimizer_state["found_inf_per_device"] = self._check_inf(grads)
         optimizer_state["stage"] = OptState.UNSCALED
         return DynamicLossScaler.unscale(self, grads)
 
-    def _maybe_opt_step(self, optimizer, grads, optimizer_state, *args, **kwargs):
+    def _maybe_opt_step(self, optimizer, optimizer_state, *args, **kwargs):
         retval = None
         if not sum(v.asnumpy().tolist() for v in optimizer_state["found_inf_per_device"].values()):
-            retval = optimizer.step(grads, *args, **kwargs)
+            retval = optimizer.step(*args, **kwargs)
         return retval
 
-    def step(self, optimizer, grads, *args, **kwargs):
+    def step(self, optimizer, *args, **kwargs):
         if not self._enabled:
-            return optimizer.step(grads)
+            return optimizer.step(*args, **kwargs)
 
         if "closure" in kwargs:
             raise RuntimeError("Closure use is not currently supported if GradScaler is enabled.")
 
         optimizer_state = self._per_optimizer_states[id(optimizer)]
 
         if optimizer_state["stage"] is OptState.STEPPED:
@@ -124,25 +145,31 @@
                 )
                 kwargs_.update({"grad_scaler": self})
             else:
                 scaler = self._get_scale_async()
                 found_inf = optimizer_state["found_inf_per_device"]
                 optimizer.grad_scale = None if optimizer_state["stage"] == OptState.UNSCALED else scaler
                 optimizer.found_inf = found_inf
-            retval = optimizer.step(grads, *args, **kwargs_)
+            retval = optimizer.step(*args, **kwargs_)
             optimizer_state["stage"] = OptState.STEPPED
             if not has_grad_scaler_kwarg:
                 del optimizer.grad_scale
                 del optimizer.found_inf
             return retval
 
         if optimizer_state["stage"] is OptState.READY:
-            self.unscale_(optimizer, grads)
+            # To see if grads is pass in.
+            if len(args) > 0 and isinstance(args[0], tuple) and \
+                len(args[0]) > 0 and isinstance(args[0][0], ms.Tensor):
+                grads = args[0]
+                self.unscale_(optimizer, grads)
+            else:
+                self.unscale_(optimizer)
 
-        retval = self._maybe_opt_step(optimizer, grads, optimizer_state, *args, **kwargs)
+        retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
 
         optimizer_state["stage"] = OptState.STEPPED
         return retval
 
     def adjust(self, grads_finite):
         one = ops.ones((), self.scale_value.dtype)
         scale_mul_factor = self.scale_value * self.scale_factor
@@ -171,14 +198,17 @@
                 self.scale_value.set_data(ms.Tensor(new_scale))
             else:
                 self.scale_value.set_data(new_scale)
         else:
             found_infs = [found_inf
                           for state in self._per_optimizer_states.values()
                           for found_inf in state["found_inf_per_device"].values()]
+            if len(found_infs) == 0:
+                raise ValueError("No inf checks were recorded prior to update."
+                                 "Maybe no grad has been unscaled in 'unscale_' process.")
             found_inf_combined = found_infs[0]
             if len(found_infs) > 1:
                 for i in range(1, len(found_infs)):
                     found_inf_combined = ms.ops.logical_or(found_inf_combined, found_infs[i])
             self.adjust(ms.ops.logical_not(found_inf_combined))
 
     def _get_scale_async(self):
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/fft/fft.py` & `mindtorch-0.3.0/mindtorch/torch/fft/fft.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/functional.py` & `mindtorch-0.3.0/mindtorch/torch/functional.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,72 +1,87 @@
 #!/usr/bin/env python
 import numbers
 # from functools import lru_cache
 from copy import deepcopy
 from builtins import max as python_max
 import numpy as np
-from scipy import signal
+try:
+    import librosa
+except ImportError:
+    # do nothings here.
+    ...
 import mindspore as ms
 from mindspore import ops
 from mindspore.common import dtype as mstype
-from mindspore.scipy.ops import SolveTriangular
+try:
+    from mindspore.scipy.ops import SolveTriangular # not support on win cpu
+except ImportError:
+    # do nothings here.
+    ...
 from mindspore.ops.primitive import _primexpr
 from mindspore.ops._primitive_cache import _get_cache_prim
+from mindspore._c_expression import Tensor as ms_Tensor_
 
-from mindtorch.torch.tensor import tensor, cast_to_ms_tensor, cast_to_adapter_tensor, custom_matmul
+from mindtorch.torch.tensor import tensor, cast_to_ms_tensor, cast_to_adapter_tensor, custom_matmul, \
+    _convert_shape_to_int
 from mindtorch.utils import unsupported_attr, pynative_mode_condition, is_under_gpu_context, \
     is_under_ascend_context, _infer_size, promote_type_lookup, bitwise_adapter, set_name_tuple, _get_ms_type, \
     set_multiple_name_tuple, INT32_MIN, INT64_MIN, INT32_MAX, INT64_MAX, FP64_MAX, FP64_MIN, FP32_MAX, FP32_MIN
 from mindtorch.torch.tensor import Tensor as adapter_tensor
 from mindtorch.torch.common._inner import _out_inplace_assign, _out_limit_pynative, \
     _out_inplace_assign_with_adapter_tensor, _functional_inplace_assign
 from mindtorch.torch.common.dtype import _TypeDict, all_int_type, all_float_type, all_complex_type, finfo, \
     all_float_and_complex_type
 from mindtorch.torch.linalg import matrix_power as linalg_matrix_power
 from mindtorch.torch.linalg import svdvals
 import mindtorch.torch._register_numpy_primitive as numpy_cell
 from mindtorch.torch.logging import warning
 import mindtorch.torch.special as _special
+from mindtorch.torch.storage import _UntypedStorage, _TypedStorage
 from mindtorch.torch._default_dtype import _dtype_or_default, get_default_dtype
 
 
 def empty(*positional_size, size=None, out=None, dtype=None, layout=None, \
           device=None, requires_grad=False, pin_memory=False, \
           memory_format=None):
     # TODO: ms.numpy.empty will create a tensor fill with zeros, not uninitialized numbers.
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(pin_memory)
     unsupported_attr(memory_format)
 
     dtype = _dtype_or_default(dtype)
 
     if size is None:
         if isinstance(positional_size[0], (tuple, list)):
             size = positional_size[0]
         else:
             size = positional_size
-    output = adapter_tensor(*size, dtype=dtype, inner=False)
+
+    size = _convert_shape_to_int(size)
+
+    if isinstance(size, (tuple, list)) and not size:
+        output = tensor(0, dtype=dtype, requires_grad=requires_grad)
+    else:
+        output = adapter_tensor(*size, requires_grad=requires_grad, dtype=dtype, inner=False)
     return _out_inplace_assign(out, output, "empty")
 
 def eye(n, m=None, *, out=None, dtype=None, layout=None, \
         device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     dtype = _dtype_or_default(dtype)
     output = ms.ops.eye(n, m, dtype)
-    return _out_inplace_assign(out, output, "eye")
+    return _out_inplace_assign(out, output, "eye", requires_grad)
 
 @_primexpr
 def _get_max_prec(dtypes):
     # When parsing in graph mode, it is necessary to make a judgment, otherwise it may be considered out of bounds.
     if len(dtypes) == 0:
-        ValueError("The dtypes cannot be empty.")
+        raise ValueError("The dtypes cannot be empty.")
     all_dtypes_sorted = (mstype.bool_, mstype.uint8, mstype.int8, mstype.int16, mstype.int32, mstype.int64, \
         mstype.float16, mstype.float32, mstype.float64, mstype.complex64, mstype.complex128)
     max_prec_rank = all_dtypes_sorted.index(dtypes[0])
     need_convert = False
     # if dtypes contain both and only uint8 and int8 (i.e. max_prec = int8 && contains uint8), convert to int16
     uint8_flag = False
     for tensor_dtype in dtypes:
@@ -113,22 +128,21 @@
     output = ms.ops.concat(_get_inputs_of_same_max_dtype(inputs), axis=dim)
     return _out_inplace_assign(out, output, "concat")
 
 def ones(*size, out=None, dtype=None, layout=None,
         device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
 
     dtype = _dtype_or_default(dtype)
 
     if isinstance(size[0], (tuple, list)):
         size = tuple(size[0])
     output = ms.ops.ones(size, dtype)
-    return _out_inplace_assign(out, output, "ones")
+    return _out_inplace_assign(out, output, "ones", requires_grad)
 
 
 def stack(tensors, dim=0, *, out=None, axis=0):
     _tensor_seq_input_warning(tensors, "stack")
     tensors = cast_to_ms_tensor(tensors)
     if dim == 0:
         dim = axis
@@ -182,24 +196,23 @@
     return _out_inplace_assign_with_adapter_tensor(out, output, "mm")
 
 
 #TODO: adapter needs to support both positional and keywords input size to be consistent with pytorch
 #positional_size represents the positional arguments of size, size represents the keywords arguments input
 def zeros(*positional_size, size=None, out=None, dtype=None, device=None, requires_grad=False):
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     if size is None:
         if isinstance(positional_size[0], (tuple, list)):
             size = positional_size[0]
         else:
             size = positional_size
 
     dtype = _dtype_or_default(dtype)
     output = ms.ops.zeros(size, dtype)
-    return _out_inplace_assign(out, output, "zeros")
+    return _out_inplace_assign(out, output, "zeros", requires_grad)
 
 
 def div(input, other, *, rounding_mode=None, out=None):
     input_ms = cast_to_ms_tensor(input)
     value = cast_to_ms_tensor(other)
     if not isinstance(input_ms, ms.Tensor):
         input_ms = ms.Tensor(input_ms)
@@ -247,41 +260,42 @@
 
 def multinomial(input, num_samples, replacement=False, *, generator=None, out=None):
     unsupported_attr(generator)
     if generator is not None:
         warning("'multinomal' don't support generator now.")
     input_tensor = cast_to_ms_tensor(input).astype(mstype.float32)
     output = ms.ops.multinomial(input_tensor, num_samples, replacement)
+
+    # ms.ops.multinomial returns int32, but torch.multinomial returns int64.
+    output = output.astype(ms.int64)
     return _out_inplace_assign(out, output, "multinomial")
 
 
 def randperm(n, *, generator=None, out=None, dtype=mstype.int64, layout=None, device=None,
              requires_grad=False, pin_memory=False):
     unsupported_attr(generator)
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(pin_memory)
 
     if generator is not None:
         warning("torch.randperm don't support generator now.")
     if layout is not None:
         warning("torch.randperm don't support layout now.")
 
     output = np.random.permutation(n)
     output = tensor(output, dtype=dtype)
-    return _out_inplace_assign(out, output, "randperm")
+    return _out_inplace_assign(out, output, "randperm", requires_grad)
 
 # torch.randint(low=0, high, size, *, generator=None, out=None,...)
 def randint(low=0, high=None, size=None, *, generator=None, out=None, dtype=None, layout=None,
             device=None, requires_grad=False):
     unsupported_attr(generator)
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
 
     if generator is not None:
         warning("torch.randint don't support generator now.")
     if layout is not None:
         warning("torch.randint don't support layout now.")
 
     # TODO: ms.ops.randint to support non-int types
@@ -308,15 +322,15 @@
         size = (1,)
         output = ms.ops.randint(low, high, size, dtype=_dtype)
         output = output[0]
     else:
         output = ms.ops.randint(low, high, size, dtype=_dtype)
     if dtype is not None:
         output = output.astype(dtype)
-    return _out_inplace_assign(out, output, "randint")
+    return _out_inplace_assign(out, output, "randint", requires_grad)
 
 
 def as_tensor(data, dtype=None, device=None):
     unsupported_attr(device)
 
     if isinstance(data, (tuple, list)):
         data = [i.data.item() if isinstance(i, adapter_tensor) else i for i in data ]
@@ -324,62 +338,62 @@
     output = ms.Tensor(data, dtype=dtype)
     return cast_to_adapter_tensor(output)
 
 
 def zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=None):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(memory_format)
     input_x = cast_to_ms_tensor(input)
     output = ms.ops.zeros_like(input_x, dtype=dtype)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 
 def ones_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=None):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(memory_format)
     input_x = cast_to_ms_tensor(input)
     dtype = _get_ms_type(dtype)
     output = ms.ops.ones_like(input_x, dtype=dtype)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 
 def empty_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=None):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(memory_format)
     if dtype is None:
         dtype = input.dtype
     size = input.shape
-    output = adapter_tensor(*size, dtype=dtype, inner=False)
-    return cast_to_adapter_tensor(output)
+
+    if isinstance(size, tuple) and not size:
+        return tensor(0, dtype=dtype, requires_grad=requires_grad)
+    return adapter_tensor(*size, requires_grad=requires_grad, dtype=dtype, inner=False)
 
 
 def full(size, fill_value, out=None, dtype=None, layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     if dtype is None:
         dtype = ms.Tensor(fill_value).dtype
         if dtype in all_float_type:
             dtype = get_default_dtype()
     output = ms.ops.full(size, fill_value, dtype=dtype)
-    return _out_inplace_assign(out, output, "full")
+    return _out_inplace_assign(out, output, "full", requires_grad)
 
 
 def full_like(input, fill_value, dtype=None, layout=None, device=None, requires_grad=False, memory_format=None):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(memory_format)
     output = ms.ops.full_like(input, fill_value=fill_value, dtype=dtype)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 
 def where(condition, x=None, y=None):
     if x is None and y is None:
         return nonzero(condition, as_tuple=True)
     x = cast_to_ms_tensor(x)
@@ -390,30 +404,28 @@
 
 #TODO: adapter needs to support both positional and keywords input size to be consistent with pytorch
 #positional_size represents the positional arguments of size, size represents the keywords arguments input
 def rand(*positional_size, size=None, out=None, dtype=None, layout=None, device=None, requires_grad=False, \
     pin_memory=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(pin_memory)
     dtype = _dtype_or_default(dtype)
     if size is None:
         if isinstance(positional_size[0], (tuple, list)):
             size = positional_size[0]
         else:
             size = positional_size
     output = from_numpy(np.random.rand(*size)).to(dtype)
-    return _out_inplace_assign_with_adapter_tensor(out, output, "rand")
+    return _out_inplace_assign_with_adapter_tensor(out, output, "rand", requires_grad)
 
 
 def randn(*size, out=None, dtype=None, layout=None, device=None, requires_grad=False, generator=None):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(generator)
 
     if isinstance(size[0], (tuple, list)):
         _size = size[0]
     elif isinstance(size[0], int):
         _size = size
     else:
@@ -422,40 +434,44 @@
     dtype = _dtype_or_default(dtype)
 
     if not _size:
         output = tensor(np.random.randn(*_size), dtype=dtype)
     else:
         output = from_numpy(np.random.randn(*_size)).to(dtype)
 
-    return _out_inplace_assign_with_adapter_tensor(out, output, "randn")
+    return _out_inplace_assign_with_adapter_tensor(out, output, "randn", requires_grad)
 
 
 def linspace(start, end, steps, *, out=None, dtype=None, device=None, requires_grad=False):
     # TODO: ms.ops.linspace not support complex, not support int dtype tensor.
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     # TODO: unsupport complex dtype
     _dtype = get_default_dtype()
     if isinstance(start, adapter_tensor):
         start = cast_to_ms_tensor(start)
         start = start.astype(_dtype)
     else:
         start = ms.Tensor(start, _dtype)
 
     if isinstance(end, adapter_tensor):
         end = cast_to_ms_tensor(end)
         end = end.astype(_dtype)
     else:
         end = ms.Tensor(end, _dtype)
 
-    output = ms.ops.linspace(start, end, steps)
+    # TODO: ms.ops.linspace has some bug on Ascend now.
+    if is_under_ascend_context():
+        _op = _get_cache_prim(ms.ops.LinSpace)().set_device('CPU')
+        output = _op(start, end, steps)
+    else:
+        output = ms.ops.linspace(start, end, steps)
     # Ascend tbe fusion unspport linspace + default_type + astype on Graph mode
     if dtype is not None:
         output = output.astype(dtype)
-    return _out_inplace_assign(out, output, "linspace")
+    return _out_inplace_assign(out, output, "linspace", requires_grad)
 
 
 def take(input, index):
     input_ms = cast_to_ms_tensor(input)
     index = cast_to_ms_tensor(index)
     output = input_ms.take(index)
     return cast_to_adapter_tensor(output)
@@ -682,16 +698,14 @@
 def sign(input, *, out=None):
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.sign(input_ms)
     return _out_inplace_assign(out, output, "sign")
 
 
 def pow(input, exponent, *, out=None):
-    # TODO: not support input that is above 7-dimention on GPU and Ascend
-    # TODO: currently not support 0-D input, mindspore 2.1 will support
     input_ms = cast_to_ms_tensor(input)
     exponent = cast_to_ms_tensor(exponent)
     output = ms.ops.pow(input_ms, exponent)
     if not is_under_ascend_context():
         #TODO: ((output <= MIN) | (output >= MAX)) compute returns error on Ascend.
         # Because currently Ascend not support bool type input in [BitwiseOr]
         if output.dtype == ms.int64:
@@ -700,22 +714,17 @@
             output = ms.ops.where(((output <= INT32_MIN) | (output >= INT32_MAX)), 0, output)
     return _out_inplace_assign(out, output, "pow")
 
 
 def exp(input, *, out=None):
     # TODO: after ms.ops.exp support over 7-dimentions input and int-dtype input, finetune the code.
     input_ms = cast_to_ms_tensor(input)
-    shape = input_ms.shape
-    if len(shape) > 7:
-        input_ms = input_ms.flatten()
     if input_ms.dtype != ms.float64:
         input_ms = input_ms.astype(ms.float32)
     output = ms.ops.exp(input_ms)
-    if len(shape) > 7:
-        output = output.reshape(shape)
     return _out_inplace_assign(out, output, "exp")
 
 
 def ge(input, other, *, out=None):
     input_ms = cast_to_ms_tensor(input)
     other = cast_to_ms_tensor(other)
     output = ms.ops.ge(input_ms, other)
@@ -760,69 +769,147 @@
 
 
 def norm(input, p='fro', dim=None, keepdim=False, out=None, dtype=None):
     output = input.norm(p=p, dim=dim, keepdim=keepdim, dtype=dtype)
     return _out_inplace_assign_with_adapter_tensor(out, output, "norm")
 
 
+def complex_splitting(x):
+    """
+    Change librosa stft output to a three-dimensional array of real and imaginary numbers
+    Args:
+        x: complex number numpy type.
+
+    Returns:
+        three-dimensional array. eg[[[real, image], [real, image], ...]
+    """
+    dim1, dim2 = np.shape(x)
+    result = np.zeros((dim1, dim2, 2))
+    for i in range(dim1):
+        for j in range(dim2):
+            result[i][j][0] = np.real(x[i][j])
+            result[i][j][1] = np.imag(x[i][j])
+    return result
+
+
 def stft(input, n_fft, hop_length=None, win_length=None, window=None, center=True,
-         pad_mode='reflect', normalized=False, onesided=None, return_complex=None):
-    # TODO: to use ms.ops.stft after it support.
+         pad_mode='reflect', normalized=False, onesided=None, return_complex=False):
+    # TODO: The window parameter requires more detailed consideration
     unsupported_attr(normalized)
     unsupported_attr(onesided)
-    unsupported_attr(return_complex)
     input_ms = cast_to_ms_tensor(input)
     input_ms = input_ms.asnumpy()
-    if pad_mode == 'reflect':
-        pad_mode = 'even'
+    # Processing window functions
     if window is None:
         window = 'hann'
-    if hop_length is None:
-        hop_length = floor(n_fft / 4)
-    if win_length is None:
-        win_length = n_fft
-    output = signal.stft(input_ms, window=window, nperseg=win_length, noverlap=hop_length, padded=center,
-                         boundary=pad_mode)
-    return output
+    elif isinstance(window, ms.Tensor):
+        window = list(window.asnumpy())
+    else:
+        NotImplementedError("This method is waiting for implementation.")
+    # librosa is used to compute the stft.
+    def call_stft(input_ms, n_fft, hop_length, win_length, window, center, pad_mode, return_complex):
+        _output = librosa.stft(input_ms,
+                               n_fft=n_fft,
+                               hop_length=hop_length,
+                               win_length=win_length,
+                               window=window,
+                               center=center,
+                               pad_mode=pad_mode,
+                               )
+        if return_complex:
+            pass
+        else:
+            _output = complex_splitting(_output)
+        return _output
+    # Implement input tensor of shape (B?, L) where B? is an optional batch dimension.
+    if len(input.shape) == 1:
+        output = call_stft(input_ms, n_fft, hop_length, win_length, window, center, pad_mode, return_complex)
+    else:
+        output = []
+        for i in range(input_ms.shape[0]):
+            output_dim1 = call_stft(input_ms[i],
+                                    n_fft,
+                                    hop_length,
+                                    win_length,
+                                    window,
+                                    center,
+                                    pad_mode,
+                                    return_complex)
+            output.append(output_dim1)
+    return tensor(output)
 
 
-def istft():
-    # TODO: implement istft after ms.ops.istft support.
-    raise NotImplementedError
+def istft(input, n_fft, hop_length=None, win_length=None, window=None, center=True,
+          normalized=False, onesided=None, length=None, return_complex=False):
+    unsupported_attr(normalized)
+    unsupported_attr(onesided)
+    unsupported_attr(return_complex)
+    input_ms = cast_to_ms_tensor(input)
+    input_ms = input_ms.asnumpy()
+    # Processing window functions
+    if window is None:
+        window = 'hann'
+    elif isinstance(window, ms.Tensor):
+        window = list(window.asnumpy())
+    else:
+        NotImplementedError("This method is waiting for implementation.")
+
+    # librosa is used to compute the istft.
+    def call_istft(input_ms, n_fft, hop_length, win_length, window, center, length):
+        _output = librosa.istft(input_ms,
+                                n_fft=n_fft,
+                                hop_length=hop_length,
+                                win_length=win_length,
+                                window=window,
+                                center=center,
+                                length=length
+                                )
+        return _output
+
+    # Implement input tensor of shape (B?, L) where B? is an optional batch dimension.
+    if len(input.shape) == 2:
+        output = call_istft(input_ms, n_fft, hop_length, win_length, window, center, length)
+    else:
+        output = []
+        for i in range(input_ms.shape[0]):
+            output_dim1 = call_istft(input_ms[i], n_fft, hop_length, win_length, window, center,
+                                    length)
+            output.append(output_dim1)
+    return tensor(output)
 
 
 def bartlett_window(window_length, periodic=True, *, dtype=None, layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     input = tensor(window_length)
     dtype = _dtype_or_default(dtype)
     output = ms.ops.bartlett_window(input, periodic=periodic, dtype=dtype)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 
 def hamming_window(window_length, periodic=True, alpha=0.54, beta=0.46, dtype=None,
                    layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     dtype = _dtype_or_default(dtype)
     output = ms.ops.hamming_window(window_length, periodic, alpha, beta, dtype=dtype)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 
 def hann_window(window_length, periodic=True, *, dtype=None, layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     #TODO: ms.ops.hann_window has bug when set dtype
     dtype = _dtype_or_default(dtype)
     # output = ms.ops.hann_window(window_length, periodic=periodic, dtype=dtype)
     output = ms.ops.hann_window(window_length, periodic=periodic)
     output = output.astype(dtype)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 
 def cumsum(input, dim, *, dtype=None, out=None):
     output = input.cumsum(dim, dtype)
     return _out_inplace_assign_with_adapter_tensor(out, output, "cumsum")
 
@@ -884,15 +971,15 @@
 def isnan(input):
     input_ms = cast_to_ms_tensor(input)
     return cast_to_adapter_tensor(input_ms.isnan())
 
 
 def view_as_real(input):
     #Todo: not view
-    warning("not support output as a view.")
+    warning("view_as_real not support output as a view.")
     input_ms = cast_to_ms_tensor(input)
     real = ms.ops.expand_dims(ms.ops.real(input_ms), axis=-1)
     imag = ms.ops.expand_dims(ms.ops.imag(input_ms), axis=-1)
     #TODO: Currently [Cat] not support float64 on Ascend
     if is_under_ascend_context() and (real.dtype == ms.float64 or imag.dtype == ms.float64):
         real = real.astype(ms.float32)
         imag = imag.astype(ms.float32)
@@ -911,30 +998,31 @@
     if weights is not None:
         weights = cast_to_ms_tensor(weights)
         type = weights.dtype
     output = ms.ops.bincount(input_ms, weights, minlength).astype(type)
     return cast_to_adapter_tensor(output)
 
 def mul(input, other, *, out=None):
-    if not isinstance(input, (int, adapter_tensor)):
-        raise TypeError(f"mul(): argument 'input' (position 1) must be Tensor, not {type(input)}")
-    if not isinstance(other, (int, adapter_tensor)):
-        raise TypeError(f"mul(): argument 'other' (position 2) must be Tensor, not {type(other)}")
-
     input_ms = cast_to_ms_tensor(input)
     other = cast_to_ms_tensor(other)
+
+    # TODO: Currently, the two inputs can not be bool type at the same time, waiting
+    #  for the new version of interface around 1230.
     output = ms.ops.mul(input_ms, other)
     return _out_inplace_assign(out, output, "mul")
 
 
 def index_select(input, dim, index, *, out=None):
     _input_params = cast_to_ms_tensor(input)
     _axis = dim
     _input_indices = cast_to_ms_tensor(index)
 
+    if isinstance(_input_indices, ms.Tensor) and _input_indices.ndim == 0:
+        _input_indices = ms.ops.unsqueeze(_input_indices, 0)
+
     output = ms.ops.gather(_input_params, _input_indices, _axis)
     return _out_inplace_assign(out, output, "index_select")
 
 def sort(input, dim=-1, descending=False, stable=False, *, out=None):
     unsupported_attr(stable)
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.sort(input_ms, dim, descending)
@@ -953,22 +1041,18 @@
 
 def t(input):
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.t(input_ms)
     return cast_to_adapter_tensor(output)
 
 def squeeze(input, dim=None):
+    if dim is not None and input.shape[dim] != 1:
+        return input
     input_ms = cast_to_ms_tensor(input)
-    if dim is not None:
-        if input_ms.shape[dim] != 1:
-            output = input
-        else:
-            output = ms.ops.squeeze(input_ms, dim)
-    else:
-        output = ms.ops.squeeze(input_ms)
+    output = ms.ops.squeeze(input_ms, dim)
     return cast_to_adapter_tensor(output)
 
 def from_numpy(np_data):
     # TODO: from_numpy can not share memory between tensor and nparray yet.
     return cast_to_adapter_tensor(ms.Tensor.from_numpy(np_data))
 
 def absolute(input, *, out=None):
@@ -1191,15 +1275,18 @@
             output = (cast_to_adapter_tensor(res.flatten()), )
         elif input_ms.ndim > 1:
             output = []
             res = ms.ops.nonzero(input_ms)
             if len(res) != 0:
                 res = res.transpose(1,0)
                 res = ms.ops.split(res, 1, axis=0)
+                res = tuple(t.flatten() for t in res)
                 output = cast_to_adapter_tensor(res)
+            else:
+                output = (tensor([], dtype=mstype.int64),) * input_ms.ndim
         else:
             raise ValueError("Do not support input ndim <= 0.")
     else:
         output = ms.ops.nonzero(input_ms)
     return _out_inplace_assign(out, output, "nonzero")
 
 def clip(input, min=None, max=None, *, out=None):
@@ -1461,21 +1548,22 @@
 # TODO: currently not support return qr as second result
 def lstsq(A, x, *, out=None):
     #TODO: ms.ops.lstsq not support GPU and Ascend, currently use numpy func
     output = A.lstsq(x)
     return _out_inplace_assign_with_adapter_tensor(out, output, "lstsq")
 
 def frombuffer(buffer, *, dtype = None, count=- 1, offset=0, requires_grad=False):
-    unsupported_attr(requires_grad)
     np_dtype = _TypeDict[dtype]
     output = np.frombuffer(buffer=buffer, dtype=np_dtype, count=count, offset=offset)
-    return adapter_tensor(output, dtype=dtype)
+    if dtype == mstype.bfloat16:
+        return adapter_tensor(output.astype(np.float32), requires_grad=requires_grad, dtype=dtype)
+    return adapter_tensor(output, requires_grad=requires_grad, dtype=dtype)
 
 def as_strided(input, size, stride, storage_offset=None):
-    warning("not support output as a view.")
+    warning("as_strided not support output as a view.")
     input_ms = cast_to_ms_tensor(input)
     if len(size) != len(stride):
         raise RuntimeError("mismatch in length of strides and shape.")
     index = np.arange(0, size[0] * stride[0], stride[0])
     for i in range(1, len(size)):
         tmp = np.arange(0, size[i] * stride[i], stride[i])
         index = np.expand_dims(index, -1)
@@ -1687,15 +1775,15 @@
     output = input.rsqrt()
     return _out_inplace_assign_with_adapter_tensor(out, output, "rsqrt")
 
 def roll(input, shifts, dims=None, *, out=None):
     output = input.roll(shifts, dims=dims)
     return _out_inplace_assign_with_adapter_tensor(out, output, "roll")
 
-def rot90(input, k, dims, *, out=None):
+def rot90(input, k=1, dims=[0, 1], *, out=None): # pylint: disable=W0102
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.rot90(input_ms, k, dims)
     return _out_inplace_assign(out, output, "rot90")
 
 def sgn(input, *, out=None):
     input_ms = cast_to_ms_tensor(input)
     if 'Bool' in str(input_ms.dtype) or 'Int' in str(input_ms.dtype):
@@ -1890,17 +1978,14 @@
 def diagflat(input, offset=0, *, out=None):
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.diagflat(input_ms, offset)
     return _out_inplace_assign(out, output, "diagflat")
 
 def diagonal(input, offset=0, dim1=0, dim2=1):
     input_ms = cast_to_ms_tensor(input)
-    #TODO float64 not support if offset != 0
-    if offset != 0:
-        input_ms = input_ms.astype(mstype.float32)
     output = ms.ops.diagonal(input_ms, offset, dim1, dim2)
     return cast_to_adapter_tensor(output)
 
 def diff(input, n=1, dim=-1, prepend=None, append=None):
     input_ms = cast_to_ms_tensor(input)
     #TODO: ms.ops.diff only support n=1
     if n == 1:
@@ -2045,14 +2130,16 @@
         return (res, idx)
     else:
         res = cast_to_adapter_tensor(res)
         return res
 
 def permute(input, dims):
     ms_input = cast_to_ms_tensor(input)
+    if isinstance(dims, list):
+        dims = tuple(dims)
     output = ms.ops.permute(ms_input, dims)
     return cast_to_adapter_tensor(output)
 
 def numel(input):
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.numel(input_ms)
     return cast_to_adapter_tensor(output)
@@ -2316,15 +2403,14 @@
         raise RuntimeError(f"For Tensor.vdot, 1D tensors expected, but got {input.ndim}D and {other.ndim}D tensors")
     input_ms = cast_to_ms_tensor(input)
     other = cast_to_ms_tensor(other)
     if input_ms.is_complex():
         input_ms = ms.ops.conj(input_ms)
     if (is_under_gpu_context() and (input_ms.dtype in all_int_type)) or \
         (is_under_ascend_context() and (input_ms.dtype in (ms.float64,) + all_int_type)):
-        warning("For vdot, input with int64 type has risk of being truncated.")
         input_dtype = input_ms.dtype
         input_ms = input_ms.astype(ms.float32)
         other = other.astype(ms.float32)
         output = ms.ops.inner(input_ms, other).astype(input_dtype)
     else:
         output = ms.ops.inner(input_ms, other)
     return _out_inplace_assign(out, output, "vdot")
@@ -2427,15 +2513,14 @@
     inputs = cast_to_ms_tensor(tensors)
     output = ms.ops.block_diag(*inputs)
     return cast_to_adapter_tensor(output)
 
 def logspace(start, end, steps, base=10.0, *, out=None, dtype=None, layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     # TODO: ms.ops.logspace to support float type `base`, number type `start` and `end
     start = ms.Tensor(start, dtype=dtype)
     end = ms.Tensor(end, dtype=dtype)
     if base % 1 != 0:
         raise ValueError("For logspace, base only support integer")
     base = int(base)
     dtype = _dtype_or_default(dtype)
@@ -2443,15 +2528,15 @@
 
     if start.dtype in all_int_type or end.dtype in all_int_type or dtype in all_int_type:
         start = start.astype(mstype.float32)
         end = end.astype(mstype.float32)
         _dtype = mstype.float32
     output = ms.ops.logspace(start, end, steps, base, dtype=_dtype)
     output = output.astype(dtype)
-    return _out_inplace_assign(out, output, "logspace")
+    return _out_inplace_assign(out, output, "logspace", requires_grad)
 
 def column_stack(tensors, *, out=None):
     _tensor_seq_input_warning(tensors, "column_stack")
     tensors = cast_to_ms_tensor(tensors)
     output = ms.ops.column_stack(_get_inputs_of_same_max_dtype(tensors))
     return _out_inplace_assign(out, output, "column_stack")
 
@@ -2509,18 +2594,18 @@
     vec = cast_to_ms_tensor(vec)
     output = ms.ops.mv(input_ms, vec)
     return _out_inplace_assign(out, output, "mv")
 
 def blackman_window(window_length, periodic=True, *, dtype=None, layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     input = ms.Tensor(window_length)
     dtype = _dtype_or_default(dtype)
     output = ms.ops.blackman_window(input, periodic=periodic, dtype=dtype)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 def tril_indices(row, col, offset=0, *, dtype=mstype.int64, device=None, layout=None):
     unsupported_attr(layout)
     unsupported_attr(device)
     # 'dtype' in ms.ops.tril_indices only support {int32, int64}
     output = ms.ops.tril_indices(row, col, offset=offset).astype(dtype)
@@ -2589,33 +2674,33 @@
     b = cast_to_ms_tensor(b)
     output = ms.ops.tensor_dot(a, b, dims)
     return _out_inplace_assign(out, output, "tensordot")
 
 def randn_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=None):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(memory_format)
     input_ms = cast_to_ms_tensor(input)
     input_shape = input_ms.shape
     if not dtype:
         dtype = input_ms.dtype
     output = from_numpy(np.random.randn(*input_shape)).to(dtype)
+    output.requires_grad = requires_grad
     return output
 
 def rand_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=None):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(memory_format)
     input_ms = cast_to_ms_tensor(input)
     input_shape = input_ms.shape
     if not dtype:
         dtype = input_ms.dtype
     output = from_numpy(np.random.rand(*input_shape)).to(dtype)
+    output.requires_grad = requires_grad
     return output
 
 def kron(input, other, *, out=None):
     # TODO: support inputs of different complex type
     input_ms = cast_to_ms_tensor(input)
     other = cast_to_ms_tensor(other)
     output = ms.ops.kron(input_ms, other)
@@ -2690,15 +2775,14 @@
     output = ms.ops.dstack(_get_inputs_of_same_max_dtype(tensors))
     return _out_inplace_assign(out, output, "dstack")
 
 def randint_like(input, low=None, high=None, *, dtype=None,
                  layout=None, device=None, requires_grad=False, memory_format=None):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(memory_format)
     input_ms = cast_to_ms_tensor(input)
 
     input_type = input_ms.dtype
     if input_type not in all_int_type:
         input_ms = input_ms.round().int()
 
@@ -2717,25 +2801,26 @@
         output = ms.ops.randint_like(input_ms, low=0, high=low, dtype=_dtype)
     elif low is None:
         output = ms.ops.randint_like(input_ms, low=0, high=high, dtype=_dtype)
     else:
         output = ms.ops.randint_like(input_ms, low=low, high=high, dtype=_dtype)
 
     output = output.astype(output_type)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 def kaiser_window(window_length, periodic=True, beta=12.0, *, dtype=None,
                   layout=None, device=None, requires_grad=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     output = ms.ops.kaiser_window(window_length, periodic=periodic, beta=beta)
     # TODO: ms.ops.kaiser_window will raise error when dtype=ms.float32
     dtype = _dtype_or_default(dtype)
     output = output.astype(dtype)
+    output.requires_grad = requires_grad
     return cast_to_adapter_tensor(output)
 
 def cartesian_prod(*tensors):
     input_tensor = cast_to_ms_tensor(tensors)
     output = ms.ops.cartesian_prod(*input_tensor)
     return cast_to_adapter_tensor(output)
 
@@ -2743,14 +2828,16 @@
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.combinations(input_ms, r=r, with_replacement=with_replacement)
     return cast_to_adapter_tensor(output)
 
 def var_mean(input, dim=None, unbiased=True, keepdim=False, *, out=None):
     input_ms = cast_to_ms_tensor(input)
     ddof = 1 if unbiased is True else 0
+    if isinstance(dim, list):
+        dim = tuple(dim)
     var = input_ms.var(axis=dim, ddof=ddof, keepdims=keepdim)
 
     # TODO: not supprt GRAPH_MODE
     mean = ms.ops.mean(input, axis=dim, keep_dims=keepdim)
     output = (var, mean)
     return _out_inplace_assign(out, output, "var_mean")
 
@@ -2759,15 +2846,15 @@
     if generator is not None:
         raise NotImplementedError("adapter not support generator.")
     if is_under_ascend_context():
         poisson_op = numpy_cell.NumpyPoisson('poisson')
         output = poisson_op(input)
     else:
         input_ms = cast_to_ms_tensor(input)
-        shape = ms.Tensor([], mstype.int32)
+        shape = ms_Tensor_([], mstype.int32)
         output = ms.ops.random_poisson(shape, input_ms, dtype=input_ms.dtype)
     return cast_to_adapter_tensor(output)
 
 #TODO: eig currently not support on GPU
 def eig(input, *, out=None):
     if is_under_gpu_context():
         raise NotImplementedError("for adapter, eig not supported on GPU")
@@ -2867,16 +2954,23 @@
     output = input.pinverse(rcond=rcond)
     return _out_inplace_assign_with_adapter_tensor(out, output, "pinverse")
 
 #TODO: use ops func
 def asarray(obj, *, dtype=None, device=None, copy=None, requires_grad=False):
     unsupported_attr(device)
     unsupported_attr(copy)
-    unsupported_attr(requires_grad)
-    return cast_to_adapter_tensor(ms.numpy.asarray(obj, dtype=dtype))
+    if isinstance(obj, _TypedStorage):
+        obj = obj._storage.inner_data
+    elif isinstance(obj, _UntypedStorage):
+        obj = obj.inner_data
+    if isinstance(obj, np.ndarray):
+        return from_numpy(obj).to(dtype)
+    output = ms.numpy.asarray(obj, dtype=dtype)
+    output.requires_grad = requires_grad
+    return cast_to_adapter_tensor(output)
 
 def symeig(input, eigenvectors=False, upper=True, *, out=None):
     output = input.symeig(eigenvectors=eigenvectors, upper=upper)
     if pynative_mode_condition():
         if out is not None:
             if len(out) != 2 or not isinstance(out[0], adapter_tensor) or not isinstance(out[1], adapter_tensor):
                 raise TypeError("In symeig(), `out` should be tuple of Tensors.")
@@ -3002,21 +3096,22 @@
     else:
         output = ms.numpy.multi_dot(input_ms)
     return _out_inplace_assign(out, output, "chain_matmul")
 
 def empty_strided(size, stride, *, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False):
     unsupported_attr(layout)
     unsupported_attr(device)
-    unsupported_attr(requires_grad)
     unsupported_attr(pin_memory)
     dtype = _dtype_or_default(dtype)
     size = cast_to_ms_tensor(size)
     stride = cast_to_ms_tensor(stride)
-    output = ms.numpy.empty(size, dtype)
-    output = cast_to_adapter_tensor(output)
+    if isinstance(size, (tuple, list)) and not size:
+        output = tensor(0, dtype=dtype, requires_grad=requires_grad)
+    else:
+        output = adapter_tensor(*size, requires_grad=requires_grad, dtype=dtype, inner=False)
     output = output.as_strided(size, stride)
     return output
 
 def cumulative_trapezoid(y, x=None, *, dx=None, dim=-1):
     y = cast_to_ms_tensor(y)
     if y.dtype in (ms.int32, ms.int64):
         y = y.astype(ms.float32)
@@ -3156,20 +3251,28 @@
 
 def triangular_solve(b, A, upper=True, transpose=False, unitriangular=False, *, out=None):
     if is_under_ascend_context():
         raise NotImplementedError("triangular_solve currently not supported on Ascend")
     B = cast_to_ms_tensor(b)
     A = cast_to_ms_tensor(A)
     trans = 'T' if transpose else 'N'
-    solve_op = _get_cache_prim(SolveTriangular)(lower=(not upper), unit_diagonal=unitriangular, trans=trans)
+    solve_op = SolveTriangular(lower=(not upper), unit_diagonal=unitriangular, trans=trans)
     output = solve_op(A, B)
     if pynative_mode_condition():
         triangular_solve_namedtuple = set_multiple_name_tuple('triangular_solve', 'solution, cloned_coefficient')
         output = triangular_solve_namedtuple(cast_to_adapter_tensor(output), cast_to_adapter_tensor(A))
         return output
     output = (output, A)
     return _out_inplace_assign(out, output, "triangular_solve")
 
 def relu(input, *, out=None):
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.relu(input_ms)
     return _out_inplace_assign(out, output, "relu")
+
+def scalar_tensor(s, **kwargs):
+    if "dtype" in kwargs:
+        dtype = kwargs.get("dtype")
+    else:
+        dtype = ms.float32
+    scalar = ms.Tensor(s, dtype=dtype)
+    return cast_to_adapter_tensor(scalar)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/fx/proxy.py` & `mindtorch-0.3.0/mindtorch/torch/fx/proxy.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/jit/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/jit/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -33,10 +33,11 @@
 
     return decorator
 
 def _overload_method(func):
     unsupported_attr(func)
     warning("`jit._overload_method` is an empty function that has not implemented now.")
 
+
 def interface(obj):
     unsupported_attr(obj)
     warning("`jit.interface` is an empty function that has not implemented now.")
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/library.py` & `mindtorch-0.3.0/mindtorch/torch/library.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/linalg/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/linalg/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/linalg/linalg.py` & `mindtorch-0.3.0/mindtorch/torch/linalg/linalg.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 
 import mindspore as ms
 from mindspore.ops.primitive import _primexpr
-from mindspore.ops._primitive_cache import _get_cache_prim
-from mindspore.scipy.ops import SolveTriangular
+try:
+    from mindspore.scipy.ops import SolveTriangular# not support on win cpu
+except ImportError:
+    ...
 from mindtorch.torch.common._inner import _out_inplace_assign
 from mindtorch.utils import unsupported_attr, pynative_mode_condition, \
                              is_under_gpu_context, is_under_ascend_context, set_multiple_name_tuple
 from mindtorch.torch.tensor import cast_to_ms_tensor, cast_to_adapter_tensor, custom_matmul
 from mindtorch.torch.tensor import Tensor as adapter_tensor
 from mindtorch.torch.common.dtype import finfo
 import mindtorch.torch._register_numpy_primitive  as numpy_cell
@@ -146,14 +148,18 @@
     x, residuals, rank, s = lstsq_op(a, b)
     rank = int(rank)
     return _out_inplace_assign(out, (x, residuals, rank, s), "lstsq")
 
 def qr(input, mode="reduced", *, out=None):
     input_ms = cast_to_ms_tensor(input)
     output = ms.ops.qr(input_ms, mode)
+    if pynative_mode_condition():
+        qr_namedtuple = set_multiple_name_tuple('qr', 'Q, R')
+        output = qr_namedtuple(cast_to_adapter_tensor(output[0]), cast_to_adapter_tensor(output[1]))
+        return output
     return _out_inplace_assign(out, output, "qr")
 
 def vander(x, N=None, *, out=None):
     x = cast_to_ms_tensor(x)
     #TODO: ms.ops.vander() result == increasing=False
     output = ms.numpy.vander(x, N, increasing=True)
     return _out_inplace_assign(out, output, "vander")
@@ -238,14 +244,16 @@
     output = output.astype(A.dtype)
     return _out_inplace_assign(out, output, "norm")
 
 def vector_norm(A, ord=2, dim=None, keepdim=False, *, dtype=None, out=None):
     A = cast_to_ms_tensor(A)
     if dim is None:
         A = A.flatten()
+    if isinstance(dim, list):
+        dim = tuple(dim)
     output = ms.ops.norm(A, ord=ord, dim=dim, keepdim=keepdim, dtype=dtype)
     return _out_inplace_assign(out, output, "vector_norm")
 
 @_primexpr
 # @lru_cache(_GLOBAL_LRU_CACHE_SIZE)
 def _check_vecdot_input_validity(x, y, dim):
     if not isinstance(x, adapter_tensor) or not isinstance(y, adapter_tensor):
@@ -302,15 +310,15 @@
 def solve_triangular(A, B, *, upper, left=True, unitriangular=False, out=None):
     if is_under_ascend_context():
         raise NotImplementedError("solve_triangular currently not supported on Ascend")
     if not left:
         raise NotImplementedError("Currently only support left equals to True")
     A = cast_to_ms_tensor(A)
     B = cast_to_ms_tensor(B)
-    solve_op = _get_cache_prim(SolveTriangular)(lower=(not upper), unit_diagonal=unitriangular)
+    solve_op = SolveTriangular(lower=(not upper), unit_diagonal=unitriangular)
     output = solve_op(A, B)
     return _out_inplace_assign(out, output, "solve_triangular")
 
 def cond(A, p=None, *, out=None):
     A = cast_to_ms_tensor(A)
     if A.dtype in (ms.float64, ms.complex128):
         output = ms.ops.cond(A, p).astype(ms.float64)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/logging.py` & `mindtorch-0.3.0/mindtorch/torch/logging.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 import os
 import logging
 import threading
+from functools import lru_cache
 from mindspore.ops.primitive import constexpr
+from mindtorch.utils import _GLOBAL_LRU_CACHE_SIZE_NN
 
 logging_level = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL]
 
 
 MSA_GLOBAL_LOGGER=None
 # The lock for setting up the logger
 _setup_logger_lock = threading.Lock()
 
 
 def _setup_logger():
-    level = logging.ERROR
+    level = logging.WARNING
     _MSA_LOG_ENV = os.environ.get('MSA_LOG')
     if _MSA_LOG_ENV:
         try:
             msa_log_level = int(_MSA_LOG_ENV)
             level = logging_level[msa_log_level]
         except:
             raise ValueError(
@@ -66,14 +68,15 @@
 
 
 @constexpr
 def info(msg, *args, **kwargs):
     _get_logger().info(msg, *args, **kwargs)
 
 
+@lru_cache(_GLOBAL_LRU_CACHE_SIZE_NN)
 @constexpr
 def warning(msg, *args, **kwargs):
     _get_logger().warning(msg, *args, **kwargs)
 
 
 @constexpr
 def error(msg, *args, **kwargs):
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/multiprocessing/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/multiprocessing/__init__.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,18 @@
 import sys
-import multiprocessing
+
+try:
+    from mindspore.multiprocessing import *
+    import mindspore.multiprocessing as multiprocessing
+except ImportError:
+    from multiprocessing import *
+    import multiprocessing
 
 __all__ = ['set_sharing_strategy', 'get_sharing_strategy',
            'get_all_sharing_strategies']
-
 __all__ += multiprocessing.__all__  # type: ignore[attr-defined]
 
 from .spawn import spawn, SpawnContext, start_processes, ProcessContext, \
     ProcessRaisedException, ProcessExitedException
 
 if sys.platform == 'darwin' or sys.platform == 'win32':
     _sharing_strategy = 'file_system'
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/multiprocessing/spawn.py` & `mindtorch-0.3.0/mindtorch/torch/multiprocessing/spawn.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/functional.py` & `mindtorch-0.3.0/mindtorch/torch/nn/functional.py`

 * *Files 1% similar despite different names*

```diff
@@ -109,29 +109,35 @@
     'prompt_flash_attention'
 ]
 
 
 def adaptive_avg_pool1d(input, output_size):
     input_ms = cast_to_ms_tensor(input)
     input_ms = input_ms.expand_dims(-1)
-    if isinstance(output_size, int):
+    if isinstance(output_size, list):
+        output_size = tuple(output_size)
+    elif isinstance(output_size, int):
         output_size = (output_size, 1)
     else:
         output_size = output_size + (1,)
     output = ms.ops.adaptive_avg_pool2d(input_ms, output_size)
     output = output.squeeze(-1)
     return cast_to_adapter_tensor(output)
 
 def adaptive_avg_pool2d(input, output_size):
     input_ms = cast_to_ms_tensor(input)
+    if isinstance(output_size, list):
+        output_size = tuple(output_size)
     output = ms.ops.adaptive_avg_pool2d(input_ms, output_size)
     return cast_to_adapter_tensor(output)
 
 def adaptive_avg_pool3d(input, output_size):
     input_ms = cast_to_ms_tensor(input)
+    if isinstance(output_size, list):
+        output_size = tuple(output_size)
     output = ms.ops.adaptive_avg_pool3d(input_ms, output_size)
     return cast_to_adapter_tensor(output)
 
 def adaptive_max_pool1d(input, output_size, return_indices=False):
     # There is bug in ms.ops.adaptive_max_pool2d when return_indices==True on Ascend.
     if return_indices and is_under_ascend_context():
         raise NotImplementedError('adaptive_max_pool1d doesn\'t  support return_indices on Ascend now.')
@@ -139,15 +145,17 @@
     input_ms = cast_to_ms_tensor(input)
     input_shpae = input_ms.shape
     ndim = input_ms.ndim
     input_type = input_ms.dtype
     if is_under_ascend_context():
         input_ms = input_ms.astype(ms.float16)
 
-    if isinstance(output_size, int):
+    if isinstance(output_size, list):
+        output_size = tuple(output_size)
+    elif isinstance(output_size, int):
         output_size = (output_size, 1)
     else:
         output_size = output_size + (1,)
 
     # TODO: On ascend, adaptive_max_pool2d not support 3D input yet. After supported, delete code below
     min_ndim = 2
     max_ndim = 3
@@ -175,14 +183,16 @@
     else:
         output = output.squeeze(-1)
     return cast_to_adapter_tensor(output)
 
 def adaptive_max_pool2d(input, output_size, return_indices=False):
     input_ms = cast_to_ms_tensor(input)
     input_type = input_ms.dtype
+    if isinstance(output_size, list):
+        output_size = tuple(output_size)
     if is_under_ascend_context():
         input_ms = input_ms.astype(ms.float16)
         output = ms.ops.adaptive_max_pool2d(input_ms, output_size, return_indices)
         if input_type != ms.float16:
             if not return_indices:
                 output = output.astype(input_type)
             else:
@@ -221,14 +231,16 @@
     kernel_w = w - (out_w - 1) * stride_w
 
     return kernel_d, kernel_h, kernel_w, stride_d, stride_h, stride_w
 
 def adaptive_max_pool3d(input, output_size, return_indices=False):
     input_ms = cast_to_ms_tensor(input)
     input_shape = ms.ops.shape(input_ms)
+    if isinstance(output_size, list):
+        output_size = tuple(output_size)
     _output_size = _get_adaptive_max_pool3d_output_size(input_shape, output_size)
     if is_under_ascend_context():
         ndim = input_ms.ndim
         if ndim == 4:
             input_ms = input_ms.expand_dims(0)
         input_shape = input_ms.shape
         # TODO: Ascend not support ms.ops.adaptive_max_pool3d, use MaxPool3D instead
@@ -572,23 +584,29 @@
     if size_average and reduce:
         ret = 'mean'
     elif reduce:
         ret = 'sum'
     else:
         ret = 'none'
 
-    warning_msg = "size_average and reduce args will be deprecated, please use reduction='{}' instead."
+    warning_msg = "For loss function, `size_average` and `reduce` args will be deprecated, " \
+                  "please use reduction='{}' instead."
     warning(warning_msg.format(ret))
     return ret
 
 
 def smooth_l1_loss(input, target, size_average=None, reduce=None, reduction='mean', beta=1.0):
     if reduce is not None or size_average is not None:
         reduction = _get_reduce_string(size_average, reduce)
 
+    if reduction == 'elementwise_mean':
+        warning_msg = "reduction='elementwise_mean' is deprecated, please use reduction='mean' instead."
+        warning(warning_msg)
+        reduction = 'mean'
+
     input_ms = cast_to_ms_tensor(input)
     target = cast_to_ms_tensor(target)
     output = ms.ops.smooth_l1_loss(input_ms, target, beta, reduction)
     return cast_to_adapter_tensor(output)
 
 def l1_loss(input, target, size_average=None, reduce=None, reduction="mean"):
     """
@@ -624,15 +642,14 @@
         reduction = _get_reduce_string(size_average, reduce)
 
     input_ms = cast_to_ms_tensor(input)
     target = cast_to_ms_tensor(target)
     #TODO: mindspore currently not support int64
     target_dtype = target.dtype
     if target_dtype in all_int_type:
-        warning("cross_entropy: when target type is int64, there is risk of overflow.")
         target = target.astype(ms.int32)
     weight = cast_to_ms_tensor(weight)
     # unsupport float64
     result = ms.ops.cross_entropy(input_ms, target, weight, ignore_index, reduction, label_smoothing)
     return cast_to_adapter_tensor(result)
 
 def ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean', zero_infinity=False):
@@ -766,21 +783,14 @@
     if size_average is not None or reduce is not None:
         reduction = _get_reduce_string(size_average, reduce)
 
     input_ms = cast_to_ms_tensor(input)
     target = cast_to_ms_tensor(target)
     weight = cast_to_ms_tensor(weight)
     pos_weight = cast_to_ms_tensor(pos_weight)
-    # TODO: ms.ops.binary_cross_entropy_with_logits do not accept `weight` and `pos_weight` to be None
-    if weight is None or pos_weight is None:
-        ones_input = ms.ops.ones_like(input_ms, dtype=ms.float32)
-        if weight is None:
-            weight = ones_input
-        if pos_weight is None:
-            pos_weight = ones_input
     # unsupport float64
     result = ms.ops.binary_cross_entropy_with_logits(input_ms, target, weight, pos_weight, reduction)
     return cast_to_adapter_tensor(result)
 
 
 @_primexpr
 # @lru_cache(_GLOBAL_LRU_CACHE_SIZE_NN)
@@ -865,23 +875,24 @@
 
 def cosine_similarity(x1, x2, dim=1, eps=1e-08):
     x1 = cast_to_ms_tensor(x1)
     x2 = cast_to_ms_tensor(x2)
     if x1.shape == x2.shape:
         out = ms.ops.cosine_similarity(x1, x2, dim, eps)
         return cast_to_adapter_tensor(out)
+    #TODO: broadcast of input is not supported in ms.ops.cosine_similarity.
     broadcast_shape = get_broadcast_shape(x1.shape, x2.shape)
     x1 = ms.ops.broadcast_to(x1, broadcast_shape)
     x2 = ms.ops.broadcast_to(x2, broadcast_shape)
     out = ms.ops.cosine_similarity(x1, x2, dim, eps)
     return cast_to_adapter_tensor(out)
 
 
 def pdist(input, p=2):
-    #TODO: ms.ops.pdist is not on Ascend.
+    #TODO: ms.ops.pdist is not on Ascend. When input is float64, there is a risk of data truncation.
     if is_under_ascend_context():
         inp_dim = input.dim()
         if inp_dim != 2:
             raise RuntimeError(f"pdist only supports 2D tensors, got: {inp_dim}D")
         if p < 0:
             raise RuntimeError("pdist only supports non-negative p values")
 
@@ -894,15 +905,14 @@
         if p > 0:
             norm = ms.ops.pow(norm, 1.0/p)
         select = np.ones([n, n])
         select = np.triu(select, 1).astype(np.bool8)
         select_t = ms.Tensor(select)
         out = ms.ops.masked_select(norm, select_t)
         if input_ms.dtype == ms.float64:
-            warning("pdist: when input is float64, there is risk that the data will be truncated.")
             out = out.astype(input_ms.dtype)
     else:
         input_ms = cast_to_ms_tensor(input)
         out = ms.ops.pdist(input_ms, float(p))
     return cast_to_adapter_tensor(out)
 
 @_primexpr
@@ -1139,14 +1149,16 @@
     size_average=None,
     reduce=None,
     reduction="mean",
 ):
     if size_average is not None or reduce is not None:
         reduction = _get_reduce_string(size_average, reduce)
 
+    p = int(p)
+
     if is_under_gpu_context():
         anchor, positive, negative = cast_to_ms_tensor((anchor, positive, negative))
         ndim = anchor.ndim
         #TODO: ms.ops.triplet_margin_loss only on GPU, and not support 1D input.
         if ndim == 1:
             anchor = anchor.expand_dims(0)
             positive = positive.expand_dims(0)
@@ -1176,15 +1188,21 @@
     reduction="mean",
 ):
     if size_average is not None or reduce is not None:
         reduction = _get_reduce_string(size_average, reduce)
 
     input_ms = cast_to_ms_tensor(input)
     target = cast_to_ms_tensor(target)
-    weight = cast_to_ms_tensor(weight)
+
+    # TODO: ms 2.3 P.MultiMarginLoss weight can not be none
+    # weight = cast_to_ms_tensor(weight)
+    if weight is None:
+        weight = ms.ops.ones(input_ms.shape[-1], dtype=input_ms.dtype)
+    else:
+        weight = cast_to_ms_tensor(weight)
 
     #TODO: 'margin' in ms.ops.multi_margin_loss must be int, but ops.MultiMarginLoss must be float.
     margin = float(margin)
     loss = _get_cache_prim(ms.ops.MultiMarginLoss)(p, margin, reduction)
 
     #`input` in ms.ops.MultiMarginLoss only support (N,C), unsupport (C)
     ndim = input_ms.ndim
@@ -1549,15 +1567,15 @@
     if isinstance(stride, int):
         stride = (stride, stride)
     elif len(stride)==1:
         stride = (stride[0], stride[0])
     pad_mode = "pad"
     if isinstance(padding, int):
         padding = (padding, padding)
-    elif isinstance(padding, tuple):
+    elif isinstance(padding, (tuple, list)):
         if len(padding)==1:
             padding = (padding[0], padding[0])
 
     else:
         pad_mode = padding
         padding = 0
     if isinstance(dilation, int):
@@ -1742,23 +1760,19 @@
         shape_out = shape_out + input_shape[:-1]
     if weight_rank == 2:
         shape_out = shape_out + (weight_shape[0],)
     return shape_out
 
 @_primexpr
 # @lru_cache(_GLOBAL_LRU_CACHE_SIZE_NN)
-def _check_linear_shape(weight_rank, input_shape, weight_shape):
+def _check_linear_shape(weight_rank):
     if weight_rank not in (1, 2):
         raise ValueError("For nn.functional.linear, weight only support 2D or 1D input"
                             f"but got {weight_rank}D input")
 
-    if input_shape[-1] != weight_shape[-1]:
-        raise ValueError("For nn.functional.linear, size mismatch,"
-                            f"got input with shape {input_shape}, and weight with shape {weight_shape}.")
-
 def linear(input, weight, bias=None):
     input_ms = cast_to_ms_tensor(input)
 
     dtype_op = _get_cache_prim(ms.ops.DType)()
     rank_op = _get_cache_prim(ms.ops.Rank)()
     shape_op = _get_cache_prim(ms.ops.Shape)()
     reshape_op = _get_cache_prim(ms.ops.Reshape)()
@@ -1768,15 +1782,15 @@
     dtype2 = dtype_op(weight)
     if not _check_same_type(dtype1, dtype2):
         input_ms = input_ms.astype(ms.float32)
         weight = weight.astype(ms.float32)
 
     input_rank, weight_rank = rank_op(input_ms), rank_op(weight)
     input_shape, weight_shape = shape_op(input_ms), shape_op(weight)
-    _check_linear_shape(weight_rank, input_shape, weight_shape)
+    _check_linear_shape(weight_rank)
 
     # infers the shape of the output
     shape_out = _get_linear_output_shape(input_shape, weight_shape, input_rank, weight_rank)
 
     _matmul = _get_cache_prim(ms.ops.MatMul)(False, True)
 
     input_ms = _expand(input_ms, 2)
@@ -2116,20 +2130,16 @@
 def _get_conv_transpose1d_channel(input_shape, weight_shape, groups):
     in_channel = input_shape[1]
     out_channel = weight_shape[1] * groups
     kernel_size = weight_shape[2]
     return in_channel, out_channel, kernel_size
 
 @_primexpr
-def _get_conv_transpose1d_pad_mode(kernel_size, stride, padding, output_padding):
-    if stride != 1 and padding == (kernel_size - 1) // 2 and output_padding == stride - 1:
-        pad_mode = 'same'
-        padding = 0
-        raise Warning("pad_mode = same is some thing wrong, please switch to others")
-    elif padding == 0 and output_padding == 0:
+def _get_conv_transpose1d_pad_mode(padding, output_padding):
+    if padding == 0 and output_padding == 0:
         pad_mode = 'valid'
         padding = 0
     else:
         pad_mode = 'pad'
     return pad_mode, padding
 
 @_primexpr
@@ -2158,15 +2168,15 @@
         raise ValueError("the rank of weight tensor should be 3")
 
     input_shape = x.shape
     weight_shape = weight.shape
     in_channel, out_channel, kernel_size = \
                 _get_conv_transpose1d_channel(input_shape, weight_shape, groups)
     _pad_mode, padding = \
-                _get_conv_transpose1d_pad_mode(kernel_size, stride, padding, output_padding)
+                _get_conv_transpose1d_pad_mode(padding, output_padding)
 
     _kernel_size, _stride, _dilation, _padding = \
                 _process_conv_transpose1d_const(kernel_size, stride, dilation, padding)
 
     _conv2d_transpose = _get_cache_prim(ms.ops.Conv2DBackpropInput)(out_channel=in_channel,
                                                                     kernel_size=_kernel_size,
                                                                     mode=1,
@@ -2629,16 +2639,16 @@
     output = ms.ops.fold(input_ms, ms.Tensor(output_size, dtype=ms.int32), kernel_size, dilation, padding, stride)
     if ndim == 2:
         output = output.squeeze(0)
     return cast_to_adapter_tensor(output)
 
 def multi_head_attention_forward(query, key, value, embed_dim_to_check, num_heads, in_proj_weight,
                                  in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight,
-                                 out_proj_bias, training=True, key_padding_mask=None, attn_mask=None,
-                                 use_separate_proj_weight=False, q_proj_weight=None, k_proj_weight=None,
+                                 out_proj_bias, training=True, key_padding_mask=None, need_weights=True,
+                                 attn_mask=None, use_separate_proj_weight=False, q_proj_weight=None, k_proj_weight=None,
                                  v_proj_weight=None, static_k=None, static_v=None, average_attn_weights=True,
                                  k_is_v=False, q_is_k=False):
     query = cast_to_ms_tensor(query)
     key = cast_to_ms_tensor(key)
     value = cast_to_ms_tensor(value)
     key_padding_mask = cast_to_ms_tensor(key_padding_mask)
     attn_mask = cast_to_ms_tensor(attn_mask)
@@ -2655,33 +2665,42 @@
     out_proj_bias = ms.ops.Identity()(out_proj_bias) if out_proj_bias is not None else None
     q_proj_weight = ms.ops.Identity()(q_proj_weight) if q_proj_weight is not None else None
     k_proj_weight = ms.ops.Identity()(k_proj_weight) if k_proj_weight is not None else None
     v_proj_weight = ms.ops.Identity()(v_proj_weight) if v_proj_weight is not None else None
     # TODO: older ver of torch doesn't have is_causal arg
     attn_output, attn_output_weights = ms.ops.function.nn_func.multi_head_attention_forward(
         query, key, value, embed_dim_to_check, num_heads,
-        in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p,
+        in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, float(dropout_p),
         out_proj_weight, out_proj_bias, training=training,
         key_padding_mask=key_padding_mask, attn_mask=attn_mask,
         use_separate_proj_weight=use_separate_proj_weight,
         q_proj_weight=q_proj_weight, k_proj_weight=k_proj_weight,
         v_proj_weight=v_proj_weight, static_k=static_k, static_v=static_v,
         average_attn_weights=average_attn_weights, k_is_v=k_is_v, q_is_k=q_is_k)
-    return cast_to_adapter_tensor(attn_output), cast_to_adapter_tensor(attn_output_weights)
+    if need_weights:
+        return cast_to_adapter_tensor(attn_output), cast_to_adapter_tensor(attn_output_weights)
+    return cast_to_adapter_tensor(attn_output), None
 
 def channel_shuffle(inputs, groups):
     x = cast_to_ms_tensor(inputs)
     x_shape = x.shape
     n, c = x_shape[0], x_shape[1]
     out = ms.ops.reshape(x, (n, groups, c // groups, -1))
     out = ms.ops.transpose(out, (0, 2, 1, 3))
     out = ms.ops.reshape(out, x_shape)
     return cast_to_adapter_tensor(out)
 
 
+def has_torch_function(*args, **kwargs):
+    unsupported_attr(args)
+    unsupported_attr(kwargs)
+    warning("Currently, `has_torch_function` is always return Flase, please be aware the risk of use.")
+    return False
+
+
 _pad_func = pad
 def constant_pad_nd(input, pad, value=0):
     return _pad_func(input, pad, 'constant', value)
 
 # TODO: Use the following code to accelerate
 #  @ms.jit
 #  @ms.trace
@@ -2721,32 +2740,27 @@
     if dropout_p != 0.:
         attn_weight = ms.ops.dropout(attn_weight, p=dropout_p)
     output = attn_weight @ value_ms
     return cast_to_adapter_tensor(output)
 
 # No corresponding api in pytorch, just using api prompt_flash_attention internally.
 # prompt_flash_attention only support on Ascend.
-def prompt_flash_attention(query, key, value, attn_mask=None,
-                           actual_seq_lengths=None, actual_seq_lengths_kv=None, padding_mask=None,
-                           dep_scale1=None, quant_scale1=None,
-                           deq_scale2=None, quant_scale2=None, quant_offset2=None,
-                           num_heads=0, scale_value=1.0,
+def prompt_flash_attention(query, key, value, attn_mask=None, padding_mask=None,
+                           actual_seq_lengths=None, num_heads=0, scale_value=1.0,
                            pre_tokens=2147483547, next_tokens=0, input_layout='BSH',
-                           num_key_value_heads=0, sparse_mode=0):
+                           num_key_value_heads=0):
     query_ms = cast_to_ms_tensor(query)
     key_ms = cast_to_ms_tensor(key)
     value_ms = cast_to_ms_tensor(value)
     if attn_mask is not None:
         attn_mask = cast_to_ms_tensor(attn_mask)
     if padding_mask is not None:
         padding_mask = cast_to_ms_tensor(padding_mask)
     if actual_seq_lengths is not None:
         actual_seq_lengths = cast_to_ms_tensor(actual_seq_lengths)
-    pfa_op = PromptFlashAttention(num_heads, scale_value=scale_value,
+    pfa_op = PromptFlashAttention(num_heads=num_heads, scale_value=scale_value,
                                   pre_tokens=pre_tokens, next_tokens=next_tokens,
                                   input_layout=input_layout,
-                                  num_key_value_heads=num_key_value_heads,
-                                  sparse_mode=sparse_mode)
-    output_ms = pfa_op(query_ms, key_ms, value_ms, attn_mask, actual_seq_lengths, actual_seq_lengths_kv,
-                       padding_mask, dep_scale1, quant_scale1, deq_scale2, quant_scale2, quant_offset2)
-    pfa_output = cast_to_adapter_tensor(output_ms[0])
+                                  num_key_value_heads=num_key_value_heads)
+    output_ms = pfa_op(query_ms, key_ms, value_ms, attn_mask, padding_mask, actual_seq_lengths)
+    pfa_output = cast_to_adapter_tensor(output_ms)
     return pfa_output
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/__init__.py`

 * *Files 12% similar despite different names*

```diff
@@ -174,9 +174,23 @@
 
     'ChannelShuffle',
 
     'TransformerEncoderLayer',
     'TransformerDecoderLayer',
     'TransformerEncoder',
     'TransformerDecoder',
-    'Transformer'
+    'Transformer',
+
+    'LazyLinear',
+    'LazyConv1d',
+    'LazyConv2d',
+    'LazyConv3d',
+    'LazyConvTranspose1d',
+    'LazyConvTranspose2d',
+    'LazyConvTranspose3d',
+    'LazyBatchNorm1d',
+    'LazyBatchNorm2d',
+    'LazyBatchNorm3d',
+    'LazyInstanceNorm1d',
+    'LazyInstanceNorm2d',
+    'LazyInstanceNorm3d',
 ]
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/activation.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/activation.py`

 * *Files 1% similar despite different names*

```diff
@@ -516,33 +516,32 @@
             attn_output, attn_output_weights = ms_torch_nn_func.multi_head_attention_forward(
                 query, key, value, self.embed_dim, self.num_heads,
                 self.in_proj_weight, self.in_proj_bias,
                 self.bias_k, self.bias_v, self.add_zero_attn,
                 self.dropout, self.out_proj.weight, self.out_proj.bias,
                 training=self.training,
                 key_padding_mask=key_padding_mask,
-                attn_mask=attn_mask, use_separate_proj_weight=True,
+                need_weights=need_weights, attn_mask=attn_mask, use_separate_proj_weight=True,
                 q_proj_weight=self.q_proj_weight, k_proj_weight=self.k_proj_weight,
                 v_proj_weight=self.v_proj_weight, average_attn_weights=average_attn_weights,
                 k_is_v=self.k_is_v, q_is_k=self.q_is_k)
         else:
             attn_output, attn_output_weights = ms_torch_nn_func.multi_head_attention_forward(
                 query, key, value, self.embed_dim, self.num_heads,
                 self.in_proj_weight, self.in_proj_bias,
                 self.bias_k, self.bias_v, self.add_zero_attn,
                 self.dropout, self.out_proj.weight, self.out_proj.bias,
                 training=self.training,
                 key_padding_mask=key_padding_mask,
-                attn_mask=attn_mask, average_attn_weights=average_attn_weights,
+                need_weights=need_weights, attn_mask=attn_mask, average_attn_weights=average_attn_weights,
                 k_is_v=self.k_is_v, q_is_k=self.q_is_k)
         if self.batch_first and is_batched:
-            attn_output = attn_output.swapaxes(1, 0)
-        if need_weights:
-            return cast_to_adapter_tensor(attn_output), cast_to_adapter_tensor(attn_output_weights)
-        return (cast_to_adapter_tensor(attn_output),)
+            return attn_output.swapaxes(1, 0), attn_output_weights
+        else:
+            return attn_output, attn_output_weights
 
 class PReLU(Module):
     def __init__(self, num_parameters=1, init=0.25, device=None, dtype=None):
         super(PReLU, self).__init__()
         unsupported_attr(device)
         validator.check_positive_int(num_parameters, 'num_parameters', self.cls_name)
         dtype = _dtype_or_default(dtype)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/adaptive.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/adaptive.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/batchnorm.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/batchnorm.py`

 * *Files 12% similar despite different names*

```diff
@@ -4,25 +4,25 @@
 
 import mindspore.ops as P
 from mindspore.ops.operations import _inner_ops as inner
 from mindspore.communication.management import get_group_size, get_rank
 import mindspore._checkparam as validator
 from mindspore.communication import management
 import mindspore.context as context
-
 from mindtorch.torch.nn import init
 from mindtorch.torch.functional import empty
-from mindtorch.torch.nn.parameter import Parameter
+from mindtorch.torch.nn.parameter import Parameter, UninitializedParameter
 from mindtorch.utils import unsupported_attr
 from mindtorch.torch.tensor import cast_to_ms_tensor, cast_to_adapter_tensor, tensor, Tensor
 from .module import Module
+from .lazy import LazyModuleMixin
 
 
-__all__ = ['BatchNorm1d', 'BatchNorm2d', 'BatchNorm3d',
-           'SyncBatchNorm']
+__all__ = ['BatchNorm1d', 'BatchNorm2d', 'BatchNorm3d', 'SyncBatchNorm', 'LazyBatchNorm1d',
+           'LazyBatchNorm2d', 'LazyBatchNorm3d']
 
 class _NormBase(Module):
     """Common base of _InstanceNorm and _BatchNorm"""
     def __init__(
         self,
         num_features,
         eps=1e-5,
@@ -130,17 +130,18 @@
         device=None,
         dtype=None
     ):
         factory_kwargs = {'device': device, 'dtype': dtype}
         super(_BatchNorm, self).__init__(num_features, eps, momentum, affine, track_running_stats, **factory_kwargs)
 
         #TODO: currently momentum only support float input
+        self.momentum = float(self.momentum) if self.momentum else 0.0
         self.bn_train = P.BatchNorm(is_training=True,
                                     epsilon=self.eps,
-                                    momentum=float(self.momentum),
+                                    momentum=self.momentum,
                                     data_format='NCHW')
 
         self.bn_infer = P.BatchNorm(is_training=False, epsilon=self.eps, data_format='NCHW')
 
     def _check_input_dim(self, input):
         raise NotImplementedError
 
@@ -353,7 +354,73 @@
 
     def _check_input_dim(self, input):
         if len(input.shape) < 4:
             raise ValueError(
                 "expected at least 2D input (got {}D input)".format(input.dim())
             )
         return True
+
+
+class _LazyNormBase(LazyModuleMixin, _NormBase):
+    def __init__(self, eps=1e-5, momentum=0.1, affine=True, track_running_stats=True,
+                 device=None, dtype=None):
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super(_LazyNormBase, self).__init__(
+            1,
+            eps,
+            momentum,
+            affine,
+            track_running_stats,
+            **factory_kwargs,
+        )
+        self.weight = UninitializedParameter(**factory_kwargs)
+        self.bias = UninitializedParameter(**factory_kwargs)
+        self.running_mean = UninitializedParameter(requires_grad=False, **factory_kwargs)
+        self.running_var = UninitializedParameter(requires_grad=False, **factory_kwargs)
+        self.register_buffer('running_mean', self.running_mean)
+        self.register_buffer('running_var', self.running_var)
+
+    def reset_parameters(self) -> None:
+        if not self.has_uninitialized_params() and self.num_features != 0:
+            super().reset_parameters()
+
+    def initialize_parameters(self, input):
+        if self.has_uninitialized_params():
+            self.num_features = input.shape[1]
+            assert isinstance(self.weight, UninitializedParameter)
+            assert isinstance(self.bias, UninitializedParameter)
+            assert isinstance(self.running_mean, UninitializedParameter)
+            assert isinstance(self.running_var, UninitializedParameter)
+            self.weight.materialize((self.num_features,))
+            self.bias.materialize((self.num_features,))
+            self.running_mean.materialize((self.num_features,))
+            self.running_var.materialize((self.num_features,))
+            self.reset_parameters()
+
+
+class LazyBatchNorm1d(_LazyNormBase, _BatchNorm):
+
+    cls_to_become = BatchNorm1d
+
+    def _check_input_dim(self, input):
+        if input.dim() != 2 and input.dim() != 3:
+            raise ValueError(
+                "expected 2D or 3D input (got {}D input)".format(input.dim())
+            )
+
+
+class LazyBatchNorm2d(_LazyNormBase, _BatchNorm):
+
+    cls_to_become = BatchNorm2d
+
+    def _check_input_dim(self, input):
+        if input.dim() != 4:
+            raise ValueError("expected 4D input (got {}D input)".format(input.dim()))
+
+
+class LazyBatchNorm3d(_LazyNormBase, BatchNorm3d):
+
+    cls_to_become = BatchNorm3d
+
+    def _check_input_dim(self, input):
+        if input.dim() != 5:
+            raise ValueError("expected 5D input (got {}D input)".format(input.dim()))
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/channelshuffle.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/channelshuffle.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/container.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/container.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/conv.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/conv.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,27 +1,29 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 import math
 # from functools import lru_cache
 
 import mindspore as ms
 from mindspore.ops.primitive import _primexpr
-
-from mindtorch.torch.nn.parameter import Parameter
+from mindspore.ops._primitive_cache import _get_cache_prim
+from mindtorch.torch.nn.parameter import Parameter, UninitializedParameter
 from mindtorch.torch.nn import init
 from mindtorch.torch.functional import empty
 from mindtorch.utils import unsupported_attr
 from mindtorch.torch.tensor import cast_to_ms_tensor, cast_to_adapter_tensor
 from mindtorch.torch.nn.functional import conv2d, conv_transpose3d, conv1d, conv3d, \
                                             _deconv_output_length, _process_conv_transpose1d_const
 from .utils import _triple, _pair, _single, _reverse_repeat_tuple
 from .module import Module
+from .lazy import LazyModuleMixin
 
-__all__ = ['Conv1d', 'Conv2d', 'Conv3d',
-           'ConvTranspose1d', 'ConvTranspose2d', 'ConvTranspose3d']
+__all__ = ['Conv1d', 'Conv2d', 'Conv3d', 'ConvTranspose1d', 'ConvTranspose2d', 'ConvTranspose3d',
+           'LazyConv1d', 'LazyConv2d', 'LazyConv3d', 'LazyConvTranspose1d', 'LazyConvTranspose2d',
+           'LazyConvTranspose3d']
 
 
 class _ConvNd(Module):
     def __init__(self,
                  in_channels,
                  out_channels,
                  kernel_size,
@@ -397,59 +399,60 @@
 
         self._ms_pad_mode = _pad_mode
         self._ms_kernel_size = _kernel_size
         self._ms_stride = _stride
         self._ms_dilation = _dilation
         self._ms_padding = _padding
 
-        self._conv_transpose2d = ms.ops.Conv2DBackpropInput(out_channel=self.in_channels,
-                                                            kernel_size=_kernel_size,
-                                                            mode=1,
-                                                            pad_mode=_pad_mode,
-                                                            pad=_padding,
-                                                            stride=_stride,
-                                                            dilation=_dilation,
-                                                            group=groups)
         self._bias_add = ms.ops.BiasAdd()
         self._expand_dims = ms.ops.ExpandDims()
         self._squeeze_0 = ms.ops.Squeeze(0)
         self._squeeze_2 = ms.ops.Squeeze(2)
         self._shape = ms.ops.Shape()
 
     def forward(self, input, output_size=None):
         # TODO: to support `output_size`
         if output_size is not None:
             raise ValueError("output_size '{}' is not currently supported.".format(output_size))
 
+        _conv_transpose2d = _get_cache_prim(ms.ops.Conv2DBackpropInput)(out_channel=self.in_channels,
+                                                                        kernel_size=self._ms_kernel_size,
+                                                                        mode=1,
+                                                                        pad_mode=self._ms_pad_mode,
+                                                                        pad=self._ms_padding,
+                                                                        stride=self._ms_stride,
+                                                                        dilation=self._ms_dilation,
+                                                                        group=self.groups)
+
         x = cast_to_ms_tensor(input)
         ndim = x.ndim
         _weight = self._expand_dims(self.weight, 2)
         if ndim == 2:
             x = self._expand_dims(x, 0)
             x = self._expand_dims(x, 2)
             n, _, h, w = self._shape(x)
 
             h_out = _deconv_output_length(self._ms_pad_mode, h, self._ms_kernel_size[0], self._ms_stride[0],
                                           self._ms_dilation[0], self._ms_padding[0] + self._ms_padding[1])
             w_out = _deconv_output_length(self._ms_pad_mode, w, self._ms_kernel_size[1], self._ms_stride[1],
                                           self._ms_dilation[1], self._ms_padding[2] + self._ms_padding[3])
-            output = self._conv_transpose2d(x, _weight, (n, self.out_channels, h_out, w_out))
+            output = _conv_transpose2d(x, _weight, (n, self.out_channels, h_out, w_out))
             if self.bias is not None:
                 output = self._bias_add(output, self.bias)
             output = self._squeeze_2(output)
             output = self._squeeze_0(output)
         else:
             x = self._expand_dims(x, 2)
             n, _, h, w = self._shape(x)
 
             h_out = _deconv_output_length(self._ms_pad_mode, h, self._ms_kernel_size[0], self._ms_stride[0],
                                           self._ms_dilation[0], self._ms_padding[0] + self._ms_padding[1])
             w_out = _deconv_output_length(self._ms_pad_mode, w, self._ms_kernel_size[1], self._ms_stride[1],
                                           self._ms_dilation[1], self._ms_padding[2] + self._ms_padding[3])
-            output = self._conv_transpose2d(x, _weight, (n, self.out_channels, h_out, w_out))
+            output = _conv_transpose2d(x, _weight, (n, self.out_channels, h_out, w_out))
             if self.bias is not None:
                 output = self._bias_add(output, self.bias)
             output = self._squeeze_2(output)
         return cast_to_adapter_tensor(output)
 
 
 class ConvTranspose2d(_ConvTransposeNd):
@@ -500,52 +503,53 @@
         if padding == (0, 0):
             _pad_mode = 'valid'
         else:
             _pad_mode = 'pad'
 
         self._ms_padding = (padding[0], padding[0], padding[1], padding[1])
         self._ms_pad_mode = _pad_mode
-        self._conv_transpose2d = ms.ops.Conv2DTranspose(out_channel=self.in_channels,
-                                                        kernel_size=self.kernel_size,
-                                                        mode=1,
-                                                        pad_mode=self._ms_pad_mode,
-                                                        pad=self._ms_padding,
-                                                        stride=self.stride,
-                                                        dilation=self.dilation,
-                                                        group=groups)
         self._bias_add = ms.ops.BiasAdd()
         self._expand_dims = ms.ops.ExpandDims()
         self._squeeze_0 = ms.ops.Squeeze(0)
         self._shape = ms.ops.Shape()
 
     def forward(self, input, output_size=None):
         # TODO: To support output_size after ms.ops.Conv2DTranspose support `out_padding`
         if output_size is not None:
             raise ValueError("output_size '{}' is not currently supported.".format(output_size))
 
+        _conv_transpose2d = _get_cache_prim(ms.ops.Conv2DTranspose)(out_channel=self.in_channels,
+                                                                    kernel_size=self.kernel_size,
+                                                                    mode=1,
+                                                                    pad_mode=self._ms_pad_mode,
+                                                                    pad=self._ms_padding,
+                                                                    stride=self.stride,
+                                                                    dilation=self.dilation,
+                                                                    group=self.groups)
+
         x = cast_to_ms_tensor(input)
         ndim = x.ndim
         if ndim == 3:
             x = self._expand_dims(x, 0)
             n, _, h, w = self._shape(x)
             h_out = _deconv_output_length(self._ms_pad_mode, h, self.kernel_size[0], self.stride[0],
                                           self.dilation[0], self._ms_padding[0] + self._ms_padding[1])
             w_out = _deconv_output_length(self._ms_pad_mode, w, self.kernel_size[1], self.stride[1],
                                           self.dilation[1], self._ms_padding[2] + self._ms_padding[3])
-            output = self._conv_transpose2d(x, self.weight, (n, self.out_channels, h_out, w_out))
+            output = _conv_transpose2d(x, self.weight, (n, self.out_channels, h_out, w_out))
             if self.bias is not None:
                 output = self._bias_add(output, self.bias)
             output = self._squeeze_0(output)
         else:
             n, _, h, w = self._shape(x)
             h_out = _deconv_output_length(self._ms_pad_mode, h, self.kernel_size[0], self.stride[0],
                                           self.dilation[0], self._ms_padding[0] + self._ms_padding[1])
             w_out = _deconv_output_length(self._ms_pad_mode, w, self.kernel_size[1], self.stride[1],
                                           self.dilation[1], self._ms_padding[2] + self._ms_padding[3])
-            output = self._conv_transpose2d(x, self.weight, (n, self.out_channels, h_out, w_out))
+            output = _conv_transpose2d(x, self.weight, (n, self.out_channels, h_out, w_out))
             if self.bias is not None:
                 output = self._bias_add(output, self.bias)
         return cast_to_adapter_tensor(output)
 
 
 class ConvTranspose3d(_ConvTransposeNd):
     r"""
@@ -616,7 +620,298 @@
 
 
 class _ConvTransposeMixin(_ConvTransposeNd):
     def __init__(self, *args, **kwargs):
         unsupported_attr(args)
         unsupported_attr(kwargs)
         raise NotImplementedError("`_ConvTransposeMixin` is not implemented now.")
+
+
+class _LazyConvXdMixin(LazyModuleMixin):
+    def reset_parameters(self):
+        if not self.has_uninitialized_params() and self.in_channels != 0:
+            super().reset_parameters()
+
+    def initialize_parameters(self, input):
+        if self.has_uninitialized_params():
+            self.in_channels = self._get_in_channels(input)
+            if self.in_channels % self.groups != 0:
+                raise ValueError('in_channels must be divisible by groups')
+            assert isinstance(self.weight, UninitializedParameter)
+            if self.transposed:
+                self.weight.materialize((
+                    self.in_channels, self.out_channels // self.groups, *self.kernel_size))
+            else:
+                self.weight.materialize((
+                    self.out_channels, self.in_channels // self.groups, *self.kernel_size))
+            if self.bias is not None:
+                assert isinstance(self.bias, UninitializedParameter)
+                self.bias.materialize((self.out_channels,))
+            self.reset_parameters()
+
+    # Function to extract in_channels from first input.
+    def _get_in_channels(self, input):
+        num_spatial_dims = self._get_num_spatial_dims()
+        num_dims_no_batch = num_spatial_dims + 1  # +1 for channels dim
+        num_dims_batch = num_dims_no_batch + 1
+        if input.dim() not in (num_dims_no_batch, num_dims_batch):
+            raise RuntimeError("Expected {}D (unbatched) or {}D (batched) input to {}, but "
+                               "got input of size: {}".format(num_dims_no_batch, num_dims_batch,
+                                                              self.__class__.__name__, input.shape))
+        return input.shape[1] if input.dim() == num_dims_batch else input.shape[0]
+
+    # Function to return the number of spatial dims expected for inputs to the module.
+    # This is expected to be implemented by subclasses.
+    def _get_num_spatial_dims(self) -> int:
+        raise NotImplementedError()
+
+
+class LazyConv1d(_LazyConvXdMixin, Conv1d):
+
+    cls_to_become = Conv1d
+
+    def __init__(
+        self,
+        out_channels,
+        kernel_size,
+        stride=1,
+        padding=0,
+        dilation=1,
+        groups=1,
+        bias=True,
+        padding_mode='zeros',
+        device=None,
+        dtype=None
+    ):
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super().__init__(
+            0,
+            0,
+            kernel_size,
+            stride,
+            padding,
+            dilation,
+            groups,
+            # bias is hardcoded to False to avoid creating tensor
+            # that will soon be overwritten.
+            False,
+            padding_mode,
+            **factory_kwargs
+        )
+        self.weight = UninitializedParameter(**factory_kwargs)
+        self.out_channels = out_channels
+        if bias:
+            self.bias = UninitializedParameter(**factory_kwargs)
+
+    def _get_num_spatial_dims(self) -> int:
+        return 1
+
+
+class LazyConv2d(_LazyConvXdMixin, Conv2d):
+
+    cls_to_become = Conv2d
+
+    def __init__(
+        self,
+        out_channels,
+        kernel_size,
+        stride=1,
+        padding=0,
+        dilation=1,
+        groups=1,
+        bias=True,
+        padding_mode='zeros',
+        device=None,
+        dtype=None
+    ):
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super().__init__(
+            0,
+            0,
+            kernel_size,
+            stride,
+            padding,
+            dilation,
+            groups,
+            # bias is hardcoded to False to avoid creating tensor
+            # that will soon be overwritten.
+            False,
+            padding_mode,
+            **factory_kwargs
+        )
+        self.weight = UninitializedParameter(**factory_kwargs)
+        self.out_channels = out_channels
+        if bias:
+            self.bias = UninitializedParameter(**factory_kwargs)
+
+    def _get_num_spatial_dims(self) -> int:
+        return 2
+
+
+class LazyConv3d(_LazyConvXdMixin, Conv3d):
+
+    cls_to_become = Conv3d
+
+    def __init__(
+        self,
+        out_channels,
+        kernel_size,
+        stride=1,
+        padding=0,
+        dilation=1,
+        groups=1,
+        bias=True,
+        padding_mode='zeros',
+        device=None,
+        dtype=None
+    ):
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super().__init__(
+            0,
+            0,
+            kernel_size,
+            stride,
+            padding,
+            dilation,
+            groups,
+            # bias is hardcoded to False to avoid creating tensor
+            # that will soon be overwritten.
+            False,
+            padding_mode,
+            **factory_kwargs
+        )
+        self.weight = UninitializedParameter(**factory_kwargs)
+        self.out_channels = out_channels
+        if bias:
+            self.bias = UninitializedParameter(**factory_kwargs)
+
+    def _get_num_spatial_dims(self) -> int:
+        return 3
+
+
+class LazyConvTranspose1d(_LazyConvXdMixin, ConvTranspose1d):
+
+    cls_to_become = ConvTranspose1d
+
+    def __init__(
+        self,
+        out_channels,
+        kernel_size,
+        stride=1,
+        padding=0,
+        output_padding=0,
+        groups=1,
+        bias=True,
+        dilation=1,
+        padding_mode='zeros',
+        device=None,
+        dtype=None
+    ):
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super().__init__(
+            0,
+            0,
+            kernel_size,
+            stride,
+            padding,
+            output_padding,
+            groups,
+            # bias is hardcoded to False to avoid creating tensor
+            # that will soon be overwritten.
+            False,
+            dilation,
+            padding_mode,
+            **factory_kwargs
+        )
+        self.weight = UninitializedParameter(**factory_kwargs)
+        self.out_channels = out_channels
+        if bias:
+            self.bias = UninitializedParameter(**factory_kwargs)
+
+    def _get_num_spatial_dims(self) -> int:
+        return 1
+
+
+class LazyConvTranspose2d(_LazyConvXdMixin, ConvTranspose2d):
+
+    cls_to_become = ConvTranspose2d
+
+    def __init__(
+        self,
+        out_channels,
+        kernel_size,
+        stride=1,
+        padding=0,
+        output_padding=0,
+        groups=1,
+        bias=True,
+        dilation=1,
+        padding_mode='zeros',
+        device=None,
+        dtype=None
+    ):
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super().__init__(
+            0,
+            0,
+            kernel_size,
+            stride,
+            padding,
+            output_padding,
+            groups,
+            # bias is hardcoded to False to avoid creating tensor
+            # that will soon be overwritten.
+            False,
+            dilation,
+            padding_mode,
+            **factory_kwargs
+        )
+        self.weight = UninitializedParameter(**factory_kwargs)
+        self.out_channels = out_channels
+        if bias:
+            self.bias = UninitializedParameter(**factory_kwargs)
+
+    def _get_num_spatial_dims(self) -> int:
+        return 2
+
+
+class LazyConvTranspose3d(_LazyConvXdMixin, ConvTranspose3d):
+
+    cls_to_become = ConvTranspose3d
+
+    def __init__(
+        self,
+        out_channels,
+        kernel_size,
+        stride=1,
+        padding=0,
+        output_padding=0,
+        groups=1,
+        bias=True,
+        dilation=1,
+        padding_mode='zeros',
+        device=None,
+        dtype=None
+    ):
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super().__init__(
+            0,
+            0,
+            kernel_size,
+            stride,
+            padding,
+            output_padding,
+            groups,
+            # bias is hardcoded to False to avoid creating tensor
+            # that will soon be overwritten.
+            False,
+            dilation,
+            padding_mode,
+            **factory_kwargs
+        )
+        self.weight = UninitializedParameter(**factory_kwargs)
+        self.out_channels = out_channels
+        if bias:
+            self.bias = UninitializedParameter(**factory_kwargs)
+
+    def _get_num_spatial_dims(self) -> int:
+        return 3
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/distance.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/distance.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/dropout.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/dropout.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/flatten.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/flatten.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/fold.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/fold.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/instancenorm.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/instancenorm.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 import mindspore as ms
 
 from mindtorch.torch.tensor import cast_to_ms_tensor, cast_to_adapter_tensor
-from mindtorch.torch.nn.modules.batchnorm import _NormBase
+from mindtorch.torch.nn.modules.batchnorm import _LazyNormBase, _NormBase
 
-__all__ = ['InstanceNorm1d', 'InstanceNorm2d', 'InstanceNorm3d']
+__all__ = ['InstanceNorm1d', 'InstanceNorm2d', 'InstanceNorm3d', 'LazyInstanceNorm1d', 'LazyInstanceNorm2d',
+           'LazyInstanceNorm3d']
 
 
 class _InstanceNorm(_NormBase):
     def __init__(
         self,
         num_features,
         eps=1e-5,
@@ -75,7 +76,46 @@
     def _get_no_batch_dim(self):
         return 4
 
     def _check_input_dim(self, ndim):
         if ndim not in (4, 5):
             raise ValueError('expected 4D or 5D input (got {}D input)'
                              .format(ndim))
+
+
+class LazyInstanceNorm1d(_LazyNormBase, _InstanceNorm):
+
+    cls_to_become = InstanceNorm1d
+
+    def _get_no_batch_dim(self):
+        return 2
+
+    def _check_input_dim(self, input):
+        if input.dim() not in (2, 3):
+            raise ValueError('expected 2D or 3D input (got {}D input)'
+                             .format(input.dim()))
+
+
+class LazyInstanceNorm2d(_LazyNormBase, _InstanceNorm):
+
+    cls_to_become = InstanceNorm2d
+
+    def _get_no_batch_dim(self):
+        return 3
+
+    def _check_input_dim(self, input):
+        if input.dim() not in (3, 4):
+            raise ValueError('expected 3D or 4D input (got {}D input)'
+                             .format(input.dim()))
+
+
+class LazyInstanceNorm3d(_LazyNormBase, _InstanceNorm):
+
+    cls_to_become = InstanceNorm3d
+
+    def _get_no_batch_dim(self):
+        return 4
+
+    def _check_input_dim(self, input):
+        if input.dim() not in (4, 5):
+            raise ValueError('expected 4D or 5D input (got {}D input)'
+                             .format(input.dim()))
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/linear.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/linear.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,21 +1,23 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 
 import math
 import mindspore.ops as P
+from mindspore import _no_grad as torch_no_grad
 from mindtorch.torch.nn import init
 from mindtorch.torch.nn.functional import linear
 from mindtorch.torch.functional import empty
-from mindtorch.torch.nn.parameter import Parameter
+from mindtorch.torch.nn.parameter import Parameter, UninitializedParameter
 from mindtorch.utils import unsupported_attr
 from mindtorch.torch.tensor import cast_to_ms_tensor, cast_to_adapter_tensor
 from .module import Module
+from .lazy import LazyModuleMixin
 
-__all__ = ['Linear', 'Identity', 'Bilinear']
+__all__ = ['Linear', 'Identity', 'Bilinear', 'LazyLinear']
 
 
 class Linear(Module):
     r"""Applies a linear transformation to the incoming data: :math:`y = xA^T + b`
 
     Args:
         in_features: size of each input sample
@@ -59,16 +61,14 @@
                                 requires_grad=True)
         if bias:
             self.bias = Parameter(empty(self.out_features, dtype=dtype, device=device), requires_grad=True)
             self.has_bias = True
         self.reset_parameters()
 
     def reset_parameters(self):
-        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with
-        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)).
         init.kaiming_uniform_(self.weight, a=math.sqrt(5))
         if self.has_bias:
             fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)
             bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
             init.uniform_(self.bias, -bound, bound)
 
     def forward(self, input):
@@ -134,7 +134,35 @@
         x = x.reshape(*input1_shape[:-1], -1)
         return cast_to_adapter_tensor(x)
 
     def extra_repr(self):
         return 'in1_features={}, in2_features={}, out_features={}, bias={}'.format(
             self.in1_features, self.in2_features, self.out_features, self.has_bias is not None
         )
+
+class LazyLinear(LazyModuleMixin, Linear):
+
+    cls_to_become = Linear
+    weight: UninitializedParameter
+    bias: UninitializedParameter
+
+    def __init__(self, out_features: int, bias: bool = True,
+                 device=None, dtype=None) -> None:
+        factory_kwargs = {'device': device, 'dtype': dtype}
+        super().__init__(1, 1, False) # Currently, Parameter does not support contain zero dimension.
+        self.weight = UninitializedParameter(**factory_kwargs)
+        self.out_features = out_features
+        if bias:
+            self.bias = UninitializedParameter(**factory_kwargs)
+
+    def reset_parameters(self):
+        if not self.has_uninitialized_params() and self.in_features != 0:
+            super().reset_parameters()
+
+    def initialize_parameters(self, input):
+        if self.has_uninitialized_params():
+            with torch_no_grad():
+                self.in_features = input.shape[-1]
+                self.weight.materialize((self.out_features, self.in_features))
+                if self.bias is not None:
+                    self.bias.materialize((self.out_features,))
+                self.reset_parameters()
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/loss.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/loss.py`

 * *Files 0% similar despite different names*

```diff
@@ -47,15 +47,16 @@
         if size_average and reduce:
             ret = 'mean'
         elif reduce:
             ret = 'sum'
         else:
             ret = 'none'
 
-        warning_msg = "size_average and reduce args will be deprecated, please use reduction='{}' instead."
+        warning_msg = "For loss function, `size_average` and `reduce` args will be deprecated, " \
+                      "please use reduction='{}' instead."
         warning(warning_msg.format(ret))
         return ret
 
 class _WeightedLoss(_Loss):
     def __init__(self, weight=None, size_average=None, reduce=None, reduction='mean'):
         super(_WeightedLoss, self).__init__(size_average, reduce, reduction)
         if weight is not None:
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/module.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/module.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,46 +1,118 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 
 import itertools
+import functools
 from collections import OrderedDict, namedtuple
 from typing import Mapping, List
 
 import mindspore as ms
 from mindspore.nn import Cell
 from mindspore import Tensor as ms_Tensor
 from mindtorch.torch.overrides import is_tensor_like
 from mindtorch.torch.tensor import Tensor, _dtypeDict, cast_to_ms_tensor
 from mindtorch.torch.nn.parameter import Parameter
-from mindtorch.utils import unsupported_attr
+from mindtorch.utils import unsupported_attr, graph_mode_condition
 from mindtorch.torch.types import device as device_class
-from mindtorch.torch.common.dtype import all_complex_type, all_float_and_complex_type
 from mindtorch.torch.functional import empty_like
 from mindtorch.torch.logging import warning
-
+import mindtorch.torch.utils.hooks as hooks
 
 __all__ = ['Module']
 
 
 _global_parameter_registration_hooks = OrderedDict()
 _global_module_registration_hooks = OrderedDict()
 _global_buffer_registration_hooks = OrderedDict()
 
-_EXTRA_STATE_KEY_SUFFIX = '_extra_state'
+
+def _addindent(s_, numSpaces):
+    s = s_.split('\n')
+    # don't do anything for single-line stuff
+    if len(s) == 1:
+        return s_
+    first = s.pop(0)
+    s = [(numSpaces * ' ') + line for line in s]
+    s = '\n'.join(s)
+    s = first + '\n' + s
+    return s
 
 
 class _IncompatibleKeys(namedtuple('IncompatibleKeys', ['missing_keys', 'unexpected_keys'])):
     def __repr__(self):
         if not self.missing_keys and not self.unexpected_keys:
             return '<All keys matched successfully>'
         return super().__repr__()
 
     __str__ = __repr__
 
 
+_global_backward_hooks = OrderedDict()
+_global_is_full_backward_hook = None
+_global_forward_pre_hooks = OrderedDict()
+_global_forward_hooks = OrderedDict()
+
+_global_hook_flag = False
+
+_EXTRA_STATE_KEY_SUFFIX = '_extra_state'
+
+
+def register_module_forward_pre_hook(hook):
+    global _global_hook_flag
+    _global_hook_flag = True
+    handle = hooks.RemovableHandle(_global_forward_pre_hooks)
+    _global_forward_pre_hooks[handle.id] = hook
+    return handle
+
+def register_module_forward_hook(hook):
+    global _global_hook_flag
+    _global_hook_flag = True
+    handle = hooks.RemovableHandle(_global_forward_hooks)
+    _global_forward_hooks[handle.id] = hook
+    return handle
+
+def register_module_backward_hook(hook):
+    global _global_hook_flag
+    _global_hook_flag = True
+    warning("Currently, it is prohibited to perform any operations on the input module in the hook function.")
+
+    global _global_is_full_backward_hook
+    if _global_is_full_backward_hook is True:
+        raise RuntimeError("Cannot use both regular backward hooks and full backward hooks as a "
+                           "global Module hook. Please use only one of them.")
+
+    _global_is_full_backward_hook = False
+
+    handle = hooks.RemovableHandle(_global_backward_hooks)
+    _global_backward_hooks[handle.id] = hook
+    return handle
+
+def register_module_full_backward_hook(hook):
+    global _global_hook_flag
+    _global_hook_flag = True
+    warning("Currently, it is prohibited to perform any operations on the input module in the hook function.")
+
+    global _global_is_full_backward_hook
+    if _global_is_full_backward_hook is False:
+        raise RuntimeError("Cannot use both regular backward hooks and full backward hooks as a "
+                           "global Module hook. Please use only one of them.")
+
+    _global_is_full_backward_hook = True
+
+    handle = hooks.RemovableHandle(_global_backward_hooks)
+    _global_backward_hooks[handle.id] = hook
+    return handle
+
+def _backward_hook_fn_replace_args(func):
+    def new_hook_fn(cell_id, grad_input, grad_output):
+        return func(cell_id, grad_output, grad_input)
+    return new_hook_fn
+
+
 class Module(Cell):
     def __init__(self, auto_prefix=True, flags=None):
         super(Module, self).__init__(auto_prefix, flags)
         # Some class members in same usage are defined in mindspore.nn.Cell, so Module reuses them
         # If re-difine these members with different names, Module should deal with data synchronization issue,
         # which is easy to make mistakes and unnecessary. Belows are the two different of members name
         # refers to torch.nn.Module
@@ -49,15 +121,22 @@
 
         # use object.__setattr__ to accelerate, because self.__setattr__ has too much procedure
         object.__setattr__(self, 'training', True)
         object.__setattr__(self, '_buffers', OrderedDict())
         object.__setattr__(self, '_non_persistent_buffers_set', set())
         object.__setattr__(self, '_state_dict_hooks', OrderedDict())
         object.__setattr__(self, '_state_dict_pre_hooks', OrderedDict())
+        object.__setattr__(self, '_load_state_dict_pre_hooks', OrderedDict())
+        object.__setattr__(self, '_load_state_dict_post_hooks', OrderedDict())
         object.__setattr__(self, '_version', 1)
+        object.__setattr__(self, '_backward_hooks', OrderedDict())
+        object.__setattr__(self, '_is_full_backward_hook', None)
+        object.__setattr__(self, '_forward_hooks', OrderedDict())
+        object.__setattr__(self, '_forward_pre_hooks', OrderedDict())
+        object.__setattr__(self, '_module_hook_flag', False)
 
     @property
     def _parameters(self):
         return self._params
 
     @property
     def _modules(self):
@@ -84,14 +163,30 @@
     def __delattr__(self, name):
         if name in self._buffers:
             del self._buffers[name]
             self._non_persistent_buffers_set.discard(name)
         else:
             super().__delattr__(name)
 
+    def __setstate__(self, state):
+        super().__setstate__(state)
+        # Support loading old checkpoints that don't have the following attrs:
+        if '_forward_pre_hooks' not in self.__dict__:
+            self._forward_pre_hooks = OrderedDict()
+        if '_state_dict_hooks' not in self.__dict__:
+            self._state_dict_hooks = OrderedDict()
+        if '_load_state_dict_pre_hooks' not in self.__dict__:
+            self._load_state_dict_pre_hooks = OrderedDict()
+        if '_load_state_dict_post_hooks' not in self.__dict__:
+            self._load_state_dict_post_hooks = OrderedDict()
+        if '_non_persistent_buffers_set' not in self.__dict__:
+            self._non_persistent_buffers_set = set()
+        if '_is_full_backward_hook' not in self.__dict__:
+            self._is_full_backward_hook = None
+
     def __getattr__(self, name):
         if '_buffers' in self.__dict__:
             buffers = self.__dict__['_buffers']
             if name in buffers:
                 return buffers[name]
 
         return super().__getattr__(name)
@@ -136,14 +231,17 @@
                     value = output
             if hasattr(self, '_is_adapter_norm') and name in ('running_mean', 'running_var') \
                 and name in self._params and isinstance(value, ms_Tensor):
                 self._params[name].set_data(value, slice_shape=True)
                 buffers[name] = self._params[name]
             else:
                 buffers[name] = value
+        elif isinstance(value, (Tensor, ms_Tensor)):
+            # TODO: Wait mindspore removes the special handling of tensor types.
+            object.__setattr__(self, name, value)
         else:
             super().__setattr__(name, value)
 
     def _save_to_state_dict(self, destination, prefix, keep_vars):
         for name, param in self._parameters.items():
             if param is not None:
                 destination[prefix + name] = param if keep_vars else param.detach()
@@ -193,22 +291,22 @@
             ms_state_dict[name] = param
         return ms_state_dict
 
     def _load_from_state_dict(self, state_dict, prefix, local_metadata, strict,
                               missing_keys, unexpected_keys, error_msgs):
 
         unsupported_attr(local_metadata)
-        # TODO:
-        # for hook in self._load_state_dict_pre_hooks.values():
-        #     hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)
+        for hook in self._load_state_dict_pre_hooks.values():
+            hook(state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)
 
         persistent_buffers = {k: v for k, v in self._buffers.items() if k not in self._non_persistent_buffers_set}
         local_name_params = itertools.chain(self._parameters.items(), persistent_buffers.items())
         local_state = {k: v for k, v in local_name_params if v is not None}
 
+        cast_cpu_op = ms.ops.Cast().set_device("CPU")
         for name, param in local_state.items():
             key = prefix + name
             if key in state_dict:
                 input_param = state_dict[key]
                 if not is_tensor_like(input_param):
                     error_msgs.append('While copying the parameter named "{}", '
                                       'expected torch.Tensor or Tensor-like object from checkpoint but '
@@ -230,19 +328,21 @@
                 #     error_msgs.append('size mismatch for {}: copying a param with shape {} from checkpoint, '
                 #                       'the shape in current model is {}.'
                 #                       .format(key, input_param.shape, param.shape))
                 #     continue
                 try:
                     def _copy_param(param, input_param):
                         input_ms = cast_to_ms_tensor(input_param)
-                        if len(param.shape) > 0 and input_ms != param.shape:
+                        if len(param.shape) > 0 and input_ms.shape != param.shape:
                             output = ms.ops.broadcast_to(input_ms, param.shape)
                         else:
                             output = input_ms
-                        output = output.astype(param.dtype)
+                        if output.dtype != param.dtype:
+                            # TODO: Cast unsupport bfloat16 on GPU
+                            output = cast_cpu_op(output, param.dtype)
                         param.assign_value(output)
 
                     _copy_param(param, input_param)
                 except Exception as ex: # pylint: disable=broad-except
                     error_msgs.append('While copying the parameter named "{}", '
                                       'whose dimensions in the model are {} and '
                                       'whose dimensions in the checkpoint are {}, '
@@ -290,23 +390,23 @@
             local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})
             module._load_from_state_dict(
                 state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)
             for name, child in module._modules.items():
                 if child is not None:
                     load(child, prefix + name + '.')
 
-            # TODO: # Note that the hook can modify missing_keys and unexpected_keys.
-            # incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)
-            # for hook in module._load_state_dict_post_hooks.values():
-            #     out = hook(module, incompatible_keys)
-            #     assert out is None, (
-            #         "Hooks registered with ``register_load_state_dict_post_hook`` are not"
-            #         "expected to return new values, if incompatible_keys need to be modified,"
-            #         "it should be done inplace."
-            #     )
+            # Note that the hook can modify missing_keys and unexpected_keys.
+            incompatible_keys = _IncompatibleKeys(missing_keys, unexpected_keys)
+            for hook in module._load_state_dict_post_hooks.values():
+                out = hook(module, incompatible_keys)
+                assert out is None, (
+                    "Hooks registered with ``register_load_state_dict_post_hook`` are not"
+                    "expected to return new values, if incompatible_keys need to be modified,"
+                    "it should be done inplace."
+                )
 
         load(self)
         del load
 
         if strict:
             if len(unexpected_keys) > 0:
                 error_msgs.insert(
@@ -325,45 +425,155 @@
     def extra_repr(self):
         r"""Set the extra representation of the module"""
         return ''
 
     def construct(self, *inputs, **kwargs):
         return self.forward(*inputs, **kwargs)
 
-    def _run_forward_pre_hook(self, inputs):
-        for fn in self._forward_pre_hook.values():
-            ret = fn(self, inputs)
-            if ret is not None:
-                if not isinstance(ret, tuple):
-                    inputs = (ret,)
-                else:
-                    inputs = ret
-        return inputs
+    def _register_load_state_dict_pre_hook(self, hook, with_module=False):
+        handle = hooks.RemovableHandle(self._load_state_dict_pre_hooks)
+        if with_module:
+            hook = functools.partial(hook, self)
+        self._load_state_dict_pre_hooks[handle.id] = hook
+        return handle
+
+    def register_load_state_dict_post_hook(self, hook):
+        handle = hooks.RemovableHandle(self._load_state_dict_post_hooks)
+        self._load_state_dict_post_hooks[handle.id] = hook
+        return handle
+
+    def _register_state_dict_hook(self, hook):
+        handle = hooks.RemovableHandle(self._state_dict_hooks)
+        self._state_dict_hooks[handle.id] = hook
+        return handle
+
+    def register_forward_pre_hook(self, hook):
+        self._module_hook_flag = True
+        handle = hooks.RemovableHandle(self._forward_pre_hooks)
+        self._forward_pre_hooks[handle.id] = hook
+        return handle
 
-    def _run_forward_hook(self, inputs, output):
-        for fn in self._forward_hook.values():
-            ret = fn(self, inputs, output)
-            if ret is not None:
-                output = ret
-        return output
+    def register_forward_hook(self, hook):
+        self._module_hook_flag = True
+        handle = hooks.RemovableHandle(self._forward_hooks)
+        self._forward_hooks[handle.id] = hook
+        return handle
 
-    def _run_construct(self, cast_inputs, kwargs):
-        """Run the construct function"""
-        if self._enable_forward_pre_hook:
-            cast_inputs = self._run_forward_pre_hook(cast_inputs)
+    def register_backward_hook(self, hook):
+        self._module_hook_flag = True
+        warning("Currently, it is prohibited to perform any operations on the input module in the hook function.")
+
+        if self._is_full_backward_hook is True:
+            raise RuntimeError("Cannot use both regular backward hooks and full backward hooks on a "
+                               "single Module. Please use only one of them.")
+
+        self._is_full_backward_hook = False
+
+        handle = hooks.RemovableHandle(self._backward_hooks)
+        self._backward_hooks[handle.id] = hook
+        return handle
+
+    def register_full_backward_hook(self, hook):
+        self._module_hook_flag = True
+        warning("Currently, it is prohibited to perform any operations on the input module in the hook function.")
+
+        if self._is_full_backward_hook is False:
+            raise RuntimeError("Cannot use both regular backward hooks and full backward hooks on a "
+                               "single Module. Please use only one of them.")
+
+        self._is_full_backward_hook = True
+
+        handle = hooks.RemovableHandle(self._backward_hooks)
+        self._backward_hooks[handle.id] = hook
+        return handle
+
+    def _get_backward_hooks(self):
+        full_backward_hooks = []
+        if _global_is_full_backward_hook is True:
+            full_backward_hooks += _global_backward_hooks.values()
+        if self._is_full_backward_hook is True:
+            full_backward_hooks += self._backward_hooks.values()
+
+        non_full_backward_hooks = []
+        if _global_is_full_backward_hook is False:
+            non_full_backward_hooks += _global_backward_hooks.values()
+        if self._is_full_backward_hook is False:
+            non_full_backward_hooks += self._backward_hooks.values()
+
+        # TODO: Delete after the new differential scheme is launched.
+        for full_bkhook in full_backward_hooks:
+            super().register_backward_hook(_backward_hook_fn_replace_args(full_bkhook))
+        for non_full_bkhook in non_full_backward_hooks:
+            super().register_backward_hook(_backward_hook_fn_replace_args(non_full_bkhook))
+
+        return full_backward_hooks, non_full_backward_hooks
+
+    def _run_construct_with_hook(self, cast_inputs, kwargs):
+        """Run the construct function with hook"""
+        if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
+                or _global_forward_hooks or _global_forward_pre_hooks):
+            return self.forward(*cast_inputs, **kwargs)
+
+        # Do not call functions when jit is used
+        full_backward_hooks, non_full_backward_hooks = [], []
+        if self._backward_hooks or _global_backward_hooks:
+            full_backward_hooks, non_full_backward_hooks = self._get_backward_hooks()
+        unsupported_attr(full_backward_hooks)
+        unsupported_attr(non_full_backward_hooks)
+
+        if _global_forward_pre_hooks or self._forward_pre_hooks:
+            for hook in (*_global_forward_pre_hooks.values(), *self._forward_pre_hooks.values()):
+                result = hook(self, cast_inputs)
+                if result is not None:
+                    if not isinstance(result, tuple):
+                        result = (result,)
+                    cast_inputs = result
+
+        # TODO: Adapt after the new differential scheme is launched.
+        # bw_hook = None
+        # if full_backward_hooks:
+        #     bw_hook = hooks.BackwardHook(self, full_backward_hooks)
+        #     cast_inputs = bw_hook.setup_input_hook(cast_inputs)
         if self._enable_backward_hook:
-            output = self._backward_hook_construct(*cast_inputs)
-        elif hasattr(self, "_shard_fn"):
-            output = self._shard_fn(*cast_inputs, **kwargs)
+            result = self._backward_hook_construct(*cast_inputs, **kwargs)
         else:
-            output = self.construct(*cast_inputs, **kwargs)
-        if self._enable_forward_hook:
-            output = self._run_forward_hook(cast_inputs, output)
+            result = self.forward(*cast_inputs, **kwargs)
+
+        if _global_forward_hooks or self._forward_hooks:
+            for hook in (*_global_forward_hooks.values(), *self._forward_hooks.values()):
+                hook_result = hook(self, cast_inputs, result)
+                if hook_result is not None:
+                    result = hook_result
+
+        # TODO: Adapt after the new differential scheme is launched.
+        # if bw_hook:
+        #     result = bw_hook.setup_output_hook(result)
+        #
+        # # Handle the non-full backward hooks
+        # if non_full_backward_hooks:
+        #     var = result
+        #     while not isinstance(var, Tensor):
+        #         if isinstance(var, dict):
+        #             var = next((v for v in var.values() if isinstance(v, Tensor)))
+        #         else:
+        #             var = var[0]
+        #     grad_fn = var.grad_fn
+        #     if grad_fn is not None:
+        #         for hook in non_full_backward_hooks:
+        #             wrapper = functools.partial(hook, self)
+        #             functools.update_wrapper(wrapper, hook)
+        #             grad_fn.register_hook(wrapper)
+        #         self._maybe_warn_non_full_backward_hook(cast_inputs, result, grad_fn)
+        return result
 
-        return output
+    def _run_construct(self, cast_inputs, kwargs):
+        """Run the construct function"""
+        if not self._module_hook_flag and not _global_hook_flag:
+            return self.forward(*cast_inputs, **kwargs)
+        return self._run_construct_with_hook(cast_inputs, kwargs)
 
     def forward(self, *inputs, **kwargs):
         raise NotImplementedError("The forward method must be implemented by inherited class")
 
     def train(self, mode=True):
         self.set_train(mode)
         return self
@@ -703,20 +913,18 @@
 
     def buffers(self, recurse=True):
         for _, buf in self.named_buffers(recurse=recurse):
             yield buf
 
     def _cast_to_dtype(self, dtype):
         if dtype is not None:
-            # TODO: if not (dtype.is_floating_point or dtype.is_complex):
-            if not dtype in all_float_and_complex_type:
+            if not (dtype.is_floating_point or dtype.is_complex):
                 raise TypeError('nn.Module.to only accepts floating point or complex '
                                 'dtypes, but got desired dtype={}'.format(dtype))
-            # TODO:if dtype.is_complex:
-            if dtype in all_complex_type:
+            if dtype.is_complex:
                 warning(
                     "Complex modules are a new feature under active development whose design may change, "
                     "and some modules might not work as expected when using complex tensors as parameters or buffers."
                 )
 
         def convert(t):
             return t.to(dtype if t.is_floating_point() or t.is_complex() else None)
@@ -825,20 +1033,21 @@
         keys = module_attrs + attrs + parameters + modules + buffers
 
         # Eliminate attrs that are not legal Python variable names
         keys = [key for key in keys if not key[0].isdigit()]
 
         return sorted(keys)
 
-    def register_forward_hook(self, hook):
-        return ms.nn.Cell.register_forward_hook(self, hook)
-
-    def register_forward_pre__hook(self, hook):
-        return ms.nn.Cell.register_forward_pre_hook(self, hook)
-
-    # TODO:
-    # to support modifying Module inside hook func
-    def register_backward_hook(self, hook):
-        return ms.nn.Cell.register_backward_hook(self, hook)
-
     def zero_grad(self, set_to_none=True):
-        unsupported_attr(set_to_none)
+        if graph_mode_condition():
+            return
+
+        for p in self.parameters():
+            if p.grad is not None:
+                if set_to_none:
+                    p.grad = None
+                else:
+                    if p.grad.grad_fn is not None:
+                        p.grad.detach_()
+                    else:
+                        p.grad.requires_grad_(False)
+                    p.grad.assign_value(ms.ops.zeros_like(p.grad))
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/normalization.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/normalization.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/padding.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/padding.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/pixelshuffle.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/pixelshuffle.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/pooling.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/pooling.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/rnn.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/rnn.py`

 * *Files 0% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 from mindtorch.torch.nn.modules.module import Module
 from mindtorch.torch.tensor import cast_to_ms_tensor, cast_to_adapter_tensor
 from mindtorch.torch.nn.parameter import Parameter
 from mindtorch.torch.functional import empty, zeros
 from mindtorch.torch.nn import init
 from mindtorch.utils import unsupported_attr, is_under_ascend_context
 from mindtorch.torch.nn.utils.rnn import PackedSequence, pad_packed_sequence
-from mindtorch.torch.logging import warning
+from mindtorch.torch.logging import warning, info
 
 def _apply_permutation(tensor, permutation, dim=1):
     return tensor.index_select(dim, permutation)
 
 class RNNBase(Module):
     def __init__(self, mode, input_size, hidden_size,
                  num_layers=1, bias=True, batch_first=False,
@@ -115,15 +115,15 @@
             idx = self._flat_weights_names.index(attr)
             self._flat_weights[idx] = value
         super(RNNBase, self).__setattr__(attr, value)
 
     def flatten_parameters(self):
         # flatten_parameters is to register the _flat_weights to cudnn, for performance improvement.
         # However mindtorch has not support yet, so here do nothings.
-        warning("'flatten_parameters' in RNN/GRU/LSTM do not actually take effect to improve performence. "
+        info("'flatten_parameters' in RNN/GRU/LSTM do not actually take effect to improve performence. "
                 "mindtorch has not supported yet.")
 
     def reset_parameters(self) -> None:
         stdv = 1.0 / math.sqrt(self.hidden_size) if self.hidden_size > 0 else 0
         for weight in self.parameters():
             init.uniform_(weight, -stdv, stdv)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/sparse.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/sparse.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/transformer.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/transformer.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/unpooling.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/unpooling.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/upsampling.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/upsampling.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/modules/utils.py` & `mindtorch-0.3.0/mindtorch/torch/nn/modules/utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/quantized/modules/functional_modules.py` & `mindtorch-0.3.0/mindtorch/torch/nn/quantized/modules/functional_modules.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/utils/clip_grad.py` & `mindtorch-0.3.0/mindtorch/torch/nn/utils/clip_grad.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 import mindspore as ms
 from mindspore.ops.function.clip_func import get_square_sum, apply_global_norm
 from mindspore import _checkparam as Validator
 from mindtorch.utils import unsupported_attr, graph_mode_condition
-from mindtorch.torch.tensor import cast_to_adapter_tensor
+from mindtorch.torch.tensor import cast_to_adapter_tensor, Tensor, cast_to_ms_tensor, tensor
+from mindtorch.torch.nn.parameter import Parameter
 
 __all__ = ['clip_grad_norm_', 'clip_grad_norm', 'clip_grad_value', 'clip_grad_value_']
 
 _hypermap = ms.ops.HyperMap()
 
 def _assign(x1, x2):
     return x1.assign_value(x2)
@@ -46,20 +47,37 @@
         raise ValueError("'clip_grad_norm_' need to pass `grads`, "
                          "which can be get from 'mindspore.ops.grad' or mindspore.ops.value_and_grad.")
 
     # rewrite _ClipByGlobalNorm to support return total_norm
     new_grads, total_norm = _ClipByGlobalNorm(max_norm, None)(grads)
     return new_grads, cast_to_adapter_tensor(total_norm)
 
-def clip_grad_norm_(parameters, max_norm, grads, norm_type=2.0, error_if_nonfinite=False, foreach=None):
+def clip_grad_norm_(parameters, max_norm, norm_type=2.0,
+                    error_if_nonfinite=False, foreach=None, grads=None):
     if graph_mode_condition():
         raise RuntimeError("Under graph mode, adapter not support in-place operation. "
                            "So please use 'clip_grad_norm' to replace 'clip_grad_norm_'")
 
-    new_grads, total_norm = clip_grad_norm(parameters, max_norm, grads, norm_type, error_if_nonfinite, foreach)
+    if isinstance(parameters, (Tensor, Parameter)):
+        parameters = [parameters]
+    if grads is None:
+        _param = list(parameters)
+        grads = [p.grad for p in _param if p.grad is not None]
+        if len(grads) == 0:
+            return tensor(0.)
+        grads = cast_to_ms_tensor(grads)
+        grads = tuple(grads)
+        new_grads, total_norm = clip_grad_norm(parameters, max_norm, grads, norm_type,
+                                               error_if_nonfinite, foreach)
+        for i, p in enumerate(_param):
+            p.grad = new_grads[i]
+        return total_norm
+
+    new_grads, total_norm = clip_grad_norm(parameters, max_norm, grads, norm_type,
+                                           error_if_nonfinite, foreach)
     _hypermap(_assign, grads, new_grads)
     return total_norm
 
 def clip_grad_value(parameters, clip_value, grads, foreach=None):
     unsupported_attr(foreach)
     unsupported_attr(parameters)
     if not isinstance(grads, tuple) or not isinstance(grads[0], ms.Tensor):
@@ -68,14 +86,27 @@
     # If clip_value < 0, _clip_value_min will greater than _clip_value_max
     # It is a special case with a special behavious, which ms.ops.clip_by_value can accept.
     _clip_value_min = -clip_value
     _clip_value_max = clip_value
     grads = ms.ops.clip_by_value(grads, _clip_value_min, _clip_value_max)
     return grads
 
-def clip_grad_value_(parameters, clip_value, grads, foreach=None):
+def clip_grad_value_(parameters, clip_value, foreach=None, grads=None):
     if graph_mode_condition():
         raise RuntimeError("Under graph mode, adapter not support in-place operation. "
                            "So please use 'clip_grad_value' to replace 'clip_grad_value_'")
 
+    if isinstance(parameters, (Tensor, Parameter)):
+        parameters = [parameters]
+    if grads is None:
+        _param = list(parameters)
+        grads = [p.grad for p in _param if p.grad is not None]
+        if len(grads) == 0:
+            return
+        grads = cast_to_ms_tensor(grads)
+        grads = tuple(grads)
+        new_grads = clip_grad_value(parameters, clip_value, grads, foreach)
+        for i, p in enumerate(_param):
+            p.grad = new_grads[i]
+        return
     new_grads = clip_grad_value(parameters, clip_value, grads, foreach)
     _hypermap(_assign, grads, new_grads)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/utils/convert_parameters.py` & `mindtorch-0.3.0/mindtorch/torch/nn/utils/convert_parameters.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/nn/utils/rnn.py` & `mindtorch-0.3.0/mindtorch/torch/nn/utils/rnn.py`

 * *Files 1% similar despite different names*

```diff
@@ -35,18 +35,18 @@
         maxlen = max(lengths)
 
         x_shape = (num_samples, maxlen) + sample_shape if batch_first else (maxlen, num_samples) + sample_shape
         x = ms.ops.full(x_shape, padding_value, dtype=sequences[0].dtype)
         for idx, s in enumerate(sequences):
             if batch_first:
                 trunc = s[:maxlen]
-                x[idx, :len(trunc)] = trunc
+                x[idx, :len(trunc)] = trunc  # pylint: disable=E1137
             else:
                 trunc = s[:maxlen]
-                x[:len(trunc), idx] = trunc
+                x[:len(trunc), idx] = trunc  # pylint: disable=E1137
         return cast_to_adapter_tensor(x)
 
     elif isinstance(sequences[0], np.ndarray):
         num_samples = len(sequences)
 
         lengths = []
         sample_shape = ()
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/optim/adam.py` & `mindtorch-0.3.0/mindtorch/torch/optim/radam.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,26 +1,22 @@
-from mindspore.experimental.optim import Adam as Adam_MS
-from mindtorch.torch.optim.optimizer import _Optimizer, _is_tensor
-from mindtorch.torch.tensor import tensor
+from mindspore.experimental.optim import RAdam as RAdam_MS
+from mindtorch.torch.optim.optimizer import _Optimizer, _warn_differentiable
+from mindtorch.utils import unsupported_attr
 
-class Adam(_Optimizer, Adam_MS):
-    def __init__(self, *args, **kwargs):
-        Adam_MS.__init__(self, *args, **kwargs)
+class RAdam(_Optimizer, RAdam_MS):
+    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0,
+                 *, foreach=None, differentiable=False):
+        unsupported_attr(foreach)
+        _warn_differentiable(differentiable)
+        RAdam_MS.__init__(self, params, lr, betas, eps, weight_decay)
         _Optimizer.__init__(self)
-
-    def __setstate__(self, state):
-        _Optimizer.__setstate__(self, state)
-        for group in self.param_groups:
-            group.setdefault('amsgrad', False)
-            group.setdefault('maximize', False)
-
-        state_values = list(self.state.values())
-        step_is_tensor = (len(state_values) != 0) and _is_tensor(state_values[0]['step'])
-        if not step_is_tensor:
-            for s in state_values:
-                s['step'] = tensor(float(s['step']))
+        self._state_map = {
+            'exp_avg':'exp_avg',
+            'exp_avg_sq':'exp_avg_sq',
+            'step_t':'step',
+        }
 
     def state_dict(self):
-        return super()._ms_state_dict('exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', 'state_step')
+        return _Optimizer._ms_state_dict(self, self._state_map)
 
     def load_state_dict(self, state_dict):
-        return super()._ms_load_state_dict(state_dict, 'exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', 'state_step')
+        return _Optimizer._ms_load_state_dict(self, state_dict, self._state_map)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/optim/adamw.py` & `mindtorch-0.3.0/mindtorch/torch/optim/adagrad.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,26 +1,19 @@
-from mindspore.experimental.optim import AdamW as AdamW_MS
-from mindtorch.torch.optim.optimizer import _Optimizer, _is_tensor
-from mindtorch.torch.tensor import tensor
+from mindspore.experimental.optim import Adagrad as Adagrad_MS
+from mindtorch.torch.optim.optimizer import _Optimizer, _warn_differentiable
+from mindtorch.utils import unsupported_attr
 
-class AdamW(_Optimizer, AdamW_MS):
-    def __init__(self, *args, **kwargs):
-        AdamW_MS.__init__(self, *args, **kwargs)
+class Adagrad(_Optimizer, Adagrad_MS):
+    def __init__(self, params, lr=1e-2, lr_decay=0, weight_decay=0, initial_accumulator_value=0,
+                 eps=1e-10, foreach=None, *, maximize=False, differentiable=False):
+        unsupported_attr(foreach)
+        _warn_differentiable(differentiable)
+        Adagrad_MS.__init__(self, params, lr, lr_decay, weight_decay, initial_accumulator_value,
+                            eps, maximize=maximize)
         _Optimizer.__init__(self)
-
-    def __setstate__(self, state):
-        _Optimizer.__setstate__(self, state)
-        for group in self.param_groups:
-            group.setdefault('amsgrad', False)
-            group.setdefault('maximize', False)
-
-        state_values = list(self.state.values())
-        step_is_tensor = (len(state_values) != 0) and _is_tensor(state_values[0]['step'])
-        if not step_is_tensor:
-            for s in state_values:
-                s['step'] = tensor(float(s['step']))
+        self._state_map = {'accum': 'sum', 'step_t': 'step'}
 
     def state_dict(self):
-        return super()._ms_state_dict('exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', 'state_step')
+        return _Optimizer._ms_state_dict(self, self._state_map)
 
     def load_state_dict(self, state_dict):
-        return super()._ms_load_state_dict(state_dict, 'exp_avg', 'exp_avg_sq', 'max_exp_avg_sq', 'state_step')
+        return _Optimizer._ms_load_state_dict(self, state_dict, self._state_map)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/optim/optimizer.py` & `mindtorch-0.3.0/mindtorch/torch/optim/optimizer.py`

 * *Files 14% similar despite different names*

```diff
@@ -2,15 +2,19 @@
 from collections import OrderedDict, defaultdict
 from collections.abc import Iterable
 from copy import deepcopy
 from itertools import chain
 import mindspore as ms
 from mindspore.experimental.optim import Optimizer as Optimizer_MS
 from mindtorch.torch.tensor import Tensor, tensor, cast_to_ms_tensor
-from mindtorch.utils import unsupported_attr
+from mindtorch.utils import unsupported_attr, graph_mode_condition
+
+def _warn_differentiable(differentiable):
+    if differentiable:
+        raise NotImplementedError("For optimizer, `differentiable` is not supported yet.")
 
 class _RequiredParameter():
     """Singleton class representing a required parameter for an Optimizer."""
     def __repr__(self):
         return "<required parameter>"
 
 required = _RequiredParameter()
@@ -22,20 +26,28 @@
 
         self._patch_step_function()
 
     def _is_inner_optimizer(self):
         return True
 
     def __getstate__(self):
-        return {
-            'defaults': self.defaults,
-            'state': self.state,
-            'param_groups': self.param_groups,
-        }
+        # TODO: mindspore.experimental.Optimizer not support __getstate__ yet.
+        # MindTorch __getstate__ depend of MindSpore's __getstate__, because MindSpore Optimizer
+        # inherit from mindspore.nn.Cell, so it need special processes in __getstate__,
+        # which can not be done only in MindTorch.
+        raise NotImplementedError("not support __getstate__ in Optimizer now.")
+
     def __setstate__(self, state):
+        # TODO: mindspore.experimental.Optimizer not support __setstate__ yet.
+        # MindTorch __setstate__ depend of MindSpore's __setstate__, because MindSpore Optimizer
+        # inherit from mindspore.nn.Cell, so it need special processes in __setstate__,
+        # which can not be done only in MindTorch.
+        raise NotImplementedError("not support __setstate__ in Optimizer now.")
+
+    def _update_state(self, state):
         self.__dict__.update(state)
         if '_optimizer_step_pre_hooks' not in self.__dict__:
             self._optimizer_step_pre_hooks = OrderedDict()
         if '_optimizer_step_post_hooks' not in self.__dict__:
             self._optimizer_step_post_hooks = OrderedDict()
         self._patch_step_function()
         self.defaults.setdefault('differentiable', False)
@@ -164,34 +176,34 @@
             new_group['params'] = group['params']
             if 'lr' in group.keys():
                 if isinstance(group['lr'], ms.Parameter):
                     new_group['lr'] = ms.Parameter(ms.Tensor(new_group['lr'], ms.float32), group['lr'].name)
             return new_group
         param_groups = [
             update_group(g, ng) for g, ng in zip(groups, saved_groups)]
-        self.__setstate__({'state': state, 'param_groups': param_groups})
+        self._update_state({'state': state, 'param_groups': param_groups})
 
-    def _ms_state_dict(self, *ms_params_name):
+    def _ms_state_dict(self, ms_params_name):
         _state_dict = _Optimizer.state_dict(self)
         def _save(ms_params):
             if isinstance(ms_params, Iterable):
                 _state = []
                 for p in ms_params:
                     _state.append(_save(p))
             else:
                 _state = tensor(ms_params.asnumpy())
             return _state
 
-        for name in ms_params_name:
+        for name in ms_params_name.keys():
             ms_params = getattr(self, name, None)
             if ms_params is not None:
                 _state_dict[name] = _save(ms_params)
         return _state_dict
 
-    def _ms_load_state_dict(self, state_dict, *ms_params_name):
+    def _ms_load_state_dict(self, state_dict, ms_params_name):
         _Optimizer.load_state_dict(self, state_dict)
 
         def _load(ms_params, state_tensor, name):
             if isinstance(ms_params, Iterable):
                 if not isinstance(state_tensor, Iterable):
                     raise ValueError(f"state_dict of ms_param '{name}' is not correct. please check. "
                                      f"(ms_param '{name}' is Iterable, but state_dict['{name}'] is not.)")
@@ -199,45 +211,81 @@
                     raise ValueError(f"state_dict of ms_param '{name}' is not correct. please check. "
                                      f"(length of ms_param '{name}' and state_dict['{name}'] are not equal, "
                                      f"get {len(ms_params)} and {len(state_tensor)}")
                 for i, _ in enumerate(ms_params):
                     _load(ms_params[i], state_tensor[i], name)
             else:
                 _data = cast_to_ms_tensor(state_tensor)
+                if isinstance(_data, ms.Tensor):
+                    _data = _data.astype(ms_params.dtype)
                 try:
                     ms_params.set_data(_data)
                 except Exception as e:
                     raise ValueError(f"state_dict of ms_param '{name}' is not correct. please check. "
                                      f"({e})") from e
 
-        for name in ms_params_name:
+        def _load_from_pt(ms_params, name):
+            _state = state_dict.get('state', None)
+            # If name in state_dict['state'], it was saved from PyTorch. Load that to MindTorch.
+            if _state is not None:
+                # _state is a dict like: {0:{name: Tensor}, 1:{name:Tensor}}
+                for k, state in _state.items():
+                    _pt_state_name = ms_params_name.get(name, None)
+                    if _pt_state_name is None:
+                        raise ValueError("ms_params_name should be dict, and name should not be None.")
+                    _params = state.get(_pt_state_name, None)
+                    # assert name in state.
+                    if _params is not None:
+                        if isinstance(ms_params, Iterable):
+                            _load(ms_params[k], _params, name)
+                        else:
+                            _load(ms_params, _params, name)
+
+        for name in ms_params_name.keys():
             ms_params = getattr(self, name, None)
             if ms_params is None:
                 continue
             _params = state_dict.get(name, None)
             # If name in state_dict, use state_dict[name], because it was saved from MindTorch.
             if _params is not None:
                 _load(ms_params, _params, name)
             else:
-                _state = state_dict.get('state', None)
-                # If name in state_dict['state'], it was saved from PyTorch. Load that to MindTorch.
-                if _state is not None:
-                    # _state is a dict like: {0:{name: Tensor}, 1:{name:Tensor}}
-                    for k, state in _state.items():
-                        _params = state.get(name, None)
-                        # assert name in state.
-                        if _params is not None:
-                            _load(ms_params[k], _params, name)
+                _load_from_pt(ms_params, name)
 
-    def step(self, grads, closure=None):
+    def step(self, grads=None, closure=None):
         loss = None
         if closure is not None:
             loss = closure()
-        self.construct(grads)
-        return loss
+        if grads is None:
+            grads = [param.grad if param.grad is not None
+                     else ms.ops.zeros_like(param) for param in self.parameters]
+            # Has to turn 'grads' to tuple type before sending to 'construct'
+            # Otherwise, it will cause recompiling every step, which will lead to poor performance.
+            grads = tuple(grads)
+        ret = self.construct(grads)
+        if closure is not None:
+            ret = loss
+        return ret
+
+    def zero_grad(self, set_to_none=True):
+        if graph_mode_condition():
+            return
+
+        for group in self.param_groups:
+            for p in group['params']:
+                if p.grad is not None:
+                    if set_to_none:
+                        p.grad = None
+                    else:
+                        if p.grad.grad_fn is not None:
+                            p.grad.detach_()
+                        else:
+                            p.grad.requires_grad_(False)
+                        p.grad.assign_value(ms.ops.zeros_like(p.grad))
+
 
 class _OptimizerMeta(abc.ABCMeta, type(Optimizer_MS)):
     """
     Meta class for Optimizer. Used internally.
     """
 
 class Optimizer(_Optimizer, Optimizer_MS, metaclass=_OptimizerMeta):
@@ -251,9 +299,12 @@
         Subclass with _is_inner_optimizer attr will be instance of Optimizer
         """
         if cls is Optimizer:
             if any("_is_inner_optimizer" in s.__dict__ for s in sub.__mro__):
                 return True
         return NotImplemented
 
+    def step(self, grads=None, closure=None):
+        raise NotImplementedError
+
 def _is_tensor(obj):
     return isinstance(obj, Tensor)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/optim/sgd.py` & `mindtorch-0.3.0/mindtorch/torch/optim/sgd.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,32 +1,31 @@
 from mindspore.experimental.optim import SGD as SGD_MS
-from mindtorch.torch.optim.optimizer import _Optimizer
+from mindtorch.torch.optim.optimizer import _Optimizer, _warn_differentiable
 from mindtorch.utils import unsupported_attr
 
 _default_lr = 0.01
 class SGD(_Optimizer, SGD_MS):
     def __init__(self, params, lr=None, momentum=0, dampening=0,
                  weight_decay=0, nesterov=False, *, maximize=False, foreach=None,
                  differentiable=False):
         unsupported_attr(foreach)
-        unsupported_attr(differentiable)
+        _warn_differentiable(differentiable)
         if lr is None:
             for p_dict in params:
                 if not isinstance(p_dict, dict) or 'lr' not in p_dict:
                     raise ValueError("parameter group didn't specify a value of required optimization parameter lr.")
             # Fake lr. The above code guarantees that every param_group has its own 'lr' setting.
             # So the following _default_lr won't take effect, just for the input args of mindspore SGD.
             lr = _default_lr
         SGD_MS.__init__(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize=maximize)
         _Optimizer.__init__(self)
-
-    def __setstate__(self, state):
-        _Optimizer.__setstate__(self, state)
-        for group in self.param_groups:
-            group.setdefault('nesterov', False)
-            group.setdefault('maximize', False)
+        self._state_map = {'accum': 'momentum_buffer'}
 
     def state_dict(self):
-        return super()._ms_state_dict('accum')
+        return _Optimizer._ms_state_dict(self, self._state_map)
 
     def load_state_dict(self, state_dict):
-        return super()._ms_load_state_dict(state_dict, 'accum')
+        for group in state_dict['param_groups']:
+            group['momentum'] = float(group['momentum'])
+            group['dampening'] = float(group['dampening'])
+            group['weight_decay'] = float(group['weight_decay'])
+        return _Optimizer._ms_load_state_dict(self, state_dict, self._state_map)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/storage.py` & `mindtorch-0.3.0/mindtorch/torch/storage.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,17 +1,20 @@
+import io
 import copy
 import collections
 from functools import lru_cache
 from ast import literal_eval
 from typing import Any
+from ml_dtypes import bfloat16 as np_bfloat16
+import mindspore as ms
 import mindtorch.torch.common.dtype as _dtype
 from mindtorch.torch.common.dtype import _TypeDict
 from mindtorch.torch.types import device
-from mindtorch.torch.logging import warning
 from mindtorch.utils import unsupported_attr
+from mindtorch.torch.logging import warning
 from ._utils import _type, _cuda, _element_size, classproperty
 try:
     import numpy as np
     HAS_NUMPY = True
 except ModuleNotFoundError:
     np = None  # type: ignore[assignment]
 
@@ -37,48 +40,78 @@
 class _StorageBase():
     _cdata: Any
     is_sparse: bool = False
     is_sparse_csr: bool = False
     device: device = 'cpu'
 
     def __init__(self, *args, **kwargs):
-        if len(args) > 0:
+        if len(args) > 1:
             raise NotImplementedError("`args` is not currently supported.")
+
+        # self.inner_data must be the nd-array with uint8 dtype.
         self.inner_data = kwargs.get('inner_data', None)
+        self.referenced_tensor = kwargs.get('referenced_tensor', None)
+        self.device = kwargs.get('device', 'cpu')
+        if len(args) > 0 and isinstance(args[0], int):
+            self.inner_data = np.random.randint(0, 255, size=args[0], dtype=np.uint8)
+
 
     def __len__(self):
-        return self.inner_data.nelement()
+        return len(self.inner_data)
 
     def __getitem__(self, idx):
-        return self.inner_data.flatten()[idx].item()
+        out = self.inner_data[idx]
+        if isinstance(idx, int):
+            return out
+        return type(self)(inner_data=out)
 
     def copy_(self, source, non_blocking=None):
-        raise NotImplementedError("`copy_` is not currently supported.")
+        unsupported_attr(non_blocking)
+        if self.size() != source.size():
+            raise RuntimeError("size dose not match in `storage.copy_`")
+        self.inner_data = source.inner_data.copy()
+        self._update_referenced_tensor()
+        return self
+
+    def _update_referenced_tensor(self, strict=True, size=None):
+        if self.referenced_tensor is not None:
+            np_data = np.frombuffer(self.inner_data,
+                                    _TypeDict.get(self.referenced_tensor.dtype))
+            if size is not None:
+                np_data = np_data.reshape(size)
+            if strict:
+                np_data = np_data.reshape(self.referenced_tensor.shape)
+            if np_data.dtype == np_bfloat16:
+                np_data = np_data.astype(np.float32)
+                value = ms.Tensor.from_numpy(np_data)
+                value = value.astype(_dtype.bfloat16)
+            else:
+                value = ms.Tensor.from_numpy(np_data)
+            self.referenced_tensor.assign_value(value)
 
     def nbytes(self):
-        return self.inner_data.numpy().nbytes
+        return self.inner_data.nbytes
 
     def size(self):
-        return self.nbytes()
+        return self.inner_data.size
 
     def type(self, dtype=None, non_blocking=False):
         raise NotImplementedError("`type` is not currently supported.")
 
     def cuda(self, device=None, non_blocking=False, **kwargs):
         raise NotImplementedError("`cuda` is not currently supported.")
 
     def element_size(self):
-        return self.inner_data.element_size()
+        return self.inner_data.itemsize
 
     def get_device(self):
         return self.device
 
     def data_ptr(self):
-        warning("The id corresponding to the python object is currently returned, rather than a pointer from C++.")
-        return id(self.inner_data)
+        return self.inner_data.ctypes.data
 
     def _share_filename_cpu_(self, *args, **kwargs):
         raise NotImplementedError("`_share_filename_cpu_` is not currently supported.")
 
     def _share_fd_cpu_(self, *args, **kwargs):
         raise NotImplementedError("`_share_fd_cpu_` is not currently supported.")
 
@@ -88,16 +121,25 @@
 
     @classmethod
     def _new_using_fd_cpu(cls, size):
         raise NotImplementedError("`_new_using_fd_cpu` is not currently supported.")
 
     @classmethod
     def from_buffer(cls, *args, **kwargs):
-        inner_data = np.frombuffer(args[0], _TypeDict.get(kwargs['dtype'], np.float32))
-        return cls(inner_data=inner_data)
+        unsupported_attr(kwargs)
+        np_data = np.frombuffer(args[0], np.uint8)
+        return cls(inner_data=np_data)
+
+    @classmethod
+    def from_file(cls, filename, shared, size):
+        unsupported_attr(shared)
+        with open(filename, 'rb') as f:
+            data = f.read()
+        np_data = np.frombuffer(data, np.uint8, count=size)
+        return cls(inner_data=np_data)
 
     @classmethod
     def _new_shared_filename_cpu(cls, manager, obj, size, *, device=None, dtype=None):
         raise NotImplementedError("`_new_shared_filename_cpu` is not currently supported.")
 
     @classmethod
     def _release_ipc_counter_cuda(cls, *args, **kwargs):
@@ -106,37 +148,55 @@
     @classmethod
     def _new_with_weak_ptr(cls, *args, **kwargs):
         raise NotImplementedError("`_new_with_weak_ptr` is not currently supported.")
 
     def _shared_decref(self):
         raise NotImplementedError("`_shared_decref` is not currently supported.")
 
-    def _write_file(self, *args, **kwargs):
-        raise NotImplementedError("`_write_file` is not currently supported.")
+    def _write_file(self, f, is_real_file, save_size, element_size):
+        if not is_real_file:
+            raise RuntimeError("Currently, in `storage._write_file` only is_real_file==True supported.")
+        if save_size:
+            numel = self.nbytes() / element_size
+            f.write(np.array(numel, dtype=np.int64).tobytes())
+        f.write(self.inner_data.tobytes())
 
     def resize_(self, size):
-        raise NotImplementedError("`resize_` is not currently supported.")
+        if size <= self.size():
+            self.inner_data = self.inner_data[:size]
+        else:
+            append_data = np.random.randint(0, 255, size=size - self.size(), dtype=np.uint8)
+            self.inner_data = np.concatenate((self.inner_data, append_data), axis=0)
+        if self.referenced_tensor is not None:
+            warning("Trying to resize storage that is not resizable, `storage.resize_` will not"
+                    " modify the tensor value in place.")
 
     def _weak_ref(self, *args, **kwargs):
         raise NotImplementedError("`_weak_ref` is not currently supported.")
 
     def is_pinned(self):
-        raise NotImplementedError("`is_pinned` is not currently supported.")
+        return False
 
-    def _set_from_file(self, *args, **kwargs):
-        raise NotImplementedError("`_set_from_file` is not currently supported.")
+    def _set_from_file(self, f, offset, is_real_file, element_size):
+        if not is_real_file:
+            raise RuntimeError("Currently, in `storage._set_from_file` only is_real_file==True supported.")
+        nbytes = np.frombuffer(f.read(8), np.int64).item() * element_size
+        array = np.fromfile(f, dtype=np.uint8, count=nbytes, offset=offset)
+        self.inner_data[:] = array
+        self._update_referenced_tensor()
+        return self
 
     def _set_cdata(self, *args, **kwargs):
         raise NotImplementedError("`_set_cdata` is not currently supported.")
 
     def _share_cuda_(self, *args, **kwargs):
         raise NotImplementedError("`_share_cuda_` is not currently supported.")
 
     def is_shared(self):
-        raise NotImplementedError("`is_shared` is not currently supported.")
+        return False
 
     @classmethod
     def _new_shared_cuda(cls, *args, **kwargs):
         raise NotImplementedError("`_new_shared_cuda` is not currently supported.")
 
     def _shared_incref(self, *args, **kwargs):
         raise NotImplementedError("`_shared_incref` is not currently supported.")
@@ -165,33 +225,38 @@
         return self.clone()
 
     def __deepcopy__(self, memo):
         unsupported_attr(memo)
         raise NotImplementedError("`__deepcopy__` is not currently supported.")
 
     def __reduce__(self):
-        raise NotImplementedError("`__reduce__` is not currently supported.")
+        b = io.BytesIO()
+        from mindtorch.torch.serialization import save  # pylint: disable=R0401, C0415
+        save(self, b, _use_new_zipfile_serialization=False)
+        return (_load_from_bytes, (b.getvalue(),))
+
 
     def __sizeof__(self):
         return super(_StorageBase, self).__sizeof__() + self.size()
 
     def clone(self):
-        raise NotImplementedError("`clone` is not currently supported.")
+        return type(self)(self.nbytes(), device=self.device).copy_(self)
 
     def tolist(self):
         """Returns a list containing the elements of this storage"""
-        return list(self.inner_data.flatten().numpy())
+        return self.inner_data.tolist()
 
     def cpu(self):
         return self
 
     def _to(self, dtype):
         if not isinstance(dtype, _dtype.ms_dtype):
             raise TypeError(f"Argument 'dtype' must be torch.dtype, not {type(dtype)}")
-        storage = self.inner_data.to(dtype).storage()
+        from mindtorch.torch.tensor import tensor # pylint: disable=R0401, C0415
+        storage = tensor(self.inner_data).to(dtype).storage()
         return storage
 
     def double(self):
         """Casts this storage to double type"""
         return self._to(_dtype.double)
 
     def float(self):
@@ -235,15 +300,15 @@
         return self._to(_dtype.cdouble)
 
     def complex_float(self):
         """Casts this storage to complex float type"""
         return self._to(_dtype.cfloat)
 
     def pin_memory(self):
-        raise NotImplementedError("`pin_memory` is not currently supported.")
+        warning("`storage.pin_memory` is currently not effective.")
 
     def share_memory_(self):
         raise NotImplementedError("`share_memory_` is not currently supported.")
 
     @classmethod
     def _new_shared(cls, size, *, device='cpu'):
         unsupported_attr(size)
@@ -256,14 +321,18 @@
 
 class _UntypedStorage(_StorageBase):
     @property
     def is_cuda(self):
         return self.device.type == 'cuda'
 
 
+def _load_from_bytes(b):
+    from mindtorch.torch.serialization import load # pylint: disable=R0401, C0415
+    return load(io.BytesIO(b))
+
 _StorageBase.type = _type  # type: ignore[assignment]
 _StorageBase.cuda = _cuda  # type: ignore[assignment]
 
 
 @lru_cache(maxsize=None)
 def _dtype_to_storage_type_map():
     return {
@@ -305,15 +374,16 @@
 
     dtype: _dtype.ms_dtype
 
     def fill_(self, value):
         self[0:len(self)] = value
         return self
 
-    def __new__(cls, *args, wrap_storage=None, dtype=None, device=None):
+    def __new__(cls, *args, wrap_storage=None, dtype=None, device=None, _internal=True):
+        unsupported_attr(_internal)
         if cls == _LegacyStorage:
             raise RuntimeError("Only child classes of _LegacyStorage can be instantiated")
 
         if cls == _TypedStorage:
             return super().__new__(cls)
 
         else:
@@ -358,28 +428,29 @@
                         "'wrap_storage'")
 
                 if not isinstance(wrap_storage, _UntypedStorage):
                     raise TypeError(
                         arg_error_msg +
                         f"\nArgument 'wrap_storage' must be _UntypedStorage, but got {type(wrap_storage)}")
 
-                cls_device = 'cuda' if cls.__module__ == 'mindtorch.torch.cuda' else 'cpu'
-
-                if wrap_storage.device.type != cls_device:
-                    raise RuntimeError(
-                        arg_error_msg +
-                        f"\nDevice of 'wrap_storage' must be {cls_device}"
-                        f", but got {wrap_storage.device.type}")
+                # TODO:
+                # cls_device = 'cuda' if cls.__module__ == 'mindtorch.torch.cuda' else 'cpu'
+                # if wrap_storage.device.type != cls_device:
+                #     raise RuntimeError(
+                #         arg_error_msg +
+                #         f"\nDevice of 'wrap_storage' must be {cls_device}"
+                #         f", but got {wrap_storage.device.type}")
 
                 return _TypedStorage(
                     *args,
                     wrap_storage=wrap_storage,
                     dtype=cls.dtype)
 
-    def __init__(self, *args, device=None, dtype=None, wrap_storage=None):
+    def __init__(self, *args, device=None, dtype=None, wrap_storage=None, _internal=True):
+        unsupported_attr(_internal)
         arg_error_msg = (
             '_TypedStorage.__init__ received an invalid combination '
             'of arguments. Expected one of:\n'
             ' * (*, torch.device device, torch.dtype dtype)\n'
             ' * (int size, *, torch.device device, torch.dtype dtype)\n'
             ' * (Sequence data, *, torch.device device, torch.dtype dtype)\n'
             ' * (*, _UntypedStorage wrap_storage, torch.dtype dtype)')
@@ -477,18 +548,31 @@
             else:
                 if (idx >= self.size()) or (idx < -self.size()):
                     raise IndexError(
                         f'index {idx} out of range for storage of size {self.size()}')
                 return idx % self.size()
 
     def __setitem__(self, idx, value):
-        raise NotImplementedError("`__setitem__` is not currently supported.")
+        if not isinstance(idx, (int, slice)):
+            raise RuntimeError(f"can't index a {type(self)} with {type(idx)}")
+
+        tmp_np_data = np.frombuffer(self._storage.inner_data, _TypeDict.get(self.dtype, np.float32))
+        tmp_np_data[idx] = value
+        inner_data = np.frombuffer(tmp_np_data, np.uint8)
+        self._storage.inner_data = inner_data
+        self._storage._update_referenced_tensor()
 
     def __getitem__(self, idx):
-        return self._storage[idx]
+        if isinstance(idx, slice):
+            raise RuntimeError('slices are only supported in _UntypedStorage.__getitem__')
+        elif not isinstance(idx, int):
+            raise RuntimeError(f"can't index a {type(self)} with {type(idx)}")
+        idx_wrapped = self._maybe_wrap_index(idx)
+        tmp_np_data = np.frombuffer(self._storage.inner_data, _TypeDict.get(self.dtype, np.float32))
+        return tmp_np_data[idx_wrapped]
 
     def copy_(self, source, non_blocking=None):
         self._storage.copy_(source._untyped(), non_blocking)
         return self
 
     def nbytes(self):
         return self._storage.nbytes()
@@ -537,15 +621,15 @@
 
     def clone(self):
         """Returns a copy of this storage"""
         return self._new_wrapped_storage(self._storage.clone())
 
     def tolist(self):
         """Returns a list containing the elements of this storage"""
-        return self._storage.tolist()
+        return list(self)
 
     def cpu(self):
         """Returns a CPU copy of this storage if it's not already on the CPU"""
         return self._new_wrapped_storage(self._storage.cpu())
 
     def pin_memory(self):
         """Coppies the  storage to pinned memory, if it's not already pinned."""
@@ -565,15 +649,15 @@
         raise NotImplementedError("`_cdata` is not currently supported.")
 
     @property
     def device(self):
         return self._storage.device
 
     def size(self):
-        return len(self._storage)
+        return len(self)
 
     def pickle_storage_type(self):
         try:
             return _dtype_to_storage_type_map()[self.dtype]
         except KeyError as e:
             raise KeyError(f'dtype {self.dtype} is not recognized') from e
 
@@ -610,15 +694,17 @@
             dtype = cls.dtype
         untyped_storage = _UntypedStorage.from_buffer(*args, dtype=dtype, **kwargs)
         return _TypedStorage(wrap_storage=untyped_storage, dtype=dtype)
 
     def _to(self, dtype):
         if not isinstance(dtype, _dtype.ms_dtype):
             raise TypeError(f"Argument 'dtype' must be torch.dtype, not {type(dtype)}")
-        storage = self._storage.inner_data.to(dtype).storage()
+        from mindtorch.torch.tensor import tensor # pylint: disable=R0401, C0415
+        np_data = np.frombuffer(self._storage.inner_data, _TypeDict.get(self.dtype))
+        storage = tensor(np_data).to(dtype).storage()
         return storage
 
     def double(self):
         """Casts this storage to double type"""
         return self._to(_dtype.double)
 
     def float(self):
@@ -663,15 +749,22 @@
 
     def complex_float(self):
         """Casts this storage to complex float type"""
         return self._to(_dtype.cfloat)
 
     @classmethod
     def from_file(cls, filename, shared, size):
-        raise NotImplementedError("`from_file` is not currently supported.")
+        if cls == _TypedStorage:
+            raise RuntimeError('from_file can only be called on derived classes')
+        untyped_storage = _UntypedStorage.from_file(
+            filename,
+            shared,
+            size * _element_size(cls.dtype))
+        storage = cls(wrap_storage=untyped_storage)
+        return storage
 
     @classmethod
     def _expired(cls, *args, **kwargs):
         return literal_eval(cls.__module__)._UntypedStorage._expired(*args, **kwargs)
 
     def is_pinned(self):
         return self._storage.is_pinned()
@@ -821,7 +914,15 @@
                          _dtype.int8: CharStorage,
                          _dtype.uint8: ByteStorage,
                          _dtype.bool: BoolStorage,
                          _dtype.bfloat16: BFloat16Storage,
                          _dtype.cdouble: ComplexDoubleStorage,
                          _dtype.cfloat: ComplexFloatStorage,
                          }
+
+
+def _get_dtype_from_pickle_storage_type(pickle_storage_type: str):
+    try:
+        return _storage_type_to_dtype_map()[pickle_storage_type]
+    except KeyError as e:
+        raise KeyError(
+            f'pickle storage type "{pickle_storage_type}" is not recognized') from e
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/tensor.py` & `mindtorch-0.3.0/mindtorch/torch/tensor.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10953 +1,11243 @@
 00000000: 2321 2f75 7372 2f62 696e 2f65 6e76 2070  #!/usr/bin/env p
 00000010: 7974 686f 6e0a 2320 2d2a 2d20 636f 6469  ython.# -*- codi
 00000020: 6e67 3a20 7574 662d 3820 2d2a 2d0a 696d  ng: utf-8 -*-.im
-00000030: 706f 7274 2061 6263 0a69 6d70 6f72 7420  port abc.import 
-00000040: 6e75 6d62 6572 730a 696d 706f 7274 206f  numbers.import o
-00000050: 7065 7261 746f 720a 2320 6672 6f6d 2066  perator.# from f
-00000060: 756e 6374 6f6f 6c73 2069 6d70 6f72 7420  unctools import 
-00000070: 7265 6475 6365 2c20 6c72 755f 6361 6368  reduce, lru_cach
-00000080: 650a 6672 6f6d 2063 6f70 7920 696d 706f  e.from copy impo
-00000090: 7274 2064 6565 7063 6f70 790a 6672 6f6d  rt deepcopy.from
-000000a0: 2066 756e 6374 6f6f 6c73 2069 6d70 6f72   functools impor
-000000b0: 7420 7265 6475 6365 0a69 6d70 6f72 7420  t reduce.import 
-000000c0: 6e75 6d70 7920 6173 206e 700a 696d 706f  numpy as np.impo
-000000d0: 7274 206d 696e 6473 706f 7265 2061 7320  rt mindspore as 
-000000e0: 6d73 0a66 726f 6d20 6d69 6e64 7370 6f72  ms.from mindspor
-000000f0: 6520 696d 706f 7274 2054 656e 736f 7220  e import Tensor 
-00000100: 6173 206d 735f 5465 6e73 6f72 0a66 726f  as ms_Tensor.fro
-00000110: 6d20 6d69 6e64 7370 6f72 652e 7363 6970  m mindspore.scip
-00000120: 792e 6f70 7320 696d 706f 7274 2053 6f6c  y.ops import Sol
-00000130: 7665 5472 6961 6e67 756c 6172 0a66 726f  veTriangular.fro
-00000140: 6d20 6d69 6e64 7370 6f72 652e 636f 6d6d  m mindspore.comm
-00000150: 6f6e 2069 6d70 6f72 7420 6474 7970 6520  on import dtype 
-00000160: 6173 206d 7374 7970 650a 696d 706f 7274  as mstype.import
-00000170: 206d 696e 6473 706f 7265 2e6f 7073 2061   mindspore.ops a
-00000180: 7320 500a 6672 6f6d 206d 696e 6473 706f  s P.from mindspo
-00000190: 7265 2e6f 7073 2e70 7269 6d69 7469 7665  re.ops.primitive
-000001a0: 2069 6d70 6f72 7420 5f70 7269 6d65 7870   import _primexp
-000001b0: 720a 6672 6f6d 206d 696e 6473 706f 7265  r.from mindspore
-000001c0: 2e6f 7073 2e5f 7072 696d 6974 6976 655f  .ops._primitive_
-000001d0: 6361 6368 6520 696d 706f 7274 205f 6765  cache import _ge
-000001e0: 745f 6361 6368 655f 7072 696d 0a66 726f  t_cache_prim.fro
-000001f0: 6d20 6d69 6e64 7370 6f72 652e 6f70 732e  m mindspore.ops.
-00000200: 6f70 6572 6174 696f 6e73 2069 6d70 6f72  operations impor
-00000210: 7420 5f69 6e6e 6572 5f6f 7073 2061 7320  t _inner_ops as 
-00000220: 696e 6e65 720a 6672 6f6d 206d 696e 6473  inner.from minds
-00000230: 706f 7265 2e63 6f6d 6d6f 6e2e 696e 6974  pore.common.init
-00000240: 6961 6c69 7a65 7220 696d 706f 7274 205a  ializer import Z
-00000250: 6572 6f0a 6672 6f6d 206d 696e 6473 706f  ero.from mindspo
-00000260: 7265 2e5f 635f 6578 7072 6573 7369 6f6e  re._c_expression
-00000270: 2069 6d70 6f72 7420 5465 6e73 6f72 2061   import Tensor a
-00000280: 7320 5465 6e73 6f72 5f0a 6672 6f6d 206d  s Tensor_.from m
-00000290: 696e 6473 706f 7265 2e63 6f6d 6d6f 6e2e  indspore.common.
-000002a0: 5f73 7475 625f 7465 6e73 6f72 2069 6d70  _stub_tensor imp
-000002b0: 6f72 7420 5374 7562 5465 6e73 6f72 0a0a  ort StubTensor..
-000002c0: 6672 6f6d 206d 696e 6474 6f72 6368 2e75  from mindtorch.u
-000002d0: 7469 6c73 2069 6d70 6f72 7420 756e 7375  tils import unsu
-000002e0: 7070 6f72 7465 645f 6174 7472 2c20 6973  pported_attr, is
-000002f0: 5f75 6e64 6572 5f67 7075 5f63 6f6e 7465  _under_gpu_conte
-00000300: 7874 2c20 6765 745f 6261 636b 656e 642c  xt, get_backend,
-00000310: 2069 735f 756e 6465 725f 6173 6365 6e64   is_under_ascend
-00000320: 5f63 6f6e 7465 7874 2c20 5f69 6e66 6572  _context, _infer
-00000330: 5f73 697a 652c 205c 0a20 2020 205f 6173  _size, \.    _as
-00000340: 6365 6e64 5f74 656e 736f 725f 6765 6e65  cend_tensor_gene
-00000350: 7261 6c5f 6361 7374 2c20 6973 5f75 6e64  ral_cast, is_und
-00000360: 6572 5f63 7075 5f63 6f6e 7465 7874 2c20  er_cpu_context, 
-00000370: 7079 6e61 7469 7665 5f6d 6f64 655f 636f  pynative_mode_co
-00000380: 6e64 6974 696f 6e2c 2073 6574 5f6d 756c  ndition, set_mul
-00000390: 7469 706c 655f 6e61 6d65 5f74 7570 6c65  tiple_name_tuple
-000003a0: 2c20 5c0a 2020 2020 7365 745f 6e61 6d65  , \.    set_name
-000003b0: 5f74 7570 6c65 2c20 6772 6170 685f 6d6f  _tuple, graph_mo
-000003c0: 6465 5f63 6f6e 6469 7469 6f6e 2c20 6269  de_condition, bi
-000003d0: 7477 6973 655f 6164 6170 7465 722c 2046  twise_adapter, F
-000003e0: 5036 345f 4d41 582c 2046 5036 345f 4d49  P64_MAX, FP64_MI
-000003f0: 4e2c 2046 5033 325f 4d41 582c 2046 5033  N, FP32_MAX, FP3
-00000400: 325f 4d49 4e2c 2070 726f 6d6f 7465 5f74  2_MIN, promote_t
-00000410: 7970 655f 6c6f 6f6b 7570 0a69 6d70 6f72  ype_lookup.impor
-00000420: 7420 6d69 6e64 746f 7263 682e 746f 7263  t mindtorch.torc
-00000430: 682e 636f 6d6d 6f6e 2e64 7479 7065 2061  h.common.dtype a
-00000440: 7320 6d73 6461 7074 6572 5f64 7479 7065  s msdapter_dtype
-00000450: 0a66 726f 6d20 6d69 6e64 746f 7263 682e  .from mindtorch.
-00000460: 746f 7263 682e 636f 6d6d 6f6e 2e64 7479  torch.common.dty
-00000470: 7065 2069 6d70 6f72 7420 616c 6c5f 696e  pe import all_in
-00000480: 745f 7479 7065 5f77 6974 685f 626f 6f6c  t_type_with_bool
-00000490: 2c20 6669 6e66 6f2c 2069 696e 666f 2c20  , finfo, iinfo, 
-000004a0: 616c 6c5f 696e 745f 7479 7065 2c20 5f67  all_int_type, _g
-000004b0: 6574 5f74 7970 655f 6672 6f6d 5f64 7479  et_type_from_dty
-000004c0: 7065 2c20 5c0a 2020 2020 5f67 6574 5f64  pe, \.    _get_d
-000004d0: 7479 7065 5f66 726f 6d5f 7479 7065 2c20  type_from_type, 
-000004e0: 616c 6c5f 666c 6f61 745f 616e 645f 636f  all_float_and_co
-000004f0: 6d70 6c65 785f 7479 7065 2c20 616c 6c5f  mplex_type, all_
-00000500: 636f 6d70 6c65 785f 7479 7065 2c20 5f6d  complex_type, _m
-00000510: 7364 7479 7065 3274 7970 6544 6963 740a  sdtype2typeDict.
-00000520: 6672 6f6d 206d 696e 6474 6f72 6368 2e74  from mindtorch.t
-00000530: 6f72 6368 2e74 7970 6573 2069 6d70 6f72  orch.types impor
-00000540: 7420 6465 7669 6365 2061 7320 6465 7669  t device as devi
-00000550: 6365 5f63 6c61 7373 0a66 726f 6d20 6d69  ce_class.from mi
-00000560: 6e64 746f 7263 682e 746f 7263 682e 7374  ndtorch.torch.st
-00000570: 6f72 6167 6520 696d 706f 7274 205f 5479  orage import _Ty
-00000580: 7065 6453 746f 7261 6765 2c20 5f55 6e74  pedStorage, _Unt
-00000590: 7970 6564 5374 6f72 6167 650a 6672 6f6d  ypedStorage.from
-000005a0: 206d 696e 6474 6f72 6368 2e74 6f72 6368   mindtorch.torch
-000005b0: 2e6c 6f67 6769 6e67 2069 6d70 6f72 7420  .logging import 
-000005c0: 7761 726e 696e 670a 696d 706f 7274 206d  warning.import m
-000005d0: 696e 6474 6f72 6368 2e74 6f72 6368 2e5f  indtorch.torch._
-000005e0: 7265 6769 7374 6572 5f6e 756d 7079 5f70  register_numpy_p
-000005f0: 7269 6d69 7469 7665 2020 6173 206e 756d  rimitive  as num
-00000600: 7079 5f63 656c 6c0a 6672 6f6d 206d 696e  py_cell.from min
-00000610: 6474 6f72 6368 2e74 6f72 6368 2e5f 6465  dtorch.torch._de
-00000620: 6661 756c 745f 6474 7970 6520 696d 706f  fault_dtype impo
-00000630: 7274 205f 6e6f 745f 6465 6661 756c 745f  rt _not_default_
-00000640: 6670 3332 5f64 7479 7065 2c20 6765 745f  fp32_dtype, get_
-00000650: 6465 6661 756c 745f 6474 7970 650a 0a0a  default_dtype...
-00000660: 5f64 7479 7065 4469 6374 203d 207b 0a20  _dtypeDict = {. 
-00000670: 2020 2027 666c 6f61 7431 3627 3a20 6d73     'float16': ms
-00000680: 7479 7065 2e66 6c6f 6174 3136 2c0a 2020  type.float16,.  
-00000690: 2020 2766 6c6f 6174 3332 273a 206d 7374    'float32': mst
-000006a0: 7970 652e 666c 6f61 7433 322c 0a20 2020  ype.float32,.   
-000006b0: 2027 666c 6f61 7436 3427 3a20 6d73 7479   'float64': msty
-000006c0: 7065 2e66 6c6f 6174 3634 2c0a 2020 2020  pe.float64,.    
-000006d0: 2769 6e74 3827 3a20 6d73 7479 7065 2e69  'int8': mstype.i
-000006e0: 6e74 382c 0a20 2020 2027 696e 7431 3627  nt8,.    'int16'
-000006f0: 3a20 6d73 7479 7065 2e69 6e74 3136 2c0a  : mstype.int16,.
-00000700: 2020 2020 2769 6e74 3332 273a 206d 7374      'int32': mst
-00000710: 7970 652e 696e 7433 322c 0a20 2020 2027  ype.int32,.    '
-00000720: 696e 7436 3427 3a20 6d73 7479 7065 2e69  int64': mstype.i
-00000730: 6e74 3634 2c0a 2020 2020 2775 696e 7438  nt64,.    'uint8
-00000740: 273a 206d 7374 7970 652e 7569 6e74 382c  ': mstype.uint8,
-00000750: 0a20 2020 2027 626f 6f6c 273a 206d 7374  .    'bool': mst
-00000760: 7970 652e 626f 6f6c 5f2c 0a20 2020 2027  ype.bool_,.    '
-00000770: 636f 6d70 6c65 7836 3427 3a20 6d73 7479  complex64': msty
-00000780: 7065 2e63 6f6d 706c 6578 3634 2c0a 2020  pe.complex64,.  
-00000790: 2020 2763 6f6d 706c 6578 3132 3827 3a20    'complex128': 
-000007a0: 6d73 7479 7065 2e63 6f6d 706c 6578 3132  mstype.complex12
-000007b0: 382c 0a20 2020 2027 6c6f 6e67 273a 206d  8,.    'long': m
-000007c0: 7374 7970 652e 696e 7436 342c 0a20 2020  stype.int64,.   
-000007d0: 2027 6861 6c66 273a 206d 7374 7970 652e   'half': mstype.
-000007e0: 666c 6f61 7431 362c 0a20 2020 2027 696e  float16,.    'in
-000007f0: 7427 3a20 6d73 7479 7065 2e69 6e74 3332  t': mstype.int32
-00000800: 2c0a 2020 2020 2764 6f75 626c 6527 3a20  ,.    'double': 
-00000810: 6d73 7479 7065 2e66 6c6f 6174 3634 2c0a  mstype.float64,.
-00000820: 2020 2020 2766 6c6f 6174 273a 206d 7374      'float': mst
-00000830: 7970 652e 666c 6f61 7433 322c 0a20 2020  ype.float32,.   
-00000840: 2027 6368 6172 273a 206d 7374 7970 652e   'char': mstype.
-00000850: 696e 7438 2c0a 2020 2020 2762 7974 6527  int8,.    'byte'
-00000860: 3a20 6d73 7479 7065 2e75 696e 7438 2c0a  : mstype.uint8,.
-00000870: 2020 2020 2773 686f 7274 273a 206d 7374      'short': mst
-00000880: 7970 652e 696e 7431 362c 0a20 2020 2027  ype.int16,.    '
-00000890: 6266 6c6f 6174 3136 273a 206d 7374 7970  bfloat16': mstyp
-000008a0: 652e 6266 6c6f 6174 3136 0a7d 0a0a 6b4d  e.bfloat16.}..kM
-000008b0: 6178 496e 7438 203d 2032 202a 2a20 3720  axInt8 = 2 ** 7 
-000008c0: 2d20 310a 6b4d 6178 496e 7431 3620 3d20  - 1.kMaxInt16 = 
-000008d0: 3220 2a2a 2031 3520 2d20 310a 6b4d 6178  2 ** 15 - 1.kMax
-000008e0: 496e 7433 3220 3d20 3220 2a2a 2033 3120  Int32 = 2 ** 31 
-000008f0: 2d20 310a 6b4d 6178 496e 7436 3420 3d20  - 1.kMaxInt64 = 
-00000900: 3220 2a2a 2036 3320 2d20 310a 6b4d 6178  2 ** 63 - 1.kMax
-00000910: 5569 6e74 3820 3d20 3220 2a2a 2038 202d  Uint8 = 2 ** 8 -
-00000920: 2031 0a6b 4d61 7855 696e 7431 3620 3d20   1.kMaxUint16 = 
-00000930: 3220 2a2a 2031 3620 2d20 310a 6b4d 6178  2 ** 16 - 1.kMax
-00000940: 5569 6e74 3332 203d 2032 202a 2a20 3332  Uint32 = 2 ** 32
-00000950: 202d 2031 0a6b 4d61 7855 696e 7436 3420   - 1.kMaxUint64 
-00000960: 3d20 3220 2a2a 2036 3420 2d20 310a 6b4d  = 2 ** 64 - 1.kM
-00000970: 616e 7469 7373 6146 6c6f 6174 3136 203d  antissaFloat16 =
-00000980: 2032 202a 2a20 3131 0a6b 4d61 6e74 6973   2 ** 11.kMantis
-00000990: 7361 466c 6f61 7433 3220 3d20 3220 2a2a  saFloat32 = 2 **
-000009a0: 2032 340a 6b4d 616e 7469 7373 6146 6c6f   24.kMantissaFlo
-000009b0: 6174 3634 203d 2032 202a 2a20 3533 0a0a  at64 = 2 ** 53..
-000009c0: 0a40 5f70 7269 6d65 7870 720a 2320 406c  .@_primexpr.# @l
-000009d0: 7275 5f63 6163 6865 285f 474c 4f42 414c  ru_cache(_GLOBAL
-000009e0: 5f4c 5255 5f43 4143 4845 5f53 495a 4529  _LRU_CACHE_SIZE)
-000009f0: 0a64 6566 205f 6765 745f 756e 666c 6174  .def _get_unflat
-00000a00: 7465 6e5f 7369 7a65 2869 6e70 7574 5f73  ten_size(input_s
-00000a10: 6861 7065 2c20 6469 6d2c 2073 697a 6573  hape, dim, sizes
-00000a20: 293a 0a20 2020 2069 6e70 7574 5f72 616e  ):.    input_ran
-00000a30: 6b20 3d20 6c65 6e28 696e 7075 745f 7368  k = len(input_sh
-00000a40: 6170 6529 0a20 2020 2069 6620 6e6f 7420  ape).    if not 
-00000a50: 6973 696e 7374 616e 6365 2873 697a 6573  isinstance(sizes
-00000a60: 2c20 2874 7570 6c65 2c20 6c69 7374 2929  , (tuple, list))
-00000a70: 3a0a 2020 2020 2020 2020 7261 6973 6520  :.        raise 
-00000a80: 5479 7065 4572 726f 7228 6622 5479 7065  TypeError(f"Type
-00000a90: 206f 6620 6073 697a 6573 6020 7368 6f75   of `sizes` shou
-00000aa0: 6c64 2062 6520 6054 7570 6c65 6020 6f72  ld be `Tuple` or
-00000ab0: 2060 4c69 7374 602c 2062 7574 2067 6f74   `List`, but got
-00000ac0: 207b 7479 7065 2873 697a 6573 297d 2229   {type(sizes)}")
-00000ad0: 0a0a 2020 2020 6966 206c 656e 2873 697a  ..    if len(siz
-00000ae0: 6573 2920 3d3d 2030 3a0a 2020 2020 2020  es) == 0:.      
-00000af0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-00000b00: 6f72 2822 6073 697a 6573 6020 6d75 7374  or("`sizes` must
-00000b10: 2062 6520 6e6f 6e2d 656d 7074 7922 290a   be non-empty").
-00000b20: 0a20 2020 2069 6620 6973 696e 7374 616e  .    if isinstan
-00000b30: 6365 2864 696d 2c20 7374 7229 3a0a 2020  ce(dim, str):.  
-00000b40: 2020 2020 2020 7261 6973 6520 5479 7065        raise Type
-00000b50: 4572 726f 7228 2255 6e74 696c 204e 6f77  Error("Until Now
-00000b60: 2c20 6064 696d 6020 6e6f 7420 7375 7070  , `dim` not supp
-00000b70: 6f72 7420 7479 7065 206f 6620 7374 7220  ort type of str 
-00000b80: 696e 2060 756e 666c 6174 7465 6e60 2229  in `unflatten`")
-00000b90: 0a0a 2020 2020 5f64 696d 203d 2064 696d  ..    _dim = dim
-00000ba0: 0a20 2020 2069 6620 5f64 696d 203c 2030  .    if _dim < 0
-00000bb0: 3a0a 2020 2020 2020 2020 5f64 696d 202b  :.        _dim +
-00000bc0: 3d20 696e 7075 745f 7261 6e6b 0a0a 2020  = input_rank..  
-00000bd0: 2020 6966 205f 6469 6d20 3c20 3020 6f72    if _dim < 0 or
-00000be0: 205f 6469 6d20 3e3d 2069 6e70 7574 5f72   _dim >= input_r
-00000bf0: 616e 6b3a 0a20 2020 2020 2020 2072 6169  ank:.        rai
-00000c00: 7365 2056 616c 7565 4572 726f 7228 2260  se ValueError("`
-00000c10: 6469 6d60 2073 686f 756c 6420 6265 2069  dim` should be i
-00000c20: 6e20 7261 6e67 6520 5b7b 7d2c 207b 7d29  n range [{}, {})
-00000c30: 2c20 6275 7420 676f 7420 7b7d 222e 666f  , but got {}".fo
-00000c40: 726d 6174 282d 696e 7075 745f 7261 6e6b  rmat(-input_rank
-00000c50: 2c20 696e 7075 745f 7261 6e6b 2c20 6469  , input_rank, di
-00000c60: 6d29 290a 0a20 2020 205f 7369 7a65 735f  m))..    _sizes_
-00000c70: 6d75 6c20 3d20 7265 6475 6365 286f 7065  mul = reduce(ope
-00000c80: 7261 746f 722e 6d75 6c2c 206c 6973 7428  rator.mul, list(
-00000c90: 7369 7a65 7329 290a 2020 2020 6966 202d  sizes)).    if -
-00000ca0: 3120 6e6f 7420 696e 2073 697a 6573 2061  1 not in sizes a
-00000cb0: 6e64 205f 7369 7a65 735f 6d75 6c20 213d  nd _sizes_mul !=
-00000cc0: 2069 6e70 7574 5f73 6861 7065 5b5f 6469   input_shape[_di
-00000cd0: 6d5d 3a0a 2020 2020 2020 2020 7261 6973  m]:.        rais
-00000ce0: 6520 5661 6c75 6545 7272 6f72 2866 2275  e ValueError(f"u
-00000cf0: 6e66 6c61 7474 656e 3a20 5072 6f76 6964  nflatten: Provid
-00000d00: 6564 2060 7369 7a65 7360 207b 7369 7a65  ed `sizes` {size
-00000d10: 737d 2064 6f6e 2774 206d 756c 7469 706c  s} don't multipl
-00000d20: 7920 7570 2074 6f20 7468 6522 0a20 2020  y up to the".   
-00000d30: 2020 2020 2020 2020 2066 2273 697a 6520           f"size 
-00000d40: 6f66 2064 696d 207b 6469 6d7d 2028 7b69  of dim {dim} ({i
-00000d50: 6e70 7574 5f73 6861 7065 5b5f 6469 6d5d  nput_shape[_dim]
-00000d60: 7d29 2069 6e20 7468 6520 696e 7075 7420  }) in the input 
-00000d70: 7465 6e73 6f72 2229 0a0a 2020 2020 6f75  tensor")..    ou
-00000d80: 745f 7368 6170 6520 3d20 696e 7075 745f  t_shape = input_
-00000d90: 7368 6170 655b 3a5f 6469 6d5d 202b 2074  shape[:_dim] + t
-00000da0: 7570 6c65 2873 697a 6573 2920 2b20 696e  uple(sizes) + in
-00000db0: 7075 745f 7368 6170 655b 5f64 696d 202b  put_shape[_dim +
-00000dc0: 2031 3a5d 0a20 2020 2072 6574 7572 6e20   1:].    return 
-00000dd0: 6f75 745f 7368 6170 650a 0a0a 405f 7072  out_shape...@_pr
-00000de0: 696d 6578 7072 0a23 2040 6c72 755f 6361  imexpr.# @lru_ca
-00000df0: 6368 6528 5f47 4c4f 4241 4c5f 4c52 555f  che(_GLOBAL_LRU_
-00000e00: 4341 4348 455f 5349 5a45 290a 6465 6620  CACHE_SIZE).def 
-00000e10: 5f67 6574 5f73 6c69 6365 5f73 6361 7474  _get_slice_scatt
-00000e20: 6572 5f63 6f6e 7374 2878 5f73 6861 7065  er_const(x_shape
-00000e30: 2c20 6469 6d2c 2073 7461 7274 2c20 656e  , dim, start, en
-00000e40: 642c 2073 7465 7029 3a0a 2020 2020 785f  d, step):.    x_
-00000e50: 7261 6e6b 203d 206c 656e 2878 5f73 6861  rank = len(x_sha
-00000e60: 7065 290a 2020 2020 6469 6d20 3d20 6469  pe).    dim = di
-00000e70: 6d20 6966 2064 696d 203e 3d20 3020 656c  m if dim >= 0 el
-00000e80: 7365 2064 696d 202b 2078 5f72 616e 6b0a  se dim + x_rank.
-00000e90: 2020 2020 7374 6172 7420 3d20 7374 6172      start = star
-00000ea0: 7420 6966 2073 7461 7274 2065 6c73 6520  t if start else 
-00000eb0: 300a 2020 2020 656e 6420 3d20 656e 6420  0.    end = end 
-00000ec0: 6966 2065 6e64 2065 6c73 6520 785f 7368  if end else x_sh
-00000ed0: 6170 655b 6469 6d5d 0a20 2020 2069 6e64  ape[dim].    ind
-00000ee0: 6578 203d 206c 6973 7428 7261 6e67 6528  ex = list(range(
-00000ef0: 7374 6172 742c 2065 6e64 2c20 7374 6570  start, end, step
-00000f00: 2929 0a20 2020 2072 6574 7572 6e20 785f  )).    return x_
-00000f10: 7261 6e6b 2c20 696e 6465 782c 2064 696d  rank, index, dim
-00000f20: 0a0a 0a40 5f70 7269 6d65 7870 720a 2320  ...@_primexpr.# 
-00000f30: 406c 7275 5f63 6163 6865 285f 474c 4f42  @lru_cache(_GLOB
-00000f40: 414c 5f4c 5255 5f43 4143 4845 5f53 495a  AL_LRU_CACHE_SIZ
-00000f50: 4529 0a64 6566 205f 6765 745f 7365 6c65  E).def _get_sele
-00000f60: 6374 5f6f 7574 5f73 6861 7065 2869 6e70  ct_out_shape(inp
-00000f70: 7574 5f73 6861 7065 2c20 6469 6d29 3a0a  ut_shape, dim):.
-00000f80: 2020 2020 7368 6170 6520 3d20 5b69 6e70      shape = [inp
-00000f90: 7574 5f73 6861 7065 5b69 5d20 666f 7220  ut_shape[i] for 
-00000fa0: 6920 696e 2072 616e 6765 286c 656e 2869  i in range(len(i
-00000fb0: 6e70 7574 5f73 6861 7065 2929 2069 6620  nput_shape)) if 
-00000fc0: 6920 213d 2064 696d 5d0a 2020 2020 7265  i != dim].    re
-00000fd0: 7475 726e 2074 7570 6c65 2873 6861 7065  turn tuple(shape
-00000fe0: 290a 0a0a 405f 7072 696d 6578 7072 0a23  )...@_primexpr.#
-00000ff0: 2040 6c72 755f 6361 6368 6528 5f47 4c4f   @lru_cache(_GLO
-00001000: 4241 4c5f 4c52 555f 4341 4348 455f 5349  BAL_LRU_CACHE_SI
-00001010: 5a45 290a 6465 6620 5f67 6574 5f75 6e66  ZE).def _get_unf
-00001020: 6f6c 645f 696e 6469 6365 7328 696e 7075  old_indices(inpu
-00001030: 745f 7368 6170 652c 2064 696d 656e 7369  t_shape, dimensi
-00001040: 6f6e 2c20 7369 7a65 2c20 7374 6570 293a  on, size, step):
-00001050: 0a20 2020 2069 6620 6469 6d65 6e73 696f  .    if dimensio
-00001060: 6e20 3c20 303a 0a20 2020 2020 2020 2064  n < 0:.        d
-00001070: 696d 656e 7369 6f6e 202b 3d20 6c65 6e28  imension += len(
-00001080: 696e 7075 745f 7368 6170 6529 0a20 2020  input_shape).   
-00001090: 2069 6e64 6963 6573 203d 205b 5d0a 2020   indices = [].  
-000010a0: 2020 666f 7220 6920 696e 2072 616e 6765    for i in range
-000010b0: 2830 2c20 696e 7075 745f 7368 6170 655b  (0, input_shape[
-000010c0: 6469 6d65 6e73 696f 6e5d 202d 2073 697a  dimension] - siz
-000010d0: 6520 2b20 312c 2073 7465 7029 3a0a 2020  e + 1, step):.  
-000010e0: 2020 2020 2020 696e 6469 6365 732e 6170        indices.ap
-000010f0: 7065 6e64 286c 6973 7428 7261 6e67 6528  pend(list(range(
-00001100: 692c 2069 202b 2073 697a 6529 2929 0a0a  i, i + size)))..
-00001110: 2020 2020 7265 7475 726e 2069 6e64 6963      return indic
-00001120: 6573 2c20 6469 6d65 6e73 696f 6e0a 0a40  es, dimension..@
-00001130: 5f70 7269 6d65 7870 720a 6465 6620 5f63  _primexpr.def _c
-00001140: 6865 636b 5f69 6e74 5f73 697a 6528 7369  heck_int_size(si
-00001150: 7a65 2c20 6f70 5f6e 616d 652c 2061 7267  ze, op_name, arg
-00001160: 5f6e 616d 653d 2773 697a 6527 293a 0a20  _name='size'):. 
-00001170: 2020 2023 2043 6865 636b 2077 6865 7468     # Check wheth
-00001180: 6572 2027 6172 675f 6e61 6d65 2720 6973  er 'arg_name' is
-00001190: 2061 6e20 696e 7465 6765 7220 6f72 2061   an integer or a
-000011a0: 2074 656e 736f 7220 7769 7468 2049 6e74   tensor with Int
-000011b0: 2074 7970 652c 206f 7220 6120 7475 706c   type, or a tupl
-000011c0: 652f 6c69 7374 2063 6f6d 706f 7365 6420  e/list composed 
-000011d0: 6f66 2074 6865 6d2c 0a20 2020 2023 2077  of them,.    # w
-000011e0: 6869 6c65 2063 6f6e 7665 7274 696e 6720  hile converting 
-000011f0: 7468 656d 2075 6e69 666f 726d 6c79 2074  them uniformly t
-00001200: 6f20 696e 7465 6765 722e 0a20 2020 2069  o integer..    i
-00001210: 6620 6973 696e 7374 616e 6365 2873 697a  f isinstance(siz
-00001220: 652c 2054 656e 736f 7229 2061 6e64 2073  e, Tensor) and s
-00001230: 697a 652e 6474 7970 6520 696e 2061 6c6c  ize.dtype in all
-00001240: 5f69 6e74 5f74 7970 653a 0a20 2020 2020  _int_type:.     
-00001250: 2020 2073 697a 6520 3d20 696e 7428 7369     size = int(si
-00001260: 7a65 290a 2020 2020 656c 6966 2069 7369  ze).    elif isi
-00001270: 6e73 7461 6e63 6528 7369 7a65 2c20 2874  nstance(size, (t
-00001280: 7570 6c65 2c20 6c69 7374 2929 3a0a 2020  uple, list)):.  
-00001290: 2020 2020 2020 7369 7a65 5f20 3d20 2829        size_ = ()
-000012a0: 0a20 2020 2020 2020 2066 6f72 2069 7465  .        for ite
-000012b0: 6d20 696e 2073 697a 653a 0a20 2020 2020  m in size:.     
-000012c0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-000012d0: 616e 6365 2869 7465 6d2c 2069 6e74 293a  ance(item, int):
-000012e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000012f0: 2073 697a 655f 203d 2073 697a 655f 202b   size_ = size_ +
-00001300: 2028 6974 656d 2c29 0a20 2020 2020 2020   (item,).       
-00001310: 2020 2020 2065 6c69 6620 6973 696e 7374       elif isinst
-00001320: 616e 6365 2869 7465 6d2c 2054 656e 736f  ance(item, Tenso
-00001330: 7229 2061 6e64 2069 7465 6d2e 6474 7970  r) and item.dtyp
-00001340: 6520 696e 2061 6c6c 5f69 6e74 5f74 7970  e in all_int_typ
-00001350: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-00001360: 2020 2073 697a 655f 203d 2073 697a 655f     size_ = size_
-00001370: 202b 2028 696e 7428 6974 656d 292c 290a   + (int(item),).
-00001380: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00001390: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-000013a0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-000013b0: 6f72 2866 2246 6f72 2027 7b6f 705f 6e61  or(f"For '{op_na
-000013c0: 6d65 7d27 2c20 7468 6520 636f 6d70 6f6e  me}', the compon
-000013d0: 656e 7420 6f66 2027 7b61 7267 5f6e 616d  ent of '{arg_nam
-000013e0: 657d 2720 6d75 7374 2062 6520 6f66 2074  e}' must be of t
-000013f0: 7970 6520 696e 742c 2022 205c 0a20 2020  ype int, " \.   
-00001400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001410: 2020 2020 2020 2020 2020 2020 2020 6622                f"
-00001420: 6275 7420 676f 7420 7b74 7970 6528 6974  but got {type(it
-00001430: 656d 297d 2e22 290a 2020 2020 2020 2020  em)}.").        
-00001440: 7369 7a65 203d 2073 697a 655f 0a20 2020  size = size_.   
-00001450: 2065 6c69 6620 7369 7a65 2061 6e64 206e   elif size and n
-00001460: 6f74 2069 7369 6e73 7461 6e63 6528 7369  ot isinstance(si
-00001470: 7a65 2c20 696e 7429 3a0a 2020 2020 2020  ze, int):.      
-00001480: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-00001490: 6f72 2866 2246 6f72 2027 7b6f 705f 6e61  or(f"For '{op_na
-000014a0: 6d65 7d27 2c20 7468 6520 277b 6172 675f  me}', the '{arg_
-000014b0: 6e61 6d65 7d27 206d 7573 7420 6265 206f  name}' must be o
-000014c0: 6620 7479 7065 2069 6e74 2c20 6275 7420  f type int, but 
-000014d0: 676f 7420 7b74 7970 6528 7369 7a65 297d  got {type(size)}
-000014e0: 2e22 290a 2020 2020 7265 7475 726e 2073  .").    return s
-000014f0: 697a 650a 0a0a 6465 6620 6375 7374 6f6d  ize...def custom
-00001500: 5f6d 6174 6d75 6c28 696e 7075 742c 206f  _matmul(input, o
-00001510: 7468 6572 293a 0a20 2020 2023 2054 4f44  ther):.    # TOD
-00001520: 4f3a 206d 732e 6f70 732e 6d61 746d 756c  O: ms.ops.matmul
-00001530: 206e 6f74 2073 7570 706f 7274 2069 6e74   not support int
-00001540: 2d64 7479 7065 2069 6e70 7365 6c66 2e64  -dtype inpself.d
-00001550: 7479 7065 7574 206f 6e20 4750 552c 206f  typeut on GPU, o
-00001560: 6e6c 7920 7375 7070 6f72 7420 666c 6f61  nly support floa
-00001570: 7431 362f 666c 6f61 7433 3220 6474 7970  t16/float32 dtyp
-00001580: 6520 696e 7075 742e 0a20 2020 2069 6e70  e input..    inp
-00001590: 7574 5f64 7479 7065 203d 2069 6e70 7574  ut_dtype = input
-000015a0: 2e64 7479 7065 0a20 2020 206f 7468 6572  .dtype.    other
-000015b0: 5f64 7479 7065 203d 206f 7468 6572 2e64  _dtype = other.d
-000015c0: 7479 7065 0a20 2020 2069 6620 696e 7075  type.    if inpu
-000015d0: 745f 6474 7970 6520 213d 206f 7468 6572  t_dtype != other
-000015e0: 5f64 7479 7065 3a0a 2020 2020 2020 2020  _dtype:.        
-000015f0: 5275 6e74 696d 6545 7272 6f72 2822 466f  RuntimeError("Fo
-00001600: 7220 6d61 746d 756c 2c20 6578 7065 6374  r matmul, expect
-00001610: 6564 2073 6361 6c61 7220 7479 7065 207b  ed scalar type {
-00001620: 7d2c 2062 7574 2066 6f75 6e64 207b 7d2e  }, but found {}.
-00001630: 222e 666f 726d 6174 2869 6e70 7574 5f64  ".format(input_d
-00001640: 7479 7065 2c20 6f74 6865 725f 6474 7970  type, other_dtyp
-00001650: 6529 290a 0a20 2020 2069 6620 6973 5f75  e))..    if is_u
-00001660: 6e64 6572 5f67 7075 5f63 6f6e 7465 7874  nder_gpu_context
-00001670: 2829 2061 6e64 2069 6e70 7574 5f64 7479  () and input_dty
-00001680: 7065 206e 6f74 2069 6e20 286d 732e 666c  pe not in (ms.fl
-00001690: 6f61 7433 322c 206d 732e 666c 6f61 7431  oat32, ms.float1
-000016a0: 3629 3a0a 2020 2020 2020 2020 696e 7075  6):.        inpu
-000016b0: 7420 3d20 696e 7075 742e 6173 7479 7065  t = input.astype
-000016c0: 286d 732e 666c 6f61 7433 3229 0a20 2020  (ms.float32).   
-000016d0: 2020 2020 206f 7468 6572 203d 206f 7468       other = oth
-000016e0: 6572 2e61 7374 7970 6528 6d73 2e66 6c6f  er.astype(ms.flo
-000016f0: 6174 3332 290a 0a20 2020 206e 6469 6d31  at32)..    ndim1
-00001700: 5f6f 7269 6720 3d20 6d73 2e6f 7073 2e72  _orig = ms.ops.r
-00001710: 616e 6b28 696e 7075 7429 0a20 2020 206e  ank(input).    n
-00001720: 6469 6d32 5f6f 7269 6720 3d20 6d73 2e6f  dim2_orig = ms.o
-00001730: 7073 2e72 616e 6b28 6f74 6865 7229 0a20  ps.rank(other). 
-00001740: 2020 2069 6620 6e64 696d 315f 6f72 6967     if ndim1_orig
-00001750: 203d 3d20 6e64 696d 325f 6f72 6967 3a0a   == ndim2_orig:.
-00001760: 2020 2020 2020 2020 6966 206e 6469 6d31          if ndim1
-00001770: 5f6f 7269 6720 3d3d 2032 3a0a 2020 2020  _orig == 2:.    
-00001780: 2020 2020 2020 2020 5f6d 6174 6d75 6c20          _matmul 
-00001790: 3d20 5f67 6574 5f63 6163 6865 5f70 7269  = _get_cache_pri
-000017a0: 6d28 502e 4d61 744d 756c 2928 4661 6c73  m(P.MatMul)(Fals
-000017b0: 652c 2046 616c 7365 290a 2020 2020 2020  e, False).      
-000017c0: 2020 2020 2020 7265 7475 726e 205f 6d61        return _ma
-000017d0: 746d 756c 2869 6e70 7574 2c20 6f74 6865  tmul(input, othe
-000017e0: 7229 2e61 7374 7970 6528 696e 7075 745f  r).astype(input_
-000017f0: 6474 7970 6529 0a0a 2020 2020 7265 7475  dtype)..    retu
-00001800: 726e 206d 732e 6f70 732e 6d61 746d 756c  rn ms.ops.matmul
-00001810: 2869 6e70 7574 2c20 6f74 6865 7229 2e61  (input, other).a
-00001820: 7374 7970 6528 696e 7075 745f 6474 7970  stype(input_dtyp
-00001830: 6529 0a0a 405f 7072 696d 6578 7072 0a64  e)..@_primexpr.d
-00001840: 6566 205f 6765 745f 6469 6167 6f6e 616c  ef _get_diagonal
-00001850: 5f73 6361 7474 6572 5f69 6e64 6578 2869  _scatter_index(i
-00001860: 6e70 7574 5f73 6861 7065 2c20 6f66 6673  nput_shape, offs
-00001870: 6574 2c20 6469 6d31 2c20 6469 6d32 293a  et, dim1, dim2):
-00001880: 0a20 2020 206e 6469 6d20 3d20 6c65 6e28  .    ndim = len(
-00001890: 696e 7075 745f 7368 6170 6529 0a20 2020  input_shape).   
-000018a0: 205f 666c 6167 203d 2030 0a20 2020 2069   _flag = 0.    i
-000018b0: 6620 6f66 6673 6574 203e 2030 206f 7220  f offset > 0 or 
-000018c0: 286f 6666 7365 7420 3d3d 2030 2061 6e64  (offset == 0 and
-000018d0: 2069 6e70 7574 5f73 6861 7065 5b64 696d   input_shape[dim
-000018e0: 325d 202d 206f 6666 7365 7420 3c20 696e  2] - offset < in
-000018f0: 7075 745f 7368 6170 655b 6469 6d31 5d29  put_shape[dim1])
-00001900: 3a0a 2020 2020 2020 2020 5f66 6c61 6720  :.        _flag 
-00001910: 3d20 310a 2020 2020 2020 2020 5f61 7261  = 1.        _ara
-00001920: 6e67 655f 7369 7a65 203d 206d 696e 2869  nge_size = min(i
-00001930: 6e70 7574 5f73 6861 7065 5b64 696d 315d  nput_shape[dim1]
-00001940: 2c20 696e 7075 745f 7368 6170 655b 6469  , input_shape[di
-00001950: 6d32 5d20 2d20 6f66 6673 6574 290a 2020  m2] - offset).  
-00001960: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00001970: 5f61 7261 6e67 655f 7369 7a65 203d 2069  _arange_size = i
-00001980: 6e70 7574 5f73 6861 7065 5b64 696d 315d  nput_shape[dim1]
-00001990: 0a0a 2020 2020 696e 6465 785f 7368 6170  ..    index_shap
-000019a0: 6520 3d20 6c69 7374 2869 6e70 7574 5f73  e = list(input_s
-000019b0: 6861 7065 290a 2020 2020 696e 6465 785f  hape).    index_
-000019c0: 7368 6170 655b 6469 6d32 5d20 3d20 310a  shape[dim2] = 1.
-000019d0: 2020 2020 6966 205f 666c 6167 203d 3d20      if _flag == 
-000019e0: 313a 0a20 2020 2020 2020 2069 6e64 6578  1:.        index
-000019f0: 5f73 6861 7065 5b64 696d 315d 203d 205f  _shape[dim1] = _
-00001a00: 6172 616e 6765 5f73 697a 650a 2020 2020  arange_size.    
-00001a10: 696e 6465 785f 7368 6170 6520 3d20 7475  index_shape = tu
-00001a20: 706c 6528 696e 6465 785f 7368 6170 6529  ple(index_shape)
-00001a30: 0a0a 2020 2020 696e 6465 7820 3d20 6e70  ..    index = np
-00001a40: 2e61 7261 6e67 6528 5f61 7261 6e67 655f  .arange(_arange_
-00001a50: 7369 7a65 290a 2020 2020 696e 6465 7820  size).    index 
-00001a60: 3d20 696e 6465 7820 2b20 6f66 6673 6574  = index + offset
-00001a70: 0a20 2020 2069 6e64 6578 203d 206e 702e  .    index = np.
-00001a80: 6578 7061 6e64 5f64 696d 7328 696e 6465  expand_dims(inde
-00001a90: 782c 202d 3129 0a20 2020 2066 6f72 205f  x, -1).    for _
-00001aa0: 2069 6e20 7261 6e67 6528 302c 2064 696d   in range(0, dim
-00001ab0: 3129 3a0a 2020 2020 2020 2020 696e 6465  1):.        inde
-00001ac0: 7820 3d20 6e70 2e65 7870 616e 645f 6469  x = np.expand_di
-00001ad0: 6d73 2869 6e64 6578 2c20 3029 0a20 2020  ms(index, 0).   
-00001ae0: 2066 6f72 2069 2069 6e20 7261 6e67 6528   for i in range(
-00001af0: 6469 6d31 202b 2031 2c20 6469 6d32 293a  dim1 + 1, dim2):
-00001b00: 0a20 2020 2020 2020 2069 6e64 6578 203d  .        index =
-00001b10: 206e 702e 6578 7061 6e64 5f64 696d 7328   np.expand_dims(
-00001b20: 696e 6465 782c 2069 290a 2020 2020 666f  index, i).    fo
-00001b30: 7220 5f20 696e 2072 616e 6765 2864 696d  r _ in range(dim
-00001b40: 3120 2b20 322c 206e 6469 6d29 3a0a 2020  1 + 2, ndim):.  
-00001b50: 2020 2020 2020 696e 6465 7820 3d20 6e70        index = np
-00001b60: 2e65 7870 616e 645f 6469 6d73 2869 6e64  .expand_dims(ind
-00001b70: 6578 2c20 2d31 290a 2020 2020 696e 6465  ex, -1).    inde
-00001b80: 7820 3d20 6e70 2e62 726f 6164 6361 7374  x = np.broadcast
-00001b90: 5f74 6f28 696e 6465 782c 2069 6e64 6578  _to(index, index
-00001ba0: 5f73 6861 7065 290a 2020 2020 7265 7475  _shape).    retu
-00001bb0: 726e 2069 6e64 6578 0a0a 405f 7072 696d  rn index..@_prim
-00001bc0: 6578 7072 0a64 6566 205f 6e6f 726d 5f67  expr.def _norm_g
-00001bd0: 6574 5f63 6f6e 7374 2870 2c20 6469 6d2c  et_const(p, dim,
-00001be0: 206e 6469 6d29 3a0a 2020 2020 6966 2070   ndim):.    if p
-00001bf0: 206e 6f74 2069 6e20 5b4e 6f6e 652c 2027   not in [None, '
-00001c00: 6672 6f27 2c20 276e 7563 272c 2066 6c6f  fro', 'nuc', flo
-00001c10: 6174 2827 696e 6627 292c 2066 6c6f 6174  at('inf'), float
-00001c20: 2827 2d69 6e66 2729 2c20 302c 2031 2c20  ('-inf'), 0, 1, 
-00001c30: 2d31 2c20 322c 202d 325d 3a0a 2020 2020  -1, 2, -2]:.    
-00001c40: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
-00001c50: 6c65 6d65 6e74 6564 4572 726f 7228 2227  lementedError("'
-00001c60: 5465 6e73 6f72 2e6e 6f72 6d27 2061 6e64  Tensor.norm' and
-00001c70: 2027 746f 7263 682e 6e6f 726d 2720 6e6f   'torch.norm' no
-00001c80: 7420 7375 7070 6f72 7420 6070 6020 6265  t support `p` be
-00001c90: 7369 6465 2022 0a20 2020 2020 2020 2020  side ".         
-00001ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001cb0: 2020 2020 2020 2020 6622 2766 726f 272c          f"'fro',
-00001cc0: 2027 6e75 6327 2c20 666c 6f61 7428 2769   'nuc', float('i
-00001cd0: 6e66 2729 2c20 666c 6f61 7428 272d 696e  nf'), float('-in
-00001ce0: 6627 292c 2030 2c20 312c 202d 312c 2032  f'), 0, 1, -1, 2
-00001cf0: 2c20 2d32 2e2c 2062 7574 2067 6f74 2070  , -2., but got p
-00001d00: 3d7b 707d 2e22 290a 0a20 2020 205f 6d61  ={p}.")..    _ma
-00001d10: 7472 6978 5f6e 6f72 6d20 3d20 4661 6c73  trix_norm = Fals
-00001d20: 650a 2020 2020 6966 2070 2069 6e20 2830  e.    if p in (0
-00001d30: 2c20 312c 202d 312c 202d 3229 3a0a 2020  , 1, -1, -2):.  
-00001d40: 2020 2020 2020 6966 2064 696d 2069 7320        if dim is 
-00001d50: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-00001d60: 2020 6966 206e 6469 6d20 3e20 313a 0a20    if ndim > 1:. 
-00001d70: 2020 2020 2020 2020 2020 2020 2020 205f                 _
-00001d80: 6d61 7472 6978 5f6e 6f72 6d20 3d20 5472  matrix_norm = Tr
-00001d90: 7565 0a20 2020 2020 2020 2065 6c69 6620  ue.        elif 
-00001da0: 6973 696e 7374 616e 6365 2864 696d 2c20  isinstance(dim, 
-00001db0: 2874 7570 6c65 2c20 6c69 7374 2929 3a0a  (tuple, list)):.
-00001dc0: 2020 2020 2020 2020 2020 2020 6966 206c              if l
-00001dd0: 656e 2864 696d 2920 213d 2031 3a0a 2020  en(dim) != 1:.  
-00001de0: 2020 2020 2020 2020 2020 2020 2020 5f6d                _m
-00001df0: 6174 7269 785f 6e6f 726d 203d 2054 7275  atrix_norm = Tru
-00001e00: 650a 2020 2020 6966 205f 6d61 7472 6978  e.    if _matrix
-00001e10: 5f6e 6f72 6d3a 0a20 2020 2020 2020 2072  _norm:.        r
-00001e20: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
-00001e30: 7465 6445 7272 6f72 2822 466f 7220 2754  tedError("For 'T
-00001e40: 656e 736f 722e 6e6f 726d 2720 616e 6420  ensor.norm' and 
-00001e50: 2774 6f72 6368 2e6e 6f72 6d27 2c20 7768  'torch.norm', wh
-00001e60: 656e 2070 2069 6e20 5b30 2c20 312c 202d  en p in [0, 1, -
-00001e70: 312c 202d 325d 2c20 220a 2020 2020 2020  1, -2], ".      
-00001e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001e90: 2020 2020 2020 2020 2020 2020 226f 6e6c              "onl
-00001ea0: 7920 7375 7070 6f72 7420 7665 6374 6f72  y support vector
-00001eb0: 2d6e 6f72 6d2e 2022 0a20 2020 2020 2020  -norm. ".       
-00001ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001ed0: 2020 2020 2020 2020 2020 2022 4966 206e             "If n
-00001ee0: 6565 6420 6d61 7472 6978 2d6e 6f72 6d2c  eed matrix-norm,
-00001ef0: 2070 6c65 6173 6520 7573 6520 746f 7263   please use torc
-00001f00: 682e 6c69 6e61 6c67 2e6e 6f72 6d20 696e  h.linalg.norm in
-00001f10: 7374 6561 642e 2229 0a20 2020 2069 6620  stead.").    if 
-00001f20: 7020 696e 2028 2766 726f 272c 2032 293a  p in ('fro', 2):
-00001f30: 0a20 2020 2020 2020 2069 6620 6469 6d20  .        if dim 
-00001f40: 6973 204e 6f6e 6520 6f72 2069 7369 6e73  is None or isins
-00001f50: 7461 6e63 6528 6469 6d2c 2069 6e74 293a  tance(dim, int):
-00001f60: 0a20 2020 2020 2020 2020 2020 2070 203d  .            p =
-00001f70: 204e 6f6e 650a 2020 2020 2020 2020 656c   None.        el
-00001f80: 6966 2069 7369 6e73 7461 6e63 6528 6469  if isinstance(di
-00001f90: 6d2c 2028 6c69 7374 2c20 7475 706c 6529  m, (list, tuple)
-00001fa0: 2920 616e 6420 6c65 6e28 6469 6d29 203d  ) and len(dim) =
-00001fb0: 3d20 313a 0a20 2020 2020 2020 2020 2020  = 1:.           
-00001fc0: 2070 203d 204e 6f6e 650a 2020 2020 7265   p = None.    re
-00001fd0: 7475 726e 2070 0a0a 405f 7072 696d 6578  turn p..@_primex
-00001fe0: 7072 0a64 6566 205f 6761 7468 6572 5f6e  pr.def _gather_n
-00001ff0: 6f5f 6e65 6564 5f70 6164 6469 6e67 2869  o_need_padding(i
-00002000: 6e70 7574 5f73 6861 7065 2c20 696e 6465  nput_shape, inde
-00002010: 785f 7368 6170 652c 2064 696d 293a 0a20  x_shape, dim):. 
-00002020: 2020 2069 6e70 7574 5f73 6861 7065 5f6c     input_shape_l
-00002030: 6973 7420 3d20 6c69 7374 2869 6e70 7574  ist = list(input
-00002040: 5f73 6861 7065 290a 2020 2020 696e 6465  _shape).    inde
-00002050: 785f 7368 6170 655f 6c69 7374 203d 206c  x_shape_list = l
-00002060: 6973 7428 696e 6465 785f 7368 6170 6529  ist(index_shape)
-00002070: 0a20 2020 2069 6e70 7574 5f73 6861 7065  .    input_shape
-00002080: 5f6c 6973 742e 706f 7028 6469 6d29 0a20  _list.pop(dim). 
-00002090: 2020 2069 6e64 6578 5f73 6861 7065 5f6c     index_shape_l
-000020a0: 6973 742e 706f 7028 6469 6d29 0a20 2020  ist.pop(dim).   
-000020b0: 2072 6574 7572 6e20 696e 7075 745f 7368   return input_sh
-000020c0: 6170 655f 6c69 7374 203d 3d20 696e 6465  ape_list == inde
-000020d0: 785f 7368 6170 655f 6c69 7374 0a0a 0a40  x_shape_list...@
-000020e0: 5f70 7269 6d65 7870 720a 6465 6620 5f67  _primexpr.def _g
-000020f0: 6174 6865 725f 6765 745f 7061 6464 696e  ather_get_paddin
-00002100: 675f 7061 7474 6572 6e28 696e 7075 745f  g_pattern(input_
-00002110: 7368 6170 652c 2069 6e64 6578 5f73 6861  shape, index_sha
-00002120: 7065 2c20 6469 6d29 3a0a 2020 2020 7061  pe, dim):.    pa
-00002130: 6464 696e 675f 7061 7474 6572 6e20 3d20  dding_pattern = 
-00002140: 2829 0a20 2020 2066 6f72 2069 2069 6e20  ().    for i in 
-00002150: 7261 6e67 6528 6c65 6e28 696e 7075 745f  range(len(input_
-00002160: 7368 6170 6529 293a 0a20 2020 2020 2020  shape)):.       
-00002170: 2069 6620 6920 3d3d 2064 696d 3a0a 2020   if i == dim:.  
-00002180: 2020 2020 2020 2020 2020 7061 6464 696e            paddin
-00002190: 675f 7061 7474 6572 6e20 3d20 2830 2c20  g_pattern = (0, 
-000021a0: 3029 202b 2070 6164 6469 6e67 5f70 6174  0) + padding_pat
-000021b0: 7465 726e 0a20 2020 2020 2020 2065 6c73  tern.        els
-000021c0: 653a 0a20 2020 2020 2020 2020 2020 2070  e:.            p
-000021d0: 6164 6469 6e67 5f70 6174 7465 726e 203d  adding_pattern =
-000021e0: 2028 302c 2069 6e70 7574 5f73 6861 7065   (0, input_shape
-000021f0: 5b69 5d20 2d20 696e 6465 785f 7368 6170  [i] - index_shap
-00002200: 655b 695d 2920 2b20 7061 6464 696e 675f  e[i]) + padding_
-00002210: 7061 7474 6572 6e0a 2020 2020 7265 7475  pattern.    retu
-00002220: 726e 2070 6164 6469 6e67 5f70 6174 7465  rn padding_patte
-00002230: 726e 0a0a 636c 6173 7320 5f54 656e 736f  rn..class _Tenso
-00002240: 724d 6574 6128 7479 7065 286d 735f 5465  rMeta(type(ms_Te
-00002250: 6e73 6f72 292c 2061 6263 2e41 4243 4d65  nsor), abc.ABCMe
-00002260: 7461 293a 0a20 2020 2022 2222 0a20 2020  ta):.    """.   
-00002270: 204d 6574 6120 636c 6173 7320 666f 7220   Meta class for 
-00002280: 5465 6e73 6f72 2e20 5573 6564 2069 6e74  Tensor. Used int
-00002290: 6572 6e61 6c6c 792e 0a20 2020 2022 2222  ernally..    """
-000022a0: 0a0a 636c 6173 7320 5465 6e73 6f72 2853  ..class Tensor(S
-000022b0: 7475 6254 656e 736f 722c 206d 6574 6163  tubTensor, metac
-000022c0: 6c61 7373 3d5f 5465 6e73 6f72 4d65 7461  lass=_TensorMeta
-000022d0: 293a 0a20 2020 2064 6566 205f 5f69 6e69  ):.    def __ini
-000022e0: 745f 5f28 7365 6c66 2c20 2a64 6174 612c  t__(self, *data,
-000022f0: 2064 7479 7065 3d4e 6f6e 652c 2069 6e6e   dtype=None, inn
-00002300: 6572 3d46 616c 7365 2c20 6361 7374 5f74  er=False, cast_t
-00002310: 656e 736f 723d 4661 6c73 6529 3a0a 2020  ensor=False):.  
-00002320: 2020 2020 2020 6966 2063 6173 745f 7465        if cast_te
-00002330: 6e73 6f72 3a0a 2020 2020 2020 2020 2020  nsor:.          
-00002340: 2020 6966 206c 656e 2864 6174 6129 2021    if len(data) !
-00002350: 3d20 313a 0a20 2020 2020 2020 2020 2020  = 1:.           
-00002360: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
-00002370: 6d65 4572 726f 7228 2254 656e 736f 7220  meError("Tensor 
-00002380: 696e 6974 2064 6174 6120 6c65 6e67 6874  init data lenght
-00002390: 2069 7320 6e6f 7420 3120 7768 656e 2063   is not 1 when c
-000023a0: 6173 745f 7465 6e73 6f72 3d54 7275 6522  ast_tensor=True"
-000023b0: 290a 2020 2020 2020 2020 2020 2020 696e  ).            in
-000023c0: 7075 745f 6461 7461 203d 2064 6174 615b  put_data = data[
-000023d0: 305d 0a20 2020 2020 2020 2020 2020 2069  0].            i
-000023e0: 6620 6973 696e 7374 616e 6365 2869 6e70  f isinstance(inp
-000023f0: 7574 5f64 6174 612c 2053 7475 6254 656e  ut_data, StubTen
-00002400: 736f 7229 3a0a 2020 2020 2020 2020 2020  sor):.          
-00002410: 2020 2020 2020 7375 7065 7228 5465 6e73        super(Tens
-00002420: 6f72 2c20 7365 6c66 292e 5f5f 696e 6974  or, self).__init
-00002430: 5f5f 2873 7475 623d 696e 7075 745f 6461  __(stub=input_da
-00002440: 7461 2e73 7475 622c 2074 656e 736f 723d  ta.stub, tensor=
-00002450: 696e 7075 745f 6461 7461 2e74 656e 736f  input_data.tenso
-00002460: 7229 0a20 2020 2020 2020 2020 2020 2065  r).            e
-00002470: 6c69 6620 6973 696e 7374 616e 6365 2869  lif isinstance(i
-00002480: 6e70 7574 5f64 6174 612c 2054 656e 736f  nput_data, Tenso
-00002490: 725f 293a 0a20 2020 2020 2020 2020 2020  r_):.           
-000024a0: 2020 2020 2073 7570 6572 2854 656e 736f       super(Tenso
-000024b0: 722c 2073 656c 6629 2e5f 5f69 6e69 745f  r, self).__init_
-000024c0: 5f28 7465 6e73 6f72 3d69 6e70 7574 5f64  _(tensor=input_d
-000024d0: 6174 6129 0a20 2020 2020 2020 2020 2020  ata).           
-000024e0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-000024f0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-00002500: 7565 4572 726f 7228 6622 5465 6e73 6f72  ueError(f"Tensor
-00002510: 2069 6e69 7420 6461 7461 2074 7970 6520   init data type 
-00002520: 6973 2069 6e76 6169 6c64 3a20 7b74 7970  is invaild: {typ
-00002530: 6528 696e 7075 745f 6461 7461 297d 2229  e(input_data)}")
-00002540: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00002550: 662e 6164 6170 7465 725f 666c 6167 203d  f.adapter_flag =
-00002560: 2054 7275 650a 2020 2020 2020 2020 2020   True.          
-00002570: 2020 7265 7475 726e 0a0a 2020 2020 2020    return..      
-00002580: 2020 6966 2064 7479 7065 2069 7320 6e6f    if dtype is no
-00002590: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
-000025a0: 2020 2020 6474 7970 6520 3d20 5f64 7479      dtype = _dty
-000025b0: 7065 4469 6374 5b73 7472 2864 7479 7065  peDict[str(dtype
-000025c0: 292e 7370 6c69 7428 272e 2729 5b2d 315d  ).split('.')[-1]
-000025d0: 2e6c 6f77 6572 2829 5d0a 0a20 2020 2020  .lower()]..     
-000025e0: 2020 2069 6620 696e 6e65 7220 6973 2054     if inner is T
-000025f0: 7275 653a 0a20 2020 2020 2020 2020 2020  rue:.           
-00002600: 2069 6e69 745f 7465 6e73 6f72 203d 206d   init_tensor = m
-00002610: 735f 5465 6e73 6f72 282a 6461 7461 2c20  s_Tensor(*data, 
-00002620: 6474 7970 653d 6474 7970 6529 0a20 2020  dtype=dtype).   
-00002630: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00002640: 2020 2020 2020 205f 696e 7075 745f 6461         _input_da
-00002650: 7461 2c20 5f73 6861 7065 203d 2073 656c  ta, _shape = sel
-00002660: 662e 5f70 726f 6365 7373 5f64 6174 6128  f._process_data(
-00002670: 6461 7461 290a 2020 2020 2020 2020 2020  data).          
-00002680: 2020 6966 205f 7368 6170 653a 0a20 2020    if _shape:.   
-00002690: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-000026a0: 6474 7970 6520 6973 204e 6f6e 653a 0a20  dtype is None:. 
-000026b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000026c0: 2020 2064 7479 7065 203d 2067 6574 5f64     dtype = get_d
-000026d0: 6566 6175 6c74 5f64 7479 7065 2829 0a20  efault_dtype(). 
-000026e0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-000026f0: 6e69 745f 6675 6e63 203d 205a 6572 6f28  nit_func = Zero(
-00002700: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00002710: 2020 696e 6974 5f66 756e 632e 5f5f 656e    init_func.__en
-00002720: 6162 6c65 5f7a 6572 6f5f 6469 6d5f 5f20  able_zero_dim__ 
-00002730: 3d20 5472 7565 0a20 2020 2020 2020 2020  = True.         
-00002740: 2020 2020 2020 2069 6e69 745f 7465 6e73         init_tens
-00002750: 6f72 203d 206d 735f 5465 6e73 6f72 2873  or = ms_Tensor(s
-00002760: 6861 7065 3d5f 7368 6170 652c 2064 7479  hape=_shape, dty
-00002770: 7065 3d64 7479 7065 2c20 696e 6974 3d69  pe=dtype, init=i
-00002780: 6e69 745f 6675 6e63 290a 2020 2020 2020  nit_func).      
-00002790: 2020 2020 2020 2020 2020 696e 6974 5f74            init_t
-000027a0: 656e 736f 722e 696e 6974 5f64 6174 6128  ensor.init_data(
-000027b0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-000027c0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-000027d0: 2020 2020 6966 2064 7479 7065 2069 7320      if dtype is 
-000027e0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-000027f0: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
-00002800: 2069 7369 6e73 7461 6e63 6528 5f69 6e70   isinstance(_inp
-00002810: 7574 5f64 6174 612c 2028 6d73 2e54 656e  ut_data, (ms.Ten
-00002820: 736f 722c 2054 656e 736f 725f 2c20 5f54  sor, Tensor_, _T
-00002830: 7970 6564 5374 6f72 6167 6529 293a 0a20  ypedStorage)):. 
-00002840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002850: 2020 2020 2020 2064 7479 7065 203d 2067         dtype = g
-00002860: 6574 5f64 6566 6175 6c74 5f64 7479 7065  et_default_dtype
-00002870: 2829 0a20 2020 2020 2020 2020 2020 2020  ().             
-00002880: 2020 2069 6e69 745f 7465 6e73 6f72 203d     init_tensor =
-00002890: 206d 735f 5465 6e73 6f72 2869 6e70 7574   ms_Tensor(input
-000028a0: 5f64 6174 613d 5f69 6e70 7574 5f64 6174  _data=_input_dat
-000028b0: 612c 2064 7479 7065 3d64 7479 7065 290a  a, dtype=dtype).
-000028c0: 2020 2020 2020 2020 7375 7065 7228 5465          super(Te
-000028d0: 6e73 6f72 2c20 7365 6c66 292e 5f5f 696e  nsor, self).__in
-000028e0: 6974 5f5f 2874 656e 736f 723d 696e 6974  it__(tensor=init
-000028f0: 5f74 656e 736f 7229 0a20 2020 2020 2020  _tensor).       
-00002900: 2073 656c 662e 6164 6170 7465 725f 666c   self.adapter_fl
-00002910: 6167 203d 2054 7275 650a 0a0a 2020 2020  ag = True...    
-00002920: 6465 6620 5f70 726f 6365 7373 5f64 6174  def _process_dat
-00002930: 6128 7365 6c66 2c20 6461 7461 293a 0a20  a(self, data):. 
-00002940: 2020 2020 2020 205f 7368 6170 6520 3d20         _shape = 
-00002950: 4e6f 6e65 0a20 2020 2020 2020 205f 696e  None.        _in
-00002960: 7075 745f 6461 7461 203d 204e 6f6e 650a  put_data = None.
-00002970: 2020 2020 2020 2020 6966 206c 656e 2864          if len(d
-00002980: 6174 6129 203d 3d20 313a 0a20 2020 2020  ata) == 1:.     
-00002990: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-000029a0: 616e 6365 2864 6174 615b 305d 2c20 696e  ance(data[0], in
-000029b0: 7429 3a0a 2020 2020 2020 2020 2020 2020  t):.            
-000029c0: 2020 2020 5f73 6861 7065 203d 2064 6174      _shape = dat
-000029d0: 610a 2020 2020 2020 2020 2020 2020 656c  a.            el
-000029e0: 6966 2069 7369 6e73 7461 6e63 6528 6461  if isinstance(da
-000029f0: 7461 5b30 5d2c 2028 6e70 2e6e 6461 7272  ta[0], (np.ndarr
-00002a00: 6179 2c20 6d73 2e54 656e 736f 722c 206c  ay, ms.Tensor, l
-00002a10: 6973 742c 2054 656e 736f 725f 2929 3a0a  ist, Tensor_)):.
-00002a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002a30: 5f69 6e70 7574 5f64 6174 6120 3d20 6461  _input_data = da
-00002a40: 7461 5b30 5d0a 2020 2020 2020 2020 2020  ta[0].          
-00002a50: 2020 656c 6966 2069 7369 6e73 7461 6e63    elif isinstanc
-00002a60: 6528 6461 7461 5b30 5d2c 2074 7570 6c65  e(data[0], tuple
-00002a70: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00002a80: 2020 2069 6620 6c65 6e28 6461 7461 5b30     if len(data[0
-00002a90: 5d29 203d 3d20 313a 0a20 2020 2020 2020  ]) == 1:.       
-00002aa0: 2020 2020 2020 2020 2020 2020 205f 7368               _sh
-00002ab0: 6170 6520 3d20 6461 7461 5b30 5d0a 2020  ape = data[0].  
-00002ac0: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00002ad0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00002ae0: 2020 2020 2020 2020 5f69 6e70 7574 5f64          _input_d
-00002af0: 6174 6120 3d20 6461 7461 5b30 5d0a 2020  ata = data[0].  
-00002b00: 2020 2020 2020 2020 2020 656c 6966 2069            elif i
-00002b10: 7369 6e73 7461 6e63 6528 6461 7461 5b30  sinstance(data[0
-00002b20: 5d2c 205f 5479 7065 6453 746f 7261 6765  ], _TypedStorage
-00002b30: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
-00002b40: 2020 205f 696e 7075 745f 6461 7461 3d64     _input_data=d
-00002b50: 6174 615b 305d 2e5f 7374 6f72 6167 652e  ata[0]._storage.
-00002b60: 696e 6e65 725f 6461 7461 0a20 2020 2020  inner_data.     
-00002b70: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-00002b80: 2020 2020 2020 2020 2020 2020 2072 6169               rai
-00002b90: 7365 2054 7970 6545 7272 6f72 2866 2246  se TypeError(f"F
-00002ba0: 6f72 2054 656e 736f 722c 2064 6174 6120  or Tensor, data 
-00002bb0: 6d75 7374 2062 6520 6120 7365 7175 656e  must be a sequen
-00002bc0: 6365 2c20 676f 7420 7b74 7970 6528 6461  ce, got {type(da
-00002bd0: 7461 5b30 5d29 7d22 290a 2020 2020 2020  ta[0])}").      
-00002be0: 2020 656c 6966 206c 656e 2864 6174 6129    elif len(data)
-00002bf0: 203e 2031 3a0a 2020 2020 2020 2020 2020   > 1:.          
-00002c00: 2020 5f73 6861 7065 203d 206c 6973 7428    _shape = list(
-00002c10: 6461 7461 290a 2020 2020 2020 2020 2020  data).          
-00002c20: 2020 666f 7220 692c 2073 2069 6e20 656e    for i, s in en
-00002c30: 756d 6572 6174 6528 6461 7461 293a 0a20  umerate(data):. 
-00002c40: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00002c50: 6620 6973 696e 7374 616e 6365 2873 2c20  f isinstance(s, 
-00002c60: 696e 7429 3a0a 2020 2020 2020 2020 2020  int):.          
-00002c70: 2020 2020 2020 2020 2020 636f 6e74 696e            contin
-00002c80: 7565 0a20 2020 2020 2020 2020 2020 2020  ue.             
-00002c90: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
-00002ca0: 2873 2c20 5465 6e73 6f72 293a 0a20 2020  (s, Tensor):.   
-00002cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002cc0: 2069 6620 732e 6474 7970 6520 6e6f 7420   if s.dtype not 
-00002cd0: 696e 2061 6c6c 5f69 6e74 5f74 7970 655f  in all_int_type_
-00002ce0: 7769 7468 5f62 6f6f 6c3a 0a20 2020 2020  with_bool:.     
-00002cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002d00: 2020 2072 6169 7365 2054 7970 6545 7272     raise TypeErr
-00002d10: 6f72 2822 466f 7220 5465 6e73 6f72 2069  or("For Tensor i
-00002d20: 6e70 7574 2073 6861 7065 2c20 220a 2020  nput shape, ".  
-00002d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002d50: 2020 2020 2020 6622 656c 656d 656e 7473        f"elements
-00002d60: 2073 686f 756c 6420 6265 2069 6e74 2074   should be int t
-00002d70: 7970 6520 6275 7420 676f 7420 7b73 2e64  ype but got {s.d
-00002d80: 7479 7065 7d20 6174 2070 6f73 207b 6920  type} at pos {i 
-00002d90: 2b20 317d 2229 0a20 2020 2020 2020 2020  + 1}").         
-00002da0: 2020 2020 2020 2020 2020 205f 7368 6170             _shap
-00002db0: 655b 695d 203d 2069 6e74 2873 290a 2020  e[i] = int(s).  
-00002dc0: 2020 2020 2020 2020 2020 2020 2020 656c                el
-00002dd0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00002de0: 2020 2020 2020 2020 7261 6973 6520 5479          raise Ty
-00002df0: 7065 4572 726f 7228 2246 6f72 2054 656e  peError("For Ten
-00002e00: 736f 722c 2065 6c65 6d65 6e74 7320 6f66  sor, elements of
-00002e10: 2073 6861 7065 206d 7573 7420 6265 2069   shape must be i
-00002e20: 6e74 206f 7220 5465 6e73 6f72 2e22 290a  nt or Tensor.").
-00002e30: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00002e40: 2020 2020 2020 2020 2020 5f69 6e70 7574            _input
-00002e50: 5f64 6174 6120 3d20 2829 0a20 2020 2020  _data = ().     
-00002e60: 2020 2072 6574 7572 6e20 5f69 6e70 7574     return _input
-00002e70: 5f64 6174 612c 205f 7368 6170 650a 0a20  _data, _shape.. 
-00002e80: 2020 2064 6566 205f 5f66 6f72 6d61 745f     def __format_
-00002e90: 5f28 7365 6c66 2c20 666f 726d 6174 5f73  _(self, format_s
-00002ea0: 7065 6329 3a0a 2020 2020 2020 2020 6966  pec):.        if
-00002eb0: 2073 656c 662e 6469 6d28 2920 3d3d 2030   self.dim() == 0
-00002ec0: 2061 6e64 2069 7369 6e73 7461 6e63 6528   and isinstance(
-00002ed0: 7365 6c66 2c20 5465 6e73 6f72 293a 0a20  self, Tensor):. 
-00002ee0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00002ef0: 6e20 7365 6c66 2e69 7465 6d28 292e 5f5f  n self.item().__
-00002f00: 666f 726d 6174 5f5f 2866 6f72 6d61 745f  format__(format_
-00002f10: 7370 6563 290a 2020 2020 2020 2020 7265  spec).        re
-00002f20: 7475 726e 206f 626a 6563 742e 5f5f 666f  turn object.__fo
-00002f30: 726d 6174 5f5f 2873 656c 662c 2066 6f72  rmat__(self, for
-00002f40: 6d61 745f 7370 6563 290a 0a20 2020 2040  mat_spec)..    @
-00002f50: 636c 6173 736d 6574 686f 640a 2020 2020  classmethod.    
-00002f60: 6465 6620 5f5f 7375 6263 6c61 7373 686f  def __subclassho
-00002f70: 6f6b 5f5f 2863 6c73 2c20 7061 7261 6d29  ok__(cls, param)
-00002f80: 3a0a 2020 2020 2020 2020 2222 220a 2020  :.        """.  
-00002f90: 2020 2020 2020 5061 7261 6d65 7465 7220        Parameter 
-00002fa0: 7769 6c6c 2062 6520 696e 7374 616e 6365  will be instance
-00002fb0: 206f 6620 5465 6e73 6f72 0a20 2020 2020   of Tensor.     
-00002fc0: 2020 2022 2222 0a20 2020 2020 2020 2069     """.        i
-00002fd0: 6620 636c 7320 6973 2054 656e 736f 723a  f cls is Tensor:
-00002fe0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00002ff0: 616e 7928 2270 6172 616d 5f69 6e66 6f22  any("param_info"
-00003000: 2069 6e20 732e 5f5f 6469 6374 5f5f 2066   in s.__dict__ f
-00003010: 6f72 2073 2069 6e20 7061 7261 6d2e 5f5f  or s in param.__
-00003020: 6d72 6f5f 5f29 3a0a 2020 2020 2020 2020  mro__):.        
-00003030: 2020 2020 2020 2020 7265 7475 726e 2054          return T
-00003040: 7275 650a 2020 2020 2020 2020 7265 7475  rue.        retu
-00003050: 726e 204e 6f74 496d 706c 656d 656e 7465  rn NotImplemente
-00003060: 640a 0a20 2020 2064 6566 205f 5f64 6565  d..    def __dee
-00003070: 7063 6f70 795f 5f28 7365 6c66 2c20 6d65  pcopy__(self, me
-00003080: 6d6f 6469 6374 293a 0a20 2020 2020 2020  modict):.       
-00003090: 2074 656e 736f 725f 6d73 203d 2063 6173   tensor_ms = cas
-000030a0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-000030b0: 656c 6629 0a20 2020 2020 2020 2072 6574  elf).        ret
-000030c0: 7572 6e20 5465 6e73 6f72 286d 732e 5465  urn Tensor(ms.Te
-000030d0: 6e73 6f72 2e5f 5f64 6565 7063 6f70 795f  nsor.__deepcopy_
-000030e0: 5f28 7465 6e73 6f72 5f6d 732c 206d 656d  _(tensor_ms, mem
-000030f0: 6f64 6963 7429 290a 0a20 2020 2064 6566  odict))..    def
-00003100: 205f 5f6e 6567 5f5f 2873 656c 6629 3a0a   __neg__(self):.
-00003110: 2020 2020 2020 2020 7465 6e73 6f72 5f6d          tensor_m
-00003120: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00003130: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00003140: 2020 2020 6f75 7420 3d20 7465 6e73 6f72      out = tensor
-00003150: 5f6d 732e 5f5f 6e65 675f 5f28 290a 2020  _ms.__neg__().  
-00003160: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00003170: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00003180: 736f 7228 6f75 7429 0a0a 2020 2020 6465  sor(out)..    de
-00003190: 6620 5f5f 696e 7665 7274 5f5f 2873 656c  f __invert__(sel
-000031a0: 6629 3a0a 2020 2020 2020 2020 7465 6e73  f):.        tens
-000031b0: 6f72 5f6d 7320 3d20 6361 7374 5f74 6f5f  or_ms = cast_to_
-000031c0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-000031d0: 2020 2020 2020 2020 6966 2074 656e 736f          if tenso
-000031e0: 725f 6d73 2e64 7479 7065 2021 3d20 6d73  r_ms.dtype != ms
-000031f0: 2e62 6f6f 6c5f 3a0a 2020 2020 2020 2020  .bool_:.        
-00003200: 2020 2020 6f75 7420 3d20 2d20 3120 2d20      out = - 1 - 
-00003210: 7465 6e73 6f72 5f6d 730a 2020 2020 2020  tensor_ms.      
-00003220: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00003230: 2020 2020 6f75 7420 3d20 7465 6e73 6f72      out = tensor
-00003240: 5f6d 732e 5f5f 696e 7665 7274 5f5f 2829  _ms.__invert__()
-00003250: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00003260: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00003270: 7465 6e73 6f72 286f 7574 290a 0a20 2020  tensor(out)..   
-00003280: 2064 6566 205f 5f72 6f75 6e64 5f5f 2873   def __round__(s
-00003290: 656c 6629 3a0a 2020 2020 2020 2020 7465  elf):.        te
-000032a0: 6e73 6f72 5f6d 7320 3d20 6361 7374 5f74  nsor_ms = cast_t
-000032b0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-000032c0: 290a 2020 2020 2020 2020 6f75 7420 3d20  ).        out = 
-000032d0: 7465 6e73 6f72 5f6d 732e 5f5f 726f 756e  tensor_ms.__roun
-000032e0: 645f 5f28 290a 2020 2020 2020 2020 7265  d__().        re
-000032f0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00003300: 7074 6572 5f74 656e 736f 7228 6f75 7429  pter_tensor(out)
-00003310: 0a0a 2020 2020 6465 6620 5f5f 706f 735f  ..    def __pos_
-00003320: 5f28 7365 6c66 293a 0a20 2020 2020 2020  _(self):.       
-00003330: 2074 656e 736f 725f 6d73 203d 2063 6173   tensor_ms = cas
-00003340: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-00003350: 656c 6629 0a20 2020 2020 2020 206f 7574  elf).        out
-00003360: 203d 2074 656e 736f 725f 6d73 2e5f 5f70   = tensor_ms.__p
-00003370: 6f73 5f5f 2829 0a20 2020 2020 2020 2072  os__().        r
-00003380: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00003390: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-000033a0: 290a 0a20 2020 2064 6566 205f 5f61 6273  )..    def __abs
-000033b0: 5f5f 2873 656c 6629 3a0a 2020 2020 2020  __(self):.      
-000033c0: 2020 7465 6e73 6f72 5f6d 7320 3d20 6361    tensor_ms = ca
-000033d0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-000033e0: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
-000033f0: 7420 3d20 7465 6e73 6f72 5f6d 732e 5f5f  t = tensor_ms.__
-00003400: 6162 735f 5f28 290a 2020 2020 2020 2020  abs__().        
-00003410: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00003420: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00003430: 7429 0a0a 2020 2020 6465 6620 5f5f 6164  t)..    def __ad
-00003440: 645f 5f28 7365 6c66 2c20 6f74 6865 7229  d__(self, other)
-00003450: 3a0a 2020 2020 2020 2020 7465 6e73 6f72  :.        tensor
-00003460: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00003470: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00003480: 2020 2020 2020 6f74 6865 725f 6d73 203d        other_ms =
-00003490: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-000034a0: 6f72 286f 7468 6572 290a 2020 2020 2020  or(other).      
-000034b0: 2020 2320 544f 444f 3a20 6d69 6e64 7370    # TODO: mindsp
-000034c0: 6f72 6520 5f5f 6164 645f 5f20 646f 206e  ore __add__ do n
-000034d0: 6f74 2073 7570 706f 7274 206c 6f67 6963  ot support logic
-000034e0: 616c 5f6f 7220 7769 7468 2074 776f 2062  al_or with two b
-000034f0: 6f6f 6c20 6474 7970 6520 7465 6e73 6f72  ool dtype tensor
-00003500: 732e 0a20 2020 2020 2020 206f 7574 203d  s..        out =
-00003510: 2074 656e 736f 725f 6d73 2e5f 5f61 6464   tensor_ms.__add
-00003520: 5f5f 286f 7468 6572 5f6d 7329 0a20 2020  __(other_ms).   
-00003530: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-00003540: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00003550: 6f72 286f 7574 290a 0a20 2020 2064 6566  or(out)..    def
-00003560: 205f 5f61 6e64 5f5f 2873 656c 662c 206f   __and__(self, o
-00003570: 7468 6572 293a 0a20 2020 2020 2020 2074  ther):.        t
-00003580: 656e 736f 725f 6d73 203d 2063 6173 745f  ensor_ms = cast_
-00003590: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-000035a0: 6629 0a20 2020 2020 2020 206f 7468 6572  f).        other
-000035b0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-000035c0: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
-000035d0: 2020 2020 2020 2069 6e70 7574 5f64 7479         input_dty
-000035e0: 7065 203d 2074 656e 736f 725f 6d73 2e64  pe = tensor_ms.d
-000035f0: 7479 7065 0a20 2020 2020 2020 2069 6620  type.        if 
-00003600: 696e 7075 745f 6474 7970 6520 3d3d 206d  input_dtype == m
-00003610: 7374 7970 652e 626f 6f6c 5f3a 0a20 2020  stype.bool_:.   
-00003620: 2020 2020 2020 2020 2023 2061 766f 6964           # avoid
-00003630: 2042 6974 7769 7365 416e 6420 6f70 2068   BitwiseAnd op h
-00003640: 6173 206e 6f74 2063 6f72 7265 7370 6f6e  as not correspon
-00003650: 6469 6e67 2062 7072 6f70 2e0a 2020 2020  ding bprop..    
-00003660: 2020 2020 2020 2020 7465 6e73 6f72 5f6d          tensor_m
-00003670: 7320 3d20 7465 6e73 6f72 5f6d 732e 6173  s = tensor_ms.as
-00003680: 7479 7065 286d 7374 7970 652e 696e 7438  type(mstype.int8
-00003690: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
-000036a0: 7420 3d20 7465 6e73 6f72 5f6d 732e 6d75  t = tensor_ms.mu
-000036b0: 6c28 6f74 6865 725f 6d73 290a 2020 2020  l(other_ms).    
-000036c0: 2020 2020 2020 2020 6f75 7420 3d20 6f75          out = ou
-000036d0: 742e 6173 7479 7065 286d 7374 7970 652e  t.astype(mstype.
-000036e0: 626f 6f6c 5f29 0a20 2020 2020 2020 2065  bool_).        e
-000036f0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00003700: 206f 7574 203d 2074 656e 736f 725f 6d73   out = tensor_ms
-00003710: 2e5f 5f61 6e64 5f5f 286f 7468 6572 5f6d  .__and__(other_m
-00003720: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
-00003730: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00003740: 725f 7465 6e73 6f72 286f 7574 290a 0a20  r_tensor(out).. 
-00003750: 2020 2064 6566 205f 5f78 6f72 5f5f 2873     def __xor__(s
-00003760: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
-00003770: 2020 2020 2074 656e 736f 725f 6d73 203d       tensor_ms =
-00003780: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00003790: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-000037a0: 206f 7468 6572 5f6d 7320 3d20 6361 7374   other_ms = cast
-000037b0: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
-000037c0: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
-000037d0: 203d 2074 656e 736f 725f 6d73 2e5f 5f78   = tensor_ms.__x
-000037e0: 6f72 5f5f 286f 7468 6572 5f6d 7329 0a20  or__(other_ms). 
-000037f0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-00003800: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00003810: 6e73 6f72 286f 7574 290a 0a20 2020 2064  nsor(out)..    d
-00003820: 6566 205f 5f6f 725f 5f28 7365 6c66 2c20  ef __or__(self, 
-00003830: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
-00003840: 7465 6e73 6f72 5f6d 7320 3d20 6361 7374  tensor_ms = cast
-00003850: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00003860: 6c66 290a 2020 2020 2020 2020 6f74 6865  lf).        othe
-00003870: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
-00003880: 735f 7465 6e73 6f72 286f 7468 6572 290a  s_tensor(other).
-00003890: 2020 2020 2020 2020 696e 7075 745f 6474          input_dt
-000038a0: 7970 6520 3d20 7465 6e73 6f72 5f6d 732e  ype = tensor_ms.
-000038b0: 6474 7970 650a 2020 2020 2020 2020 6966  dtype.        if
-000038c0: 2069 6e70 7574 5f64 7479 7065 203d 3d20   input_dtype == 
-000038d0: 6d73 7479 7065 2e62 6f6f 6c5f 3a0a 2020  mstype.bool_:.  
-000038e0: 2020 2020 2020 2020 2020 2320 6176 6f69            # avoi
-000038f0: 6420 4269 7477 6973 654f 7220 6f70 2068  d BitwiseOr op h
-00003900: 6173 206e 6f74 2063 6f72 7265 7370 6f6e  as not correspon
-00003910: 6469 6e67 2062 7072 6f70 2e0a 2020 2020  ding bprop..    
-00003920: 2020 2020 2020 2020 7465 6e73 6f72 5f6d          tensor_m
-00003930: 7320 3d20 7465 6e73 6f72 5f6d 732e 6173  s = tensor_ms.as
-00003940: 7479 7065 286d 7374 7970 652e 696e 7438  type(mstype.int8
-00003950: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
-00003960: 7420 3d20 7465 6e73 6f72 5f6d 732e 6164  t = tensor_ms.ad
-00003970: 6428 6f74 6865 725f 6d73 290a 2020 2020  d(other_ms).    
-00003980: 2020 2020 2020 2020 6f75 7420 3d20 6f75          out = ou
-00003990: 742e 6173 7479 7065 286d 7374 7970 652e  t.astype(mstype.
-000039a0: 626f 6f6c 5f29 0a20 2020 2020 2020 2065  bool_).        e
-000039b0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-000039c0: 206f 7574 203d 2074 656e 736f 725f 6d73   out = tensor_ms
-000039d0: 2e5f 5f6f 725f 5f28 6f74 6865 725f 6d73  .__or__(other_ms
-000039e0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-000039f0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00003a00: 5f74 656e 736f 7228 6f75 7429 0a0a 2020  _tensor(out)..  
-00003a10: 2020 6465 6620 5f5f 7261 6464 5f5f 2873    def __radd__(s
-00003a20: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
-00003a30: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00003a40: 2e5f 5f61 6464 5f5f 286f 7468 6572 290a  .__add__(other).
-00003a50: 0a20 2020 2064 6566 205f 5f69 6164 645f  .    def __iadd_
-00003a60: 5f28 7365 6c66 2c20 6f74 6865 7229 3a0a  _(self, other):.
-00003a70: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00003a80: 656c 662e 5f5f 6164 645f 5f28 6f74 6865  elf.__add__(othe
-00003a90: 7229 0a0a 2020 2020 6465 6620 5f5f 7375  r)..    def __su
-00003aa0: 625f 5f28 7365 6c66 2c20 6f74 6865 7229  b__(self, other)
-00003ab0: 3a0a 2020 2020 2020 2020 7465 6e73 6f72  :.        tensor
-00003ac0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00003ad0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00003ae0: 2020 2020 2020 6f74 6865 725f 6d73 203d        other_ms =
-00003af0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00003b00: 6f72 286f 7468 6572 290a 2020 2020 2020  or(other).      
-00003b10: 2020 6f75 7420 3d20 7465 6e73 6f72 5f6d    out = tensor_m
-00003b20: 732e 5f5f 7375 625f 5f28 6f74 6865 725f  s.__sub__(other_
-00003b30: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-00003b40: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00003b50: 6572 5f74 656e 736f 7228 6f75 7429 0a0a  er_tensor(out)..
-00003b60: 2020 2020 6465 6620 5f5f 7273 7562 5f5f      def __rsub__
-00003b70: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-00003b80: 2020 2020 2020 2074 656e 736f 725f 6d73         tensor_ms
-00003b90: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00003ba0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00003bb0: 2020 206f 7468 6572 5f6d 7320 3d20 6361     other_ms = ca
-00003bc0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00003bd0: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
-00003be0: 7574 203d 2074 656e 736f 725f 6d73 2e5f  ut = tensor_ms._
-00003bf0: 5f72 7375 625f 5f28 6f74 6865 725f 6d73  _rsub__(other_ms
-00003c00: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00003c10: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00003c20: 5f74 656e 736f 7228 6f75 7429 0a0a 2020  _tensor(out)..  
-00003c30: 2020 6465 6620 5f5f 6973 7562 5f5f 2873    def __isub__(s
-00003c40: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
-00003c50: 2020 2020 2074 656e 736f 725f 6d73 203d       tensor_ms =
-00003c60: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00003c70: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00003c80: 206f 7468 6572 5f6d 7320 3d20 6361 7374   other_ms = cast
-00003c90: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
-00003ca0: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
-00003cb0: 203d 2074 656e 736f 725f 6d73 2e5f 5f69   = tensor_ms.__i
-00003cc0: 7375 625f 5f28 6f74 6865 725f 6d73 290a  sub__(other_ms).
-00003cd0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-00003ce0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00003cf0: 656e 736f 7228 6f75 7429 0a0a 2020 2020  ensor(out)..    
-00003d00: 6465 6620 5f5f 6d75 6c5f 5f28 7365 6c66  def __mul__(self
-00003d10: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-00003d20: 2020 2320 544f 444f 3a20 496e 206d 696e    # TODO: In min
-00003d30: 6473 706f 7265 2074 656e 736f 722e 5f5f  dspore tensor.__
-00003d40: 6d75 6c5f 5f2c 2066 6c6f 6174 2074 656e  mul__, float ten
-00003d50: 736f 7220 6361 6e20 6e6f 7420 6d75 6c20  sor can not mul 
-00003d60: 7769 7468 2063 6f6d 706c 6578 2074 656e  with complex ten
-00003d70: 736f 720a 2020 2020 2020 2020 7465 6e73  sor.        tens
-00003d80: 6f72 5f6d 7320 3d20 6361 7374 5f74 6f5f  or_ms = cast_to_
-00003d90: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00003da0: 2020 2020 2020 2020 6f74 6865 725f 6d73          other_ms
-00003db0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00003dc0: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
-00003dd0: 2020 2020 6f75 7420 3d20 7465 6e73 6f72      out = tensor
-00003de0: 5f6d 732e 5f5f 6d75 6c5f 5f28 6f74 6865  _ms.__mul__(othe
-00003df0: 725f 6d73 290a 2020 2020 2020 2020 7265  r_ms).        re
-00003e00: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00003e10: 7074 6572 5f74 656e 736f 7228 6f75 7429  pter_tensor(out)
-00003e20: 0a0a 2020 2020 6465 6620 5f5f 726d 756c  ..    def __rmul
-00003e30: 5f5f 2873 656c 662c 206f 7468 6572 293a  __(self, other):
-00003e40: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00003e50: 7365 6c66 2e5f 5f6d 756c 5f5f 286f 7468  self.__mul__(oth
-00003e60: 6572 290a 0a20 2020 2064 6566 205f 5f69  er)..    def __i
-00003e70: 6d75 6c5f 5f28 7365 6c66 2c20 6f74 6865  mul__(self, othe
-00003e80: 7229 3a0a 2020 2020 2020 2020 7265 7475  r):.        retu
-00003e90: 726e 2073 656c 662e 5f5f 6d75 6c5f 5f28  rn self.__mul__(
-00003ea0: 6f74 6865 7229 0a0a 2020 2020 6465 6620  other)..    def 
-00003eb0: 5f5f 7472 7565 6469 765f 5f28 7365 6c66  __truediv__(self
-00003ec0: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-00003ed0: 2020 7465 6e73 6f72 5f6d 7320 3d20 6361    tensor_ms = ca
-00003ee0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00003ef0: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
-00003f00: 6865 725f 6d73 203d 2063 6173 745f 746f  her_ms = cast_to
-00003f10: 5f6d 735f 7465 6e73 6f72 286f 7468 6572  _ms_tensor(other
-00003f20: 290a 2020 2020 2020 2020 7465 6e73 6f72  ).        tensor
-00003f30: 5f74 7970 6520 3d20 7465 6e73 6f72 5f6d  _type = tensor_m
-00003f40: 732e 6474 7970 650a 2020 2020 2020 2020  s.dtype.        
-00003f50: 6966 2027 496e 7427 2069 6e20 7374 7228  if 'Int' in str(
-00003f60: 7465 6e73 6f72 5f74 7970 6529 3a0a 2020  tensor_type):.  
-00003f70: 2020 2020 2020 2020 2020 7465 6e73 6f72            tensor
-00003f80: 5f6d 7320 3d20 6d73 2e6f 7073 2e63 6173  _ms = ms.ops.cas
-00003f90: 7428 7465 6e73 6f72 5f6d 732c 206d 7374  t(tensor_ms, mst
-00003fa0: 7970 652e 666c 6f61 7433 3229 0a20 2020  ype.float32).   
-00003fb0: 2020 2020 206f 7574 203d 2074 656e 736f       out = tenso
-00003fc0: 725f 6d73 2e5f 5f74 7275 6564 6976 5f5f  r_ms.__truediv__
-00003fd0: 286f 7468 6572 5f6d 7329 0a20 2020 2020  (other_ms).     
-00003fe0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-00003ff0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-00004000: 286f 7574 290a 0a20 2020 2064 6566 205f  (out)..    def _
-00004010: 5f72 7472 7565 6469 765f 5f28 7365 6c66  _rtruediv__(self
-00004020: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-00004030: 2020 7465 6e73 6f72 5f6d 7320 3d20 6361    tensor_ms = ca
-00004040: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00004050: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
-00004060: 6865 725f 6d73 203d 2063 6173 745f 746f  her_ms = cast_to
-00004070: 5f6d 735f 7465 6e73 6f72 286f 7468 6572  _ms_tensor(other
-00004080: 290a 2020 2020 2020 2020 7465 6e73 6f72  ).        tensor
-00004090: 5f74 7970 6520 3d20 7465 6e73 6f72 5f6d  _type = tensor_m
-000040a0: 732e 6474 7970 650a 2020 2020 2020 2020  s.dtype.        
-000040b0: 6966 2027 496e 7427 2069 6e20 7374 7228  if 'Int' in str(
-000040c0: 7465 6e73 6f72 5f74 7970 6529 3a0a 2020  tensor_type):.  
-000040d0: 2020 2020 2020 2020 2020 7465 6e73 6f72            tensor
-000040e0: 5f6d 7320 3d20 6d73 2e6f 7073 2e63 6173  _ms = ms.ops.cas
-000040f0: 7428 7465 6e73 6f72 5f6d 732c 206d 7374  t(tensor_ms, mst
-00004100: 7970 652e 666c 6f61 7433 3229 0a20 2020  ype.float32).   
-00004110: 2020 2020 206f 7574 203d 2074 656e 736f       out = tenso
-00004120: 725f 6d73 2e5f 5f72 7472 7565 6469 765f  r_ms.__rtruediv_
-00004130: 5f28 6f74 6865 725f 6d73 290a 2020 2020  _(other_ms).    
-00004140: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00004150: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00004160: 7228 6f75 7429 0a0a 2020 2020 6465 6620  r(out)..    def 
-00004170: 5f5f 6d6f 645f 5f28 7365 6c66 2c20 6f74  __mod__(self, ot
-00004180: 6865 7229 3a0a 2020 2020 2020 2020 7465  her):.        te
-00004190: 6e73 6f72 5f6d 7320 3d20 6361 7374 5f74  nsor_ms = cast_t
-000041a0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-000041b0: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
-000041c0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-000041d0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
-000041e0: 2020 2020 2020 6f75 7420 3d20 7465 6e73        out = tens
-000041f0: 6f72 5f6d 732e 5f5f 6d6f 645f 5f28 6f74  or_ms.__mod__(ot
-00004200: 6865 725f 6d73 290a 2020 2020 2020 2020  her_ms).        
-00004210: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00004220: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00004230: 7429 0a0a 2020 2020 6465 6620 5f5f 726d  t)..    def __rm
-00004240: 6f64 5f5f 2873 656c 662c 206f 7468 6572  od__(self, other
-00004250: 293a 0a20 2020 2020 2020 2074 656e 736f  ):.        tenso
-00004260: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
-00004270: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00004280: 2020 2020 2020 206f 7468 6572 5f6d 7320         other_ms 
-00004290: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-000042a0: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
-000042b0: 2020 206f 7574 203d 2074 656e 736f 725f     out = tensor_
-000042c0: 6d73 2e5f 5f72 6d6f 645f 5f28 6f74 6865  ms.__rmod__(othe
-000042d0: 725f 6d73 290a 2020 2020 2020 2020 7265  r_ms).        re
-000042e0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-000042f0: 7074 6572 5f74 656e 736f 7228 6f75 7429  pter_tensor(out)
-00004300: 0a0a 2020 2020 6465 6620 5f5f 696d 6f64  ..    def __imod
-00004310: 5f5f 2873 656c 662c 206f 7468 6572 293a  __(self, other):
-00004320: 0a20 2020 2020 2020 2074 656e 736f 725f  .        tensor_
-00004330: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00004340: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-00004350: 2020 2020 206f 7468 6572 5f6d 7320 3d20       other_ms = 
-00004360: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00004370: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
-00004380: 206f 7574 203d 2074 656e 736f 725f 6d73   out = tensor_ms
-00004390: 2e5f 5f69 6d6f 645f 5f28 6f74 6865 725f  .__imod__(other_
-000043a0: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-000043b0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-000043c0: 6572 5f74 656e 736f 7228 6f75 7429 0a0a  er_tensor(out)..
-000043d0: 2020 2020 6465 6620 5f5f 706f 775f 5f28      def __pow__(
-000043e0: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
-000043f0: 2020 2020 2020 7465 6e73 6f72 5f6d 7320        tensor_ms 
-00004400: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00004410: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00004420: 2020 6f74 6865 725f 6d73 203d 2063 6173    other_ms = cas
-00004430: 745f 746f 5f6d 735f 7465 6e73 6f72 286f  t_to_ms_tensor(o
-00004440: 7468 6572 290a 2020 2020 2020 2020 6f75  ther).        ou
-00004450: 7420 3d20 7465 6e73 6f72 5f6d 732e 5f5f  t = tensor_ms.__
-00004460: 706f 775f 5f28 6f74 6865 725f 6d73 290a  pow__(other_ms).
-00004470: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-00004480: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00004490: 656e 736f 7228 6f75 7429 0a0a 2020 2020  ensor(out)..    
-000044a0: 6465 6620 5f5f 7270 6f77 5f5f 2873 656c  def __rpow__(sel
-000044b0: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
-000044c0: 2020 2074 656e 736f 725f 6d73 203d 2063     tensor_ms = c
-000044d0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-000044e0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-000044f0: 7468 6572 5f6d 7320 3d20 6361 7374 5f74  ther_ms = cast_t
-00004500: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
-00004510: 7229 0a20 2020 2020 2020 206f 7574 203d  r).        out =
-00004520: 2074 656e 736f 725f 6d73 2e5f 5f72 706f   tensor_ms.__rpo
-00004530: 775f 5f28 6f74 6865 725f 6d73 290a 2020  w__(other_ms).  
-00004540: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00004550: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00004560: 736f 7228 6f75 7429 0a0a 2020 2020 6465  sor(out)..    de
-00004570: 6620 5f5f 666c 6f6f 7264 6976 5f5f 2873  f __floordiv__(s
-00004580: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
-00004590: 2020 2020 2074 656e 736f 725f 6d73 203d       tensor_ms =
-000045a0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-000045b0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-000045c0: 206f 7468 6572 5f6d 7320 3d20 6361 7374   other_ms = cast
-000045d0: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
-000045e0: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
-000045f0: 203d 2074 656e 736f 725f 6d73 2e5f 5f66   = tensor_ms.__f
-00004600: 6c6f 6f72 6469 765f 5f28 6f74 6865 725f  loordiv__(other_
-00004610: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-00004620: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00004630: 6572 5f74 656e 736f 7228 6f75 7429 0a0a  er_tensor(out)..
-00004640: 2020 2020 6465 6620 5f5f 7266 6c6f 6f72      def __rfloor
-00004650: 6469 765f 5f28 7365 6c66 2c20 6f74 6865  div__(self, othe
-00004660: 7229 3a0a 2020 2020 2020 2020 7465 6e73  r):.        tens
-00004670: 6f72 5f6d 7320 3d20 6361 7374 5f74 6f5f  or_ms = cast_to_
-00004680: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00004690: 2020 2020 2020 2020 6f74 6865 725f 6d73          other_ms
-000046a0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-000046b0: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
-000046c0: 2020 2020 6f75 7420 3d20 7465 6e73 6f72      out = tensor
-000046d0: 5f6d 732e 5f5f 7266 6c6f 6f72 6469 765f  _ms.__rfloordiv_
-000046e0: 5f28 6f74 6865 725f 6d73 290a 2020 2020  _(other_ms).    
-000046f0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00004700: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00004710: 7228 6f75 7429 0a0a 2020 2020 6465 6620  r(out)..    def 
-00004720: 5f5f 6966 6c6f 6f72 6469 765f 5f28 7365  __ifloordiv__(se
-00004730: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
-00004740: 2020 2020 7465 6e73 6f72 5f6d 7320 3d20      tensor_ms = 
-00004750: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00004760: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00004770: 6f74 6865 725f 6d73 203d 2063 6173 745f  other_ms = cast_
-00004780: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
-00004790: 6572 290a 2020 2020 2020 2020 6f75 7420  er).        out 
-000047a0: 3d20 7465 6e73 6f72 5f6d 732e 5f5f 6966  = tensor_ms.__if
-000047b0: 6c6f 6f72 6469 765f 5f28 6f74 6865 725f  loordiv__(other_
-000047c0: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-000047d0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-000047e0: 6572 5f74 656e 736f 7228 6f75 7429 0a0a  er_tensor(out)..
-000047f0: 2020 2020 6465 6620 5f5f 6c74 5f5f 2873      def __lt__(s
-00004800: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
-00004810: 2020 2020 2074 656e 736f 725f 6d73 203d       tensor_ms =
-00004820: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00004830: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00004840: 206f 7468 6572 5f6d 7320 3d20 6361 7374   other_ms = cast
-00004850: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
-00004860: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
-00004870: 203d 2074 656e 736f 725f 6d73 2e5f 5f6c   = tensor_ms.__l
-00004880: 745f 5f28 6f74 6865 725f 6d73 290a 2020  t__(other_ms).  
-00004890: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-000048a0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-000048b0: 736f 7228 6f75 7429 0a0a 2020 2020 6465  sor(out)..    de
-000048c0: 6620 5f5f 6c65 5f5f 2873 656c 662c 206f  f __le__(self, o
-000048d0: 7468 6572 293a 0a20 2020 2020 2020 2074  ther):.        t
-000048e0: 656e 736f 725f 6d73 203d 2063 6173 745f  ensor_ms = cast_
-000048f0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00004900: 6629 0a20 2020 2020 2020 206f 7468 6572  f).        other
-00004910: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00004920: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
-00004930: 2020 2020 2020 206f 7574 203d 2074 656e         out = ten
-00004940: 736f 725f 6d73 2e5f 5f6c 655f 5f28 6f74  sor_ms.__le__(ot
-00004950: 6865 725f 6d73 290a 2020 2020 2020 2020  her_ms).        
-00004960: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00004970: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00004980: 7429 0a0a 2020 2020 6465 6620 5f5f 6774  t)..    def __gt
-00004990: 5f5f 2873 656c 662c 206f 7468 6572 293a  __(self, other):
-000049a0: 0a20 2020 2020 2020 2074 656e 736f 725f  .        tensor_
-000049b0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-000049c0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-000049d0: 2020 2020 206f 7468 6572 5f6d 7320 3d20       other_ms = 
-000049e0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-000049f0: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
-00004a00: 206f 7574 203d 2074 656e 736f 725f 6d73   out = tensor_ms
-00004a10: 2e5f 5f67 745f 5f28 6f74 6865 725f 6d73  .__gt__(other_ms
-00004a20: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00004a30: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00004a40: 5f74 656e 736f 7228 6f75 7429 0a0a 2020  _tensor(out)..  
-00004a50: 2020 6465 6620 5f5f 6765 5f5f 2873 656c    def __ge__(sel
-00004a60: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
-00004a70: 2020 2074 656e 736f 725f 6d73 203d 2063     tensor_ms = c
-00004a80: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00004a90: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-00004aa0: 7468 6572 5f6d 7320 3d20 6361 7374 5f74  ther_ms = cast_t
-00004ab0: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
-00004ac0: 7229 0a20 2020 2020 2020 206f 7574 203d  r).        out =
-00004ad0: 2074 656e 736f 725f 6d73 2e5f 5f67 655f   tensor_ms.__ge_
-00004ae0: 5f28 6f74 6865 725f 6d73 290a 2020 2020  _(other_ms).    
-00004af0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00004b00: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00004b10: 7228 6f75 7429 0a0a 2020 2020 6465 6620  r(out)..    def 
-00004b20: 5f5f 6571 5f5f 2873 656c 662c 206f 7468  __eq__(self, oth
-00004b30: 6572 293a 0a20 2020 2020 2020 2074 656e  er):.        ten
-00004b40: 736f 725f 6d73 203d 2063 6173 745f 746f  sor_ms = cast_to
-00004b50: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00004b60: 0a20 2020 2020 2020 206f 7468 6572 5f6d  .        other_m
-00004b70: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00004b80: 656e 736f 7228 6f74 6865 7229 0a20 2020  ensor(other).   
-00004b90: 2020 2020 206f 7574 203d 2074 656e 736f       out = tenso
-00004ba0: 725f 6d73 2e5f 5f65 715f 5f28 6f74 6865  r_ms.__eq__(othe
-00004bb0: 725f 6d73 290a 2020 2020 2020 2020 7265  r_ms).        re
-00004bc0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00004bd0: 7074 6572 5f74 656e 736f 7228 6f75 7429  pter_tensor(out)
-00004be0: 0a0a 2020 2020 6465 6620 5f5f 6d61 746d  ..    def __matm
-00004bf0: 756c 5f5f 2873 656c 662c 206f 7468 6572  ul__(self, other
-00004c00: 293a 0a20 2020 2020 2020 2074 656e 736f  ):.        tenso
-00004c10: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
-00004c20: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00004c30: 2020 2020 2020 206f 7468 6572 5f6d 7320         other_ms 
-00004c40: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00004c50: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
-00004c60: 2020 206f 7574 203d 2074 656e 736f 725f     out = tensor_
-00004c70: 6d73 2e5f 5f6d 6174 6d75 6c5f 5f28 6f74  ms.__matmul__(ot
-00004c80: 6865 725f 6d73 290a 2020 2020 2020 2020  her_ms).        
-00004c90: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00004ca0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00004cb0: 7429 0a0a 2020 2020 6465 6620 5f5f 726d  t)..    def __rm
-00004cc0: 6174 6d75 6c5f 5f28 7365 6c66 2c20 6f74  atmul__(self, ot
-00004cd0: 6865 7229 3a0a 2020 2020 2020 2020 7465  her):.        te
-00004ce0: 6e73 6f72 5f6d 7320 3d20 6361 7374 5f74  nsor_ms = cast_t
-00004cf0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00004d00: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
-00004d10: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00004d20: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
-00004d30: 2020 2020 2020 6f75 7420 3d20 7465 6e73        out = tens
-00004d40: 6f72 5f6d 732e 5f5f 726d 6174 6d75 6c5f  or_ms.__rmatmul_
-00004d50: 5f28 6f74 6865 725f 6d73 290a 2020 2020  _(other_ms).    
-00004d60: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00004d70: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00004d80: 7228 6f75 7429 0a0a 2020 2020 6465 6620  r(out)..    def 
-00004d90: 5f5f 6861 7368 5f5f 2873 656c 6629 3a0a  __hash__(self):.
-00004da0: 2020 2020 2020 2020 7265 7475 726e 2068          return h
-00004db0: 6173 6828 6964 2873 656c 6629 290a 0a20  ash(id(self)).. 
-00004dc0: 2020 2064 6566 205f 5f6e 655f 5f28 7365     def __ne__(se
-00004dd0: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
-00004de0: 2020 2020 7465 6e73 6f72 5f6d 7320 3d20      tensor_ms = 
-00004df0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00004e00: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00004e10: 6f74 6865 725f 6d73 203d 2063 6173 745f  other_ms = cast_
-00004e20: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
-00004e30: 6572 290a 2020 2020 2020 2020 6f75 7420  er).        out 
-00004e40: 3d20 7465 6e73 6f72 5f6d 732e 5f5f 6e65  = tensor_ms.__ne
-00004e50: 5f5f 286f 7468 6572 5f6d 7329 0a20 2020  __(other_ms).   
-00004e60: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-00004e70: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00004e80: 6f72 286f 7574 290a 0a20 2020 2023 205f  or(out)..    # _
-00004e90: 5f73 6574 6974 656d 5f5f 206e 6f20 6e65  _setitem__ no ne
-00004ea0: 6564 2074 6f20 6f76 6572 6c6f 6164 0a20  ed to overload. 
-00004eb0: 2020 2064 6566 205f 5f67 6574 6974 656d     def __getitem
-00004ec0: 5f5f 2873 656c 662c 2069 6e64 6578 293a  __(self, index):
-00004ed0: 0a20 2020 2020 2020 2023 2054 4f44 4f3a  .        # TODO:
-00004ee0: 206e 6f74 2073 7570 706f 7274 2063 6f6d   not support com
-00004ef0: 706c 6578 2054 656e 736f 7220 616e 6420  plex Tensor and 
-00004f00: 4661 6c73 6520 626f 6f6c 2069 6e64 6578  False bool index
-00004f10: 2067 6574 6974 656d 0a20 2020 2020 2020   getitem.       
-00004f20: 2064 6566 205f 6765 7469 7465 6d5f 6861   def _getitem_ha
-00004f30: 6e64 6c65 7228 7465 6e73 6f72 5f6d 732c  ndler(tensor_ms,
-00004f40: 2069 6e64 6578 293a 0a20 2020 2020 2020   index):.       
-00004f50: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
-00004f60: 6365 2869 6e64 6578 2c20 626f 6f6c 293a  ce(index, bool):
-00004f70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00004f80: 2069 6620 696e 6465 783a 0a20 2020 2020   if index:.     
-00004f90: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00004fa0: 6574 7572 6e20 7465 6e73 6f72 5f6d 732e  eturn tensor_ms.
-00004fb0: 6578 7061 6e64 5f64 696d 7328 3029 0a20  expand_dims(0). 
-00004fc0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-00004fd0: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00004fe0: 2020 2020 2020 2020 2069 6e64 6578 203d           index =
-00004ff0: 206d 732e 5465 6e73 6f72 2846 616c 7365   ms.Tensor(False
-00005000: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-00005010: 2020 2020 2020 6f75 7420 3d20 6d73 2e6f        out = ms.o
-00005020: 7073 2e6d 6173 6b65 645f 7365 6c65 6374  ps.masked_select
-00005030: 2874 656e 736f 725f 6d73 2c20 696e 6465  (tensor_ms, inde
-00005040: 7829 0a20 2020 2020 2020 2020 2020 2020  x).             
-00005050: 2020 2020 2020 2072 6574 7572 6e20 6f75         return ou
-00005060: 740a 2020 2020 2020 2020 2020 2020 6966  t.            if
-00005070: 2069 7369 6e73 7461 6e63 6528 696e 6465   isinstance(inde
-00005080: 782c 2074 7570 6c65 2920 616e 6420 6973  x, tuple) and is
-00005090: 696e 7374 616e 6365 2869 6e64 6578 5b30  instance(index[0
-000050a0: 5d2c 2062 6f6f 6c29 3a0a 2020 2020 2020  ], bool):.      
-000050b0: 2020 2020 2020 2020 2020 6966 2046 616c            if Fal
-000050c0: 7365 2069 6e20 696e 6465 783a 0a20 2020  se in index:.   
-000050d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000050e0: 2069 6e64 6578 203d 206d 732e 5465 6e73   index = ms.Tens
-000050f0: 6f72 2846 616c 7365 290a 2020 2020 2020  or(False).      
-00005100: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-00005110: 7420 3d20 6d73 2e6f 7073 2e6d 6173 6b65  t = ms.ops.maske
-00005120: 645f 7365 6c65 6374 2874 656e 736f 725f  d_select(tensor_
-00005130: 6d73 2c20 696e 6465 7829 0a20 2020 2020  ms, index).     
-00005140: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00005150: 6574 7572 6e20 6f75 740a 2020 2020 2020  eturn out.      
-00005160: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-00005170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005180: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
-00005190: 725f 6d73 2e65 7870 616e 645f 6469 6d73  r_ms.expand_dims
-000051a0: 2830 290a 2020 2020 2020 2020 2020 2020  (0).            
-000051b0: 7265 7475 726e 2074 656e 736f 725f 6d73  return tensor_ms
-000051c0: 2e5f 5f67 6574 6974 656d 5f5f 2869 6e64  .__getitem__(ind
-000051d0: 6578 290a 0a20 2020 2020 2020 2074 656e  ex)..        ten
-000051e0: 736f 725f 6d73 203d 2063 6173 745f 746f  sor_ms = cast_to
-000051f0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00005200: 0a20 2020 2020 2020 206f 7574 5f6d 7320  .        out_ms 
-00005210: 3d20 5f67 6574 6974 656d 5f68 616e 646c  = _getitem_handl
-00005220: 6572 2874 656e 736f 725f 6d73 2c20 696e  er(tensor_ms, in
-00005230: 6465 7829 0a20 2020 2020 2020 206f 7574  dex).        out
-00005240: 203d 2063 6173 745f 746f 5f61 6461 7074   = cast_to_adapt
-00005250: 6572 5f74 656e 736f 7228 6f75 745f 6d73  er_tensor(out_ms
-00005260: 290a 2020 2020 2020 2020 6966 206f 7574  ).        if out
-00005270: 5f6d 7320 6973 206e 6f74 2074 656e 736f  _ms is not tenso
-00005280: 725f 6d73 3a0a 2020 2020 2020 2020 2020  r_ms:.          
-00005290: 2020 6f75 742e 7061 7265 6e74 5f74 656e    out.parent_ten
-000052a0: 736f 725f 203d 2074 656e 736f 725f 6d73  sor_ = tensor_ms
-000052b0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-000052c0: 2e69 6e64 6578 5f6f 665f 7061 7265 6e74  .index_of_parent
-000052d0: 5f20 3d20 696e 6465 780a 2020 2020 2020  _ = index.      
-000052e0: 2020 7265 7475 726e 206f 7574 0a0a 2020    return out..  
-000052f0: 2020 6465 6620 5f5f 6765 7473 7461 7465    def __getstate
-00005300: 5f5f 2873 656c 6629 3a0a 2020 2020 2020  __(self):.      
-00005310: 2020 7069 636b 6c65 6420 3d20 7b22 696e    pickled = {"in
-00005320: 7075 745f 6461 7461 223a 2073 656c 662e  put_data": self.
-00005330: 6173 6e75 6d70 7928 292c 2022 6474 7970  asnumpy(), "dtyp
-00005340: 6522 3a20 7365 6c66 2e64 7479 7065 7d0a  e": self.dtype}.
-00005350: 2020 2020 2020 2020 7265 7475 726e 2070          return p
-00005360: 6963 6b6c 6564 0a0a 2020 2020 6465 6620  ickled..    def 
-00005370: 5f5f 7365 7473 7461 7465 5f5f 2873 656c  __setstate__(sel
-00005380: 662c 2073 7461 7465 293a 0a20 2020 2020  f, state):.     
-00005390: 2020 2054 656e 736f 722e 5f5f 696e 6974     Tensor.__init
-000053a0: 5f5f 2873 656c 662c 2073 7461 7465 5b22  __(self, state["
-000053b0: 696e 7075 745f 6461 7461 225d 2c20 6474  input_data"], dt
-000053c0: 7970 653d 7374 6174 655b 2264 7479 7065  ype=state["dtype
-000053d0: 225d 2c20 696e 6e65 723d 5472 7565 290a  "], inner=True).
-000053e0: 0a20 2020 2064 6566 2073 746f 7261 6765  .    def storage
-000053f0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00005400: 6966 2067 7261 7068 5f6d 6f64 655f 636f  if graph_mode_co
-00005410: 6e64 6974 696f 6e28 293a 0a20 2020 2020  ndition():.     
-00005420: 2020 2020 2020 2077 6172 6e69 6e67 2827         warning('
-00005430: 4375 7272 656e 746c 792c 2060 7465 6e73  Currently, `tens
-00005440: 6f72 2e73 746f 7261 6765 2829 6020 6973  or.storage()` is
-00005450: 206e 6f74 2073 7570 706f 7274 6564 2069   not supported i
-00005460: 6e20 6772 6170 6820 6d6f 6465 2e20 270a  n graph mode. '.
-00005470: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005480: 2020 2020 2750 6c65 6173 6520 7265 706c      'Please repl
-00005490: 6163 6520 6053 746f 7261 6765 6020 7265  ace `Storage` re
-000054a0: 6c61 7465 6420 696e 7465 7266 6163 6573  lated interfaces
-000054b0: 2077 6974 6820 7468 6520 6571 7569 7661   with the equiva
-000054c0: 6c65 6e74 2069 6e74 6572 6661 6365 2e27  lent interface.'
-000054d0: 290a 2020 2020 2020 2020 5f73 746f 7261  ).        _stora
-000054e0: 6765 203d 205f 556e 7479 7065 6453 746f  ge = _UntypedSto
-000054f0: 7261 6765 2869 6e6e 6572 5f64 6174 613d  rage(inner_data=
-00005500: 7365 6c66 290a 2020 2020 2020 2020 7265  self).        re
-00005510: 7475 726e 205f 5479 7065 6453 746f 7261  turn _TypedStora
-00005520: 6765 2877 7261 705f 7374 6f72 6167 653d  ge(wrap_storage=
-00005530: 5f73 746f 7261 6765 2c20 6474 7970 653d  _storage, dtype=
-00005540: 7365 6c66 2e64 7479 7065 290a 0a20 2020  self.dtype)..   
-00005550: 2064 6566 2073 746f 7261 6765 5f74 7970   def storage_typ
-00005560: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
-00005570: 2072 6574 7572 6e20 7365 6c66 2e73 746f   return self.sto
-00005580: 7261 6765 2829 2e5f 6765 745f 6c65 6761  rage()._get_lega
-00005590: 6379 5f73 746f 7261 6765 5f63 6c61 7373  cy_storage_class
-000055a0: 2829 0a0a 2020 2020 6465 6620 7374 6f72  ()..    def stor
-000055b0: 6167 655f 6f66 6673 6574 2873 656c 6629  age_offset(self)
-000055c0: 3a0a 2020 2020 2020 2020 2320 544f 444f  :.        # TODO
-000055d0: 3a20 6f75 7470 7574 206f 6620 785b 333a  : output of x[3:
-000055e0: 5d2e 7374 6f72 6167 655f 6f66 6673 6574  ].storage_offset
-000055f0: 2829 2069 7320 332c 2077 6869 6368 2064  () is 3, which d
-00005600: 6570 656e 6473 206f 6e20 7468 6520 736c  epends on the sl
-00005610: 6963 6520 7375 7070 6f72 7469 6e67 2069  ice supporting i
-00005620: 6e70 6c61 6365 206f 7065 7261 7469 6f6e  nplace operation
-00005630: 732e 0a20 2020 2020 2020 2072 6574 7572  s..        retur
-00005640: 6e20 300a 0a20 2020 2040 7072 6f70 6572  n 0..    @proper
-00005650: 7479 0a20 2020 2064 6566 2064 7479 7065  ty.    def dtype
-00005660: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00005670: 7820 3d20 6361 7374 5f74 6f5f 6d73 5f74  x = cast_to_ms_t
-00005680: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00005690: 2020 2020 6474 7970 6520 3d20 782e 6474      dtype = x.dt
-000056a0: 7970 650a 2020 2020 2020 2020 7265 7475  ype.        retu
-000056b0: 726e 205f 6d73 6474 7970 6532 7479 7065  rn _msdtype2type
-000056c0: 4469 6374 2e67 6574 2873 7472 2864 7479  Dict.get(str(dty
-000056d0: 7065 292c 2064 7479 7065 290a 0a20 2020  pe), dtype)..   
-000056e0: 2064 6566 2066 696c 6c5f 6164 6170 7465   def fill_adapte
-000056f0: 7228 7365 6c66 2c20 7661 6c29 3a0a 2020  r(self, val):.  
-00005700: 2020 2020 2020 7661 6c20 3d20 6361 7374        val = cast
-00005710: 5f74 6f5f 6d73 5f74 656e 736f 7228 7661  _to_ms_tensor(va
-00005720: 6c29 0a20 2020 2020 2020 206f 7574 7075  l).        outpu
-00005730: 7420 3d20 6d73 2e6f 7073 2e66 696c 6c28  t = ms.ops.fill(
-00005740: 7365 6c66 2e64 7479 7065 2c20 7365 6c66  self.dtype, self
-00005750: 2e73 6861 7065 2c20 7661 6c29 0a20 2020  .shape, val).   
-00005760: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-00005770: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00005780: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-00005790: 6465 6620 6669 6c6c 5f28 7365 6c66 2c20  def fill_(self, 
-000057a0: 7661 6c29 3a0a 2020 2020 2020 2020 6f75  val):.        ou
-000057b0: 7470 7574 203d 2073 656c 662e 6669 6c6c  tput = self.fill
-000057c0: 5f61 6461 7074 6572 2876 616c 290a 2020  _adapter(val).  
-000057d0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-000057e0: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-000057f0: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-00005800: 2c20 2266 696c 6c5f 222c 2022 6669 6c6c  , "fill_", "fill
-00005810: 5f61 6461 7074 6572 2229 0a0a 2020 2020  _adapter")..    
-00005820: 6465 6620 6e6f 726d 616c 5f61 6461 7074  def normal_adapt
-00005830: 6572 2873 656c 662c 206d 6561 6e3d 302c  er(self, mean=0,
-00005840: 2073 7464 3d31 2c20 2a2c 2067 656e 6572   std=1, *, gener
-00005850: 6174 6f72 3d4e 6f6e 6529 3a0a 2020 2020  ator=None):.    
-00005860: 2020 2020 6966 2067 656e 6572 6174 6f72      if generator
-00005870: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-00005880: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00005890: 5661 6c75 6545 7272 6f72 2822 6067 656e  ValueError("`gen
-000058a0: 6572 6174 6f72 6020 6361 6e20 6e6f 7420  erator` can not 
-000058b0: 6265 2073 7570 706f 7274 7465 642e 2229  be supportted.")
-000058c0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-000058d0: 3d20 6d73 2e6f 7073 2e6e 6f72 6d61 6c28  = ms.ops.normal(
-000058e0: 7365 6c66 2e73 6861 7065 2c20 6d65 616e  self.shape, mean
-000058f0: 2c20 7374 6429 2e61 7374 7970 6528 7365  , std).astype(se
-00005900: 6c66 2e64 7479 7065 290a 2020 2020 2020  lf.dtype).      
-00005910: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00005920: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00005930: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00005940: 206e 6f72 6d61 6c5f 2873 656c 662c 206d   normal_(self, m
-00005950: 6561 6e3d 302c 2073 7464 3d31 2c20 2a2c  ean=0, std=1, *,
-00005960: 2067 656e 6572 6174 6f72 3d4e 6f6e 6529   generator=None)
-00005970: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-00005980: 203d 2073 656c 662e 6e6f 726d 616c 5f61   = self.normal_a
-00005990: 6461 7074 6572 286d 6561 6e2c 2073 7464  dapter(mean, std
-000059a0: 2c20 6765 6e65 7261 746f 723d 6765 6e65  , generator=gene
-000059b0: 7261 746f 7229 0a20 2020 2020 2020 2072  rator).        r
-000059c0: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
-000059d0: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
-000059e0: 662c 206f 7574 7075 742c 2022 6e6f 726d  f, output, "norm
-000059f0: 616c 5f22 2c20 226e 6f72 6d61 6c5f 6164  al_", "normal_ad
-00005a00: 6170 7465 7222 290a 0a20 2020 2064 6566  apter")..    def
-00005a10: 2073 697a 6528 7365 6c66 2c20 6469 6d3d   size(self, dim=
-00005a20: 4e6f 6e65 293a 0a20 2020 2020 2020 2022  None):.        "
-00005a30: 2222 0a20 2020 2020 2020 2074 656e 736f  "".        tenso
-00005a40: 722e 7369 7a65 2829 2068 6173 2074 6865  r.size() has the
-00005a50: 2073 616d 6520 6675 6e63 7469 6f6e 2061   same function a
-00005a60: 7320 7465 6e73 6f72 2e73 697a 6528 2920  s tensor.size() 
-00005a70: 696e 2050 7954 6f72 6368 2c0a 2020 2020  in PyTorch,.    
-00005a80: 2020 2020 6275 7420 6469 6666 6572 656e      but differen
-00005a90: 7420 6672 6f6d 2074 6865 2074 656e 736f  t from the tenso
-00005aa0: 722e 7369 7a65 2069 6e20 4d69 6e64 5370  r.size in MindSp
-00005ab0: 6f72 652e 0a20 2020 2020 2020 2022 2222  ore..        """
-00005ac0: 0a20 2020 2020 2020 2069 6620 6469 6d20  .        if dim 
-00005ad0: 6973 204e 6f6e 653a 0a20 2020 2020 2020  is None:.       
-00005ae0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00005af0: 2e73 6861 7065 0a20 2020 2020 2020 2072  .shape.        r
-00005b00: 6574 7572 6e20 7365 6c66 2e73 6861 7065  eturn self.shape
-00005b10: 5b64 696d 5d0a 0a20 2020 2064 6566 2075  [dim]..    def u
-00005b20: 6e69 666f 726d 5f61 6461 7074 6572 2873  niform_adapter(s
-00005b30: 656c 662c 2066 726f 6d5f 616c 6961 733d  elf, from_alias=
-00005b40: 302c 2074 6f3d 3129 3a20 2023 544f 444f  0, to=1):  #TODO
-00005b50: 3a20 6672 6f6d 5f61 6c69 6173 2d3e 6672  : from_alias->fr
-00005b60: 6f6d 0a20 2020 2020 2020 2066 726f 6d5f  om.        from_
-00005b70: 616c 6961 7320 3d20 6d73 2e54 656e 736f  alias = ms.Tenso
-00005b80: 7228 6672 6f6d 5f61 6c69 6173 2c20 6d73  r(from_alias, ms
-00005b90: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
-00005ba0: 2020 746f 203d 206d 732e 5465 6e73 6f72    to = ms.Tensor
-00005bb0: 2874 6f2c 206d 732e 666c 6f61 7433 3229  (to, ms.float32)
-00005bc0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00005bd0: 3d20 6d73 2e6f 7073 2e75 6e69 666f 726d  = ms.ops.uniform
-00005be0: 2873 656c 662e 7368 6170 652c 2066 726f  (self.shape, fro
-00005bf0: 6d5f 616c 6961 732c 2074 6f29 2e61 7374  m_alias, to).ast
-00005c00: 7970 6528 7365 6c66 2e64 7479 7065 290a  ype(self.dtype).
-00005c10: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-00005c20: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00005c30: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
-00005c40: 2020 2064 6566 2075 6e69 666f 726d 5f28     def uniform_(
-00005c50: 7365 6c66 2c20 6672 6f6d 5f61 6c69 6173  self, from_alias
-00005c60: 3d30 2c20 746f 3d31 293a 0a20 2020 2020  =0, to=1):.     
-00005c70: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-00005c80: 2e75 6e69 666f 726d 5f61 6461 7074 6572  .uniform_adapter
-00005c90: 2866 726f 6d5f 616c 6961 732c 2074 6f29  (from_alias, to)
-00005ca0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00005cb0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-00005cc0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-00005cd0: 7075 742c 2022 756e 6966 6f72 6d5f 222c  put, "uniform_",
-00005ce0: 2022 756e 6966 6f72 6d5f 6164 6170 7465   "uniform_adapte
-00005cf0: 7222 290a 0a20 2020 2064 6566 2072 616e  r")..    def ran
-00005d00: 646f 6d5f 6164 6170 7465 7228 7365 6c66  dom_adapter(self
-00005d10: 2c20 6672 6f6d 5f61 6c69 6173 3d30 2c20  , from_alias=0, 
-00005d20: 746f 3d4e 6f6e 652c 202a 2c20 6765 6e65  to=None, *, gene
-00005d30: 7261 746f 723d 4e6f 6e65 293a 2020 2354  rator=None):  #T
-00005d40: 4f44 4f3a 2066 726f 6d5f 616c 6961 732d  ODO: from_alias-
-00005d50: 3e66 726f 6d0a 2020 2020 2020 2020 756e  >from.        un
-00005d60: 7375 7070 6f72 7465 645f 6174 7472 2867  supported_attr(g
-00005d70: 656e 6572 6174 6f72 290a 2020 2020 2020  enerator).      
-00005d80: 2020 6966 2067 656e 6572 6174 6f72 3a0a    if generator:.
-00005d90: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00005da0: 6520 4e6f 7449 6d70 6c65 6d65 6e74 6564  e NotImplemented
-00005db0: 4572 726f 7228 2267 656e 6572 6174 6f72  Error("generator
-00005dc0: 2069 7320 6e6f 7420 7375 7070 6f72 7465   is not supporte
-00005dd0: 642e 2229 0a0a 2020 2020 2020 2020 7365  d.")..        se
-00005de0: 6c66 5f64 7479 7065 203d 2073 656c 662e  lf_dtype = self.
-00005df0: 6474 7970 650a 0a20 2020 2020 2020 2069  dtype..        i
-00005e00: 6620 6e6f 7420 746f 3a0a 2020 2020 2020  f not to:.      
-00005e10: 2020 2020 2020 6966 2073 656c 665f 6474        if self_dt
-00005e20: 7970 6520 3d3d 206d 732e 666c 6f61 7436  ype == ms.float6
-00005e30: 343a 0a20 2020 2020 2020 2020 2020 2020  4:.             
-00005e40: 2020 2072 6574 7572 6e20 7365 6c66 2e75     return self.u
-00005e50: 6e69 666f 726d 5f61 6461 7074 6572 2866  niform_adapter(f
-00005e60: 726f 6d5f 616c 6961 732c 206b 4d61 6e74  rom_alias, kMant
-00005e70: 6973 7361 466c 6f61 7436 3429 0a20 2020  issaFloat64).   
-00005e80: 2020 2020 2020 2020 2065 6c69 6620 7365           elif se
-00005e90: 6c66 5f64 7479 7065 203d 3d20 6d73 2e66  lf_dtype == ms.f
-00005ea0: 6c6f 6174 3332 3a0a 2020 2020 2020 2020  loat32:.        
-00005eb0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00005ec0: 656c 662e 756e 6966 6f72 6d5f 6164 6170  elf.uniform_adap
-00005ed0: 7465 7228 6672 6f6d 5f61 6c69 6173 2c20  ter(from_alias, 
-00005ee0: 6b4d 616e 7469 7373 6146 6c6f 6174 3332  kMantissaFloat32
-00005ef0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-00005f00: 6966 2073 656c 665f 6474 7970 6520 3d3d  if self_dtype ==
-00005f10: 206d 732e 666c 6f61 7431 363a 0a20 2020   ms.float16:.   
-00005f20: 2020 2020 2020 2020 2020 2020 2072 6574               ret
-00005f30: 7572 6e20 7365 6c66 2e75 6e69 666f 726d  urn self.uniform
-00005f40: 5f61 6461 7074 6572 2866 726f 6d5f 616c  _adapter(from_al
-00005f50: 6961 732c 206b 4d61 6e74 6973 7361 466c  ias, kMantissaFl
-00005f60: 6f61 7431 3629 0a20 2020 2020 2020 2020  oat16).         
-00005f70: 2020 2065 6c69 6620 7365 6c66 5f64 7479     elif self_dty
-00005f80: 7065 203d 3d20 6d73 2e75 696e 7438 3a0a  pe == ms.uint8:.
-00005f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005fa0: 7265 7475 726e 2073 656c 662e 756e 6966  return self.unif
-00005fb0: 6f72 6d5f 6164 6170 7465 7228 6672 6f6d  orm_adapter(from
-00005fc0: 5f61 6c69 6173 2c20 6b4d 6178 5569 6e74  _alias, kMaxUint
-00005fd0: 3829 0a20 2020 2020 2020 2020 2020 2065  8).            e
-00005fe0: 6c69 6620 7365 6c66 5f64 7479 7065 203d  lif self_dtype =
-00005ff0: 3d20 6d73 2e69 6e74 3634 3a0a 2020 2020  = ms.int64:.    
-00006000: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00006010: 726e 2073 656c 662e 756e 6966 6f72 6d5f  rn self.uniform_
-00006020: 6164 6170 7465 7228 6672 6f6d 5f61 6c69  adapter(from_ali
-00006030: 6173 2c20 6b4d 6178 496e 7436 3429 0a20  as, kMaxInt64). 
-00006040: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-00006050: 7365 6c66 5f64 7479 7065 203d 3d20 6d73  self_dtype == ms
-00006060: 2e69 6e74 3332 3a0a 2020 2020 2020 2020  .int32:.        
-00006070: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00006080: 656c 662e 756e 6966 6f72 6d5f 6164 6170  elf.uniform_adap
-00006090: 7465 7228 6672 6f6d 5f61 6c69 6173 2c20  ter(from_alias, 
-000060a0: 6b4d 6178 496e 7433 3229 0a20 2020 2020  kMaxInt32).     
-000060b0: 2020 2020 2020 2065 6c69 6620 7365 6c66         elif self
-000060c0: 5f64 7479 7065 203d 3d20 6d73 2e69 6e74  _dtype == ms.int
-000060d0: 3136 3a0a 2020 2020 2020 2020 2020 2020  16:.            
-000060e0: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-000060f0: 756e 6966 6f72 6d5f 6164 6170 7465 7228  uniform_adapter(
-00006100: 6672 6f6d 5f61 6c69 6173 2c20 6b4d 6178  from_alias, kMax
-00006110: 496e 7431 3629 0a20 2020 2020 2020 2020  Int16).         
-00006120: 2020 2065 6c69 6620 7365 6c66 5f64 7479     elif self_dty
-00006130: 7065 203d 3d20 6d73 2e69 6e74 383a 0a20  pe == ms.int8:. 
-00006140: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-00006150: 6574 7572 6e20 7365 6c66 2e75 6e69 666f  eturn self.unifo
-00006160: 726d 5f61 6461 7074 6572 2866 726f 6d5f  rm_adapter(from_
-00006170: 616c 6961 732c 206b 4d61 7849 6e74 3829  alias, kMaxInt8)
-00006180: 0a20 2020 2020 2020 2074 6f20 3d20 746f  .        to = to
-00006190: 202d 2031 2069 6620 746f 203e 2031 2065   - 1 if to > 1 e
-000061a0: 6c73 6520 746f 0a20 2020 2020 2020 2072  lse to.        r
-000061b0: 6574 7572 6e20 7365 6c66 2e75 6e69 666f  eturn self.unifo
-000061c0: 726d 5f61 6461 7074 6572 2866 726f 6d5f  rm_adapter(from_
-000061d0: 616c 6961 732c 2074 6f29 0a0a 2020 2020  alias, to)..    
-000061e0: 6465 6620 7261 6e64 6f6d 5f28 7365 6c66  def random_(self
-000061f0: 2c20 6672 6f6d 5f61 6c69 6173 3d30 2c20  , from_alias=0, 
-00006200: 746f 3d4e 6f6e 652c 202a 2c20 6765 6e65  to=None, *, gene
-00006210: 7261 746f 723d 4e6f 6e65 293a 2020 2354  rator=None):  #T
-00006220: 4f44 4f3a 2066 726f 6d5f 616c 6961 732d  ODO: from_alias-
-00006230: 3e66 726f 6d0a 2020 2020 2020 2020 6f75  >from.        ou
-00006240: 7470 7574 203d 2073 656c 662e 7261 6e64  tput = self.rand
-00006250: 6f6d 5f61 6461 7074 6572 2866 726f 6d5f  om_adapter(from_
-00006260: 616c 6961 732c 2074 6f2c 2067 656e 6572  alias, to, gener
-00006270: 6174 6f72 3d67 656e 6572 6174 6f72 290a  ator=generator).
-00006280: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-00006290: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-000062a0: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-000062b0: 7574 2c20 2272 616e 646f 6d5f 222c 2022  ut, "random_", "
-000062c0: 7261 6e64 6f6d 5f61 6461 7074 6572 2229  random_adapter")
-000062d0: 0a0a 2020 2020 6465 6620 7a65 726f 5f61  ..    def zero_a
-000062e0: 6461 7074 6572 2873 656c 6629 3a0a 2020  dapter(self):.  
-000062f0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-00006300: 732e 6f70 732e 6669 6c6c 2873 656c 662e  s.ops.fill(self.
-00006310: 6474 7970 652c 2073 656c 662e 7368 6170  dtype, self.shap
-00006320: 652c 2030 2e30 290a 2020 2020 2020 2020  e, 0.0).        
-00006330: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00006340: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00006350: 7470 7574 290a 0a20 2020 2064 6566 207a  tput)..    def z
-00006360: 6572 6f5f 2873 656c 6629 3a0a 2020 2020  ero_(self):.    
-00006370: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-00006380: 662e 7a65 726f 5f61 6461 7074 6572 2829  f.zero_adapter()
-00006390: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000063a0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-000063b0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-000063c0: 7075 742c 2022 7a65 726f 5f22 2c20 227a  put, "zero_", "z
-000063d0: 6572 6f5f 6164 6170 7465 7222 290a 0a20  ero_adapter").. 
-000063e0: 2020 2023 544f 444f 3a20 6164 6170 7465     #TODO: adapte
-000063f0: 7220 6e65 6564 7320 746f 2073 7570 706f  r needs to suppo
-00006400: 7274 2062 6f74 6820 706f 7369 7469 6f6e  rt both position
-00006410: 616c 2061 6e64 206b 6579 776f 7264 7320  al and keywords 
-00006420: 696e 7075 7420 7369 7a65 2074 6f20 6265  input size to be
-00006430: 2063 6f6e 7369 7374 656e 7420 7769 7468   consistent with
-00006440: 2070 7974 6f72 6368 0a20 2020 2023 706f   pytorch.    #po
-00006450: 7369 7469 6f6e 616c 5f73 697a 6520 7265  sitional_size re
-00006460: 7072 6573 656e 7473 2074 6865 2070 6f73  presents the pos
-00006470: 6974 696f 6e61 6c20 6172 6775 6d65 6e74  itional argument
-00006480: 7320 6f66 2073 697a 652c 2073 697a 6520  s of size, size 
-00006490: 7265 7072 6573 656e 7473 2074 6865 206b  represents the k
-000064a0: 6579 776f 7264 7320 6172 6775 6d65 6e74  eywords argument
-000064b0: 7320 696e 7075 740a 2020 2020 6465 6620  s input.    def 
-000064c0: 6e65 775f 7a65 726f 7328 7365 6c66 2c20  new_zeros(self, 
-000064d0: 2a70 6f73 6974 696f 6e61 6c5f 7369 7a65  *positional_size
-000064e0: 2c20 7369 7a65 3d4e 6f6e 652c 2064 7479  , size=None, dty
-000064f0: 7065 3d4e 6f6e 652c 2064 6576 6963 653d  pe=None, device=
-00006500: 4e6f 6e65 2c20 7265 7175 6972 6573 5f67  None, requires_g
-00006510: 7261 643d 4661 6c73 6529 3a0a 2020 2020  rad=False):.    
-00006520: 2020 2020 756e 7375 7070 6f72 7465 645f      unsupported_
-00006530: 6174 7472 2864 6576 6963 6529 0a20 2020  attr(device).   
-00006540: 2020 2020 2075 6e73 7570 706f 7274 6564       unsupported
-00006550: 5f61 7474 7228 7265 7175 6972 6573 5f67  _attr(requires_g
-00006560: 7261 6429 0a0a 2020 2020 2020 2020 6966  rad)..        if
-00006570: 206e 6f74 2064 7479 7065 3a0a 2020 2020   not dtype:.    
-00006580: 2020 2020 2020 2020 6474 7970 6520 3d20          dtype = 
-00006590: 7365 6c66 2e64 7479 7065 0a20 2020 2020  self.dtype.     
-000065a0: 2020 2069 6620 7369 7a65 2069 7320 4e6f     if size is No
-000065b0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-000065c0: 6966 2069 7369 6e73 7461 6e63 6528 706f  if isinstance(po
-000065d0: 7369 7469 6f6e 616c 5f73 697a 655b 305d  sitional_size[0]
-000065e0: 2c20 2874 7570 6c65 2c20 6c69 7374 2929  , (tuple, list))
-000065f0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00006600: 2020 7369 7a65 203d 2070 6f73 6974 696f    size = positio
-00006610: 6e61 6c5f 7369 7a65 5b30 5d0a 2020 2020  nal_size[0].    
-00006620: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00006630: 2020 2020 2020 2020 2020 2020 2020 7369                si
-00006640: 7a65 203d 2070 6f73 6974 696f 6e61 6c5f  ze = positional_
-00006650: 7369 7a65 0a20 2020 2020 2020 2069 6620  size.        if 
-00006660: 6973 696e 7374 616e 6365 2873 697a 655b  isinstance(size[
-00006670: 305d 2c20 7475 706c 6529 3a0a 2020 2020  0], tuple):.    
-00006680: 2020 2020 2020 2020 7369 7a65 203d 2073          size = s
-00006690: 697a 655b 305d 0a0a 2020 2020 2020 2020  ize[0]..        
-000066a0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-000066b0: 6669 6c6c 2864 7479 7065 2c20 7369 7a65  fill(dtype, size
-000066c0: 2c20 302e 3029 0a20 2020 2020 2020 2072  , 0.0).        r
-000066d0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-000066e0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-000066f0: 7075 7429 0a0a 2020 2020 6465 6620 6e65  put)..    def ne
-00006700: 775f 6675 6c6c 2873 656c 662c 2073 697a  w_full(self, siz
-00006710: 652c 2066 696c 6c5f 7661 6c75 652c 202a  e, fill_value, *
-00006720: 2c20 6474 7970 653d 4e6f 6e65 2c20 6465  , dtype=None, de
-00006730: 7669 6365 3d4e 6f6e 652c 2072 6571 7569  vice=None, requi
-00006740: 7265 735f 6772 6164 3d46 616c 7365 2c0a  res_grad=False,.
-00006750: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006760: 206c 6179 6f75 743d 4e6f 6e65 2c20 7069   layout=None, pi
-00006770: 6e5f 6d65 6d6f 7279 3d46 616c 7365 293a  n_memory=False):
-00006780: 0a20 2020 2020 2020 2075 6e73 7570 706f  .        unsuppo
-00006790: 7274 6564 5f61 7474 7228 6465 7669 6365  rted_attr(device
-000067a0: 290a 2020 2020 2020 2020 756e 7375 7070  ).        unsupp
-000067b0: 6f72 7465 645f 6174 7472 2872 6571 7569  orted_attr(requi
-000067c0: 7265 735f 6772 6164 290a 2020 2020 2020  res_grad).      
-000067d0: 2020 756e 7375 7070 6f72 7465 645f 6174    unsupported_at
-000067e0: 7472 286c 6179 6f75 7429 0a20 2020 2020  tr(layout).     
-000067f0: 2020 2069 6620 6c61 796f 7574 3a0a 2020     if layout:.  
-00006800: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00006810: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
-00006820: 726f 7228 226c 6179 6f75 7420 6973 206e  ror("layout is n
-00006830: 6f74 2073 7570 706f 7274 6564 2e22 290a  ot supported.").
-00006840: 2020 2020 2020 2020 756e 7375 7070 6f72          unsuppor
-00006850: 7465 645f 6174 7472 2870 696e 5f6d 656d  ted_attr(pin_mem
-00006860: 6f72 7929 0a20 2020 2020 2020 2069 6620  ory).        if 
-00006870: 7069 6e5f 6d65 6d6f 7279 2069 7320 5472  pin_memory is Tr
-00006880: 7565 3a0a 2020 2020 2020 2020 2020 2020  ue:.            
-00006890: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
-000068a0: 6e74 6564 4572 726f 7228 2270 696e 5f6d  ntedError("pin_m
-000068b0: 656d 6f72 7920 6973 206e 6f74 2073 7570  emory is not sup
-000068c0: 706f 7274 6564 2074 6f20 5472 7565 2e22  ported to True."
-000068d0: 290a 0a20 2020 2020 2020 2069 6620 6e6f  )..        if no
-000068e0: 7420 6474 7970 653a 0a20 2020 2020 2020  t dtype:.       
-000068f0: 2020 2020 2064 7479 7065 203d 2073 656c       dtype = sel
-00006900: 662e 6474 7970 650a 0a20 2020 2020 2020  f.dtype..       
-00006910: 2073 697a 6520 3d20 5f63 6865 636b 5f69   size = _check_i
-00006920: 6e74 5f73 697a 6528 7369 7a65 2c20 226e  nt_size(size, "n
-00006930: 6577 5f66 756c 6c22 290a 2020 2020 2020  ew_full").      
-00006940: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-00006950: 732e 6669 6c6c 2864 7479 7065 2c20 7369  s.fill(dtype, si
-00006960: 7a65 2c20 6669 6c6c 5f76 616c 7565 290a  ze, fill_value).
-00006970: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-00006980: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00006990: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
-000069a0: 2020 2064 6566 2061 6464 2873 656c 662c     def add(self,
-000069b0: 206f 7468 6572 2c20 2a2c 2061 6c70 6861   other, *, alpha
-000069c0: 3d31 293a 0a20 2020 2020 2020 2023 2054  =1):.        # T
-000069d0: 4f44 4f3a 206d 732e 6f70 732e 6164 6420  ODO: ms.ops.add 
-000069e0: 7768 656e 2061 6464 2062 6f74 6820 626f  when add both bo
-000069f0: 6f6c 2054 656e 736f 722c 2072 6574 7572  ol Tensor, retur
-00006a00: 6e20 696e 7420 7465 6e73 6f72 2069 6e73  n int tensor ins
-00006a10: 7465 6164 206f 6620 626f 6f6c 2074 656e  tead of bool ten
-00006a20: 736f 722e 0a20 2020 2020 2020 2069 6e70  sor..        inp
-00006a30: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-00006a40: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00006a50: 2020 2020 2020 2020 6f74 6865 7220 3d20          other = 
-00006a60: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00006a70: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
-00006a80: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-00006a90: 2e61 6464 2869 6e70 7574 5f6d 732c 206f  .add(input_ms, o
-00006aa0: 7468 6572 2a61 6c70 6861 290a 2020 2020  ther*alpha).    
-00006ab0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00006ac0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00006ad0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00006ae0: 6566 2061 6464 5f28 7365 6c66 2c20 6f74  ef add_(self, ot
-00006af0: 6865 722c 202a 2c20 616c 7068 613d 3129  her, *, alpha=1)
-00006b00: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-00006b10: 203d 2073 656c 662e 6164 6428 6f74 6865   = self.add(othe
-00006b20: 722c 2061 6c70 6861 3d61 6c70 6861 290a  r, alpha=alpha).
-00006b30: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-00006b40: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-00006b50: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-00006b60: 7574 2c20 2261 6464 5f22 2c20 2261 6464  ut, "add_", "add
-00006b70: 2229 0a0a 2020 2020 6465 6620 6572 6669  ")..    def erfi
-00006b80: 6e76 2873 656c 6629 3a0a 2020 2020 2020  nv(self):.      
-00006b90: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
-00006ba0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-00006bb0: 656c 6629 0a20 2020 2020 2020 206f 7574  elf).        out
-00006bc0: 7075 7420 3d20 6d73 2e6f 7073 2e65 7266  put = ms.ops.erf
-00006bd0: 696e 7628 696e 7075 745f 6d73 290a 2020  inv(input_ms).  
-00006be0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00006bf0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00006c00: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-00006c10: 2064 6566 2065 7266 696e 765f 2873 656c   def erfinv_(sel
-00006c20: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
-00006c30: 7574 203d 2073 656c 662e 6572 6669 6e76  ut = self.erfinv
-00006c40: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
-00006c50: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-00006c60: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-00006c70: 7574 7075 742c 2022 6572 6669 6e76 5f22  utput, "erfinv_"
-00006c80: 2c20 2265 7266 696e 7622 290a 0a20 2020  , "erfinv")..   
-00006c90: 2064 6566 2070 6572 6d75 7465 2873 656c   def permute(sel
-00006ca0: 662c 202a 6469 6d73 293a 0a20 2020 2020  f, *dims):.     
-00006cb0: 2020 206d 735f 696e 7075 7420 3d20 6361     ms_input = ca
-00006cc0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00006cd0: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
-00006ce0: 7470 7574 203d 206d 735f 696e 7075 742e  tput = ms_input.
-00006cf0: 7472 616e 7370 6f73 6528 2a64 696d 7329  transpose(*dims)
-00006d00: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00006d10: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00006d20: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00006d30: 2020 2020 6465 6620 636f 6e74 6967 756f      def contiguo
-00006d40: 7573 2873 656c 662c 206d 656d 6f72 795f  us(self, memory_
-00006d50: 666f 726d 6174 3d4e 6f6e 6529 3a0a 2020  format=None):.  
-00006d60: 2020 2020 2020 2354 4f44 4f0a 2020 2020        #TODO.    
-00006d70: 2020 2020 756e 7375 7070 6f72 7465 645f      unsupported_
-00006d80: 6174 7472 286d 656d 6f72 795f 666f 726d  attr(memory_form
-00006d90: 6174 290a 2020 2020 2020 2020 7265 7475  at).        retu
-00006da0: 726e 2073 656c 660a 0a20 2020 2064 6566  rn self..    def
-00006db0: 206e 6577 5f74 656e 736f 7228 7365 6c66   new_tensor(self
-00006dc0: 2c20 6461 7461 2c20 2a2c 2064 7479 7065  , data, *, dtype
-00006dd0: 3d4e 6f6e 652c 2064 6576 6963 653d 4e6f  =None, device=No
-00006de0: 6e65 2c20 7265 7175 6972 6573 5f67 7261  ne, requires_gra
-00006df0: 643d 4661 6c73 652c 206c 6179 6f75 743d  d=False, layout=
-00006e00: 4e6f 6e65 2c20 7069 6e5f 6d65 6d6f 7279  None, pin_memory
-00006e10: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
-00006e20: 2075 6e73 7570 706f 7274 6564 5f61 7474   unsupported_att
-00006e30: 7228 6c61 796f 7574 290a 2020 2020 2020  r(layout).      
-00006e40: 2020 756e 7375 7070 6f72 7465 645f 6174    unsupported_at
-00006e50: 7472 2870 696e 5f6d 656d 6f72 7929 0a20  tr(pin_memory). 
-00006e60: 2020 2020 2020 2069 6620 6e6f 7420 6474         if not dt
-00006e70: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
-00006e80: 2064 7479 7065 203d 2073 656c 662e 6474   dtype = self.dt
-00006e90: 7970 650a 0a20 2020 2020 2020 2069 6620  ype..        if 
-00006ea0: 6973 696e 7374 616e 6365 2864 6174 612c  isinstance(data,
-00006eb0: 2054 656e 736f 7229 3a0a 2020 2020 2020   Tensor):.      
-00006ec0: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
-00006ed0: 6545 7272 6f72 2822 546f 2063 6f70 7920  eError("To copy 
-00006ee0: 636f 6e73 7472 7563 7420 6672 6f6d 2061  construct from a
-00006ef0: 2074 656e 736f 722c 2069 7420 6973 2072   tensor, it is r
-00006f00: 6563 6f6d 6d65 6e64 6564 2074 6f20 7573  ecommended to us
-00006f10: 6520 736f 7572 6365 5465 6e73 6f72 2e63  e sourceTensor.c
-00006f20: 6c6f 6e65 2829 2e64 6574 6163 6828 2920  lone().detach() 
-00006f30: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00006f40: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00006f50: 6f72 2073 6f75 7263 6554 656e 736f 722e  or sourceTensor.
-00006f60: 636c 6f6e 6528 292e 6465 7461 6368 2829  clone().detach()
-00006f70: 2e72 6571 7569 7265 735f 6772 6164 5f28  .requires_grad_(
-00006f80: 5472 7565 292c 2022 0a20 2020 2020 2020  True), ".       
-00006f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006fa0: 2020 2020 2020 2272 6174 6865 7220 7468        "rather th
-00006fb0: 616e 2074 656e 736f 722e 6e65 775f 7465  an tensor.new_te
-00006fc0: 6e73 6f72 2873 6f75 7263 6554 656e 736f  nsor(sourceTenso
-00006fd0: 7229 2e22 290a 2020 2020 2020 2020 7265  r).").        re
-00006fe0: 7475 726e 2074 656e 736f 7228 6461 7461  turn tensor(data
-00006ff0: 2c20 6474 7970 652c 2064 6576 6963 652c  , dtype, device,
-00007000: 2072 6571 7569 7265 735f 6772 6164 290a   requires_grad).
-00007010: 0a20 2020 2064 6566 2063 6f70 795f 6164  .    def copy_ad
-00007020: 6170 7465 7228 7365 6c66 2c20 7372 632c  apter(self, src,
-00007030: 206e 6f6e 5f62 6c6f 636b 696e 673d 4661   non_blocking=Fa
-00007040: 6c73 6529 3a0a 2020 2020 2020 2020 756e  lse):.        un
-00007050: 7375 7070 6f72 7465 645f 6174 7472 286e  supported_attr(n
-00007060: 6f6e 5f62 6c6f 636b 696e 6729 0a20 2020  on_blocking).   
-00007070: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00007080: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00007090: 7228 7372 6329 0a20 2020 2020 2020 2069  r(src).        i
-000070a0: 6620 6c65 6e28 7365 6c66 2e73 6861 7065  f len(self.shape
-000070b0: 2920 3e20 3020 616e 6420 696e 7075 745f  ) > 0 and input_
-000070c0: 6d73 2021 3d20 7365 6c66 2e73 6861 7065  ms != self.shape
-000070d0: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
-000070e0: 7470 7574 203d 206d 732e 6f70 732e 6272  tput = ms.ops.br
-000070f0: 6f61 6463 6173 745f 746f 2869 6e70 7574  oadcast_to(input
-00007100: 5f6d 732c 2073 656c 662e 7368 6170 6529  _ms, self.shape)
-00007110: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00007120: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-00007130: 7420 3d20 696e 7075 745f 6d73 0a20 2020  t = input_ms.   
-00007140: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
-00007150: 7470 7574 2e61 7374 7970 6528 7365 6c66  tput.astype(self
-00007160: 2e64 7479 7065 290a 2020 2020 2020 2020  .dtype).        
-00007170: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00007180: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00007190: 7470 7574 290a 0a20 2020 2064 6566 2063  tput)..    def c
-000071a0: 6f70 795f 2873 656c 662c 2073 7263 2c20  opy_(self, src, 
-000071b0: 6e6f 6e5f 626c 6f63 6b69 6e67 3d46 616c  non_blocking=Fal
-000071c0: 7365 293a 0a20 2020 2020 2020 2075 6e73  se):.        uns
-000071d0: 7570 706f 7274 6564 5f61 7474 7228 6e6f  upported_attr(no
-000071e0: 6e5f 626c 6f63 6b69 6e67 290a 2020 2020  n_blocking).    
-000071f0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-00007200: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00007210: 2873 7263 290a 2020 2020 2020 2020 6966  (src).        if
-00007220: 206c 656e 2873 656c 662e 7368 6170 6529   len(self.shape)
-00007230: 203e 2030 2061 6e64 2069 6e70 7574 5f6d   > 0 and input_m
-00007240: 7320 213d 2073 656c 662e 7368 6170 653a  s != self.shape:
-00007250: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00007260: 7075 7420 3d20 6d73 2e6f 7073 2e62 726f  put = ms.ops.bro
-00007270: 6164 6361 7374 5f74 6f28 696e 7075 745f  adcast_to(input_
-00007280: 6d73 2c20 7365 6c66 2e73 6861 7065 290a  ms, self.shape).
-00007290: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-000072a0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-000072b0: 203d 2069 6e70 7574 5f6d 730a 2020 2020   = input_ms.    
-000072c0: 2020 2020 6f75 7470 7574 203d 206f 7574      output = out
-000072d0: 7075 742e 6173 7479 7065 2873 656c 662e  put.astype(self.
-000072e0: 6474 7970 6529 0a20 2020 2020 2020 2072  dtype).        r
-000072f0: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
-00007300: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
-00007310: 662c 206f 7574 7075 742c 2022 636f 7079  f, output, "copy
-00007320: 5f22 2c20 2263 6f70 795f 6164 6170 7465  _", "copy_adapte
-00007330: 7222 290a 0a20 2020 2064 6566 2065 7870  r")..    def exp
-00007340: 616e 6428 7365 6c66 2c20 2a73 697a 6529  and(self, *size)
-00007350: 3a0a 2020 2020 2020 2020 2320 544f 444f  :.        # TODO
-00007360: 3a20 746f 2075 7365 206d 732e 6f70 732e  : to use ms.ops.
-00007370: 6578 7061 6e64 2061 6674 6572 2069 7420  expand after it 
-00007380: 7375 7070 6f72 7420 6f6e 2067 7075 2e20  support on gpu. 
-00007390: 416e 6420 6d73 2e6f 7073 2e65 7870 616e  And ms.ops.expan
-000073a0: 6420 7375 7070 6f72 7420 746f 6f20 6665  d support too fe
-000073b0: 7720 6461 7461 2074 7970 6520 6e6f 770a  w data type now.
-000073c0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-000073d0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-000073e0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-000073f0: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
-00007400: 2873 697a 655b 305d 2c20 286c 6973 742c  (size[0], (list,
-00007410: 2074 7570 6c65 2929 3a0a 2020 2020 2020   tuple)):.      
-00007420: 2020 2020 2020 7369 7a65 203d 2073 697a        size = siz
-00007430: 655b 305d 0a20 2020 2020 2020 2069 6620  e[0].        if 
-00007440: 6973 696e 7374 616e 6365 2873 697a 652c  isinstance(size,
-00007450: 206c 6973 7429 3a0a 2020 2020 2020 2020   list):.        
-00007460: 2020 2020 7369 7a65 203d 2074 7570 6c65      size = tuple
-00007470: 2873 697a 6529 0a20 2020 2020 2020 206f  (size).        o
-00007480: 7574 203d 206d 732e 6f70 732e 6272 6f61  ut = ms.ops.broa
-00007490: 6463 6173 745f 746f 2869 6e70 7574 5f6d  dcast_to(input_m
-000074a0: 732c 2073 697a 6529 0a20 2020 2020 2020  s, size).       
-000074b0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-000074c0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-000074d0: 7574 290a 0a20 2020 2064 6566 2073 6967  ut)..    def sig
-000074e0: 6d6f 6964 2873 656c 6629 3a0a 2020 2020  moid(self):.    
-000074f0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-00007500: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00007510: 2873 656c 6629 0a20 2020 2020 2020 2023  (self).        #
-00007520: 2054 4f44 4f3a 206d 732e 6f70 732e 7369   TODO: ms.ops.si
-00007530: 676d 6f69 6420 6e6f 7420 7375 7070 6f72  gmoid not suppor
-00007540: 7420 666c 6f61 7436 3420 6f6e 2041 7363  t float64 on Asc
-00007550: 656e 640a 2020 2020 2020 2020 6966 2069  end.        if i
-00007560: 735f 756e 6465 725f 6173 6365 6e64 5f63  s_under_ascend_c
-00007570: 6f6e 7465 7874 2829 2061 6e64 2069 6e70  ontext() and inp
-00007580: 7574 5f6d 732e 6474 7970 6520 3d3d 206d  ut_ms.dtype == m
-00007590: 732e 666c 6f61 7436 343a 0a20 2020 2020  s.float64:.     
-000075a0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-000075b0: 3d20 696e 7075 745f 6d73 2e61 7374 7970  = input_ms.astyp
-000075c0: 6528 6d73 2e66 6c6f 6174 3332 290a 2020  e(ms.float32).  
-000075d0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-000075e0: 203d 206d 732e 6f70 732e 7369 676d 6f69   = ms.ops.sigmoi
-000075f0: 6428 696e 7075 745f 6d73 290a 2020 2020  d(input_ms).    
-00007600: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00007610: 206f 7574 7075 742e 6173 7479 7065 286d   output.astype(m
-00007620: 732e 666c 6f61 7436 3429 0a20 2020 2020  s.float64).     
-00007630: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00007640: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00007650: 2e6f 7073 2e73 6967 6d6f 6964 2869 6e70  .ops.sigmoid(inp
-00007660: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
-00007670: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00007680: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00007690: 7075 7429 0a0a 2020 2020 6465 6620 7369  put)..    def si
-000076a0: 676d 6f69 645f 2873 656c 6629 3a0a 2020  gmoid_(self):.  
-000076b0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-000076c0: 656c 662e 7369 676d 6f69 6428 290a 2020  elf.sigmoid().  
-000076d0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-000076e0: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-000076f0: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-00007700: 2c20 2273 6967 6d6f 6964 5f22 2c20 2273  , "sigmoid_", "s
-00007710: 6967 6d6f 6964 2229 0a0a 2020 2020 6465  igmoid")..    de
-00007720: 6620 666c 6f61 7428 7365 6c66 2c20 6d65  f float(self, me
-00007730: 6d6f 7279 5f66 6f72 6d61 743d 4e6f 6e65  mory_format=None
-00007740: 293a 0a20 2020 2020 2020 2069 6620 6d65  ):.        if me
-00007750: 6d6f 7279 5f66 6f72 6d61 743a 0a20 2020  mory_format:.   
-00007760: 2020 2020 2020 2020 2072 6169 7365 204e           raise N
-00007770: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
-00007780: 6f72 2822 6d65 6d6f 7279 5f66 6f72 6d61  or("memory_forma
-00007790: 7420 6973 206e 6f74 2073 7570 706f 7274  t is not support
-000077a0: 6564 2e22 290a 2020 2020 2020 2020 696e  ed.").        in
-000077b0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-000077c0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-000077d0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000077e0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-000077f0: 7465 6e73 6f72 2869 6e70 7574 5f6d 732e  tensor(input_ms.
-00007800: 666c 6f61 7428 2929 0a0a 2020 2020 6465  float())..    de
-00007810: 6620 666c 6970 2873 656c 662c 2064 696d  f flip(self, dim
-00007820: 7329 3a0a 2020 2020 2020 2020 696e 7075  s):.        inpu
-00007830: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00007840: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00007850: 2020 2020 2020 2069 6620 6e6f 7420 6973         if not is
-00007860: 696e 7374 616e 6365 2864 696d 732c 2028  instance(dims, (
-00007870: 6c69 7374 2c20 7475 706c 6529 293a 0a20  list, tuple)):. 
-00007880: 2020 2020 2020 2020 2020 2064 696d 7320             dims 
-00007890: 3d20 2864 696d 732c 290a 2020 2020 2020  = (dims,).      
-000078a0: 2020 6f75 7470 7574 203d 2069 6e70 7574    output = input
-000078b0: 5f6d 732e 666c 6970 2864 696d 7329 0a20  _ms.flip(dims). 
-000078c0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-000078d0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-000078e0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-000078f0: 2020 6465 6620 7369 676e 2873 656c 6629    def sign(self)
-00007900: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-00007910: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00007920: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-00007930: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00007940: 2e6f 7073 2e73 6967 6e28 696e 7075 745f  .ops.sign(input_
-00007950: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-00007960: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00007970: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00007980: 290a 0a20 2020 2064 6566 2073 6967 6e5f  )..    def sign_
-00007990: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-000079a0: 6f75 7470 7574 203d 2073 656c 662e 7369  output = self.si
-000079b0: 676e 2829 0a20 2020 2020 2020 2072 6574  gn().        ret
-000079c0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-000079d0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-000079e0: 206f 7574 7075 742c 2022 7369 676e 5f22   output, "sign_"
-000079f0: 2c20 2273 6967 6e22 290a 0a20 2020 2064  , "sign")..    d
-00007a00: 6566 2073 6967 6e62 6974 2873 656c 6629  ef signbit(self)
-00007a10: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-00007a20: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00007a30: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-00007a40: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00007a50: 2e6f 7073 2e73 6967 6e62 6974 2869 6e70  .ops.signbit(inp
-00007a60: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
-00007a70: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00007a80: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00007a90: 7075 7429 0a0a 2020 2020 6465 6620 7376  put)..    def sv
-00007aa0: 6428 7365 6c66 2c20 736f 6d65 3d54 7275  d(self, some=Tru
-00007ab0: 652c 2063 6f6d 7075 7465 5f75 763d 5472  e, compute_uv=Tr
-00007ac0: 7565 293a 0a20 2020 2020 2020 2069 6e70  ue):.        inp
-00007ad0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-00007ae0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00007af0: 2020 2020 2020 2020 6966 2069 735f 756e          if is_un
-00007b00: 6465 725f 6173 6365 6e64 5f63 6f6e 7465  der_ascend_conte
-00007b10: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
-00007b20: 2020 6675 6c6c 5f6d 6174 7269 6365 7320    full_matrices 
-00007b30: 3d20 6e6f 7420 736f 6d65 0a20 2020 2020  = not some.     
-00007b40: 2020 2020 2020 2073 7664 5f6f 7020 3d20         svd_op = 
-00007b50: 6e75 6d70 795f 6365 6c6c 2e4e 756d 7079  numpy_cell.Numpy
-00007b60: 5376 6428 2773 7664 2729 0a20 2020 2020  Svd('svd').     
-00007b70: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00007b80: 7376 645f 6f70 2869 6e70 7574 5f6d 732c  svd_op(input_ms,
-00007b90: 2066 756c 6c5f 6d61 7472 6963 6573 2c20   full_matrices, 
-00007ba0: 636f 6d70 7574 655f 7576 290a 2020 2020  compute_uv).    
-00007bb0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00007bc0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-00007bd0: 732e 6f70 732e 7376 6428 696e 7075 745f  s.ops.svd(input_
-00007be0: 6d73 2c20 6e6f 7420 736f 6d65 2c20 636f  ms, not some, co
-00007bf0: 6d70 7574 655f 7576 290a 2020 2020 2020  mpute_uv).      
-00007c00: 2020 6966 2063 6f6d 7075 7465 5f75 763a    if compute_uv:
-00007c10: 0a20 2020 2020 2020 2020 2020 2073 2c20  .            s, 
-00007c20: 752c 2076 203d 206f 7574 7075 740a 2020  u, v = output.  
-00007c30: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00007c40: 2020 2020 2020 2020 6966 2073 6f6d 653a          if some:
-00007c50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007c60: 2073 203d 206f 7574 7075 740a 2020 2020   s = output.    
-00007c70: 2020 2020 2020 2020 2020 2020 726f 7720              row 
-00007c80: 3d20 696e 7075 745f 6d73 2e73 6861 7065  = input_ms.shape
-00007c90: 5b30 5d0a 2020 2020 2020 2020 2020 2020  [0].            
-00007ca0: 2020 2020 636f 6c20 3d20 696e 7075 745f      col = input_
-00007cb0: 6d73 2e73 6861 7065 5b31 5d0a 2020 2020  ms.shape[1].    
-00007cc0: 2020 2020 2020 2020 2020 2020 7520 3d20              u = 
-00007cd0: 6d73 2e6f 7073 2e7a 6572 6f73 2828 726f  ms.ops.zeros((ro
-00007ce0: 772c 2072 6f77 292c 2069 6e70 7574 5f6d  w, row), input_m
-00007cf0: 732e 6474 7970 6529 0a20 2020 2020 2020  s.dtype).       
-00007d00: 2020 2020 2020 2020 2076 203d 206d 732e           v = ms.
-00007d10: 6f70 732e 7a65 726f 7328 2863 6f6c 2c20  ops.zeros((col, 
-00007d20: 636f 6c29 2c20 696e 7075 745f 6d73 2e64  col), input_ms.d
-00007d30: 7479 7065 290a 2020 2020 2020 2020 6f75  type).        ou
-00007d40: 7470 7574 203d 2028 752c 2073 2c20 7629  tput = (u, s, v)
-00007d50: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00007d60: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00007d70: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00007d80: 2020 2020 6465 6620 7377 6170 6178 6573      def swapaxes
-00007d90: 2873 656c 662c 2061 7869 7330 2c20 6178  (self, axis0, ax
-00007da0: 6973 3129 3a0a 2020 2020 2020 2020 6966  is1):.        if
-00007db0: 2073 656c 662e 6e65 6c65 6d65 6e74 2829   self.nelement()
-00007dc0: 203d 3d20 303a 0a20 2020 2020 2020 2020   == 0:.         
-00007dd0: 2020 206f 7574 5f73 6861 7065 203d 206c     out_shape = l
-00007de0: 6973 7428 7365 6c66 2e73 6861 7065 290a  ist(self.shape).
-00007df0: 2020 2020 2020 2020 2020 2020 6f75 745f              out_
-00007e00: 7368 6170 655b 6178 6973 305d 2c20 6f75  shape[axis0], ou
-00007e10: 745f 7368 6170 655b 6178 6973 315d 203d  t_shape[axis1] =
-00007e20: 206f 7574 5f73 6861 7065 5b61 7869 7331   out_shape[axis1
-00007e30: 5d2c 206f 7574 5f73 6861 7065 5b61 7869  ], out_shape[axi
-00007e40: 7330 5d0a 2020 2020 2020 2020 2020 2020  s0].            
-00007e50: 7265 7475 726e 2073 656c 662e 7265 7368  return self.resh
-00007e60: 6170 6528 7475 706c 6528 6f75 745f 7368  ape(tuple(out_sh
-00007e70: 6170 6529 290a 2020 2020 2020 2020 696e  ape)).        in
-00007e80: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-00007e90: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00007ea0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00007eb0: 3d20 696e 7075 745f 6d73 2e73 7761 7061  = input_ms.swapa
-00007ec0: 7865 7328 6178 6973 302c 2061 7869 7331  xes(axis0, axis1
-00007ed0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00007ee0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00007ef0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-00007f00: 0a20 2020 2064 6566 2073 7761 7064 696d  .    def swapdim
-00007f10: 7328 7365 6c66 2c20 6469 6d30 2c20 6469  s(self, dim0, di
-00007f20: 6d31 293a 0a20 2020 2020 2020 2069 6e70  m1):.        inp
-00007f30: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-00007f40: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00007f50: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00007f60: 206d 732e 6f70 732e 7377 6170 6469 6d73   ms.ops.swapdims
-00007f70: 2869 6e70 7574 5f6d 732c 2064 696d 302c  (input_ms, dim0,
-00007f80: 2064 696d 3129 0a20 2020 2020 2020 2072   dim1).        r
-00007f90: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00007fa0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00007fb0: 7075 7429 0a0a 2020 2020 6465 6620 7375  put)..    def su
-00007fc0: 6274 7261 6374 2873 656c 662c 206f 7468  btract(self, oth
-00007fd0: 6572 2c20 2a2c 2061 6c70 6861 3d31 293a  er, *, alpha=1):
-00007fe0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-00007ff0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00008000: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00008010: 2020 2020 6f74 6865 7220 3d20 6361 7374      other = cast
-00008020: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
-00008030: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
-00008040: 7075 7420 3d20 6d73 2e6f 7073 2e73 7562  put = ms.ops.sub
-00008050: 7472 6163 7428 696e 7075 745f 6d73 2c20  tract(input_ms, 
-00008060: 6f74 6865 722c 2061 6c70 6861 3d61 6c70  other, alpha=alp
-00008070: 6861 290a 2020 2020 2020 2020 7265 7475  ha).        retu
-00008080: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00008090: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-000080a0: 290a 0a20 2020 2064 6566 2073 7562 7472  )..    def subtr
-000080b0: 6163 745f 2873 656c 662c 206f 7468 6572  act_(self, other
-000080c0: 2c20 2a2c 2061 6c70 6861 3d31 293a 0a20  , *, alpha=1):. 
-000080d0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-000080e0: 7365 6c66 2e73 7562 7472 6163 7428 6f74  self.subtract(ot
-000080f0: 6865 722c 2061 6c70 6861 3d61 6c70 6861  her, alpha=alpha
-00008100: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00008110: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
-00008120: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
-00008130: 7470 7574 2c20 2273 7562 7472 6163 745f  tput, "subtract_
-00008140: 222c 2022 7375 6274 7261 6374 2229 0a0a  ", "subtract")..
-00008150: 2020 2020 6465 6620 7472 6163 6528 7365      def trace(se
-00008160: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
-00008170: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-00008180: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00008190: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-000081a0: 2069 6e70 7574 5f6d 732e 7472 6163 6528   input_ms.trace(
-000081b0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-000081c0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-000081d0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-000081e0: 0a20 2020 2064 6566 2063 6569 6c28 7365  .    def ceil(se
-000081f0: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
-00008200: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-00008210: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00008220: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00008230: 206d 732e 6f70 732e 6365 696c 2869 6e70   ms.ops.ceil(inp
-00008240: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
-00008250: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00008260: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00008270: 7075 7429 0a0a 2020 2020 6465 6620 6365  put)..    def ce
-00008280: 696c 5f28 7365 6c66 293a 0a20 2020 2020  il_(self):.     
-00008290: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-000082a0: 2e63 6569 6c28 290a 2020 2020 2020 2020  .ceil().        
-000082b0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-000082c0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-000082d0: 6c66 2c20 6f75 7470 7574 2c20 2263 6569  lf, output, "cei
-000082e0: 6c5f 222c 2022 6365 696c 2229 0a0a 2020  l_", "ceil")..  
-000082f0: 2020 6465 6620 636f 6e6a 2873 656c 6629    def conj(self)
-00008300: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-00008310: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00008320: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-00008330: 2020 2020 206f 7574 7075 7420 3d20 696e       output = in
-00008340: 7075 745f 6d73 2e63 6f6e 6a28 290a 2020  put_ms.conj().  
-00008350: 2020 2020 2020 6f75 7470 7574 203d 2063        output = c
-00008360: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00008370: 656e 736f 7228 6f75 7470 7574 290a 2020  ensor(output).  
-00008380: 2020 2020 2020 6f75 7470 7574 2e63 6f6e        output.con
-00008390: 6a5f 6269 7420 3d20 5472 7565 0a20 2020  j_bit = True.   
-000083a0: 2020 2020 2072 6574 7572 6e20 6f75 7470       return outp
-000083b0: 7574 0a0a 2020 2020 6465 6620 6973 5f63  ut..    def is_c
-000083c0: 6f6e 6a28 7365 6c66 293a 0a20 2020 2020  onj(self):.     
-000083d0: 2020 2069 6620 6e6f 7420 6861 7361 7474     if not hasatt
-000083e0: 7228 7365 6c66 2c20 2263 6f6e 6a5f 6269  r(self, "conj_bi
-000083f0: 7422 293a 0a20 2020 2020 2020 2020 2020  t"):.           
-00008400: 2072 6574 7572 6e20 4661 6c73 650a 2020   return False.  
-00008410: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00008420: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00008430: 656c 662e 636f 6e6a 5f62 6974 0a0a 2020  elf.conj_bit..  
-00008440: 2020 6465 6620 7265 736f 6c76 655f 636f    def resolve_co
-00008450: 6e6a 2873 656c 6629 3a0a 2020 2020 2020  nj(self):.      
-00008460: 2020 6f75 7470 7574 203d 2064 6565 7063    output = deepc
-00008470: 6f70 7928 7365 6c66 290a 2020 2020 2020  opy(self).      
-00008480: 2020 6f75 7470 7574 2e63 6f6e 6a5f 6269    output.conj_bi
-00008490: 7420 3d20 4661 6c73 650a 2020 2020 2020  t = False.      
-000084a0: 2020 7265 7475 726e 206f 7574 7075 740a    return output.
-000084b0: 0a20 2020 2064 6566 2067 6572 2873 656c  .    def ger(sel
-000084c0: 662c 2076 6563 3229 3a0a 2020 2020 2020  f, vec2):.      
-000084d0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
-000084e0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-000084f0: 656c 6629 0a20 2020 2020 2020 2076 6563  elf).        vec
-00008500: 3220 3d20 6361 7374 5f74 6f5f 6d73 5f74  2 = cast_to_ms_t
-00008510: 656e 736f 7228 7665 6332 290a 2020 2020  ensor(vec2).    
-00008520: 2020 2020 6966 2069 6e70 7574 5f6d 732e      if input_ms.
-00008530: 6474 7970 6520 213d 2076 6563 322e 6474  dtype != vec2.dt
-00008540: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
-00008550: 2072 6169 7365 2054 7970 6545 7272 6f72   raise TypeError
-00008560: 2822 466f 7220 746f 7263 682e 6765 7228  ("For torch.ger(
-00008570: 292c 2069 6e70 7574 5f6d 7320 616e 6420  ), input_ms and 
-00008580: 7665 6332 2064 7479 7065 206d 7573 7420  vec2 dtype must 
-00008590: 6265 2074 6865 2073 616d 6522 290a 2020  be the same").  
-000085a0: 2020 2020 2020 6966 206e 6f74 2069 6e70        if not inp
-000085b0: 7574 5f6d 732e 6973 5f66 6c6f 6174 696e  ut_ms.is_floatin
-000085c0: 675f 706f 696e 7428 293a 0a20 2020 2020  g_point():.     
-000085d0: 2020 2020 2020 205f 6f75 745f 6474 7970         _out_dtyp
-000085e0: 6520 3d20 696e 7075 745f 6d73 2e64 7479  e = input_ms.dty
-000085f0: 7065 0a20 2020 2020 2020 2020 2020 2069  pe.            i
-00008600: 6e70 7574 5f6d 7320 3d20 696e 7075 745f  nput_ms = input_
-00008610: 6d73 2e61 7374 7970 6528 6d73 2e66 6c6f  ms.astype(ms.flo
-00008620: 6174 3332 290a 2020 2020 2020 2020 2020  at32).          
-00008630: 2020 7665 6332 203d 2076 6563 322e 6173    vec2 = vec2.as
-00008640: 7479 7065 286d 732e 666c 6f61 7433 3229  type(ms.float32)
-00008650: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00008660: 7075 7420 3d20 6d73 2e6f 7073 2e67 6572  put = ms.ops.ger
-00008670: 2869 6e70 7574 5f6d 732c 2076 6563 3229  (input_ms, vec2)
-00008680: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00008690: 7075 7420 3d20 6f75 7470 7574 2e61 7374  put = output.ast
-000086a0: 7970 6528 5f6f 7574 5f64 7479 7065 290a  ype(_out_dtype).
-000086b0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-000086c0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-000086d0: 203d 206d 732e 6f70 732e 6765 7228 696e   = ms.ops.ger(in
-000086e0: 7075 745f 6d73 2c20 7665 6332 290a 2020  put_ms, vec2).  
-000086f0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00008700: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00008710: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-00008720: 2064 6566 206d 6f76 6564 696d 2873 656c   def movedim(sel
-00008730: 662c 2073 6f75 7263 652c 2064 6573 7469  f, source, desti
-00008740: 6e61 7469 6f6e 293a 0a20 2020 2020 2020  nation):.       
-00008750: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00008760: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00008770: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
-00008780: 7574 203d 206d 732e 6f70 732e 6d6f 7665  ut = ms.ops.move
-00008790: 6469 6d28 696e 7075 745f 6d73 2c20 736f  dim(input_ms, so
-000087a0: 7572 6365 2c20 6465 7374 696e 6174 696f  urce, destinatio
-000087b0: 6e29 0a20 2020 2020 2020 2072 6574 7572  n).        retur
-000087c0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-000087d0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-000087e0: 0a0a 2020 2020 6465 6620 6d6f 7665 6178  ..    def moveax
-000087f0: 6973 2873 656c 662c 2073 6f75 7263 652c  is(self, source,
-00008800: 2064 6573 7469 6e61 7469 6f6e 293a 0a20   destination):. 
-00008810: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00008820: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00008830: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00008840: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-00008850: 732e 6d6f 7665 6178 6973 2869 6e70 7574  s.moveaxis(input
-00008860: 5f6d 732c 2073 6f75 7263 652c 2064 6573  _ms, source, des
-00008870: 7469 6e61 7469 6f6e 290a 2020 2020 2020  tination).      
-00008880: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00008890: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-000088a0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-000088b0: 206d 756c 2873 656c 662c 2076 616c 7565   mul(self, value
-000088c0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-000088d0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-000088e0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-000088f0: 2020 2020 2020 6d73 5f76 616c 7565 203d        ms_value =
-00008900: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00008910: 6f72 2876 616c 7565 290a 2020 2020 2020  or(value).      
-00008920: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-00008930: 732e 6d75 6c28 696e 7075 745f 6d73 2c20  s.mul(input_ms, 
-00008940: 6d73 5f76 616c 7565 290a 2020 2020 2020  ms_value).      
-00008950: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00008960: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00008970: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00008980: 206d 756c 5f28 7365 6c66 2c20 7661 6c75   mul_(self, valu
-00008990: 6529 3a0a 2020 2020 2020 2020 6f75 7470  e):.        outp
-000089a0: 7574 203d 2073 656c 662e 6d75 6c28 7661  ut = self.mul(va
-000089b0: 6c75 6529 0a20 2020 2020 2020 2072 6574  lue).        ret
-000089c0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-000089d0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-000089e0: 206f 7574 7075 742c 2022 6d75 6c5f 222c   output, "mul_",
-000089f0: 2022 6d75 6c22 290a 0a20 2020 2040 7072   "mul")..    @pr
-00008a00: 6f70 6572 7479 0a20 2020 2064 6566 2064  operty.    def d
-00008a10: 6576 6963 6528 7365 6c66 293a 0a20 2020  evice(self):.   
-00008a20: 2020 2020 2023 2054 656e 736f 722e 6465       # Tensor.de
-00008a30: 7669 6365 2061 6e64 2074 656e 736f 722e  vice and tensor.
-00008a40: 746f 2864 6576 6963 6529 2064 6f20 6e6f  to(device) do no
-00008a50: 7420 6163 7475 616c 6c79 2068 6176 6520  t actually have 
-00008a60: 6566 6665 6374 2069 6e20 6164 6170 7465  effect in adapte
-00008a70: 720a 2020 2020 2020 2020 2320 6265 6361  r.        # beca
-00008a80: 7573 6520 6d69 6e64 7370 6f72 6520 646f  use mindspore do
-00008a90: 206e 6f74 2063 6f6e 7472 6f6c 2061 2073   not control a s
-00008aa0: 696e 676c 6520 7465 6e73 6f72 2074 6f20  ingle tensor to 
-00008ab0: 6120 6365 7274 6169 6e20 6465 6976 6365  a certain deivce
-00008ac0: 0a20 2020 2020 2020 2023 2053 6f20 6865  .        # So he
-00008ad0: 7265 2066 6f72 2070 6572 666f 726d 616e  re for performan
-00008ae0: 6365 2c20 7265 7475 726e 2063 6c61 7373  ce, return class
-00008af0: 2064 6576 6963 6520 7769 7468 2074 6172   device with tar
-00008b00: 6765 7420 616e 6420 6964 2e0a 2020 2020  get and id..    
-00008b10: 2020 2020 7265 7475 726e 2064 6576 6963      return devic
-00008b20: 655f 636c 6173 7328 6765 745f 6261 636b  e_class(get_back
-00008b30: 656e 6428 292c 2030 290a 0a20 2020 2064  end(), 0)..    d
-00008b40: 6566 2064 6976 2873 656c 662c 2076 616c  ef div(self, val
-00008b50: 7565 2c20 2a2c 2072 6f75 6e64 696e 675f  ue, *, rounding_
-00008b60: 6d6f 6465 3d4e 6f6e 6529 203a 0a20 2020  mode=None) :.   
-00008b70: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00008b80: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00008b90: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00008ba0: 7661 6c75 6520 3d20 6361 7374 5f74 6f5f  value = cast_to_
-00008bb0: 6d73 5f74 656e 736f 7228 7661 6c75 6529  ms_tensor(value)
-00008bc0: 0a20 2020 2020 2020 2023 2054 4f44 4f3a  .        # TODO:
-00008bd0: 206d 732e 6f70 732e 6469 7620 746f 2073   ms.ops.div to s
-00008be0: 7570 706f 7274 2072 6561 6c20 6469 7620  upport real div 
-00008bf0: 7768 656e 2072 6f75 6e64 696e 675f 6d6f  when rounding_mo
-00008c00: 6465 2069 7320 4e6f 6e65 2061 6e64 2069  de is None and i
-00008c10: 6e70 7574 2061 7265 2061 6c6c 2069 6e74  nput are all int
-00008c20: 2074 7970 650a 2020 2020 2020 2020 6966   type.        if
-00008c30: 2072 6f75 6e64 696e 675f 6d6f 6465 2069   rounding_mode i
-00008c40: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-00008c50: 2020 2020 6966 2069 6e70 7574 5f6d 732e      if input_ms.
-00008c60: 6474 7970 6520 696e 2061 6c6c 5f69 6e74  dtype in all_int
-00008c70: 5f74 7970 653a 0a20 2020 2020 2020 2020  _type:.         
-00008c80: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00008c90: 3d20 6d73 2e6f 7073 2e63 6173 7428 696e  = ms.ops.cast(in
-00008ca0: 7075 745f 6d73 2c20 6d73 7479 7065 2e66  put_ms, mstype.f
-00008cb0: 6c6f 6174 3332 290a 2020 2020 2020 2020  loat32).        
-00008cc0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-00008cd0: 6469 7628 696e 7075 745f 6d73 2c20 7661  div(input_ms, va
-00008ce0: 6c75 652c 2072 6f75 6e64 696e 675f 6d6f  lue, rounding_mo
-00008cf0: 6465 3d72 6f75 6e64 696e 675f 6d6f 6465  de=rounding_mode
-00008d00: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00008d10: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00008d20: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-00008d30: 0a20 2020 2064 6566 2064 6976 5f28 7365  .    def div_(se
-00008d40: 6c66 2c20 7661 6c75 652c 202a 2c20 726f  lf, value, *, ro
-00008d50: 756e 6469 6e67 5f6d 6f64 653d 4e6f 6e65  unding_mode=None
-00008d60: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
-00008d70: 7420 3d20 7365 6c66 2e64 6976 2876 616c  t = self.div(val
-00008d80: 7565 2c20 726f 756e 6469 6e67 5f6d 6f64  ue, rounding_mod
-00008d90: 653d 726f 756e 6469 6e67 5f6d 6f64 6529  e=rounding_mode)
-00008da0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00008db0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-00008dc0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-00008dd0: 7075 742c 2022 6469 765f 222c 2022 6469  put, "div_", "di
-00008de0: 7622 290a 0a20 2020 2064 6566 2063 7075  v")..    def cpu
-00008df0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00008e00: 2354 4f44 4f0a 2020 2020 2020 2020 7265  #TODO.        re
-00008e10: 7475 726e 2073 656c 660a 0a20 2020 2023  turn self..    #
-00008e20: 2054 6f20 6163 6869 6576 6520 7468 6520   To achieve the 
-00008e30: 706f 6c79 6d6f 7270 6869 736d 2054 656e  polymorphism Ten
-00008e40: 736f 722e 6d69 6e28 5465 6e73 6f72 2069  sor.min(Tensor i
-00008e50: 6e70 7574 2c20 5465 6e73 6f72 206f 7468  nput, Tensor oth
-00008e60: 6572 2c20 2a2c 2054 656e 736f 7220 6f75  er, *, Tensor ou
-00008e70: 7429 0a20 2020 2023 206f 7468 6572 3d4e  t).    # other=N
-00008e80: 6f6e 6520 6973 2075 7365 6420 746f 2072  one is used to r
-00008e90: 6570 7265 7365 6e74 2074 6865 206b 6579  epresent the key
-00008ea0: 776f 7264 7320 7061 7261 6d20 696e 7075  words param inpu
-00008eb0: 740a 2020 2020 6465 6620 6d69 6e28 7365  t.    def min(se
-00008ec0: 6c66 2c20 6469 6d3d 4e6f 6e65 2c20 6b65  lf, dim=None, ke
-00008ed0: 6570 6469 6d3d 4661 6c73 652c 206f 7468  epdim=False, oth
-00008ee0: 6572 3d4e 6f6e 6529 3a0a 2020 2020 2020  er=None):.      
-00008ef0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
-00008f00: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-00008f10: 656c 6629 0a20 2020 2020 2020 2074 7970  elf).        typ
-00008f20: 6520 3d20 696e 7075 745f 6d73 2e64 7479  e = input_ms.dty
-00008f30: 7065 0a20 2020 2020 2020 2069 6620 6f74  pe.        if ot
-00008f40: 6865 7220 6973 206e 6f74 204e 6f6e 653a  her is not None:
-00008f50: 0a20 2020 2020 2020 2020 2020 206f 7468  .            oth
-00008f60: 6572 203d 2063 6173 745f 746f 5f6d 735f  er = cast_to_ms_
-00008f70: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
-00008f80: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00008f90: 203d 206d 732e 6f70 732e 6d69 6e69 6d75   = ms.ops.minimu
-00008fa0: 6d28 696e 7075 745f 6d73 2c20 6f74 6865  m(input_ms, othe
-00008fb0: 7229 2e61 7374 7970 6528 7479 7065 290a  r).astype(type).
-00008fc0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00008fd0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00008fe0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00008ff0: 290a 2020 2020 2020 2020 6966 2069 7369  ).        if isi
-00009000: 6e73 7461 6e63 6528 6469 6d2c 2054 656e  nstance(dim, Ten
-00009010: 736f 7229 3a0a 2020 2020 2020 2020 2020  sor):.          
-00009020: 2020 6f74 6865 7220 3d20 6361 7374 5f74    other = cast_t
-00009030: 6f5f 6d73 5f74 656e 736f 7228 6469 6d29  o_ms_tensor(dim)
-00009040: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00009050: 7075 7420 3d20 6d73 2e6f 7073 2e6d 696e  put = ms.ops.min
-00009060: 696d 756d 2869 6e70 7574 5f6d 732c 206f  imum(input_ms, o
-00009070: 7468 6572 292e 6173 7479 7065 2874 7970  ther).astype(typ
-00009080: 6529 0a20 2020 2020 2020 2020 2020 2072  e).            r
-00009090: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-000090a0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-000090b0: 7075 7429 0a20 2020 2020 2020 2069 6620  put).        if 
-000090c0: 6469 6d20 6973 204e 6f6e 653a 0a20 2020  dim is None:.   
-000090d0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
-000090e0: 3d20 696e 7075 745f 6d73 2e6d 696e 2861  = input_ms.min(a
-000090f0: 7869 733d 6469 6d2c 206b 6565 7064 696d  xis=dim, keepdim
-00009100: 733d 6b65 6570 6469 6d29 2e61 7374 7970  s=keepdim).astyp
-00009110: 6528 7479 7065 290a 2020 2020 2020 2020  e(type).        
-00009120: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00009130: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00009140: 7228 6f75 7470 7574 290a 2020 2020 2020  r(output).      
-00009150: 2020 7661 6c75 652c 2069 6e64 6963 6520    value, indice 
-00009160: 3d20 6d73 2e6f 7073 2e6d 696e 2869 6e70  = ms.ops.min(inp
-00009170: 7574 5f6d 732c 2064 696d 2c20 6b65 6570  ut_ms, dim, keep
-00009180: 6469 6d29 0a20 2020 2020 2020 2076 616c  dim).        val
-00009190: 7565 203d 2076 616c 7565 2e61 7374 7970  ue = value.astyp
-000091a0: 6528 7479 7065 290a 2020 2020 2020 2020  e(type).        
-000091b0: 696e 6469 6365 203d 2069 6e64 6963 652e  indice = indice.
-000091c0: 6173 7479 7065 286d 732e 696e 7436 3429  astype(ms.int64)
-000091d0: 0a20 2020 2020 2020 2069 6620 7079 6e61  .        if pyna
-000091e0: 7469 7665 5f6d 6f64 655f 636f 6e64 6974  tive_mode_condit
-000091f0: 696f 6e28 293a 0a20 2020 2020 2020 2020  ion():.         
-00009200: 2020 2070 6f69 6e74 203d 2073 6574 5f6e     point = set_n
-00009210: 616d 655f 7475 706c 6528 276d 696e 2729  ame_tuple('min')
-00009220: 0a20 2020 2020 2020 2020 2020 2072 6c74  .            rlt
-00009230: 203d 2070 6f69 6e74 2863 6173 745f 746f   = point(cast_to
-00009240: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00009250: 7661 6c75 6529 2c20 6361 7374 5f74 6f5f  value), cast_to_
-00009260: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
-00009270: 6e64 6963 6529 290a 2020 2020 2020 2020  ndice)).        
-00009280: 2020 2020 7265 7475 726e 2072 6c74 0a20      return rlt. 
-00009290: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-000092a0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-000092b0: 6e73 6f72 2876 616c 7565 292c 2063 6173  nsor(value), cas
-000092c0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-000092d0: 736f 7228 696e 6469 6365 290a 0a20 2020  sor(indice)..   
-000092e0: 2023 2054 6f20 6163 6869 6576 6520 7468   # To achieve th
-000092f0: 6520 706f 6c79 6d6f 7270 6869 736d 2054  e polymorphism T
-00009300: 656e 736f 722e 6d61 7828 5465 6e73 6f72  ensor.max(Tensor
-00009310: 2069 6e70 7574 2c20 5465 6e73 6f72 206f   input, Tensor o
-00009320: 7468 6572 2c20 2a2c 2054 656e 736f 7220  ther, *, Tensor 
-00009330: 6f75 7429 0a20 2020 2023 206f 7468 6572  out).    # other
-00009340: 3d4e 6f6e 6520 6973 2075 7365 6420 746f  =None is used to
-00009350: 2072 6570 7265 7365 6e74 2074 6865 206b   represent the k
-00009360: 6579 776f 7264 7320 7061 7261 6d20 696e  eywords param in
-00009370: 7075 740a 2020 2020 6465 6620 6d61 7828  put.    def max(
-00009380: 7365 6c66 2c20 6469 6d3d 4e6f 6e65 2c20  self, dim=None, 
-00009390: 6b65 6570 6469 6d3d 4661 6c73 652c 206f  keepdim=False, o
-000093a0: 7468 6572 3d4e 6f6e 6529 3a0a 2020 2020  ther=None):.    
-000093b0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-000093c0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-000093d0: 2873 656c 6629 0a20 2020 2020 2020 2074  (self).        t
-000093e0: 7970 6520 3d20 696e 7075 745f 6d73 2e64  ype = input_ms.d
-000093f0: 7479 7065 0a20 2020 2020 2020 2069 6620  type.        if 
-00009400: 6f74 6865 7220 6973 206e 6f74 204e 6f6e  other is not Non
-00009410: 653a 0a20 2020 2020 2020 2020 2020 206f  e:.            o
-00009420: 7468 6572 203d 2063 6173 745f 746f 5f6d  ther = cast_to_m
-00009430: 735f 7465 6e73 6f72 286f 7468 6572 290a  s_tensor(other).
-00009440: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00009450: 7574 203d 206d 732e 6f70 732e 6d61 7869  ut = ms.ops.maxi
-00009460: 6d75 6d28 696e 7075 745f 6d73 2c20 6f74  mum(input_ms, ot
-00009470: 6865 7229 2e61 7374 7970 6528 7479 7065  her).astype(type
-00009480: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
-00009490: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-000094a0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-000094b0: 7574 290a 2020 2020 2020 2020 6966 2069  ut).        if i
-000094c0: 7369 6e73 7461 6e63 6528 6469 6d2c 2054  sinstance(dim, T
-000094d0: 656e 736f 7229 3a0a 2020 2020 2020 2020  ensor):.        
-000094e0: 2020 2020 6f74 6865 7220 3d20 6361 7374      other = cast
-000094f0: 5f74 6f5f 6d73 5f74 656e 736f 7228 6469  _to_ms_tensor(di
-00009500: 6d29 0a20 2020 2020 2020 2020 2020 206f  m).            o
-00009510: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6d  utput = ms.ops.m
-00009520: 6178 696d 756d 2869 6e70 7574 5f6d 732c  aximum(input_ms,
-00009530: 206f 7468 6572 292e 6173 7479 7065 2874   other).astype(t
-00009540: 7970 6529 0a20 2020 2020 2020 2020 2020  ype).           
-00009550: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00009560: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00009570: 7574 7075 7429 0a20 2020 2020 2020 2069  utput).        i
-00009580: 6620 6469 6d20 6973 204e 6f6e 653a 0a20  f dim is None:. 
-00009590: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-000095a0: 7420 3d20 696e 7075 745f 6d73 2e6d 6178  t = input_ms.max
-000095b0: 2861 7869 733d 6469 6d2c 206b 6565 7064  (axis=dim, keepd
-000095c0: 696d 733d 6b65 6570 6469 6d29 2e61 7374  ims=keepdim).ast
-000095d0: 7970 6528 7479 7065 290a 2020 2020 2020  ype(type).      
-000095e0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-000095f0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00009600: 736f 7228 6f75 7470 7574 290a 2020 2020  sor(output).    
-00009610: 2020 2020 7661 6c75 652c 2069 6e64 6963      value, indic
-00009620: 6520 3d20 6d73 2e6f 7073 2e6d 6178 2869  e = ms.ops.max(i
-00009630: 6e70 7574 5f6d 732c 2064 696d 2c20 6b65  nput_ms, dim, ke
-00009640: 6570 6469 6d29 0a20 2020 2020 2020 2076  epdim).        v
-00009650: 616c 7565 203d 2076 616c 7565 2e61 7374  alue = value.ast
-00009660: 7970 6528 7479 7065 290a 2020 2020 2020  ype(type).      
-00009670: 2020 696e 6469 6365 203d 2069 6e64 6963    indice = indic
-00009680: 652e 6173 7479 7065 286d 732e 696e 7436  e.astype(ms.int6
-00009690: 3429 0a20 2020 2020 2020 2069 6620 7079  4).        if py
-000096a0: 6e61 7469 7665 5f6d 6f64 655f 636f 6e64  native_mode_cond
-000096b0: 6974 696f 6e28 293a 0a20 2020 2020 2020  ition():.       
-000096c0: 2020 2020 2070 6f69 6e74 203d 2073 6574       point = set
-000096d0: 5f6e 616d 655f 7475 706c 6528 276d 6178  _name_tuple('max
-000096e0: 2729 0a20 2020 2020 2020 2020 2020 2072  ').            r
-000096f0: 6c74 203d 2070 6f69 6e74 2863 6173 745f  lt = point(cast_
-00009700: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00009710: 7228 7661 6c75 6529 2c20 6361 7374 5f74  r(value), cast_t
-00009720: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-00009730: 2869 6e64 6963 6529 290a 2020 2020 2020  (indice)).      
-00009740: 2020 2020 2020 7265 7475 726e 2072 6c74        return rlt
-00009750: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00009760: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00009770: 7465 6e73 6f72 2876 616c 7565 292c 2063  tensor(value), c
-00009780: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00009790: 656e 736f 7228 696e 6469 6365 290a 0a0a  ensor(indice)...
-000097a0: 2020 2020 6465 6620 6e75 6d65 6c28 7365      def numel(se
-000097b0: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
-000097c0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-000097d0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-000097e0: 2020 2020 2020 2020 7265 7475 726e 2050          return P
-000097f0: 2e73 697a 6528 696e 7075 745f 6d73 290a  .size(input_ms).
-00009800: 0a20 2020 2064 6566 2064 6574 6163 6828  .    def detach(
-00009810: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
-00009820: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-00009830: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00009840: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-00009850: 203d 206d 732e 6f70 732e 7374 6f70 5f67   = ms.ops.stop_g
-00009860: 7261 6469 656e 7428 696e 7075 745f 6d73  radient(input_ms
-00009870: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00009880: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00009890: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-000098a0: 0a20 2020 2064 6566 2064 6574 6163 685f  .    def detach_
-000098b0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-000098c0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-000098d0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-000098e0: 6c66 2c20 7365 6c66 2e64 6574 6163 6828  lf, self.detach(
-000098f0: 292c 2022 6465 7461 6368 5f22 2c20 2264  ), "detach_", "d
-00009900: 6574 6163 6822 290a 0a20 2020 2064 6566  etach")..    def
-00009910: 2073 756d 2873 656c 662c 2064 696d 3d4e   sum(self, dim=N
-00009920: 6f6e 652c 206b 6565 7064 696d 3d46 616c  one, keepdim=Fal
-00009930: 7365 2c20 6474 7970 653d 4e6f 6e65 293a  se, dtype=None):
-00009940: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-00009950: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00009960: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00009970: 2020 2020 2320 544f 444f 3a20 6d69 6e64      # TODO: mind
-00009980: 7370 6f72 6520 7465 6e73 6f72 2e73 756d  spore tensor.sum
-00009990: 2063 616e 206e 6f74 2061 7574 6f6d 6174   can not automat
-000099a0: 6963 616c 6c79 2070 726f 6d6f 7465 2064  ically promote d
-000099b0: 7479 7065 2079 6574 2c20 7769 6c6c 2063  type yet, will c
-000099c0: 6175 7365 206f 7665 7266 6c6f 772e 0a20  ause overflow.. 
-000099d0: 2020 2020 2020 2069 6620 6474 7970 6520         if dtype 
-000099e0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-000099f0: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
-00009a00: 7320 3d20 696e 7075 745f 6d73 2e61 7374  s = input_ms.ast
-00009a10: 7970 6528 6474 7970 6529 2069 6620 6474  ype(dtype) if dt
-00009a20: 7970 6520 213d 206d 7374 7970 652e 626f  ype != mstype.bo
-00009a30: 6f6c 5f20 656c 7365 205c 0a20 2020 2020  ol_ else \.     
-00009a40: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00009a50: 5f6d 732e 6173 7479 7065 286d 7374 7970  _ms.astype(mstyp
-00009a60: 652e 626f 6f6c 5f29 2e61 7374 7970 6528  e.bool_).astype(
-00009a70: 6d73 7479 7065 2e69 6e74 3634 290a 2020  mstype.int64).  
-00009a80: 2020 2020 2020 656c 6966 2069 6e70 7574        elif input
-00009a90: 5f6d 732e 6474 7970 6520 696e 206d 7364  _ms.dtype in msd
-00009aa0: 6170 7465 725f 6474 7970 652e 616c 6c5f  apter_dtype.all_
-00009ab0: 696e 745f 7479 7065 5f77 6974 685f 626f  int_type_with_bo
-00009ac0: 6f6c 3a0a 2020 2020 2020 2020 2020 2020  ol:.            
-00009ad0: 6474 7970 6520 3d20 6d73 7479 7065 2e69  dtype = mstype.i
-00009ae0: 6e74 3634 0a20 2020 2020 2020 2020 2020  nt64.           
-00009af0: 2069 6e70 7574 5f6d 7320 3d20 696e 7075   input_ms = inpu
-00009b00: 745f 6d73 2e61 7374 7970 6528 6474 7970  t_ms.astype(dtyp
-00009b10: 6529 0a0a 2020 2020 2020 2020 6966 2069  e)..        if i
-00009b20: 7369 6e73 7461 6e63 6528 6469 6d2c 206c  sinstance(dim, l
-00009b30: 6973 7429 3a0a 2020 2020 2020 2020 2020  ist):.          
-00009b40: 2020 6469 6d20 3d20 7475 706c 6528 6469    dim = tuple(di
-00009b50: 6d29 0a20 2020 2020 2020 2072 6573 203d  m).        res =
-00009b60: 2069 6e70 7574 5f6d 732e 7375 6d28 6469   input_ms.sum(di
-00009b70: 6d2c 2064 7479 7065 2c20 6b65 6570 6469  m, dtype, keepdi
-00009b80: 6d29 0a20 2020 2020 2020 2069 6620 6474  m).        if dt
-00009b90: 7970 6520 6973 206e 6f74 204e 6f6e 6520  ype is not None 
-00009ba0: 616e 6420 6474 7970 6520 3d3d 206d 7374  and dtype == mst
-00009bb0: 7970 652e 626f 6f6c 5f3a 0a20 2020 2020  ype.bool_:.     
-00009bc0: 2020 2020 2020 2072 6573 203d 2072 6573         res = res
-00009bd0: 2e61 7374 7970 6528 6d73 7479 7065 2e62  .astype(mstype.b
-00009be0: 6f6f 6c5f 290a 2020 2020 2020 2020 7265  ool_).        re
-00009bf0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00009c00: 7074 6572 5f74 656e 736f 7228 7265 7329  pter_tensor(res)
-00009c10: 0a0a 2020 2020 6465 6620 7375 6d5f 746f  ..    def sum_to
-00009c20: 5f73 697a 6528 7365 6c66 2c20 2a73 697a  _size(self, *siz
-00009c30: 6529 3a0a 2020 2020 2020 2020 696e 7075  e):.        inpu
-00009c40: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00009c50: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00009c60: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00009c70: 696e 7075 745f 6d73 2e73 756d 5f74 6f5f  input_ms.sum_to_
-00009c80: 7369 7a65 282a 7369 7a65 290a 2020 2020  size(*size).    
-00009c90: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00009ca0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00009cb0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00009cc0: 6566 206d 6561 6e28 7365 6c66 2c20 6469  ef mean(self, di
-00009cd0: 6d3d 4e6f 6e65 2c20 6b65 6570 6469 6d3d  m=None, keepdim=
-00009ce0: 4661 6c73 652c 2064 7479 7065 3d4e 6f6e  False, dtype=Non
-00009cf0: 652c 2061 7869 733d 4e6f 6e65 293a 0a20  e, axis=None):. 
-00009d00: 2020 2020 2020 2069 6620 6469 6d20 6973         if dim is
-00009d10: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-00009d20: 2020 2064 696d 203d 2061 7869 730a 0a20     dim = axis.. 
-00009d30: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00009d40: 3d20 6361 7374 5f74 6f5f 6164 6170 7465  = cast_to_adapte
-00009d50: 725f 7465 6e73 6f72 2873 656c 6629 0a20  r_tensor(self). 
-00009d60: 2020 2020 2020 2069 6620 6474 7970 653a         if dtype:
-00009d70: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
-00009d80: 7574 5f6d 7320 3d20 7365 6c66 2e61 7374  ut_ms = self.ast
-00009d90: 7970 6528 6474 7970 6529 0a0a 2020 2020  ype(dtype)..    
-00009da0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00009db0: 6f70 732e 6d65 616e 2869 6e70 7574 5f6d  ops.mean(input_m
-00009dc0: 732c 2064 696d 2c20 6b65 6570 6469 6d29  s, dim, keepdim)
-00009dd0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00009de0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00009df0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00009e00: 2020 2020 6465 6620 7072 6f64 2873 656c      def prod(sel
-00009e10: 662c 2064 696d 3d4e 6f6e 652c 206b 6565  f, dim=None, kee
-00009e20: 7064 696d 3d46 616c 7365 2c20 6474 7970  pdim=False, dtyp
-00009e30: 653d 4e6f 6e65 293a 0a20 2020 2020 2020  e=None):.       
-00009e40: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00009e50: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00009e60: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00009e70: 2069 6620 6474 7970 653a 0a20 2020 2020   if dtype:.     
-00009e80: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00009e90: 3d20 7365 6c66 2e61 7374 7970 6528 6474  = self.astype(dt
-00009ea0: 7970 6529 0a0a 2020 2020 2020 2020 2354  ype)..        #T
-00009eb0: 4f44 4f3a 206d 732e 6f70 732e 7072 6f64  ODO: ms.ops.prod
-00009ec0: 206e 6f74 2073 7570 706f 7274 2062 6f6f   not support boo
-00009ed0: 6c20 7479 7065 206f 6e20 4173 6365 6e64  l type on Ascend
-00009ee0: 2c20 4350 5526 4750 5520 7265 7475 726e  , CPU&GPU return
-00009ef0: 2074 7970 6520 6973 2062 6f6f 6c0a 2020   type is bool.  
-00009f00: 2020 2020 2020 6966 2069 6e70 7574 5f6d        if input_m
-00009f10: 732e 6474 7970 6520 3d3d 206d 732e 626f  s.dtype == ms.bo
-00009f20: 6f6c 5f3a 0a20 2020 2020 2020 2020 2020  ol_:.           
-00009f30: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-00009f40: 2e70 726f 6428 696e 7075 745f 6d73 2e61  .prod(input_ms.a
-00009f50: 7374 7970 6528 6d73 2e69 6e74 3829 2c20  stype(ms.int8), 
-00009f60: 6469 6d2c 206b 6565 7064 696d 290a 2020  dim, keepdim).  
-00009f70: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00009f80: 203d 206f 7574 7075 742e 6173 7479 7065   = output.astype
-00009f90: 286d 732e 696e 7436 3429 0a20 2020 2020  (ms.int64).     
-00009fa0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00009fb0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00009fc0: 2e6f 7073 2e70 726f 6428 696e 7075 745f  .ops.prod(input_
-00009fd0: 6d73 2c20 6469 6d2c 206b 6565 7064 696d  ms, dim, keepdim
-00009fe0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00009ff0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-0000a000: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-0000a010: 0a20 2020 2064 6566 2073 706c 6974 2873  .    def split(s
-0000a020: 656c 662c 2073 706c 6974 5f73 697a 652c  elf, split_size,
-0000a030: 2064 696d 3d30 293a 0a20 2020 2020 2020   dim=0):.       
-0000a040: 2074 656e 736f 7220 3d20 6361 7374 5f74   tensor = cast_t
-0000a050: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0000a060: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-0000a070: 203d 206d 732e 6f70 732e 7370 6c69 7428   = ms.ops.split(
-0000a080: 7465 6e73 6f72 2c20 7370 6c69 745f 7369  tensor, split_si
-0000a090: 7a65 2c20 6469 6d29 0a20 2020 2020 2020  ze, dim).       
-0000a0a0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0000a0b0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-0000a0c0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-0000a0d0: 6e75 6d70 7928 7365 6c66 293a 0a20 2020  numpy(self):.   
-0000a0e0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-0000a0f0: 2e61 736e 756d 7079 2829 0a0a 2020 2020  .asnumpy()..    
-0000a100: 6465 6620 7669 6577 2873 656c 662c 202a  def view(self, *
-0000a110: 7368 6170 6529 3a0a 2020 2020 2020 2020  shape):.        
-0000a120: 7265 7475 726e 2073 656c 662e 7265 7368  return self.resh
-0000a130: 6170 6528 2a73 6861 7065 290a 0a20 2020  ape(*shape)..   
-0000a140: 2064 6566 2076 6965 775f 6173 2873 656c   def view_as(sel
-0000a150: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
-0000a160: 2020 2072 6574 7572 6e20 7365 6c66 2e76     return self.v
-0000a170: 6965 7728 6f74 6865 722e 7368 6170 6529  iew(other.shape)
-0000a180: 0a0a 2020 2020 6465 6620 6e64 696d 656e  ..    def ndimen
-0000a190: 7369 6f6e 2873 656c 6629 3a0a 2020 2020  sion(self):.    
-0000a1a0: 2020 2020 7265 7475 726e 206c 656e 2873      return len(s
-0000a1b0: 656c 662e 7368 6170 6529 0a0a 2020 2020  elf.shape)..    
-0000a1c0: 6465 6620 706f 7728 7365 6c66 2c20 6578  def pow(self, ex
-0000a1d0: 706f 6e65 6e74 293a 0a20 2020 2020 2020  ponent):.       
-0000a1e0: 2070 6f77 6572 203d 2063 6173 745f 746f   power = cast_to
-0000a1f0: 5f6d 735f 7465 6e73 6f72 2865 7870 6f6e  _ms_tensor(expon
-0000a200: 656e 7429 0a20 2020 2020 2020 2069 6e70  ent).        inp
-0000a210: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0000a220: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0000a230: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-0000a240: 2069 6e70 7574 5f6d 732e 706f 7728 706f   input_ms.pow(po
-0000a250: 7765 7229 0a20 2020 2020 2020 2072 6574  wer).        ret
-0000a260: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-0000a270: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-0000a280: 7429 0a0a 2020 2020 6465 6620 706f 775f  t)..    def pow_
-0000a290: 2873 656c 662c 2065 7870 6f6e 656e 7429  (self, exponent)
-0000a2a0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-0000a2b0: 203d 2073 656c 662e 706f 7728 6578 706f   = self.pow(expo
-0000a2c0: 6e65 6e74 290a 2020 2020 2020 2020 7265  nent).        re
-0000a2d0: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
-0000a2e0: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
-0000a2f0: 2c20 6f75 7470 7574 2c20 2270 6f77 5f22  , output, "pow_"
-0000a300: 2c20 2270 6f77 2229 0a0a 2020 2020 6465  , "pow")..    de
-0000a310: 6620 7261 6432 6465 6728 7365 6c66 293a  f rad2deg(self):
-0000a320: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0000a330: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0000a340: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0000a350: 2020 2020 6966 206e 6f74 2069 6e70 7574      if not input
-0000a360: 5f6d 732e 6973 5f66 6c6f 6174 696e 675f  _ms.is_floating_
-0000a370: 706f 696e 7428 293a 0a20 2020 2020 2020  point():.       
-0000a380: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0000a390: 696e 7075 745f 6d73 2e61 7374 7970 6528  input_ms.astype(
-0000a3a0: 6d73 2e66 6c6f 6174 3332 290a 2020 2020  ms.float32).    
-0000a3b0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-0000a3c0: 6f70 732e 7261 6432 6465 6728 696e 7075  ops.rad2deg(inpu
-0000a3d0: 745f 6d73 290a 2020 2020 2020 2020 7265  t_ms).        re
-0000a3e0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-0000a3f0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-0000a400: 7574 290a 0a20 2020 2040 7072 6f70 6572  ut)..    @proper
-0000a410: 7479 0a20 2020 2064 6566 2072 6561 6c28  ty.    def real(
-0000a420: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
-0000a430: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0000a440: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0000a450: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-0000a460: 203d 206d 732e 6f70 732e 7265 616c 2869   = ms.ops.real(i
-0000a470: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-0000a480: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0000a490: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-0000a4a0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-0000a4b0: 7265 6369 7072 6f63 616c 2873 656c 6629  reciprocal(self)
-0000a4c0: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-0000a4d0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0000a4e0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-0000a4f0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-0000a500: 2e6f 7073 2e72 6563 6970 726f 6361 6c28  .ops.reciprocal(
-0000a510: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
-0000a520: 2020 2354 4f44 4f3a 2047 5055 2068 6173    #TODO: GPU has
-0000a530: 2070 726f 626c 656d 2068 616e 646c 696e   problem handlin
-0000a540: 6720 626f 756e 6461 7279 2076 616c 7565  g boundary value
-0000a550: 0a20 2020 2020 2020 2069 6620 6973 5f75  .        if is_u
-0000a560: 6e64 6572 5f67 7075 5f63 6f6e 7465 7874  nder_gpu_context
-0000a570: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-0000a580: 6f75 7470 7574 5f64 7479 7065 203d 206f  output_dtype = o
-0000a590: 7574 7075 742e 6474 7970 650a 2020 2020  utput.dtype.    
-0000a5a0: 2020 2020 2020 2020 6966 206f 7574 7075          if outpu
-0000a5b0: 745f 6474 7970 6520 3d3d 206d 732e 666c  t_dtype == ms.fl
-0000a5c0: 6f61 7433 323a 0a20 2020 2020 2020 2020  oat32:.         
-0000a5d0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0000a5e0: 6d73 2e6f 7073 2e77 6865 7265 2828 6f75  ms.ops.where((ou
-0000a5f0: 7470 7574 203c 3d20 4650 3332 5f4d 494e  tput <= FP32_MIN
-0000a600: 2920 7c20 286f 7574 7075 7420 3e3d 2046  ) | (output >= F
-0000a610: 5033 325f 4d41 5829 2c20 666c 6f61 7428  P32_MAX), float(
-0000a620: 2769 6e66 2729 2c20 6f75 7470 7574 290a  'inf'), output).
-0000a630: 2020 2020 2020 2020 2020 2020 6966 206f              if o
-0000a640: 7574 7075 745f 6474 7970 6520 3d3d 206d  utput_dtype == m
-0000a650: 732e 666c 6f61 7436 343a 0a20 2020 2020  s.float64:.     
-0000a660: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-0000a670: 7420 3d20 6d73 2e6f 7073 2e77 6865 7265  t = ms.ops.where
-0000a680: 2828 6f75 7470 7574 203c 3d20 4650 3634  ((output <= FP64
-0000a690: 5f4d 494e 2920 7c20 286f 7574 7075 7420  _MIN) | (output 
-0000a6a0: 3e3d 2046 5036 345f 4d41 5829 2c20 666c  >= FP64_MAX), fl
-0000a6b0: 6f61 7428 2769 6e66 2729 2c20 6f75 7470  oat('inf'), outp
-0000a6c0: 7574 290a 2020 2020 2020 2020 7265 7475  ut).        retu
-0000a6d0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-0000a6e0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-0000a6f0: 290a 0a20 2020 2064 6566 2072 6563 6970  )..    def recip
-0000a700: 726f 6361 6c5f 2873 656c 6629 3a0a 2020  rocal_(self):.  
-0000a710: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-0000a720: 656c 662e 7265 6369 7072 6f63 616c 2829  elf.reciprocal()
-0000a730: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000a740: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-0000a750: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-0000a760: 7075 742c 2022 7265 6369 7072 6f63 616c  put, "reciprocal
-0000a770: 5f22 2c20 2272 6563 6970 726f 6361 6c22  _", "reciprocal"
-0000a780: 290a 0a20 2020 2064 6566 2072 656d 6169  )..    def remai
-0000a790: 6e64 6572 2873 656c 662c 206f 7468 6572  nder(self, other
-0000a7a0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-0000a7b0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-0000a7c0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-0000a7d0: 2020 2020 2020 6f74 6865 7220 3d20 6361        other = ca
-0000a7e0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-0000a7f0: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
-0000a800: 7574 7075 7420 3d20 6d73 2e6f 7073 2e72  utput = ms.ops.r
-0000a810: 656d 6169 6e64 6572 2869 6e70 7574 5f6d  emainder(input_m
-0000a820: 732c 206f 7468 6572 290a 2020 2020 2020  s, other).      
-0000a830: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0000a840: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0000a850: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-0000a860: 2072 656d 6169 6e64 6572 5f28 7365 6c66   remainder_(self
-0000a870: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-0000a880: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
-0000a890: 7265 6d61 696e 6465 7228 6f74 6865 7229  remainder(other)
-0000a8a0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000a8b0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-0000a8c0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-0000a8d0: 7075 742c 2022 7265 6d61 696e 6465 725f  put, "remainder_
-0000a8e0: 222c 2022 7265 6d61 696e 6465 7222 290a  ", "remainder").
-0000a8f0: 0a20 2020 2064 6566 2072 6570 6561 7428  .    def repeat(
-0000a900: 7365 6c66 2c20 2a73 697a 6573 293a 0a20  self, *sizes):. 
-0000a910: 2020 2020 2020 2069 6e70 7574 5f78 203d         input_x =
-0000a920: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0000a930: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-0000a940: 2069 6620 6973 696e 7374 616e 6365 2873   if isinstance(s
-0000a950: 697a 6573 5b30 5d2c 206c 6973 7429 3a0a  izes[0], list):.
-0000a960: 2020 2020 2020 2020 2020 2020 7369 7a65              size
-0000a970: 7320 3d20 7475 706c 6528 2a73 697a 6573  s = tuple(*sizes
-0000a980: 290a 2020 2020 2020 2020 656c 6966 2069  ).        elif i
-0000a990: 7369 6e73 7461 6e63 6528 7369 7a65 735b  sinstance(sizes[
-0000a9a0: 305d 2c20 7475 706c 6529 3a0a 2020 2020  0], tuple):.    
-0000a9b0: 2020 2020 2020 2020 7369 7a65 7320 3d20          sizes = 
-0000a9c0: 7369 7a65 735b 305d 0a20 2020 2020 2020  sizes[0].       
-0000a9d0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-0000a9e0: 2e74 696c 6528 696e 7075 745f 782c 2073  .tile(input_x, s
-0000a9f0: 697a 6573 290a 2020 2020 2020 2020 7265  izes).        re
-0000aa00: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-0000aa10: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-0000aa20: 7574 290a 0a20 2020 2064 6566 2072 6570  ut)..    def rep
-0000aa30: 6561 745f 696e 7465 726c 6561 7665 2873  eat_interleave(s
-0000aa40: 656c 662c 2072 6570 6561 7473 2c20 6469  elf, repeats, di
-0000aa50: 6d3d 4e6f 6e65 2c20 2a2c 206f 7574 7075  m=None, *, outpu
-0000aa60: 745f 7369 7a65 3d4e 6f6e 6529 3a0a 2020  t_size=None):.  
-0000aa70: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
-0000aa80: 645f 6174 7472 286f 7574 7075 745f 7369  d_attr(output_si
-0000aa90: 7a65 290a 0a20 2020 2020 2020 2069 6620  ze)..        if 
-0000aaa0: 6973 696e 7374 616e 6365 2872 6570 6561  isinstance(repea
-0000aab0: 7473 2c20 5465 6e73 6f72 293a 0a20 2020  ts, Tensor):.   
-0000aac0: 2020 2020 2020 2020 206e 6577 5f72 6570           new_rep
-0000aad0: 6561 7473 203d 205b 5d0a 2020 2020 2020  eats = [].      
-0000aae0: 2020 2020 2020 666f 7220 696e 6465 7820        for index 
-0000aaf0: 696e 2072 6570 6561 7473 3a0a 2020 2020  in repeats:.    
-0000ab00: 2020 2020 2020 2020 2020 2020 6e65 775f              new_
-0000ab10: 7265 7065 6174 732e 6170 7065 6e64 2869  repeats.append(i
-0000ab20: 6e74 2869 6e64 6578 2929 0a20 2020 2020  nt(index)).     
-0000ab30: 2020 2020 2020 2072 6570 6561 7473 203d         repeats =
-0000ab40: 206e 6577 5f72 6570 6561 7473 0a20 2020   new_repeats.   
-0000ab50: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0000ab60: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-0000ab70: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-0000ab80: 6f75 7470 7574 203d 2069 6e70 7574 5f6d  output = input_m
-0000ab90: 732e 7265 7065 6174 2872 6570 6561 7473  s.repeat(repeats
-0000aba0: 2c20 6469 6d29 0a20 2020 2020 2020 2072  , dim).        r
-0000abb0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0000abc0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-0000abd0: 7075 7429 0a0a 2020 2020 6465 6620 7265  put)..    def re
-0000abe0: 7368 6170 6528 7365 6c66 2c20 2a73 6861  shape(self, *sha
-0000abf0: 7065 293a 0a20 2020 2020 2020 2069 6620  pe):.        if 
-0000ac00: 6e6f 7420 7368 6170 653a 0a20 2020 2020  not shape:.     
-0000ac10: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-0000ac20: 7565 4572 726f 7228 2254 6865 2073 6861  ueError("The sha
-0000ac30: 7065 2076 6172 6961 626c 6520 7368 6f75  pe variable shou
-0000ac40: 6c64 206e 6f74 2062 6520 656d 7074 7922  ld not be empty"
-0000ac50: 290a 2020 2020 2020 2020 6966 2069 7369  ).        if isi
-0000ac60: 6e73 7461 6e63 6528 7368 6170 655b 305d  nstance(shape[0]
-0000ac70: 2c20 2874 7570 6c65 2c20 6c69 7374 2929  , (tuple, list))
-0000ac80: 3a0a 2020 2020 2020 2020 2020 2020 7368  :.            sh
-0000ac90: 6170 6520 3d20 7368 6170 655b 305d 0a20  ape = shape[0]. 
-0000aca0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-0000acb0: 616e 6365 2873 6861 7065 2c20 6c69 7374  ance(shape, list
-0000acc0: 293a 0a20 2020 2020 2020 2020 2020 2073  ):.            s
-0000acd0: 6861 7065 203d 2074 7570 6c65 2873 6861  hape = tuple(sha
-0000ace0: 7065 290a 0a20 2020 2020 2020 2069 6e70  pe)..        inp
-0000acf0: 7574 5f73 697a 6520 3d20 7365 6c66 2e73  ut_size = self.s
-0000ad00: 6861 7065 0a20 2020 2020 2020 2069 6620  hape.        if 
-0000ad10: 6e6f 7420 6d73 2e6f 7073 2e69 735f 7365  not ms.ops.is_se
-0000ad20: 7175 656e 6365 5f76 616c 7565 5f75 6e6b  quence_value_unk
-0000ad30: 6e6f 776e 2869 6e70 7574 5f73 697a 6529  nown(input_size)
-0000ad40: 2061 6e64 2069 6e70 7574 5f73 697a 655b   and input_size[
-0000ad50: 305d 203d 3d20 303a 2020 2320 6f6e 6c79  0] == 0:  # only
-0000ad60: 2073 7570 706f 7274 2066 6972 7374 2065   support first e
-0000ad70: 6c65 6d65 6e74 2069 7320 300a 2020 2020  lement is 0.    
-0000ad80: 2020 2020 2020 2020 6e75 6d65 6c20 3d20          numel = 
-0000ad90: 6d73 2e6f 7073 2e73 697a 6528 7365 6c66  ms.ops.size(self
-0000ada0: 290a 2020 2020 2020 2020 2020 2020 7368  ).            sh
-0000adb0: 6170 6520 3d20 5f69 6e66 6572 5f73 697a  ape = _infer_siz
-0000adc0: 6528 7368 6170 652c 206e 756d 656c 290a  e(shape, numel).
-0000add0: 2020 2020 2020 2020 2020 2020 2320 544f              # TO
-0000ade0: 444f 3a20 6d73 2e6f 7073 2e7a 6572 6f73  DO: ms.ops.zeros
-0000adf0: 2829 2063 7572 7265 6e74 6c79 2068 6173  () currently has
-0000ae00: 2070 726f 626c 656d 2068 616e 646c 696e   problem handlin
-0000ae10: 6720 696e 7075 7420 7368 6170 6520 696e  g input shape in
-0000ae20: 636c 7564 696e 6720 300a 2020 2020 2020  cluding 0.      
-0000ae30: 2020 2020 2020 6f75 7470 7574 203d 205f        output = _
-0000ae40: 6765 745f 6361 6368 655f 7072 696d 286d  get_cache_prim(m
-0000ae50: 732e 6f70 732e 5a65 726f 7329 2829 2873  s.ops.Zeros)()(s
-0000ae60: 6861 7065 2c20 7365 6c66 2e64 7479 7065  hape, self.dtype
-0000ae70: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-0000ae80: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
-0000ae90: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-0000aea0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-0000aeb0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-0000aec0: 7420 3d20 6d73 2e6f 7073 2e72 6573 6861  t = ms.ops.resha
-0000aed0: 7065 2869 6e70 7574 5f6d 732c 2073 6861  pe(input_ms, sha
-0000aee0: 7065 290a 2020 2020 2020 2020 7265 7475  pe).        retu
-0000aef0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-0000af00: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-0000af10: 290a 0a20 2020 2064 6566 2072 6573 6861  )..    def resha
-0000af20: 7065 5f61 7328 7365 6c66 2c20 6f74 6865  pe_as(self, othe
-0000af30: 7229 3a0a 2020 2020 2020 2020 7265 7475  r):.        retu
-0000af40: 726e 2073 656c 662e 7265 7368 6170 6528  rn self.reshape(
-0000af50: 6f74 6865 722e 7368 6170 6529 0a0a 2020  other.shape)..  
-0000af60: 2020 6465 6620 6172 6373 696e 6828 7365    def arcsinh(se
-0000af70: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
-0000af80: 7572 6e20 7365 6c66 2e61 7369 6e68 2829  urn self.asinh()
-0000af90: 0a0a 2020 2020 6465 6620 6172 6373 696e  ..    def arcsin
-0000afa0: 685f 2873 656c 6629 3a0a 2020 2020 2020  h_(self):.      
-0000afb0: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
-0000afc0: 6173 696e 6828 290a 2020 2020 2020 2020  asinh().        
-0000afd0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-0000afe0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-0000aff0: 6c66 2c20 6f75 7470 7574 2c20 2261 7263  lf, output, "arc
-0000b000: 7369 6e68 5f22 2c20 2261 7263 7369 6e68  sinh_", "arcsinh
-0000b010: 2229 0a0a 2020 2020 6465 6620 6172 6374  ")..    def arct
-0000b020: 616e 6828 7365 6c66 293a 0a20 2020 2020  anh(self):.     
-0000b030: 2020 2072 6574 7572 6e20 7365 6c66 2e61     return self.a
-0000b040: 7461 6e68 2829 0a0a 2020 2020 6465 6620  tanh()..    def 
-0000b050: 6172 6374 616e 685f 2873 656c 6629 3a0a  arctanh_(self):.
-0000b060: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-0000b070: 2073 656c 662e 6174 616e 6828 290a 2020   self.atanh().  
-0000b080: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-0000b090: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-0000b0a0: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-0000b0b0: 2c20 2261 7263 7461 6e68 5f22 2c20 2261  , "arctanh_", "a
-0000b0c0: 7263 7461 6e68 2229 0a0a 2020 2020 6465  rctanh")..    de
-0000b0d0: 6620 6465 7428 7365 6c66 293a 0a20 2020  f det(self):.   
-0000b0e0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0000b0f0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-0000b100: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-0000b110: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-0000b120: 6465 7428 696e 7075 745f 6d73 290a 2020  det(input_ms).  
-0000b130: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-0000b140: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-0000b150: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-0000b160: 2064 6566 206e 6567 6174 6976 6528 7365   def negative(se
-0000b170: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
-0000b180: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0000b190: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0000b1a0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-0000b1b0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-0000b1c0: 656e 736f 7228 696e 7075 745f 6d73 2e6e  ensor(input_ms.n
-0000b1d0: 6567 6174 6976 6528 2929 0a0a 2020 2020  egative())..    
-0000b1e0: 6465 6620 6e65 6761 7469 7665 5f28 7365  def negative_(se
-0000b1f0: 6c66 293a 0a20 2020 2020 2020 206f 7574  lf):.        out
-0000b200: 7075 7420 3d20 7365 6c66 2e6e 6567 6174  put = self.negat
-0000b210: 6976 6528 290a 2020 2020 2020 2020 7265  ive().        re
-0000b220: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
-0000b230: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
-0000b240: 2c20 6f75 7470 7574 2c20 226e 6567 6174  , output, "negat
-0000b250: 6976 655f 222c 2022 6e65 6761 7469 7665  ive_", "negative
-0000b260: 2229 0a0a 2020 2020 6465 6620 6162 7328  ")..    def abs(
-0000b270: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
-0000b280: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0000b290: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0000b2a0: 290a 2020 2020 2020 2020 6966 2069 6e70  ).        if inp
-0000b2b0: 7574 5f6d 732e 6474 7970 6520 696e 205b  ut_ms.dtype in [
-0000b2c0: 6d73 7479 7065 2e63 6f6d 706c 6578 3634  mstype.complex64
-0000b2d0: 2c20 6d73 7479 7065 2e63 6f6d 706c 6578  , mstype.complex
-0000b2e0: 3132 385d 3a0a 2020 2020 2020 2020 2020  128]:.          
-0000b2f0: 2020 6f75 7470 7574 203d 205f 6765 745f    output = _get_
-0000b300: 6361 6368 655f 7072 696d 286d 732e 6f70  cache_prim(ms.op
-0000b310: 732e 436f 6d70 6c65 7841 6273 2928 2928  s.ComplexAbs)()(
-0000b320: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
-0000b330: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-0000b340: 2020 2020 6f75 7470 7574 203d 2069 6e70      output = inp
-0000b350: 7574 5f6d 732e 6162 7328 290a 2020 2020  ut_ms.abs().    
-0000b360: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-0000b370: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-0000b380: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-0000b390: 6566 2061 6273 5f28 7365 6c66 293a 0a20  ef abs_(self):. 
-0000b3a0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0000b3b0: 7365 6c66 2e61 6273 2829 0a20 2020 2020  self.abs().     
-0000b3c0: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-0000b3d0: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-0000b3e0: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-0000b3f0: 6162 735f 222c 2022 6162 7322 290a 0a20  abs_", "abs").. 
-0000b400: 2020 2040 7072 6f70 6572 7479 0a20 2020     @property.   
-0000b410: 2064 6566 206e 6469 6d28 7365 6c66 293a   def ndim(self):
-0000b420: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000b430: 6c65 6e28 7365 6c66 2e73 6861 7065 290a  len(self.shape).
-0000b440: 0a20 2020 2064 6566 2061 6d61 7828 7365  .    def amax(se
-0000b450: 6c66 2c20 6469 6d3d 4e6f 6e65 2c20 6b65  lf, dim=None, ke
-0000b460: 6570 6469 6d3d 4661 6c73 6529 3a0a 2020  epdim=False):.  
-0000b470: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-0000b480: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0000b490: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-0000b4a0: 2069 6620 6469 6d20 6973 206e 6f74 204e   if dim is not N
-0000b4b0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-0000b4c0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0000b4d0: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
-0000b4e0: 6e70 7574 5f6d 732e 616d 6178 2861 7869  nput_ms.amax(axi
-0000b4f0: 733d 6469 6d2c 206b 6565 7064 696d 733d  s=dim, keepdims=
-0000b500: 6b65 6570 6469 6d29 290a 2020 2020 2020  keepdim)).      
-0000b510: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0000b520: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0000b530: 696e 7075 745f 6d73 2e61 6d61 7828 6b65  input_ms.amax(ke
-0000b540: 6570 6469 6d73 3d6b 6565 7064 696d 2929  epdims=keepdim))
-0000b550: 0a0a 2020 2020 6465 6620 616d 696e 2873  ..    def amin(s
-0000b560: 656c 662c 2064 696d 3d4e 6f6e 652c 206b  elf, dim=None, k
-0000b570: 6565 7064 696d 3d46 616c 7365 293a 0a20  eepdim=False):. 
-0000b580: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0000b590: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-0000b5a0: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-0000b5b0: 2020 6966 2064 696d 2069 7320 6e6f 7420    if dim is not 
-0000b5c0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
-0000b5d0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0000b5e0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0000b5f0: 696e 7075 745f 6d73 2e61 6d69 6e28 6178  input_ms.amin(ax
-0000b600: 6973 3d64 696d 2c20 6b65 6570 6469 6d73  is=dim, keepdims
-0000b610: 3d6b 6565 7064 696d 2929 0a20 2020 2020  =keepdim)).     
-0000b620: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-0000b630: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-0000b640: 2869 6e70 7574 5f6d 732e 616d 696e 286b  (input_ms.amin(k
-0000b650: 6565 7064 696d 733d 6b65 6570 6469 6d29  eepdims=keepdim)
-0000b660: 290a 0a20 2020 2064 6566 2061 735f 7374  )..    def as_st
-0000b670: 7269 6465 6428 7365 6c66 2c20 7369 7a65  rided(self, size
-0000b680: 2c20 7374 7269 6465 2c20 7374 6f72 6167  , stride, storag
-0000b690: 655f 6f66 6673 6574 3d4e 6f6e 6529 3a0a  e_offset=None):.
-0000b6a0: 2020 2020 2020 2020 7761 726e 696e 6728          warning(
-0000b6b0: 226e 6f74 2073 7570 706f 7274 206f 7574  "not support out
-0000b6c0: 7075 7420 6173 2061 2076 6965 772e 2229  put as a view.")
-0000b6d0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0000b6e0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0000b6f0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0000b700: 2020 2020 6966 206c 656e 2873 697a 6529      if len(size)
-0000b710: 2021 3d20 6c65 6e28 7374 7269 6465 293a   != len(stride):
-0000b720: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0000b730: 7365 2052 756e 7469 6d65 4572 726f 7228  se RuntimeError(
-0000b740: 226d 6973 6d61 7463 6820 696e 206c 656e  "mismatch in len
-0000b750: 6774 6820 6f66 2073 7472 6964 6573 2061  gth of strides a
-0000b760: 6e64 2073 6861 7065 2e22 290a 2020 2020  nd shape.").    
-0000b770: 2020 2020 696e 6465 7820 3d20 6e70 2e61      index = np.a
-0000b780: 7261 6e67 6528 302c 2073 697a 655b 305d  range(0, size[0]
-0000b790: 2a73 7472 6964 655b 305d 2c20 7374 7269  *stride[0], stri
-0000b7a0: 6465 5b30 5d29 0a20 2020 2020 2020 2066  de[0]).        f
-0000b7b0: 6f72 2069 2069 6e20 7261 6e67 6528 312c  or i in range(1,
-0000b7c0: 206c 656e 2873 697a 6529 293a 0a20 2020   len(size)):.   
-0000b7d0: 2020 2020 2020 2020 2074 6d70 203d 206e           tmp = n
-0000b7e0: 702e 6172 616e 6765 2830 2c20 7369 7a65  p.arange(0, size
-0000b7f0: 5b69 5d2a 7374 7269 6465 5b69 5d2c 2073  [i]*stride[i], s
-0000b800: 7472 6964 655b 695d 290a 2020 2020 2020  tride[i]).      
-0000b810: 2020 2020 2020 696e 6465 7820 3d20 6e70        index = np
-0000b820: 2e65 7870 616e 645f 6469 6d73 2869 6e64  .expand_dims(ind
-0000b830: 6578 2c20 2d31 290a 2020 2020 2020 2020  ex, -1).        
-0000b840: 2020 2020 696e 6465 7820 3d20 696e 6465      index = inde
-0000b850: 7820 2b20 746d 700a 2020 2020 2020 2020  x + tmp.        
-0000b860: 6966 2073 746f 7261 6765 5f6f 6666 7365  if storage_offse
-0000b870: 7420 6973 206e 6f74 204e 6f6e 653a 0a20  t is not None:. 
-0000b880: 2020 2020 2020 2020 2020 2069 6e64 6578             index
-0000b890: 203d 2069 6e64 6578 202b 2073 746f 7261   = index + stora
-0000b8a0: 6765 5f6f 6666 7365 740a 2020 2020 2020  ge_offset.      
-0000b8b0: 2020 6966 2069 6e64 6578 2e73 697a 6520    if index.size 
-0000b8c0: 3d3d 2030 3a0a 2020 2020 2020 2020 2020  == 0:.          
-0000b8d0: 2020 696e 7075 745f 696e 6469 6365 7320    input_indices 
-0000b8e0: 3d20 6d73 2e6e 756d 7079 2e65 6d70 7479  = ms.numpy.empty
-0000b8f0: 2869 6e64 6578 2e73 6861 7065 2c20 6474  (index.shape, dt
-0000b900: 7970 653d 6d73 7479 7065 2e69 6e74 3332  ype=mstype.int32
-0000b910: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-0000b920: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
-0000b930: 745f 696e 6469 6365 7320 3d20 6d73 2e54  t_indices = ms.T
-0000b940: 656e 736f 7228 696e 6465 7829 0a20 2020  ensor(index).   
-0000b950: 2020 2020 206f 7574 203d 206d 732e 6f70       out = ms.op
-0000b960: 732e 6761 7468 6572 2869 6e70 7574 5f6d  s.gather(input_m
-0000b970: 732e 7265 7368 6170 6528 2d31 292c 2069  s.reshape(-1), i
-0000b980: 6e70 7574 5f69 6e64 6963 6573 2c20 3029  nput_indices, 0)
-0000b990: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000b9a0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-0000b9b0: 7465 6e73 6f72 286f 7574 290a 0a20 2020  tensor(out)..   
-0000b9c0: 2064 6566 2062 6d6d 2873 656c 662c 2062   def bmm(self, b
-0000b9d0: 6174 6368 3229 3a0a 2020 2020 2020 2020  atch2):.        
-0000b9e0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-0000b9f0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-0000ba00: 6629 0a20 2020 2020 2020 2072 6574 7572  f).        retur
-0000ba10: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-0000ba20: 725f 7465 6e73 6f72 2869 6e70 7574 5f6d  r_tensor(input_m
-0000ba30: 732e 626d 6d28 6261 7463 6832 2929 0a0a  s.bmm(batch2))..
-0000ba40: 2020 2020 6465 6620 636c 616d 7028 7365      def clamp(se
-0000ba50: 6c66 2c20 6d69 6e3d 4e6f 6e65 2c20 6d61  lf, min=None, ma
-0000ba60: 783d 4e6f 6e65 293a 0a20 2020 2020 2020  x=None):.       
-0000ba70: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-0000ba80: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-0000ba90: 6c66 290a 2020 2020 2020 2020 6966 2069  lf).        if i
-0000baa0: 735f 756e 6465 725f 6173 6365 6e64 5f63  s_under_ascend_c
-0000bab0: 6f6e 7465 7874 2829 2061 6e64 2069 6e70  ontext() and inp
-0000bac0: 7574 5f6d 732e 6474 7970 6520 3d3d 206d  ut_ms.dtype == m
-0000bad0: 732e 666c 6f61 7436 343a 0a20 2020 2020  s.float64:.     
-0000bae0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0000baf0: 3d20 696e 7075 745f 6d73 2e61 7374 7970  = input_ms.astyp
-0000bb00: 6528 6d73 2e66 6c6f 6174 3332 290a 2020  e(ms.float32).  
-0000bb10: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-0000bb20: 203d 206d 732e 6f70 732e 636c 616d 7028   = ms.ops.clamp(
-0000bb30: 696e 7075 745f 6d73 2c20 6d69 6e2c 206d  input_ms, min, m
-0000bb40: 6178 290a 2020 2020 2020 2020 2020 2020  ax).            
-0000bb50: 6f75 7470 7574 203d 206f 7574 7075 742e  output = output.
-0000bb60: 6173 7479 7065 286d 732e 666c 6f61 7436  astype(ms.float6
-0000bb70: 3429 0a20 2020 2020 2020 2065 6c73 653a  4).        else:
-0000bb80: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-0000bb90: 7075 7420 3d20 6d73 2e6f 7073 2e63 6c61  put = ms.ops.cla
-0000bba0: 6d70 2869 6e70 7574 5f6d 732c 206d 696e  mp(input_ms, min
-0000bbb0: 2c20 6d61 7829 0a20 2020 2020 2020 2072  , max).        r
-0000bbc0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0000bbd0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-0000bbe0: 7075 7429 0a0a 2020 2020 6465 6620 636c  put)..    def cl
-0000bbf0: 616d 705f 2873 656c 662c 206d 696e 3d4e  amp_(self, min=N
-0000bc00: 6f6e 652c 206d 6178 3d4e 6f6e 6529 3a0a  one, max=None):.
-0000bc10: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-0000bc20: 2073 656c 662e 636c 616d 7028 6d69 6e2c   self.clamp(min,
-0000bc30: 206d 6178 290a 2020 2020 2020 2020 7265   max).        re
-0000bc40: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
-0000bc50: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
-0000bc60: 2c20 6f75 7470 7574 2c20 2263 6c61 6d70  , output, "clamp
-0000bc70: 5f22 2c20 2263 6c61 6d70 2229 0a0a 2020  _", "clamp")..  
-0000bc80: 2020 6465 6620 6469 6d28 7365 6c66 293a    def dim(self):
-0000bc90: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000bca0: 6c65 6e28 7365 6c66 2e73 6861 7065 290a  len(self.shape).
-0000bcb0: 0a20 2020 2064 6566 2065 7870 616e 645f  .    def expand_
-0000bcc0: 6173 2873 656c 662c 206f 7468 6572 293a  as(self, other):
-0000bcd0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0000bce0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0000bcf0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0000bd00: 2020 2020 6f74 6865 725f 6d73 203d 2063      other_ms = c
-0000bd10: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0000bd20: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
-0000bd30: 6f75 7470 7574 203d 2069 6e70 7574 5f6d  output = input_m
-0000bd40: 732e 6578 7061 6e64 5f61 7328 6f74 6865  s.expand_as(othe
-0000bd50: 725f 6d73 290a 2020 2020 2020 2020 7265  r_ms).        re
-0000bd60: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-0000bd70: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-0000bd80: 7574 290a 0a20 2020 2064 6566 2069 7465  ut)..    def ite
-0000bd90: 6d28 7365 6c66 293a 0a20 2020 2020 2020  m(self):.       
-0000bda0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-0000bdb0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-0000bdc0: 6c66 290a 2020 2020 2020 2020 6966 2069  lf).        if i
-0000bdd0: 6e70 7574 5f6d 732e 7369 7a65 203e 2031  nput_ms.size > 1
-0000bde0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-0000bdf0: 6973 6520 5661 6c75 6545 7272 6f72 2822  ise ValueError("
-0000be00: 6f6e 6c79 206f 6e65 2065 6c65 6d65 6e74  only one element
-0000be10: 2074 656e 736f 7273 2063 616e 2062 6520   tensors can be 
-0000be20: 636f 6e76 6572 7465 6420 746f 2050 7974  converted to Pyt
-0000be30: 686f 6e20 7363 616c 6172 7322 290a 2020  hon scalars").  
-0000be40: 2020 2020 2020 6f75 7470 7574 203d 2069        output = i
-0000be50: 6e70 7574 5f6d 732e 6173 6e75 6d70 7928  nput_ms.asnumpy(
-0000be60: 292e 7265 7368 6170 6528 2d31 292e 746f  ).reshape(-1).to
-0000be70: 6c69 7374 2829 0a20 2020 2020 2020 2072  list().        r
-0000be80: 6574 7572 6e20 6f75 7470 7574 5b30 5d0a  eturn output[0].
-0000be90: 0a20 2020 2064 6566 206c 6f67 2873 656c  .    def log(sel
-0000bea0: 6629 3a0a 2020 2020 2020 2020 696e 7075  f):.        inpu
-0000beb0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-0000bec0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-0000bed0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0000bee0: 696e 7075 745f 6d73 2e6c 6f67 2829 0a20  input_ms.log(). 
-0000bef0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-0000bf00: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-0000bf10: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-0000bf20: 2020 6465 6620 6c6f 675f 2873 656c 6629    def log_(self)
-0000bf30: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-0000bf40: 203d 2073 656c 662e 6c6f 6728 290a 2020   = self.log().  
-0000bf50: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-0000bf60: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-0000bf70: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-0000bf80: 2c20 226c 6f67 5f22 2c20 226c 6f67 2229  , "log_", "log")
-0000bf90: 0a0a 2020 2020 6465 6620 6c6f 6732 2873  ..    def log2(s
-0000bfa0: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
-0000bfb0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-0000bfc0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-0000bfd0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-0000bfe0: 3d20 6d73 2e6f 7073 2e6c 6f67 3228 696e  = ms.ops.log2(in
-0000bff0: 7075 745f 6d73 290a 2020 2020 2020 2020  put_ms).        
-0000c000: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0000c010: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-0000c020: 7470 7574 290a 0a20 2020 2064 6566 206c  tput)..    def l
-0000c030: 6f67 325f 2873 656c 6629 3a0a 2020 2020  og2_(self):.    
-0000c040: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-0000c050: 662e 6c6f 6732 2829 0a20 2020 2020 2020  f.log2().       
-0000c060: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
-0000c070: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
-0000c080: 656c 662c 206f 7574 7075 742c 2022 6c6f  elf, output, "lo
-0000c090: 6732 5f22 2c20 226c 6f67 3222 290a 0a20  g2_", "log2").. 
-0000c0a0: 2020 2023 2054 4f44 4f3a 2063 7572 7265     # TODO: curre
-0000c0b0: 6e74 6c79 206e 6f74 2073 7570 706f 7274  ntly not support
-0000c0c0: 2072 6574 7572 6e20 7172 2061 7320 7365   return qr as se
-0000c0d0: 636f 6e64 2072 6573 756c 740a 2020 2020  cond result.    
-0000c0e0: 6465 6620 6c73 7473 7128 7365 6c66 2c20  def lstsq(self, 
-0000c0f0: 4129 3a0a 2020 2020 2020 2020 696e 7075  A):.        inpu
-0000c100: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-0000c110: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-0000c120: 2020 2020 2020 2041 203d 2063 6173 745f         A = cast_
-0000c130: 746f 5f6d 735f 7465 6e73 6f72 2841 290a  to_ms_tensor(A).
-0000c140: 2020 2020 2020 2020 6966 2069 735f 756e          if is_un
-0000c150: 6465 725f 6370 755f 636f 6e74 6578 7428  der_cpu_context(
-0000c160: 293a 0a20 2020 2020 2020 2020 2020 206f  ):.            o
-0000c170: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6c  utput = ms.ops.l
-0000c180: 7374 7371 2841 2c20 696e 7075 745f 6d73  stsq(A, input_ms
-0000c190: 290a 2020 2020 2020 2020 2020 2020 7172  ).            qr
-0000c1a0: 203d 206d 732e 6f70 732e 7a65 726f 7328   = ms.ops.zeros(
-0000c1b0: 412e 7368 6170 652c 2041 2e64 7479 7065  A.shape, A.dtype
-0000c1c0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-0000c1d0: 2020 2020 2020 2020 2020 2020 2354 4f44              #TOD
-0000c1e0: 4f3a 206d 732e 6f70 732e 6c73 7473 7120  O: ms.ops.lstsq 
-0000c1f0: 6e6f 7420 7375 7070 6f72 7420 4750 5520  not support GPU 
-0000c200: 616e 6420 4173 6365 6e64 2c20 7573 6520  and Ascend, use 
-0000c210: 6e75 6d70 7920 6675 6e63 0a20 2020 2020  numpy func.     
-0000c220: 2020 2020 2020 206c 7374 7371 5f6f 7020         lstsq_op 
-0000c230: 3d20 6e75 6d70 795f 6365 6c6c 2e4e 756d  = numpy_cell.Num
-0000c240: 7079 4c73 7473 7128 276c 7374 7371 2729  pyLstsq('lstsq')
-0000c250: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-0000c260: 7075 742c 2071 7220 3d20 6c73 7473 715f  put, qr = lstsq_
-0000c270: 6f70 2869 6e70 7574 5f6d 732c 2041 290a  op(input_ms, A).
-0000c280: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-0000c290: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-0000c2a0: 656e 736f 7228 286f 7574 7075 742c 2071  ensor((output, q
-0000c2b0: 7229 290a 0a20 2020 2064 6566 206d 6174  r))..    def mat
-0000c2c0: 6d75 6c28 7365 6c66 2c20 7465 6e73 6f72  mul(self, tensor
-0000c2d0: 3229 3a0a 2020 2020 2020 2020 696e 7075  2):.        inpu
-0000c2e0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-0000c2f0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-0000c300: 2020 2020 2020 2074 656e 736f 7232 5f6d         tensor2_m
-0000c310: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0000c320: 656e 736f 7228 7465 6e73 6f72 3229 0a20  ensor(tensor2). 
-0000c330: 2020 2020 2020 2023 2054 4f44 4f3a 2072         # TODO: r
-0000c340: 6570 616c 6365 2077 6974 6820 6f75 7470  epalce with outp
-0000c350: 7574 203d 206d 732e 6f70 732e 6d61 746d  ut = ms.ops.matm
-0000c360: 756c 2869 6e70 7574 5f6d 732c 2074 656e  ul(input_ms, ten
-0000c370: 736f 7232 5f6d 7329 0a20 2020 2020 2020  sor2_ms).       
-0000c380: 206f 7574 7075 7420 3d20 6375 7374 6f6d   output = custom
-0000c390: 5f6d 6174 6d75 6c28 696e 7075 745f 6d73  _matmul(input_ms
-0000c3a0: 2c20 7465 6e73 6f72 325f 6d73 290a 2020  , tensor2_ms).  
-0000c3b0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-0000c3c0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-0000c3d0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-0000c3e0: 2064 6566 2073 7175 6565 7a65 2873 656c   def squeeze(sel
-0000c3f0: 662c 2064 696d 3d4e 6f6e 6529 3a0a 2020  f, dim=None):.  
-0000c400: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-0000c410: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0000c420: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-0000c430: 2069 6620 6469 6d20 6973 206e 6f74 204e   if dim is not N
-0000c440: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-0000c450: 2069 6620 696e 7075 745f 6d73 2e73 6861   if input_ms.sha
-0000c460: 7065 5b64 696d 5d20 213d 2031 3a0a 2020  pe[dim] != 1:.  
-0000c470: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-0000c480: 7470 7574 203d 2069 6e70 7574 5f6d 730a  tput = input_ms.
-0000c490: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0000c4a0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000c4b0: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-0000c4c0: 732e 7371 7565 657a 6528 696e 7075 745f  s.squeeze(input_
-0000c4d0: 6d73 2c20 6469 6d29 0a20 2020 2020 2020  ms, dim).       
-0000c4e0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-0000c4f0: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
-0000c500: 7073 2e73 7175 6565 7a65 2869 6e70 7574  ps.squeeze(input
-0000c510: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
-0000c520: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-0000c530: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-0000c540: 7429 0a0a 2020 2020 6465 6620 7371 7565  t)..    def sque
-0000c550: 657a 655f 2873 656c 662c 2064 696d 3d4e  eze_(self, dim=N
-0000c560: 6f6e 6529 3a0a 2020 2020 2020 2020 6f75  one):.        ou
-0000c570: 7470 7574 203d 2073 656c 662e 7371 7565  tput = self.sque
-0000c580: 657a 6528 6469 6d29 0a20 2020 2020 2020  eze(dim).       
-0000c590: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
-0000c5a0: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
-0000c5b0: 656c 662c 206f 7574 7075 742c 2022 7371  elf, output, "sq
-0000c5c0: 7565 657a 655f 222c 2022 7371 7565 657a  ueeze_", "squeez
-0000c5d0: 6522 290a 0a20 2020 2064 6566 2073 7472  e")..    def str
-0000c5e0: 6964 6528 7365 6c66 2c20 6469 6d3d 4e6f  ide(self, dim=No
-0000c5f0: 6e65 293a 0a20 2020 2020 2020 2069 6e70  ne):.        inp
-0000c600: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0000c610: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0000c620: 2020 2020 2020 2020 6279 7465 6c65 6e20          bytelen 
-0000c630: 3d20 696e 7075 745f 6d73 2e69 7465 6d73  = input_ms.items
-0000c640: 697a 650a 2020 2020 2020 2020 6f75 7470  ize.        outp
-0000c650: 7574 203d 206c 6973 7428 696e 7075 745f  ut = list(input_
-0000c660: 6d73 2e73 7472 6964 6573 290a 2020 2020  ms.strides).    
-0000c670: 2020 2020 666f 7220 6920 696e 2072 616e      for i in ran
-0000c680: 6765 286c 656e 286f 7574 7075 7429 293a  ge(len(output)):
-0000c690: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-0000c6a0: 7075 745b 695d 203d 206f 7574 7075 745b  put[i] = output[
-0000c6b0: 695d 2f2f 6279 7465 6c65 6e0a 2020 2020  i]//bytelen.    
-0000c6c0: 2020 2020 6f75 7470 7574 203d 2074 7570      output = tup
-0000c6d0: 6c65 286f 7574 7075 7429 0a20 2020 2020  le(output).     
-0000c6e0: 2020 2069 6620 6469 6d20 6973 206e 6f74     if dim is not
-0000c6f0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-0000c700: 2020 206f 7574 7075 7420 3d20 6f75 7470     output = outp
-0000c710: 7574 5b64 696d 5d0a 2020 2020 2020 2020  ut[dim].        
-0000c720: 7265 7475 726e 206f 7574 7075 740a 0a20  return output.. 
-0000c730: 2020 2064 6566 2073 7562 2873 656c 662c     def sub(self,
-0000c740: 206f 7468 6572 2c20 2a2c 2061 6c70 6861   other, *, alpha
-0000c750: 3d31 293a 0a20 2020 2020 2020 2069 6e70  =1):.        inp
-0000c760: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0000c770: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0000c780: 2020 2020 2020 2020 696e 7075 745f 6f74          input_ot
-0000c790: 6865 7220 3d20 6361 7374 5f74 6f5f 6d73  her = cast_to_ms
-0000c7a0: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
-0000c7b0: 2020 2020 2020 2069 6620 616c 7068 6120         if alpha 
-0000c7c0: 213d 2031 3a0a 2020 2020 2020 2020 2020  != 1:.          
-0000c7d0: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-0000c7e0: 696e 7075 745f 6f74 6865 722c 206d 732e  input_other, ms.
-0000c7f0: 5465 6e73 6f72 2920 616e 6420 696e 7075  Tensor) and inpu
-0000c800: 745f 6f74 6865 722e 6474 7970 6520 696e  t_other.dtype in
-0000c810: 2061 6c6c 5f63 6f6d 706c 6578 5f74 7970   all_complex_typ
-0000c820: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-0000c830: 2020 2023 206d 732e 6f70 732e 6d75 6c20     # ms.ops.mul 
-0000c840: 6f6e 6c79 2073 7570 706f 7274 2074 656e  only support ten
-0000c850: 736f 7220 696e 7075 7420 7768 656e 2064  sor input when d
-0000c860: 7479 7065 2069 7320 636f 6d70 6c65 7820  type is complex 
-0000c870: 7479 7065 2e0a 2020 2020 2020 2020 2020  type..          
-0000c880: 2020 2020 2020 696e 7075 745f 6f74 6865        input_othe
-0000c890: 7220 3d20 696e 7075 745f 6f74 6865 7220  r = input_other 
-0000c8a0: 2a20 6d73 2e6f 7073 2e73 6361 6c61 725f  * ms.ops.scalar_
-0000c8b0: 746f 5f74 656e 736f 7228 616c 7068 612c  to_tensor(alpha,
-0000c8c0: 2069 6e70 7574 5f6f 7468 6572 2e64 7479   input_other.dty
-0000c8d0: 7065 290a 2020 2020 2020 2020 2020 2020  pe).            
-0000c8e0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0000c8f0: 2020 2020 2020 696e 7075 745f 6f74 6865        input_othe
-0000c900: 7220 3d20 696e 7075 745f 6f74 6865 7220  r = input_other 
-0000c910: 2a20 616c 7068 610a 2020 2020 2020 2020  * alpha.        
-0000c920: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-0000c930: 7375 6228 696e 7075 745f 6d73 2c20 696e  sub(input_ms, in
-0000c940: 7075 745f 6f74 6865 7229 0a20 2020 2020  put_other).     
-0000c950: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-0000c960: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-0000c970: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
-0000c980: 6620 7375 625f 2873 656c 662c 206f 7468  f sub_(self, oth
-0000c990: 6572 2c20 2a2c 2061 6c70 6861 3d31 293a  er, *, alpha=1):
-0000c9a0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-0000c9b0: 3d20 7365 6c66 2e73 7562 286f 7468 6572  = self.sub(other
-0000c9c0: 2c20 616c 7068 613d 616c 7068 6129 0a20  , alpha=alpha). 
-0000c9d0: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-0000c9e0: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-0000c9f0: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-0000ca00: 742c 2022 7375 625f 222c 2022 7375 6222  t, "sub_", "sub"
-0000ca10: 290a 0a20 2020 2064 6566 2069 735f 666c  )..    def is_fl
-0000ca20: 6f61 7469 6e67 5f70 6f69 6e74 2873 656c  oating_point(sel
-0000ca30: 6629 3a0a 2020 2020 2020 2020 696e 7075  f):.        inpu
-0000ca40: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-0000ca50: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-0000ca60: 2020 2020 2020 2072 6574 7572 6e20 696e         return in
-0000ca70: 7075 745f 6d73 2e69 735f 666c 6f61 7469  put_ms.is_floati
-0000ca80: 6e67 5f70 6f69 6e74 2829 0a0a 2020 2020  ng_point()..    
-0000ca90: 6465 6620 756e 6269 6e64 2873 656c 662c  def unbind(self,
-0000caa0: 2064 696d 3d30 293a 0a20 2020 2020 2020   dim=0):.       
-0000cab0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-0000cac0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-0000cad0: 6c66 290a 2020 2020 2020 2020 7265 7475  lf).        retu
-0000cae0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-0000caf0: 6572 5f74 656e 736f 7228 696e 7075 745f  er_tensor(input_
-0000cb00: 6d73 2e75 6e62 696e 6428 6469 6d29 290a  ms.unbind(dim)).
-0000cb10: 0a20 2020 2064 6566 2075 6e73 7175 6565  .    def unsquee
-0000cb20: 7a65 2873 656c 662c 2064 696d 293a 0a20  ze(self, dim):. 
-0000cb30: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0000cb40: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-0000cb50: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-0000cb60: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0000cb70: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0000cb80: 696e 7075 745f 6d73 2e75 6e73 7175 6565  input_ms.unsquee
-0000cb90: 7a65 2864 696d 2929 0a0a 2020 2020 6465  ze(dim))..    de
-0000cba0: 6620 756e 7371 7565 657a 655f 2873 656c  f unsqueeze_(sel
-0000cbb0: 662c 2064 696d 293a 0a20 2020 2020 2020  f, dim):.       
-0000cbc0: 206f 7574 7075 7420 3d20 7365 6c66 2e75   output = self.u
-0000cbd0: 6e73 7175 6565 7a65 2864 696d 290a 2020  nsqueeze(dim).  
-0000cbe0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-0000cbf0: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-0000cc00: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-0000cc10: 2c20 2275 6e73 7175 6565 7a65 5f22 2c20  , "unsqueeze_", 
-0000cc20: 2275 6e73 7175 6565 7a65 2229 0a0a 2020  "unsqueeze")..  
-0000cc30: 2020 6465 6620 6973 5f73 6967 6e65 6428    def is_signed(
-0000cc40: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
-0000cc50: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0000cc60: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0000cc70: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0000cc80: 2069 6e70 7574 5f6d 732e 6973 5f73 6967   input_ms.is_sig
-0000cc90: 6e65 6428 290a 0a20 2020 2064 6566 2074  ned()..    def t
-0000cca0: 7261 6e73 706f 7365 2873 656c 662c 2064  ranspose(self, d
-0000ccb0: 696d 302c 2064 696d 3129 3a0a 2020 2020  im0, dim1):.    
-0000ccc0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-0000ccd0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0000cce0: 2873 656c 6629 0a20 2020 2020 2020 2023  (self).        #
-0000ccf0: 2054 6865 2066 756e 6374 696f 6e73 206f   The functions o
-0000cd00: 6620 6d73 2e6f 7073 2e73 7761 7061 7865  f ms.ops.swapaxe
-0000cd10: 7320 6172 6520 636f 6e73 6973 7465 6e74  s are consistent
-0000cd20: 2077 6974 6820 746f 7263 682e 7472 616e   with torch.tran
-0000cd30: 7370 6f73 650a 2020 2020 2020 2020 6f75  spose.        ou
-0000cd40: 7470 7574 203d 206d 732e 6f70 732e 7377  tput = ms.ops.sw
-0000cd50: 6170 6178 6573 2869 6e70 7574 5f6d 732c  apaxes(input_ms,
-0000cd60: 2064 696d 302c 2064 696d 3129 0a20 2020   dim0, dim1).   
-0000cd70: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0000cd80: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0000cd90: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0000cda0: 6465 6620 7472 616e 7370 6f73 655f 2873  def transpose_(s
-0000cdb0: 656c 662c 2064 696d 302c 2064 696d 3129  elf, dim0, dim1)
-0000cdc0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-0000cdd0: 203d 2073 656c 662e 7472 616e 7370 6f73   = self.transpos
-0000cde0: 6528 6469 6d30 2c20 6469 6d31 290a 2020  e(dim0, dim1).  
-0000cdf0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-0000ce00: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-0000ce10: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-0000ce20: 2c20 2274 7261 6e73 706f 7365 5f22 2c20  , "transpose_", 
-0000ce30: 2274 7261 6e73 706f 7365 2229 0a0a 2020  "transpose")..  
-0000ce40: 2020 6465 6620 666c 6f6f 7228 7365 6c66    def floor(self
-0000ce50: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-0000ce60: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-0000ce70: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-0000ce80: 2020 2020 2020 6f75 7470 7574 203d 2069        output = i
-0000ce90: 6e70 7574 5f6d 732e 666c 6f6f 7228 290a  nput_ms.floor().
-0000cea0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-0000ceb0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-0000cec0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
-0000ced0: 2020 2064 6566 2066 6c6f 6f72 5f28 7365     def floor_(se
-0000cee0: 6c66 293a 0a20 2020 2020 2020 206f 7574  lf):.        out
-0000cef0: 7075 7420 3d20 7365 6c66 2e66 6c6f 6f72  put = self.floor
-0000cf00: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
-0000cf10: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-0000cf20: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-0000cf30: 7574 7075 742c 2022 666c 6f6f 725f 222c  utput, "floor_",
-0000cf40: 2022 666c 6f6f 7222 290a 0a20 2020 2064   "floor")..    d
-0000cf50: 6566 2069 7366 696e 6974 6528 7365 6c66  ef isfinite(self
-0000cf60: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-0000cf70: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-0000cf80: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-0000cf90: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-0000cfa0: 732e 6f70 732e 6973 6669 6e69 7465 2869  s.ops.isfinite(i
-0000cfb0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-0000cfc0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0000cfd0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-0000cfe0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-0000cff0: 6973 6e61 6e28 7365 6c66 293a 0a20 2020  isnan(self):.   
-0000d000: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0000d010: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-0000d020: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-0000d030: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0000d040: 6461 7074 6572 5f74 656e 736f 7228 696e  dapter_tensor(in
-0000d050: 7075 745f 6d73 2e69 736e 616e 2829 290a  put_ms.isnan()).
-0000d060: 0a20 2020 2064 6566 2069 735f 636f 6e74  .    def is_cont
-0000d070: 6967 756f 7573 2873 656c 662c 206d 656d  iguous(self, mem
-0000d080: 6f72 795f 666f 726d 6174 3d4e 6f6e 6529  ory_format=None)
-0000d090: 3a0a 2020 2020 2020 2020 756e 7375 7070  :.        unsupp
-0000d0a0: 6f72 7465 645f 6174 7472 286d 656d 6f72  orted_attr(memor
-0000d0b0: 795f 666f 726d 6174 290a 2020 2020 2020  y_format).      
-0000d0c0: 2020 7761 726e 696e 6728 2269 735f 636f    warning("is_co
-0000d0d0: 6e74 6967 756f 7573 2069 7320 616c 7761  ntiguous is alwa
-0000d0e0: 7973 2054 7275 6520 696e 2054 656e 736f  ys True in Tenso
-0000d0f0: 722e 2229 0a20 2020 2020 2020 2072 6574  r.").        ret
-0000d100: 7572 6e20 5472 7565 0a0a 2020 2020 6465  urn True..    de
-0000d110: 6620 6973 5f70 696e 6e65 6428 7365 6c66  f is_pinned(self
-0000d120: 293a 0a20 2020 2020 2020 2077 6172 6e69  ):.        warni
-0000d130: 6e67 2822 6973 5f70 696e 6e65 6420 6973  ng("is_pinned is
-0000d140: 2061 6c77 6179 7320 4661 6c73 6520 696e   always False in
-0000d150: 2054 656e 736f 722e 2229 0a20 2020 2020   Tensor.").     
-0000d160: 2020 2072 6574 7572 6e20 4661 6c73 650a     return False.
-0000d170: 0a20 2020 2064 6566 2069 735f 7365 745f  .    def is_set_
-0000d180: 746f 2873 656c 662c 2074 656e 736f 7229  to(self, tensor)
-0000d190: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
-0000d1a0: 2069 6428 7365 6c66 2e74 656e 736f 7229   id(self.tensor)
-0000d1b0: 203d 3d20 6964 2874 656e 736f 722e 7465   == id(tensor.te
-0000d1c0: 6e73 6f72 290a 0a20 2020 2064 6566 2069  nsor)..    def i
-0000d1d0: 735f 7368 6172 6564 2873 656c 6629 3a0a  s_shared(self):.
-0000d1e0: 2020 2020 2020 2020 7761 726e 696e 6728          warning(
-0000d1f0: 2269 735f 7368 6172 6564 2069 7320 616c  "is_shared is al
-0000d200: 7761 7973 2046 616c 7365 2069 6e20 5465  ways False in Te
-0000d210: 6e73 6f72 2e22 290a 2020 2020 2020 2020  nsor.").        
-0000d220: 7265 7475 726e 2046 616c 7365 0a0a 2020  return False..  
-0000d230: 2020 4070 726f 7065 7274 790a 2020 2020    @property.    
-0000d240: 6465 6620 6973 5f73 7061 7273 6528 7365  def is_sparse(se
-0000d250: 6c66 293a 0a20 2020 2020 2020 2077 6172  lf):.        war
-0000d260: 6e69 6e67 2822 6973 5f73 7061 7273 6520  ning("is_sparse 
-0000d270: 6973 2061 6c77 6179 7320 4661 6c73 6520  is always False 
-0000d280: 696e 2054 656e 736f 722e 2229 0a20 2020  in Tensor.").   
-0000d290: 2020 2020 2072 6574 7572 6e20 4661 6c73       return Fals
-0000d2a0: 650a 0a20 2020 2064 6566 2070 696e 5f6d  e..    def pin_m
-0000d2b0: 656d 6f72 7928 7365 6c66 293a 0a20 2020  emory(self):.   
-0000d2c0: 2020 2020 2077 6172 6e69 6e67 2822 4375       warning("Cu
-0000d2d0: 7272 656e 746c 792c 2070 696e 5f6d 656d  rrently, pin_mem
-0000d2e0: 6f72 7920 6973 206e 6f74 2065 6666 6563  ory is not effec
-0000d2f0: 7469 7665 2e22 290a 2020 2020 2020 2020  tive.").        
-0000d300: 7265 7475 726e 2073 656c 660a 0a20 2020  return self..   
-0000d310: 2064 6566 2063 6c6f 6e65 2873 656c 6629   def clone(self)
-0000d320: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-0000d330: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0000d340: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-0000d350: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0000d360: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0000d370: 6f72 2869 6e70 7574 5f6d 732e 636f 7079  or(input_ms.copy
-0000d380: 2829 290a 0a20 2020 2064 6566 2074 6f28  ())..    def to(
-0000d390: 7365 6c66 2c20 2a61 7267 732c 202a 2a6b  self, *args, **k
-0000d3a0: 7761 7267 7329 3a0a 2020 2020 2020 2020  wargs):.        
-0000d3b0: 2320 544f 444f 3a0a 2020 2020 2020 2020  # TODO:.        
-0000d3c0: 2320 4e6f 7465 2074 6861 7420 7468 6973  # Note that this
-0000d3d0: 2041 5049 2072 6571 7569 7265 7320 7468   API requires th
-0000d3e0: 6520 7573 6572 2074 6f20 656e 7375 7265  e user to ensure
-0000d3f0: 2074 6865 2063 6f72 7265 6374 6e65 7373   the correctness
-0000d400: 206f 6620 7468 6520 696e 7075 7420 6375   of the input cu
-0000d410: 7272 656e 746c 792c 0a20 2020 2020 2020  rrently,.       
-0000d420: 2023 2061 6e64 206f 6e6c 7920 7468 6520   # and only the 
-0000d430: 6675 6e63 7469 6f6e 206f 6620 6d6f 6469  function of modi
-0000d440: 6679 696e 6720 6474 7970 6520 6973 2061  fying dtype is a
-0000d450: 7661 696c 6162 6c65 2e0a 0a20 2020 2020  vailable...     
-0000d460: 2020 2069 6620 6c65 6e28 6172 6773 2920     if len(args) 
-0000d470: 3d3d 2030 2061 6e64 206c 656e 286b 7761  == 0 and len(kwa
-0000d480: 7267 7329 203d 3d20 303a 0a20 2020 2020  rgs) == 0:.     
-0000d490: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-0000d4a0: 7565 4572 726f 7228 2254 656e 736f 722e  ueError("Tensor.
-0000d4b0: 746f 2069 7320 6d69 7373 696e 6720 696e  to is missing in
-0000d4c0: 7075 7473 2c20 706c 6561 7365 2063 6865  puts, please che
-0000d4d0: 636b 2e22 290a 2020 2020 2020 2020 696e  ck.").        in
-0000d4e0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-0000d4f0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-0000d500: 0a0a 2020 2020 2020 2020 6966 2022 6474  ..        if "dt
-0000d510: 7970 6522 2069 6e20 6b77 6172 6773 3a0a  ype" in kwargs:.
-0000d520: 2020 2020 2020 2020 2020 2020 7365 745f              set_
-0000d530: 6474 7970 6520 3d20 6b77 6172 6773 2e67  dtype = kwargs.g
-0000d540: 6574 2822 6474 7970 6522 290a 2020 2020  et("dtype").    
-0000d550: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-0000d560: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-0000d570: 656e 736f 7228 696e 7075 745f 6d73 2e61  ensor(input_ms.a
-0000d580: 7374 7970 6528 7365 745f 6474 7970 6529  stype(set_dtype)
-0000d590: 290a 2020 2020 2020 2020 656c 6966 2022  ).        elif "
-0000d5a0: 6f74 6865 7222 2069 6e20 6b77 6172 6773  other" in kwargs
-0000d5b0: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
-0000d5c0: 745f 6474 7970 6520 3d20 6b77 6172 6773  t_dtype = kwargs
-0000d5d0: 2e67 6574 2822 6f74 6865 7222 292e 6474  .get("other").dt
-0000d5e0: 7970 650a 2020 2020 2020 2020 2020 2020  ype.            
-0000d5f0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0000d600: 6461 7074 6572 5f74 656e 736f 7228 696e  dapter_tensor(in
-0000d610: 7075 745f 6d73 2e61 7374 7970 6528 7365  put_ms.astype(se
-0000d620: 745f 6474 7970 6529 290a 2020 2020 2020  t_dtype)).      
-0000d630: 2020 656c 6966 2022 6465 7669 6365 2220    elif "device" 
-0000d640: 696e 206b 7761 7267 733a 0a20 2020 2020  in kwargs:.     
-0000d650: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-0000d660: 6c66 0a0a 2020 2020 2020 2020 6966 206c  lf..        if l
-0000d670: 656e 2861 7267 7329 203d 3d20 303a 0a20  en(args) == 0:. 
-0000d680: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-0000d690: 6e20 7365 6c66 0a0a 2020 2020 2020 2020  n self..        
-0000d6a0: 6966 2061 7267 735b 305d 2069 6e20 5f64  if args[0] in _d
-0000d6b0: 7479 7065 4469 6374 2e76 616c 7565 7328  typeDict.values(
-0000d6c0: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
-0000d6d0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0000d6e0: 6170 7465 725f 7465 6e73 6f72 2869 6e70  apter_tensor(inp
-0000d6f0: 7574 5f6d 732e 6173 7479 7065 2861 7267  ut_ms.astype(arg
-0000d700: 735b 305d 2929 0a20 2020 2020 2020 2065  s[0])).        e
-0000d710: 6c69 6620 6973 696e 7374 616e 6365 2861  lif isinstance(a
-0000d720: 7267 735b 305d 2c20 5465 6e73 6f72 293a  rgs[0], Tensor):
-0000d730: 0a20 2020 2020 2020 2020 2020 2073 6574  .            set
-0000d740: 5f64 7479 7065 203d 2061 7267 735b 305d  _dtype = args[0]
-0000d750: 2e64 7479 7065 0a20 2020 2020 2020 2020  .dtype.         
-0000d760: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-0000d770: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-0000d780: 2869 6e70 7574 5f6d 732e 6173 7479 7065  (input_ms.astype
-0000d790: 2873 6574 5f64 7479 7065 2929 0a20 2020  (set_dtype)).   
-0000d7a0: 2020 2020 2065 6c69 6620 6172 6773 5b30       elif args[0
-0000d7b0: 5d20 616e 6420 6e6f 7420 6973 696e 7374  ] and not isinst
-0000d7c0: 616e 6365 2861 7267 735b 305d 2c20 2873  ance(args[0], (s
-0000d7d0: 7472 2c20 6465 7669 6365 5f63 6c61 7373  tr, device_class
-0000d7e0: 2c20 696e 7429 293a 0a20 2020 2020 2020  , int)):.       
-0000d7f0: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
-0000d800: 4572 726f 7228 2254 6865 2069 6e70 7574  Error("The input
-0000d810: 7320 6f66 2054 656e 736f 722e 746f 2069  s of Tensor.to i
-0000d820: 7320 6162 6e6f 726d 616c 2c20 706c 6561  s abnormal, plea
-0000d830: 7365 2063 6865 636b 2e22 290a 0a20 2020  se check.")..   
-0000d840: 2020 2020 2069 6620 6c65 6e28 6172 6773       if len(args
-0000d850: 2920 3e20 3120 616e 6420 6172 6773 5b31  ) > 1 and args[1
-0000d860: 5d20 696e 205f 6474 7970 6544 6963 742e  ] in _dtypeDict.
-0000d870: 7661 6c75 6573 2829 3a0a 2020 2020 2020  values():.      
-0000d880: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-0000d890: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-0000d8a0: 736f 7228 696e 7075 745f 6d73 2e61 7374  sor(input_ms.ast
-0000d8b0: 7970 6528 6172 6773 5b31 5d29 290a 2020  ype(args[1])).  
-0000d8c0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-0000d8d0: 660a 0a20 2020 2064 6566 2073 6f72 7428  f..    def sort(
-0000d8e0: 7365 6c66 2c20 6469 6d3d 2d31 2c20 6465  self, dim=-1, de
-0000d8f0: 7363 656e 6469 6e67 3d46 616c 7365 293a  scending=False):
-0000d900: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0000d910: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0000d920: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0000d930: 2020 2020 696e 7075 745f 7479 7065 203d      input_type =
-0000d940: 2069 6e70 7574 5f6d 732e 6474 7970 650a   input_ms.dtype.
-0000d950: 2020 2020 2020 2020 6966 2027 496e 7427          if 'Int'
-0000d960: 2069 6e20 7374 7228 696e 7075 745f 7479   in str(input_ty
-0000d970: 7065 293a 0a20 2020 2020 2020 2020 2020  pe):.           
-0000d980: 2069 6e70 7574 5f6d 7320 3d20 696e 7075   input_ms = inpu
-0000d990: 745f 6d73 2e61 7374 7970 6528 6d73 2e66  t_ms.astype(ms.f
-0000d9a0: 6c6f 6174 3332 290a 2020 2020 2020 2020  loat32).        
-0000d9b0: 2020 2020 736f 7274 5f74 656e 736f 722c      sort_tensor,
-0000d9c0: 2073 6f72 745f 696e 6465 7820 3d20 6d73   sort_index = ms
-0000d9d0: 2e6f 7073 2e73 6f72 7428 696e 7075 745f  .ops.sort(input_
-0000d9e0: 6d73 2c20 6469 6d2c 2064 6573 6365 6e64  ms, dim, descend
-0000d9f0: 696e 6729 0a20 2020 2020 2020 2020 2020  ing).           
-0000da00: 2073 6f72 745f 7465 6e73 6f72 203d 2073   sort_tensor = s
-0000da10: 6f72 745f 7465 6e73 6f72 2e61 7374 7970  ort_tensor.astyp
-0000da20: 6528 696e 7075 745f 7479 7065 290a 2020  e(input_type).  
-0000da30: 2020 2020 2020 2020 2020 736f 7274 5f69            sort_i
-0000da40: 6e64 6578 203d 2073 6f72 745f 696e 6465  ndex = sort_inde
-0000da50: 782e 6173 7479 7065 286d 732e 696e 7436  x.astype(ms.int6
-0000da60: 3429 0a20 2020 2020 2020 2020 2020 2072  4).            r
-0000da70: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0000da80: 6170 7465 725f 7465 6e73 6f72 2828 736f  apter_tensor((so
-0000da90: 7274 5f74 656e 736f 722c 2073 6f72 745f  rt_tensor, sort_
-0000daa0: 696e 6465 7829 290a 2020 2020 2020 2020  index)).        
-0000dab0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0000dac0: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-0000dad0: 732e 736f 7274 2869 6e70 7574 5f6d 732c  s.sort(input_ms,
-0000dae0: 2064 696d 2c20 6465 7363 656e 6469 6e67   dim, descending
-0000daf0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0000db00: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-0000db10: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-0000db20: 0a20 2020 2064 6566 206d 736f 7274 2873  .    def msort(s
-0000db30: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
-0000db40: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-0000db50: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-0000db60: 0a20 2020 2020 2020 2069 6e70 7574 5f74  .        input_t
-0000db70: 7970 6520 3d20 696e 7075 745f 6d73 2e64  ype = input_ms.d
-0000db80: 7479 7065 0a20 2020 2020 2020 2069 6620  type.        if 
-0000db90: 696e 7075 745f 7479 7065 2069 6e20 6d73  input_type in ms
-0000dba0: 6461 7074 6572 5f64 7479 7065 2e61 6c6c  dapter_dtype.all
-0000dbb0: 5f69 6e74 5f74 7970 653a 0a20 2020 2020  _int_type:.     
-0000dbc0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0000dbd0: 3d20 696e 7075 745f 6d73 2e61 7374 7970  = input_ms.astyp
-0000dbe0: 6528 6d73 2e66 6c6f 6174 3332 290a 2020  e(ms.float32).  
-0000dbf0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-0000dc00: 3d20 6d73 2e6f 7073 2e6d 736f 7274 2869  = ms.ops.msort(i
-0000dc10: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-0000dc20: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
-0000dc30: 7470 7574 2e61 7374 7970 6528 696e 7075  tput.astype(inpu
-0000dc40: 745f 7479 7065 290a 2020 2020 2020 2020  t_type).        
-0000dc50: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-0000dc60: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-0000dc70: 732e 6d73 6f72 7428 696e 7075 745f 6d73  s.msort(input_ms
-0000dc80: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0000dc90: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-0000dca0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-0000dcb0: 0a20 2020 2064 6566 2061 7267 736f 7274  .    def argsort
-0000dcc0: 2873 656c 662c 2064 696d 3d2d 312c 2064  (self, dim=-1, d
-0000dcd0: 6573 6365 6e64 696e 673d 4661 6c73 6529  escending=False)
-0000dce0: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-0000dcf0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0000dd00: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-0000dd10: 2020 2020 2069 6620 696e 7075 745f 6d73       if input_ms
-0000dd20: 2e64 7479 7065 2069 6e20 6d73 6461 7074  .dtype in msdapt
-0000dd30: 6572 5f64 7479 7065 2e61 6c6c 5f69 6e74  er_dtype.all_int
-0000dd40: 5f74 7970 653a 0a20 2020 2020 2020 2020  _type:.         
-0000dd50: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
-0000dd60: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
-0000dd70: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
-0000dd80: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-0000dd90: 732e 6f70 732e 6172 6773 6f72 7428 696e  s.ops.argsort(in
-0000dda0: 7075 745f 6d73 2c20 6469 6d2c 2064 6573  put_ms, dim, des
-0000ddb0: 6365 6e64 696e 6729 0a20 2020 2020 2020  cending).       
-0000ddc0: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
-0000ddd0: 7470 7574 2e61 7374 7970 6528 6d73 2e69  tput.astype(ms.i
-0000dde0: 6e74 3634 290a 2020 2020 2020 2020 656c  nt64).        el
-0000ddf0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-0000de00: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-0000de10: 6172 6773 6f72 7428 696e 7075 745f 6d73  argsort(input_ms
-0000de20: 2c20 6469 6d2c 2064 6573 6365 6e64 696e  , dim, descendin
-0000de30: 6729 0a20 2020 2020 2020 2072 6574 7572  g).        retur
-0000de40: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-0000de50: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-0000de60: 0a0a 2020 2020 6465 6620 7371 7274 2873  ..    def sqrt(s
-0000de70: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
-0000de80: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-0000de90: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-0000dea0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000deb0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-0000dec0: 7465 6e73 6f72 286d 732e 6f70 732e 7371  tensor(ms.ops.sq
-0000ded0: 7274 2869 6e70 7574 5f6d 7329 290a 0a20  rt(input_ms)).. 
-0000dee0: 2020 2064 6566 2073 7172 745f 2873 656c     def sqrt_(sel
-0000def0: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
-0000df00: 7574 203d 2073 656c 662e 7371 7274 2829  ut = self.sqrt()
-0000df10: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000df20: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-0000df30: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-0000df40: 7075 742c 2022 7371 7274 5f22 2c20 2273  put, "sqrt_", "s
-0000df50: 7172 7422 290a 0a20 2020 2064 6566 2072  qrt")..    def r
-0000df60: 7371 7274 2873 656c 6629 3a0a 2020 2020  sqrt(self):.    
-0000df70: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-0000df80: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0000df90: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
-0000dfa0: 6620 696e 7075 745f 6d73 2e64 7479 7065  f input_ms.dtype
-0000dfb0: 2069 6e20 616c 6c5f 696e 745f 7479 7065   in all_int_type
-0000dfc0: 5f77 6974 685f 626f 6f6c 3a0a 2020 2020  _with_bool:.    
-0000dfd0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-0000dfe0: 203d 2069 6e70 7574 5f6d 732e 6173 7479   = input_ms.asty
-0000dff0: 7065 286d 732e 666c 6f61 7433 3229 0a20  pe(ms.float32). 
-0000e000: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0000e010: 6d73 2e6f 7073 2e72 7371 7274 2869 6e70  ms.ops.rsqrt(inp
-0000e020: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
-0000e030: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0000e040: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-0000e050: 7075 7429 0a0a 2020 2020 6465 6620 7273  put)..    def rs
-0000e060: 7172 745f 2873 656c 6629 3a0a 2020 2020  qrt_(self):.    
-0000e070: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-0000e080: 662e 7273 7172 7428 290a 2020 2020 2020  f.rsqrt().      
-0000e090: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
-0000e0a0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
-0000e0b0: 7365 6c66 2c20 6f75 7470 7574 2c20 2272  self, output, "r
-0000e0c0: 7371 7274 5f22 2c20 2272 7371 7274 2229  sqrt_", "rsqrt")
-0000e0d0: 0a0a 2020 2020 6465 6620 7265 7369 7a65  ..    def resize
-0000e0e0: 2873 656c 662c 202a 7369 7a65 2c20 6d65  (self, *size, me
-0000e0f0: 6d6f 7279 5f66 6f72 6d61 743d 4e6f 6e65  mory_format=None
-0000e100: 293a 0a20 2020 2020 2020 2075 6e73 7570  ):.        unsup
-0000e110: 706f 7274 6564 5f61 7474 7228 6d65 6d6f  ported_attr(memo
-0000e120: 7279 5f66 6f72 6d61 7429 0a20 2020 2020  ry_format).     
-0000e130: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-0000e140: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-0000e150: 7365 6c66 290a 2020 2020 2020 2020 696e  self).        in
-0000e160: 7075 745f 7369 7a65 203d 2069 6e70 7574  put_size = input
-0000e170: 5f6d 732e 7368 6170 650a 2020 2020 2020  _ms.shape.      
-0000e180: 2020 6966 206c 656e 2869 6e70 7574 5f73    if len(input_s
-0000e190: 697a 6529 203d 3d20 3120 616e 6420 696e  ize) == 1 and in
-0000e1a0: 7075 745f 7369 7a65 5b30 5d20 3d3d 2030  put_size[0] == 0
-0000e1b0: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
-0000e1c0: 2069 7369 6e73 7461 6e63 6528 7369 7a65   isinstance(size
-0000e1d0: 5b30 5d2c 2028 7475 706c 652c 206c 6973  [0], (tuple, lis
-0000e1e0: 7429 293a 0a20 2020 2020 2020 2020 2020  t)):.           
-0000e1f0: 2020 2020 2073 697a 6520 3d20 7369 7a65       size = size
-0000e200: 5b30 5d0a 2020 2020 2020 2020 2020 2020  [0].            
-0000e210: 6f75 7420 3d20 6d73 2e6f 7073 2e7a 6572  out = ms.ops.zer
-0000e220: 6f73 2873 697a 652c 2073 656c 662e 6474  os(size, self.dt
-0000e230: 7970 6529 0a20 2020 2020 2020 2065 6c69  ype).        eli
-0000e240: 6620 6c65 6e28 7369 7a65 2920 3e20 3020  f len(size) > 0 
-0000e250: 616e 6420 6973 696e 7374 616e 6365 2873  and isinstance(s
-0000e260: 697a 655b 305d 2c20 7475 706c 6529 3a0a  ize[0], tuple):.
-0000e270: 2020 2020 2020 2020 2020 2020 6f75 7420              out 
-0000e280: 3d20 696e 7075 745f 6d73 2e72 6573 697a  = input_ms.resiz
-0000e290: 6528 7369 7a65 5b30 5d29 0a20 2020 2020  e(size[0]).     
-0000e2a0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0000e2b0: 2020 2020 206f 7574 203d 2069 6e70 7574       out = input
-0000e2c0: 5f6d 732e 7265 7369 7a65 2873 697a 6529  _ms.resize(size)
-0000e2d0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0000e2e0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-0000e2f0: 7465 6e73 6f72 286f 7574 290a 0a20 2020  tensor(out)..   
-0000e300: 2064 6566 2072 6573 697a 655f 2873 656c   def resize_(sel
-0000e310: 662c 202a 7369 7a65 2c20 6d65 6d6f 7279  f, *size, memory
-0000e320: 5f66 6f72 6d61 743d 4e6f 6e65 293a 0a20  _format=None):. 
-0000e330: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0000e340: 7365 6c66 2e72 6573 697a 6528 2a73 697a  self.resize(*siz
-0000e350: 652c 206d 656d 6f72 795f 666f 726d 6174  e, memory_format
-0000e360: 3d6d 656d 6f72 795f 666f 726d 6174 290a  =memory_format).
-0000e370: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-0000e380: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-0000e390: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-0000e3a0: 7574 2c20 2272 6573 697a 655f 222c 2022  ut, "resize_", "
-0000e3b0: 7265 7369 7a65 2229 0a0a 2020 2020 6465  resize")..    de
-0000e3c0: 6620 7265 7369 7a65 5f61 7328 7365 6c66  f resize_as(self
-0000e3d0: 2c20 7465 6e73 6f72 2c20 6d65 6d6f 7279  , tensor, memory
-0000e3e0: 5f66 6f72 6d61 743d 4e6f 6e65 293a 0a20  _format=None):. 
-0000e3f0: 2020 2020 2020 2075 6e73 7570 706f 7274         unsupport
-0000e400: 6564 5f61 7474 7228 6d65 6d6f 7279 5f66  ed_attr(memory_f
-0000e410: 6f72 6d61 7429 0a20 2020 2020 2020 2069  ormat).        i
-0000e420: 6620 6e6f 7420 6973 696e 7374 616e 6365  f not isinstance
-0000e430: 2874 656e 736f 722c 2054 656e 736f 7229  (tensor, Tensor)
-0000e440: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
-0000e450: 6973 6520 5479 7065 4572 726f 7228 2272  ise TypeError("r
-0000e460: 6573 697a 655f 6173 2829 3a20 6172 6775  esize_as(): argu
-0000e470: 6d65 6e74 2027 7465 6e73 6f72 2720 6d75  ment 'tensor' mu
-0000e480: 7374 2062 6520 5465 6e73 6f72 2e22 290a  st be Tensor.").
-0000e490: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-0000e4a0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-0000e4b0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-0000e4c0: 2020 2073 697a 6520 3d20 7465 6e73 6f72     size = tensor
-0000e4d0: 2e73 6861 7065 0a20 2020 2020 2020 2069  .shape.        i
-0000e4e0: 6e70 7574 5f73 697a 6520 3d20 696e 7075  nput_size = inpu
-0000e4f0: 745f 6d73 2e73 6861 7065 0a20 2020 2020  t_ms.shape.     
-0000e500: 2020 2069 6620 6c65 6e28 696e 7075 745f     if len(input_
-0000e510: 7369 7a65 2920 3d3d 2031 2061 6e64 2069  size) == 1 and i
-0000e520: 6e70 7574 5f73 697a 655b 305d 203d 3d20  nput_size[0] == 
-0000e530: 303a 0a20 2020 2020 2020 2020 2020 206f  0:.            o
-0000e540: 7574 203d 206d 732e 6f70 732e 7a65 726f  ut = ms.ops.zero
-0000e550: 7328 7369 7a65 2c20 7365 6c66 2e64 7479  s(size, self.dty
-0000e560: 7065 290a 2020 2020 2020 2020 656c 7365  pe).        else
-0000e570: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
-0000e580: 7420 3d20 696e 7075 745f 6d73 2e72 6573  t = input_ms.res
-0000e590: 697a 6528 7369 7a65 290a 2020 2020 2020  ize(size).      
-0000e5a0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0000e5b0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0000e5c0: 6f75 7429 0a0a 2020 2020 6465 6620 7265  out)..    def re
-0000e5d0: 7369 7a65 5f61 735f 2873 656c 662c 2074  size_as_(self, t
-0000e5e0: 656e 736f 722c 206d 656d 6f72 795f 666f  ensor, memory_fo
-0000e5f0: 726d 6174 3d4e 6f6e 6529 3a0a 2020 2020  rmat=None):.    
-0000e600: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-0000e610: 662e 7265 7369 7a65 5f61 7328 7465 6e73  f.resize_as(tens
-0000e620: 6f72 2c20 6d65 6d6f 7279 5f66 6f72 6d61  or, memory_forma
-0000e630: 7429 0a20 2020 2020 2020 2072 6574 7572  t).        retur
-0000e640: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-0000e650: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-0000e660: 7574 7075 742c 2022 7265 7369 7a65 5f61  utput, "resize_a
-0000e670: 735f 222c 2022 7265 7369 7a65 5f61 7322  s_", "resize_as"
-0000e680: 290a 0a20 2020 2064 6566 2069 6e64 6578  )..    def index
-0000e690: 5f66 696c 6c28 7365 6c66 2c20 6469 6d2c  _fill(self, dim,
-0000e6a0: 2069 6e64 6578 2c20 7661 6c75 6529 3a0a   index, value):.
-0000e6b0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-0000e6c0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-0000e6d0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-0000e6e0: 2020 2069 6e64 6578 203d 2063 6173 745f     index = cast_
-0000e6f0: 746f 5f6d 735f 7465 6e73 6f72 2869 6e64  to_ms_tensor(ind
-0000e700: 6578 290a 2020 2020 2020 2020 696e 6465  ex).        inde
-0000e710: 7820 3d20 6d73 2e6f 7073 2e63 6173 7428  x = ms.ops.cast(
-0000e720: 696e 6465 782c 206d 7374 7970 652e 696e  index, mstype.in
-0000e730: 7433 3229 0a20 2020 2020 2020 206f 7574  t32).        out
-0000e740: 203d 2069 6e70 7574 5f6d 732e 696e 6465   = input_ms.inde
-0000e750: 785f 6669 6c6c 2864 696d 2c20 696e 6465  x_fill(dim, inde
-0000e760: 782c 2076 616c 7565 290a 2020 2020 2020  x, value).      
-0000e770: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0000e780: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0000e790: 6f75 7429 0a0a 2020 2020 6465 6620 696e  out)..    def in
-0000e7a0: 6465 785f 6669 6c6c 5f28 7365 6c66 2c20  dex_fill_(self, 
-0000e7b0: 6469 6d2c 2069 6e64 6578 2c20 7661 6c75  dim, index, valu
-0000e7c0: 6529 3a0a 2020 2020 2020 2020 6f75 7470  e):.        outp
-0000e7d0: 7574 203d 2073 656c 662e 696e 6465 785f  ut = self.index_
-0000e7e0: 6669 6c6c 2864 696d 2c20 696e 6465 782c  fill(dim, index,
-0000e7f0: 2076 616c 7565 290a 2020 2020 2020 2020   value).        
-0000e800: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-0000e810: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-0000e820: 6c66 2c20 6f75 7470 7574 2c20 2269 6e64  lf, output, "ind
-0000e830: 6578 5f66 696c 6c5f 222c 2022 696e 6465  ex_fill_", "inde
-0000e840: 785f 6669 6c6c 2229 0a0a 2020 2020 6465  x_fill")..    de
-0000e850: 6620 696e 6465 785f 7365 6c65 6374 2873  f index_select(s
-0000e860: 656c 662c 2064 696d 2c20 696e 6465 7829  elf, dim, index)
-0000e870: 3a0a 2020 2020 2020 2020 5f69 6e70 7574  :.        _input
-0000e880: 5f70 6172 616d 7320 3d20 6361 7374 5f74  _params = cast_t
-0000e890: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0000e8a0: 290a 2020 2020 2020 2020 5f69 6e70 7574  ).        _input
-0000e8b0: 5f69 6e64 6963 6573 203d 2063 6173 745f  _indices = cast_
-0000e8c0: 746f 5f6d 735f 7465 6e73 6f72 2869 6e64  to_ms_tensor(ind
-0000e8d0: 6578 290a 0a20 2020 2020 2020 206f 7574  ex)..        out
-0000e8e0: 7075 7420 3d20 6d73 2e6f 7073 2e67 6174  put = ms.ops.gat
-0000e8f0: 6865 7228 5f69 6e70 7574 5f70 6172 616d  her(_input_param
-0000e900: 732c 205f 696e 7075 745f 696e 6469 6365  s, _input_indice
-0000e910: 732c 2064 696d 290a 2020 2020 2020 2020  s, dim).        
-0000e920: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0000e930: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-0000e940: 7470 7574 290a 0a20 2020 2040 7072 6f70  tput)..    @prop
-0000e950: 6572 7479 0a20 2020 2064 6566 2064 6174  erty.    def dat
-0000e960: 6128 7365 6c66 293a 0a20 2020 2020 2020  a(self):.       
-0000e970: 2072 6574 7572 6e20 7365 6c66 2e64 6574   return self.det
-0000e980: 6163 6828 290a 0a20 2020 2040 6461 7461  ach()..    @data
-0000e990: 2e73 6574 7465 720a 2020 2020 6465 6620  .setter.    def 
-0000e9a0: 6461 7461 2873 656c 662c 2064 6174 6129  data(self, data)
-0000e9b0: 3a0a 2020 2020 2020 2020 6d73 5f64 6174  :.        ms_dat
-0000e9c0: 6120 3d20 6361 7374 5f74 6f5f 6d73 5f74  a = cast_to_ms_t
-0000e9d0: 656e 736f 7228 6461 7461 290a 2020 2020  ensor(data).    
-0000e9e0: 2020 2020 7365 6c66 2e61 7373 6967 6e5f      self.assign_
-0000e9f0: 7661 6c75 6528 6d73 5f64 6174 6129 0a0a  value(ms_data)..
-0000ea00: 2020 2020 6465 6620 6e65 7728 7365 6c66      def new(self
-0000ea10: 2c20 2a73 697a 6529 3a0a 2020 2020 2020  , *size):.      
-0000ea20: 2020 6966 206c 656e 2873 697a 6529 203e    if len(size) >
-0000ea30: 2030 2061 6e64 2069 7369 6e73 7461 6e63   0 and isinstanc
-0000ea40: 6528 7369 7a65 5b30 5d2c 2074 7570 6c65  e(size[0], tuple
-0000ea50: 293a 0a20 2020 2020 2020 2020 2020 2073  ):.            s
-0000ea60: 697a 6520 3d20 7369 7a65 5b30 5d0a 2020  ize = size[0].  
-0000ea70: 2020 2020 2020 5f64 7479 7065 203d 2073        _dtype = s
-0000ea80: 656c 662e 6474 7970 650a 2020 2020 2020  elf.dtype.      
-0000ea90: 2020 7265 7475 726e 2054 656e 736f 7228    return Tensor(
-0000eaa0: 2a73 697a 652c 2064 7479 7065 3d5f 6474  *size, dtype=_dt
-0000eab0: 7970 6529 0a0a 2020 2020 6465 6620 6375  ype)..    def cu
-0000eac0: 6461 2873 656c 662c 2064 6576 6963 653d  da(self, device=
-0000ead0: 4e6f 6e65 2c20 6e6f 6e5f 626c 6f63 6b69  None, non_blocki
-0000eae0: 6e67 3d46 616c 7365 2c20 6d65 6d6f 7279  ng=False, memory
-0000eaf0: 5f66 6f72 6d61 743d 4e6f 6e65 293a 0a20  _format=None):. 
-0000eb00: 2020 2020 2020 2075 6e73 7570 706f 7274         unsupport
-0000eb10: 6564 5f61 7474 7228 6465 7669 6365 290a  ed_attr(device).
-0000eb20: 2020 2020 2020 2020 756e 7375 7070 6f72          unsuppor
-0000eb30: 7465 645f 6174 7472 286e 6f6e 5f62 6c6f  ted_attr(non_blo
-0000eb40: 636b 696e 6729 0a20 2020 2020 2020 2075  cking).        u
-0000eb50: 6e73 7570 706f 7274 6564 5f61 7474 7228  nsupported_attr(
-0000eb60: 6d65 6d6f 7279 5f66 6f72 6d61 7429 0a20  memory_format). 
-0000eb70: 2020 2020 2020 2069 6620 6e6f 7420 6973         if not is
-0000eb80: 5f75 6e64 6572 5f67 7075 5f63 6f6e 7465  _under_gpu_conte
-0000eb90: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
-0000eba0: 2020 6261 636b 656e 6420 3d20 6765 745f    backend = get_
-0000ebb0: 6261 636b 656e 6428 290a 2020 2020 2020  backend().      
-0000ebc0: 2020 2020 2020 7761 726e 696e 675f 6d73        warning_ms
-0000ebd0: 6720 3d20 6622 4d73 4164 6174 6572 2e70  g = f"MsAdater.p
-0000ebe0: 7974 6f72 6368 2e54 656e 736f 722e 6375  ytorch.Tensor.cu
-0000ebf0: 6461 2829 2064 6964 6e27 7420 776f 726b  da() didn't work
-0000ec00: 2062 6563 6175 7365 2069 7420 6973 2075   because it is u
-0000ec10: 6e64 6572 207b 6261 636b 656e 647d 2063  nder {backend} c
-0000ec20: 6f6e 7465 7874 2e22 0a20 2020 2020 2020  ontext.".       
-0000ec30: 2020 2020 2077 6172 6e69 6e67 2877 6172       warning(war
-0000ec40: 6e69 6e67 5f6d 7367 290a 2020 2020 2020  ning_msg).      
-0000ec50: 2020 7265 7475 726e 2073 656c 660a 0a20    return self.. 
-0000ec60: 2020 2064 6566 2069 735f 6375 6461 2873     def is_cuda(s
-0000ec70: 656c 6629 3a0a 2020 2020 2020 2020 7265  elf):.        re
-0000ec80: 7475 726e 2069 735f 756e 6465 725f 6770  turn is_under_gp
-0000ec90: 755f 636f 6e74 6578 7428 290a 0a20 2020  u_context()..   
-0000eca0: 2064 6566 206c 6528 7365 6c66 2c20 6f74   def le(self, ot
-0000ecb0: 6865 7229 3a0a 2020 2020 2020 2020 696e  her):.        in
-0000ecc0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-0000ecd0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-0000ece0: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
-0000ecf0: 7374 616e 6365 286f 7468 6572 2c20 5465  stance(other, Te
-0000ed00: 6e73 6f72 293a 0a20 2020 2020 2020 2020  nsor):.         
-0000ed10: 2020 206f 7468 6572 203d 2063 6173 745f     other = cast_
-0000ed20: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
-0000ed30: 6572 290a 2020 2020 2020 2020 6f75 7420  er).        out 
-0000ed40: 3d20 6d73 2e6f 7073 2e6c 6528 696e 7075  = ms.ops.le(inpu
-0000ed50: 745f 6d73 2c20 6f74 6865 7229 0a20 2020  t_ms, other).   
-0000ed60: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0000ed70: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0000ed80: 6f72 286f 7574 290a 0a20 2020 2064 6566  or(out)..    def
-0000ed90: 206c 655f 2873 656c 662c 206f 7468 6572   le_(self, other
-0000eda0: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
-0000edb0: 7420 3d20 7365 6c66 2e6c 6528 6f74 6865  t = self.le(othe
-0000edc0: 7229 0a20 2020 2020 2020 2072 6574 7572  r).        retur
-0000edd0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-0000ede0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-0000edf0: 7574 7075 742c 2022 6c65 5f22 2c20 226c  utput, "le_", "l
-0000ee00: 6522 290a 0a20 2020 2064 6566 2074 2873  e")..    def t(s
-0000ee10: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
-0000ee20: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-0000ee30: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-0000ee40: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-0000ee50: 3d20 6d73 2e6f 7073 2e74 2869 6e70 7574  = ms.ops.t(input
-0000ee60: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
-0000ee70: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-0000ee80: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-0000ee90: 7429 0a0a 2020 2020 6465 6620 745f 2873  t)..    def t_(s
-0000eea0: 656c 6629 3a0a 2020 2020 2020 2020 6f75  elf):.        ou
-0000eeb0: 7470 7574 203d 2073 656c 662e 7428 290a  tput = self.t().
-0000eec0: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-0000eed0: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-0000eee0: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-0000eef0: 7574 2c20 2274 5f22 2c20 2274 2229 0a0a  ut, "t_", "t")..
-0000ef00: 2020 2020 4070 726f 7065 7274 790a 2020      @property.  
-0000ef10: 2020 6465 6620 5428 7365 6c66 293a 0a20    def T(self):. 
-0000ef20: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0000ef30: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-0000ef40: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-0000ef50: 2020 6966 2069 6e70 7574 5f6d 732e 6e64    if input_ms.nd
-0000ef60: 696d 203c 3d20 323a 0a20 2020 2020 2020  im <= 2:.       
-0000ef70: 2020 2020 2077 6172 6e69 6e67 5f6d 7367       warning_msg
-0000ef80: 203d 2028 2254 6865 2075 7365 206f 6620   = ("The use of 
-0000ef90: 5465 6e73 6f72 2e54 2829 206f 6e20 7465  Tensor.T() on te
-0000efa0: 6e73 6f72 7320 6f66 2064 696d 656e 7369  nsors of dimensi
-0000efb0: 6f6e 206f 7468 6572 2074 6861 6e20 3220  on other than 2 
-0000efc0: 746f 2072 6576 6572 7365 2022 0a20 2020  to reverse ".   
-0000efd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000efe0: 2020 2020 2020 2020 2274 6865 6972 2073          "their s
-0000eff0: 6861 7065 2069 7320 6465 7072 6563 6174  hape is deprecat
-0000f000: 6564 2061 6e64 2069 7420 7769 6c6c 2074  ed and it will t
-0000f010: 6872 6f77 2061 6e20 6572 726f 7220 696e  hrow an error in
-0000f020: 2061 2066 7574 7572 6520 7265 6c65 6173   a future releas
-0000f030: 652e 2022 290a 2020 2020 2020 2020 2020  e. ").          
-0000f040: 2020 7761 726e 696e 6728 7761 726e 696e    warning(warnin
-0000f050: 675f 6d73 6729 0a20 2020 2020 2020 206f  g_msg).        o
-0000f060: 7574 7075 7420 3d20 696e 7075 745f 6d73  utput = input_ms
-0000f070: 2e74 7261 6e73 706f 7365 2829 0a20 2020  .transpose().   
-0000f080: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0000f090: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0000f0a0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0000f0b0: 4070 726f 7065 7274 790a 2020 2020 6465  @property.    de
-0000f0c0: 6620 4828 7365 6c66 293a 0a20 2020 2020  f H(self):.     
-0000f0d0: 2020 2023 2054 4f44 4f3a 2074 6f72 6368     # TODO: torch
-0000f0e0: 2069 7320 7669 6577 206f 6620 6f72 6967   is view of orig
-0000f0f0: 696e 2054 656e 736f 722c 2062 7574 2061  in Tensor, but a
-0000f100: 6461 7074 6572 2063 7265 6174 6520 6120  dapter create a 
-0000f110: 6e65 7720 7465 6e73 6f72 0a20 2020 2020  new tensor.     
-0000f120: 2020 2069 6620 6e6f 7420 7365 6c66 2e6e     if not self.n
-0000f130: 6469 6d20 3d3d 2032 3a0a 2020 2020 2020  dim == 2:.      
-0000f140: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
-0000f150: 6545 7272 6f72 2866 2274 656e 736f 722e  eError(f"tensor.
-0000f160: 4820 6973 206f 6e6c 7920 7375 7070 6f72  H is only suppor
-0000f170: 7465 6420 6f6e 206d 6174 7269 6365 7320  ted on matrices 
-0000f180: 2832 2d44 2074 656e 736f 7273 292e 2047  (2-D tensors). G
-0000f190: 6f74 207b 7365 6c66 2e6e 6469 6d7d 2d44  ot {self.ndim}-D
-0000f1a0: 2074 656e 736f 722e 2229 0a0a 2020 2020   tensor.")..    
-0000f1b0: 2020 2020 6966 2073 656c 662e 6973 5f63      if self.is_c
-0000f1c0: 6f6d 706c 6578 2829 3a0a 2020 2020 2020  omplex():.      
-0000f1d0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-0000f1e0: 662e 7472 616e 7370 6f73 6528 302c 2031  f.transpose(0, 1
-0000f1f0: 292e 636f 6e6a 2829 0a20 2020 2020 2020  ).conj().       
-0000f200: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
-0000f210: 2020 2072 6574 7572 6e20 7365 6c66 2e74     return self.t
-0000f220: 7261 6e73 706f 7365 2830 2c20 3129 0a0a  ranspose(0, 1)..
-0000f230: 2020 2020 4070 726f 7065 7274 790a 2020      @property.  
-0000f240: 2020 6465 6620 6973 5f71 7561 6e74 697a    def is_quantiz
-0000f250: 6564 2873 656c 6629 3a0a 2020 2020 2020  ed(self):.      
-0000f260: 2020 7761 726e 696e 6728 2274 656e 736f    warning("tenso
-0000f270: 722e 6973 5f71 7561 6e74 697a 6564 206f  r.is_quantized o
-0000f280: 6e6c 7920 7375 7070 706f 7274 2073 6574  nly suppport set
-0000f290: 2074 6f20 4661 6c73 6520 6e6f 772e 2053   to False now. S
-0000f2a0: 6f20 4974 2069 7320 616c 7761 7973 2046  o It is always F
-0000f2b0: 616c 7365 2e22 290a 2020 2020 2020 2020  alse.").        
-0000f2c0: 7265 7475 726e 2046 616c 7365 0a0a 2020  return False..  
-0000f2d0: 2020 4069 735f 7175 616e 7469 7a65 642e    @is_quantized.
-0000f2e0: 7365 7474 6572 0a20 2020 2064 6566 2069  setter.    def i
-0000f2f0: 735f 7175 616e 7469 7a65 6428 7365 6c66  s_quantized(self
-0000f300: 2c20 666c 6167 293a 0a20 2020 2020 2020  , flag):.       
-0000f310: 2072 6169 7365 2041 7474 7269 6275 7465   raise Attribute
-0000f320: 4572 726f 7228 2261 7474 7269 6275 7465  Error("attribute
-0000f330: 2027 6973 5f71 7561 6e74 697a 6564 2720   'is_quantized' 
-0000f340: 6f66 2027 746f 7263 682e 5465 6e73 6f72  of 'torch.Tensor
-0000f350: 2720 6f62 6a65 6374 7320 6973 206e 6f74  ' objects is not
-0000f360: 2077 7269 7461 626c 652e 2229 0a0a 2020   writable.")..  
-0000f370: 2020 4070 726f 7065 7274 790a 2020 2020    @property.    
-0000f380: 6465 6620 7265 7175 6972 6573 5f67 7261  def requires_gra
-0000f390: 6428 7365 6c66 293a 0a20 2020 2020 2020  d(self):.       
-0000f3a0: 2077 6172 6e69 6e67 2822 7465 6e73 6f72   warning("tensor
-0000f3b0: 2e72 6571 7569 7265 735f 6772 6164 206f  .requires_grad o
-0000f3c0: 6e6c 7920 7375 7070 706f 7274 2073 6574  nly suppport set
-0000f3d0: 2074 6f20 5472 7565 206e 6f77 2e20 536f   to True now. So
-0000f3e0: 2049 7420 6973 2061 6c77 6179 7320 5472   It is always Tr
-0000f3f0: 7565 2e22 290a 2020 2020 2020 2020 7265  ue.").        re
-0000f400: 7475 726e 2054 7275 650a 0a20 2020 2040  turn True..    @
-0000f410: 7265 7175 6972 6573 5f67 7261 642e 7365  requires_grad.se
-0000f420: 7474 6572 0a20 2020 2064 6566 2072 6571  tter.    def req
-0000f430: 7569 7265 735f 6772 6164 2873 656c 662c  uires_grad(self,
-0000f440: 2066 6c61 6729 3a0a 2020 2020 2020 2020   flag):.        
-0000f450: 6966 206e 6f74 2069 7369 6e73 7461 6e63  if not isinstanc
-0000f460: 6528 666c 6167 2c20 626f 6f6c 293a 0a20  e(flag, bool):. 
-0000f470: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-0000f480: 2052 756e 7469 6d65 4572 726f 7228 2272   RuntimeError("r
-0000f490: 6571 7569 7265 735f 6772 6164 206d 7573  equires_grad mus
-0000f4a0: 7420 6265 2061 2062 6f6f 6c22 290a 2020  t be a bool").  
-0000f4b0: 2020 2020 2020 6966 2066 6c61 6720 6973        if flag is
-0000f4c0: 2046 616c 7365 3a0a 2020 2020 2020 2020   False:.        
-0000f4d0: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
-0000f4e0: 6c65 6d65 6e74 6564 4572 726f 7228 2274  lementedError("t
-0000f4f0: 656e 736f 722e 7265 7175 6972 6573 5f67  ensor.requires_g
-0000f500: 7261 6420 6361 6e20 6e6f 7420 7365 7420  rad can not set 
-0000f510: 746f 2046 616c 7365 2079 6574 2e20 220a  to False yet. ".
-0000f520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f540: 2020 2020 2020 2249 6620 7465 6e73 6f72        "If tensor
-0000f550: 2069 7320 6e6f 7420 6c65 6166 2054 656e   is not leaf Ten
-0000f560: 736f 722c 2063 616e 2074 7279 2074 656e  sor, can try ten
-0000f570: 736f 722e 6465 7461 6368 2829 2069 6e73  sor.detach() ins
-0000f580: 7465 6164 2e20 220a 2020 2020 2020 2020  tead. ".        
-0000f590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f5a0: 2020 2020 2020 2020 2020 2020 2020 2249                "I
-0000f5b0: 6620 7465 6e73 6f72 2069 7320 6c65 6166  f tensor is leaf
-0000f5c0: 2054 656e 736f 722c 2063 616e 2072 6570   Tensor, can rep
-0000f5d0: 6c61 6365 7320 7465 6e73 6f72 2077 6974  laces tensor wit
-0000f5e0: 6820 5061 7261 6d65 7465 722c 2062 6563  h Parameter, bec
-0000f5f0: 6175 7365 2022 0a20 2020 2020 2020 2020  ause ".         
-0000f600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f610: 2020 2020 2020 2020 2020 2020 2022 5061               "Pa
-0000f620: 7261 6d65 7465 722e 7265 7175 6972 6573  rameter.requires
-0000f630: 5f67 7261 6420 776f 726b 2077 6974 6820  _grad work with 
-0000f640: 6d69 6e64 7370 6f72 6520 6175 746f 6772  mindspore autogr
-0000f650: 6164 206d 6563 6861 6e69 736d 2c20 220a  ad mechanism, ".
-0000f660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f680: 2020 2020 2020 2277 6865 6e20 6974 2073        "when it s
-0000f690: 6574 2074 6f20 4661 6c73 652c 2074 6865  et to False, the
-0000f6a0: 2067 7261 6469 656e 7420 7265 7475 726e   gradient return
-0000f6b0: 2062 7920 6d73 2e67 7261 6422 0a20 2020   by ms.grad".   
-0000f6c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f6e0: 2020 2022 2868 7474 7073 3a2f 2f77 7777     "(https://www
-0000f6f0: 2e6d 696e 6473 706f 7265 2e63 6e2f 646f  .mindspore.cn/do
-0000f700: 6373 2f7a 682d 434e 2f72 322e 302f 220a  cs/zh-CN/r2.0/".
-0000f710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f730: 2020 2020 2020 2261 7069 5f70 7974 686f        "api_pytho
-0000f740: 6e2f 6d69 6e64 7370 6f72 652f 6d69 6e64  n/mindspore/mind
-0000f750: 7370 6f72 652e 6772 6164 2e68 746d 6c29  spore.grad.html)
-0000f760: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
-0000f770: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f780: 2020 2020 2020 2020 2022 6f72 206d 732e           "or ms.
-0000f790: 7661 6c75 655f 616e 645f 6772 6164 220a  value_and_grad".
-0000f7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f7b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f7c0: 2020 2020 2020 2228 6874 7470 733a 2f2f        "(https://
-0000f7d0: 7777 772e 6d69 6e64 7370 6f72 652e 636e  www.mindspore.cn
-0000f7e0: 2f64 6f63 732f 7a68 2d43 4e2f 7232 2e30  /docs/zh-CN/r2.0
-0000f7f0: 2f22 0a20 2020 2020 2020 2020 2020 2020  /".             
-0000f800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f810: 2020 2020 2020 2020 2022 6170 695f 7079           "api_py
-0000f820: 7468 6f6e 2f6d 696e 6473 706f 7265 2f6d  thon/mindspore/m
-0000f830: 696e 6473 706f 7265 2e76 616c 7565 5f61  indspore.value_a
-0000f840: 6e64 5f67 7261 642e 6874 6d6c 2922 0a20  nd_grad.html)". 
-0000f850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f860: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f870: 2020 2020 2022 2069 7320 7a65 726f 2e20       " is zero. 
-0000f880: 2229 0a0a 2020 2020 6465 6620 7265 7175  ")..    def requ
-0000f890: 6972 6573 5f67 7261 645f 2873 656c 662c  ires_grad_(self,
-0000f8a0: 2072 6571 7569 7265 735f 6772 6164 3d54   requires_grad=T
-0000f8b0: 7275 6529 3a0a 2020 2020 2020 2020 6966  rue):.        if
-0000f8c0: 2072 6571 7569 7265 735f 6772 6164 2069   requires_grad i
-0000f8d0: 7320 4661 6c73 653a 0a20 2020 2020 2020  s False:.       
-0000f8e0: 2020 2020 2077 6172 6e69 6e67 2822 7265       warning("re
-0000f8f0: 7175 6972 6573 5f67 7261 6420 6973 2061  quires_grad is a
-0000f900: 6c77 6179 7320 5472 7565 2069 6e20 5465  lways True in Te
-0000f910: 6e73 6f72 2e22 290a 2020 2020 2020 2020  nsor.").        
-0000f920: 7265 7475 726e 2073 656c 660a 0a20 2020  return self..   
-0000f930: 2064 6566 206e 6f6e 7a65 726f 2873 656c   def nonzero(sel
-0000f940: 662c 2020 2a2c 206f 7574 3d4e 6f6e 652c  f,  *, out=None,
-0000f950: 2061 735f 7475 706c 653d 4661 6c73 6529   as_tuple=False)
-0000f960: 3a0a 2020 2020 2020 2020 6966 206f 7574  :.        if out
-0000f970: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
-0000f980: 2020 2020 2020 2020 2020 7761 726e 696e            warnin
-0000f990: 6728 2244 6f20 6e6f 7420 7375 7070 6f72  g("Do not suppor
-0000f9a0: 7420 7061 7261 6d65 7465 7220 276f 7574  t parameter 'out
-0000f9b0: 272e 2229 0a20 2020 2020 2020 2069 6e70  '.").        inp
-0000f9c0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0000f9d0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0000f9e0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-0000f9f0: 204e 6f6e 650a 2020 2020 2020 2020 6966   None.        if
-0000fa00: 2061 735f 7475 706c 653a 0a20 2020 2020   as_tuple:.     
-0000fa10: 2020 2020 2020 2069 6620 696e 7075 745f         if input_
-0000fa20: 6d73 2e6e 6469 6d20 3d3d 2031 3a0a 2020  ms.ndim == 1:.  
-0000fa30: 2020 2020 2020 2020 2020 2020 2020 7265                re
-0000fa40: 7320 3d20 6d73 2e6f 7073 2e6e 6f6e 7a65  s = ms.ops.nonze
-0000fa50: 726f 2869 6e70 7574 5f6d 7329 0a20 2020  ro(input_ms).   
-0000fa60: 2020 2020 2020 2020 2020 2020 206f 7574               out
-0000fa70: 7075 7420 3d20 2863 6173 745f 746f 5f61  put = (cast_to_a
-0000fa80: 6461 7074 6572 5f74 656e 736f 7228 7265  dapter_tensor(re
-0000fa90: 732e 666c 6174 7465 6e28 2929 2c29 0a20  s.flatten()),). 
-0000faa0: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-0000fab0: 696e 7075 745f 6d73 2e6e 6469 6d20 3e20  input_ms.ndim > 
-0000fac0: 313a 0a20 2020 2020 2020 2020 2020 2020  1:.             
-0000fad0: 2020 206f 7574 7075 7420 3d20 5b5d 0a20     output = []. 
-0000fae0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0000faf0: 6573 203d 206d 732e 6f70 732e 6e6f 6e7a  es = ms.ops.nonz
-0000fb00: 6572 6f28 696e 7075 745f 6d73 290a 2020  ero(input_ms).  
-0000fb10: 2020 2020 2020 2020 2020 2020 2020 7265                re
-0000fb20: 7320 3d20 7265 732e 7472 616e 7370 6f73  s = res.transpos
-0000fb30: 6528 312c 2030 290a 2020 2020 2020 2020  e(1, 0).        
-0000fb40: 2020 2020 2020 2020 7265 7320 3d20 6d73          res = ms
-0000fb50: 2e6f 7073 2e73 706c 6974 2872 6573 2c20  .ops.split(res, 
-0000fb60: 696e 7075 745f 6d73 2e6e 6469 6d2c 2061  input_ms.ndim, a
-0000fb70: 7869 733d 3029 0a20 2020 2020 2020 2020  xis=0).         
-0000fb80: 2020 2020 2020 2066 6f72 2063 7572 2069         for cur i
-0000fb90: 6e20 7265 733a 0a20 2020 2020 2020 2020  n res:.         
-0000fba0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-0000fbb0: 742e 6170 7065 6e64 2863 6173 745f 746f  t.append(cast_to
-0000fbc0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0000fbd0: 6375 7229 290a 2020 2020 2020 2020 2020  cur)).          
-0000fbe0: 2020 2020 2020 6f75 7470 7574 203d 2074        output = t
-0000fbf0: 7570 6c65 286f 7574 7075 7429 0a20 2020  uple(output).   
-0000fc00: 2020 2020 2020 2020 2065 6c69 6620 696e           elif in
-0000fc10: 7075 745f 6d73 2e6e 6469 6d20 3d3d 2030  put_ms.ndim == 0
-0000fc20: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0000fc30: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
-0000fc40: 6f72 2822 446f 206e 6f74 2073 7570 706f  or("Do not suppo
-0000fc50: 7274 2069 6e70 7574 206e 6469 6d20 3d3d  rt input ndim ==
-0000fc60: 2030 2e22 290a 2020 2020 2020 2020 2020   0.").          
-0000fc70: 2020 7265 7475 726e 206f 7574 7075 740a    return output.
-0000fc80: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-0000fc90: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-0000fca0: 656e 736f 7228 6d73 2e6f 7073 2e6e 6f6e  ensor(ms.ops.non
-0000fcb0: 7a65 726f 2869 6e70 7574 5f6d 7329 290a  zero(input_ms)).
-0000fcc0: 0a20 2020 2064 6566 2062 6f6f 6c28 7365  .    def bool(se
-0000fcd0: 6c66 2c20 6d65 6d6f 7279 5f66 6f72 6d61  lf, memory_forma
-0000fce0: 743d 4e6f 6e65 293a 0a20 2020 2020 2020  t=None):.       
-0000fcf0: 2075 6e73 7570 706f 7274 6564 5f61 7474   unsupported_att
-0000fd00: 7228 6d65 6d6f 7279 5f66 6f72 6d61 7429  r(memory_format)
-0000fd10: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0000fd20: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0000fd30: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0000fd40: 2020 2020 6f75 7470 7574 203d 2069 6e70      output = inp
-0000fd50: 7574 5f6d 732e 626f 6f6c 2829 0a20 2020  ut_ms.bool().   
-0000fd60: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0000fd70: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0000fd80: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0000fd90: 6465 6620 6571 2873 656c 662c 206f 7468  def eq(self, oth
-0000fda0: 6572 293a 0a20 2020 2020 2020 2069 6e70  er):.        inp
-0000fdb0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0000fdc0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0000fdd0: 2020 2020 2020 2020 6f74 6865 725f 6d73          other_ms
-0000fde0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-0000fdf0: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
-0000fe00: 2020 2020 6f75 7470 7574 203d 2069 6e70      output = inp
-0000fe10: 7574 5f6d 732e 6571 7561 6c28 6f74 6865  ut_ms.equal(othe
-0000fe20: 725f 6d73 290a 2020 2020 2020 2020 7265  r_ms).        re
-0000fe30: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-0000fe40: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-0000fe50: 7574 290a 0a20 2020 2064 6566 2065 715f  ut)..    def eq_
-0000fe60: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-0000fe70: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0000fe80: 7365 6c66 2e65 7128 6f74 6865 7229 0a20  self.eq(other). 
-0000fe90: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-0000fea0: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-0000feb0: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-0000fec0: 742c 2022 6571 5f22 2c20 2265 7122 290a  t, "eq_", "eq").
-0000fed0: 0a20 2020 2064 6566 2073 7464 2873 656c  .    def std(sel
-0000fee0: 662c 2064 696d 3d4e 6f6e 652c 2075 6e62  f, dim=None, unb
-0000fef0: 6961 7365 643d 5472 7565 2c20 6b65 6570  iased=True, keep
-0000ff00: 6469 6d3d 4661 6c73 6529 3a0a 2020 2020  dim=False):.    
-0000ff10: 2020 2020 2354 4f44 4f3a 206e 6f74 2073      #TODO: not s
-0000ff20: 7570 706f 7274 2063 6f6d 706c 6578 2069  upport complex i
-0000ff30: 6e70 7574 0a20 2020 2020 2020 2069 6e70  nput.        inp
-0000ff40: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0000ff50: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0000ff60: 2020 2020 2020 2020 5f64 696d 203d 2064          _dim = d
-0000ff70: 696d 2069 6620 6469 6d20 6973 206e 6f74  im if dim is not
-0000ff80: 204e 6f6e 6520 656c 7365 2028 290a 2020   None else ().  
-0000ff90: 2020 2020 2020 5f64 646f 6620 3d20 3120        _ddof = 1 
-0000ffa0: 6966 2075 6e62 6961 7365 6420 656c 7365  if unbiased else
-0000ffb0: 2030 0a20 2020 2020 2020 206f 7574 7075   0.        outpu
-0000ffc0: 7420 3d20 696e 7075 745f 6d73 2e73 7464  t = input_ms.std
-0000ffd0: 285f 6469 6d2c 205f 6464 6f66 2c20 6b65  (_dim, _ddof, ke
-0000ffe0: 6570 6469 6d29 0a20 2020 2020 2020 2072  epdim).        r
-0000fff0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00010000: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00010010: 7075 7429 0a0a 2020 2020 6465 6620 6578  put)..    def ex
-00010020: 7028 7365 6c66 293a 0a20 2020 2020 2020  p(self):.       
-00010030: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00010040: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00010050: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
-00010060: 7574 203d 2069 6e70 7574 5f6d 732e 6578  ut = input_ms.ex
-00010070: 7028 290a 2020 2020 2020 2020 7265 7475  p().        retu
-00010080: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00010090: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-000100a0: 290a 0a20 2020 2064 6566 2065 7870 5f28  )..    def exp_(
-000100b0: 7365 6c66 293a 0a20 2020 2020 2020 206f  self):.        o
-000100c0: 7574 7075 7420 3d20 7365 6c66 2e65 7870  utput = self.exp
-000100d0: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
-000100e0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-000100f0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-00010100: 7574 7075 742c 2022 6578 705f 222c 2022  utput, "exp_", "
-00010110: 6578 7022 290a 0a20 2020 2064 6566 206d  exp")..    def m
-00010120: 6173 6b65 645f 6669 6c6c 2873 656c 662c  asked_fill(self,
-00010130: 206d 6173 6b2c 2076 616c 7565 293a 0a20   mask, value):. 
-00010140: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00010150: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00010160: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00010170: 2020 6f75 7470 7574 203d 2069 6e70 7574    output = input
-00010180: 5f6d 732e 6d61 736b 6564 5f66 696c 6c28  _ms.masked_fill(
-00010190: 6d61 736b 2e62 6f6f 6c28 292c 2076 616c  mask.bool(), val
-000101a0: 7565 290a 2020 2020 2020 2020 7265 7475  ue).        retu
-000101b0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-000101c0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-000101d0: 290a 0a20 2020 2064 6566 206d 6173 6b65  )..    def maske
-000101e0: 645f 6669 6c6c 5f28 7365 6c66 2c20 6d61  d_fill_(self, ma
-000101f0: 736b 2c20 7661 6c75 6529 3a0a 2020 2020  sk, value):.    
-00010200: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-00010210: 662e 6d61 736b 6564 5f66 696c 6c28 6d61  f.masked_fill(ma
-00010220: 736b 2c20 7661 6c75 6529 0a20 2020 2020  sk, value).     
-00010230: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-00010240: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-00010250: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-00010260: 6d61 736b 6564 5f66 696c 6c5f 222c 2022  masked_fill_", "
-00010270: 6d61 736b 6564 5f66 696c 6c22 290a 0a20  masked_fill").. 
-00010280: 2020 2064 6566 2074 6f6c 6973 7428 7365     def tolist(se
-00010290: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
-000102a0: 7572 6e20 7365 6c66 2e6e 756d 7079 2829  urn self.numpy()
-000102b0: 2e74 6f6c 6973 7428 290a 0a20 2020 2064  .tolist()..    d
-000102c0: 6566 2062 6572 6e6f 756c 6c69 2873 656c  ef bernoulli(sel
-000102d0: 662c 202a 2c20 6765 6e65 7261 746f 723d  f, *, generator=
-000102e0: 4e6f 6e65 293a 0a20 2020 2020 2020 2072  None):.        r
-000102f0: 6574 7572 6e20 7365 6c66 2e5f 6265 726e  eturn self._bern
-00010300: 6f75 6c6c 695f 6164 6170 7465 7228 7365  oulli_adapter(se
-00010310: 6c66 2c20 6765 6e65 7261 746f 723d 6765  lf, generator=ge
-00010320: 6e65 7261 746f 7229 0a0a 2020 2020 6465  nerator)..    de
-00010330: 6620 6265 726e 6f75 6c6c 695f 2873 656c  f bernoulli_(sel
-00010340: 662c 2070 3d30 2e35 2c20 2a2c 2067 656e  f, p=0.5, *, gen
-00010350: 6572 6174 6f72 3d4e 6f6e 6529 3a0a 2020  erator=None):.  
-00010360: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-00010370: 656c 662e 5f62 6572 6e6f 756c 6c69 5f61  elf._bernoulli_a
-00010380: 6461 7074 6572 2870 2c20 6765 6e65 7261  dapter(p, genera
-00010390: 746f 723d 6765 6e65 7261 746f 7229 0a20  tor=generator). 
-000103a0: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-000103b0: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-000103c0: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-000103d0: 742c 2022 6265 726e 6f75 6c6c 695f 222c  t, "bernoulli_",
-000103e0: 2022 5f62 6572 6e6f 756c 6c69 5f61 6461   "_bernoulli_ada
-000103f0: 7074 6572 2229 0a0a 2020 2020 6465 6620  pter")..    def 
-00010400: 5f62 6572 6e6f 756c 6c69 5f61 6461 7074  _bernoulli_adapt
-00010410: 6572 2873 656c 662c 2070 3d30 2e35 2c20  er(self, p=0.5, 
-00010420: 2a2c 2067 656e 6572 6174 6f72 3d4e 6f6e  *, generator=Non
-00010430: 6529 3a0a 2020 2020 2020 2020 6966 2067  e):.        if g
-00010440: 656e 6572 6174 6f72 3a0a 2020 2020 2020  enerator:.      
-00010450: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
-00010460: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
-00010470: 2267 656e 6572 6174 6f72 2069 7320 6e6f  "generator is no
-00010480: 7420 7375 7070 6f72 7465 642e 2229 0a20  t supported."). 
-00010490: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-000104a0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-000104b0: 736f 7228 7365 6c66 290a 0a20 2020 2020  sor(self)..     
-000104c0: 2020 2062 6572 6e6f 756c 6c69 5f73 6565     bernoulli_see
-000104d0: 6420 3d20 6d73 2e67 6574 5f73 6565 6428  d = ms.get_seed(
-000104e0: 290a 2020 2020 2020 2020 6966 206e 6f74  ).        if not
-000104f0: 2062 6572 6e6f 756c 6c69 5f73 6565 643a   bernoulli_seed:
-00010500: 0a20 2020 2020 2020 2020 2020 2062 6572  .            ber
-00010510: 6e6f 756c 6c69 5f73 6565 6420 3d20 2d31  noulli_seed = -1
-00010520: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00010530: 6973 696e 7374 616e 6365 2870 2c20 2854  isinstance(p, (T
-00010540: 656e 736f 722c 2066 6c6f 6174 2929 3a0a  ensor, float)):.
-00010550: 2020 2020 2020 2020 2020 2020 7020 3d20              p = 
-00010560: 666c 6f61 7428 7029 0a20 2020 2020 2020  float(p).       
-00010570: 2023 544f 444f 3a20 4173 6365 6e64 2063   #TODO: Ascend c
-00010580: 7572 7265 6e74 6c79 206e 6f74 2073 7570  urrently not sup
-00010590: 706f 7274 206f 7073 2e62 6572 6e6f 756c  port ops.bernoul
-000105a0: 6c69 2c20 7573 6520 6e75 6d70 792e 7261  li, use numpy.ra
-000105b0: 6e64 6f6d 2e62 696e 6f6d 6961 6c0a 2020  ndom.binomial.  
-000105c0: 2020 2020 2020 6966 2069 735f 756e 6465        if is_unde
-000105d0: 725f 6173 6365 6e64 5f63 6f6e 7465 7874  r_ascend_context
-000105e0: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-000105f0: 6966 2069 7369 6e73 7461 6e63 6528 702c  if isinstance(p,
-00010600: 206d 732e 5465 6e73 6f72 293a 0a20 2020   ms.Tensor):.   
-00010610: 2020 2020 2020 2020 2020 2020 2070 203d               p =
-00010620: 2070 2e6e 756d 7079 2829 0a20 2020 2020   p.numpy().     
-00010630: 2020 2020 2020 2023 206f 6e20 4173 6365         # on Asce
-00010640: 6e64 2c20 7573 6520 6e75 6d70 7920 6269  nd, use numpy bi
-00010650: 6e6f 6d69 616c 2074 6f20 646f 2066 6f72  nomial to do for
-00010660: 7761 7264 2063 6f6d 7075 7461 7469 6f6e  ward computation
-00010670: 0a20 2020 2020 2020 2020 2020 2023 2068  .            # h
-00010680: 6572 6520 6974 2064 6f65 736e 2774 206e  ere it doesn't n
-00010690: 6565 6420 746f 2063 6f6e 7369 6465 7220  eed to consider 
-000106a0: 7468 6520 6261 636b 7761 7264 0a20 2020  the backward.   
-000106b0: 2020 2020 2020 2020 2023 2062 6563 6175           # becau
-000106c0: 7365 2074 6f72 6368 2e62 6572 6e6f 756c  se torch.bernoul
-000106d0: 6c69 2072 6574 7572 6e20 7a65 726f 2067  li return zero g
-000106e0: 7261 642c 2061 6e64 206d 696e 6473 706f  rad, and mindspo
-000106f0: 7265 2072 6574 7572 6e20 7a65 726f 2067  re return zero g
-00010700: 7261 6420 6865 7265 2061 7320 7765 6c6c  rad here as well
-00010710: 2e0a 2020 2020 2020 2020 2020 2020 6e70  ..            np
-00010720: 5f6f 7574 7075 7420 3d20 6e70 2e72 616e  _output = np.ran
-00010730: 646f 6d2e 6269 6e6f 6d69 616c 2831 2c20  dom.binomial(1, 
-00010740: 702c 2073 697a 653d 696e 7075 745f 6d73  p, size=input_ms
-00010750: 2e73 6861 7065 290a 2020 2020 2020 2020  .shape).        
-00010760: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00010770: 5465 6e73 6f72 2e66 726f 6d5f 6e75 6d70  Tensor.from_nump
-00010780: 7928 6e70 5f6f 7574 7075 7429 2e74 6f28  y(np_output).to(
-00010790: 6474 7970 653d 696e 7075 745f 6d73 2e64  dtype=input_ms.d
-000107a0: 7479 7065 290a 2020 2020 2020 2020 2020  type).          
-000107b0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-000107c0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-000107d0: 6f75 7470 7574 290a 2020 2020 2020 2020  output).        
-000107e0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-000107f0: 2020 7020 3d20 6361 7374 5f74 6f5f 6d73    p = cast_to_ms
-00010800: 5f74 656e 736f 7228 7029 0a20 2020 2020  _tensor(p).     
-00010810: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-00010820: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00010830: 6e73 6f72 2869 6e70 7574 5f6d 732e 6265  nsor(input_ms.be
-00010840: 726e 6f75 6c6c 6928 702c 2062 6572 6e6f  rnoulli(p, berno
-00010850: 756c 6c69 5f73 6565 6429 290a 0a20 2020  ulli_seed))..   
-00010860: 2064 6566 2072 6f75 6e64 2873 656c 662c   def round(self,
-00010870: 2064 6563 696d 616c 733d 3029 3a0a 2020   decimals=0):.  
-00010880: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00010890: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-000108a0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-000108b0: 2023 2054 4f44 4f3a 2061 6674 6572 206d   # TODO: after m
-000108c0: 732e 6f70 732e 726f 756e 6428 2920 7375  s.ops.round() su
-000108d0: 7070 6f72 7420 6064 6563 696d 616c 7360  pport `decimals`
-000108e0: 2c20 6368 616e 6765 2063 6f64 6520 6265  , change code be
-000108f0: 6c6f 772e 0a20 2020 2020 2020 2069 6620  low..        if 
-00010900: 6465 6369 6d61 6c73 203d 3d20 303a 0a20  decimals == 0:. 
-00010910: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-00010920: 7420 3d20 6d73 2e6f 7073 2e72 6f75 6e64  t = ms.ops.round
-00010930: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
-00010940: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00010950: 2020 2020 2070 203d 2031 3020 2a2a 2064       p = 10 ** d
-00010960: 6563 696d 616c 730a 2020 2020 2020 2020  ecimals.        
-00010970: 2020 2020 696e 7075 745f 6d73 203d 2069      input_ms = i
-00010980: 6e70 7574 5f6d 7320 2a20 700a 2020 2020  nput_ms * p.    
-00010990: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-000109a0: 206d 732e 6f70 732e 726f 756e 6428 696e   ms.ops.round(in
-000109b0: 7075 745f 6d73 2920 2f20 700a 2020 2020  put_ms) / p.    
-000109c0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-000109d0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-000109e0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-000109f0: 6566 2072 6f75 6e64 5f28 7365 6c66 2c20  ef round_(self, 
-00010a00: 6465 6369 6d61 6c73 3d30 293a 0a20 2020  decimals=0):.   
-00010a10: 2020 2020 206f 7574 7075 7420 3d20 7365       output = se
-00010a20: 6c66 2e72 6f75 6e64 2864 6563 696d 616c  lf.round(decimal
-00010a30: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
-00010a40: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-00010a50: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-00010a60: 7574 7075 742c 2022 726f 756e 645f 222c  utput, "round_",
-00010a70: 2022 726f 756e 6422 290a 0a20 2020 2064   "round")..    d
-00010a80: 6566 206c 6f6e 6728 7365 6c66 2c20 6d65  ef long(self, me
-00010a90: 6d6f 7279 5f66 6f72 6d61 743d 4e6f 6e65  mory_format=None
-00010aa0: 293a 0a20 2020 2020 2020 2075 6e73 7570  ):.        unsup
-00010ab0: 706f 7274 6564 5f61 7474 7228 6d65 6d6f  ported_attr(memo
-00010ac0: 7279 5f66 6f72 6d61 7429 0a20 2020 2020  ry_format).     
-00010ad0: 2020 2069 6620 6d65 6d6f 7279 5f66 6f72     if memory_for
-00010ae0: 6d61 743a 0a20 2020 2020 2020 2020 2020  mat:.           
-00010af0: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
-00010b00: 656e 7465 6445 7272 6f72 2822 6d65 6d6f  entedError("memo
-00010b10: 7279 5f66 6f72 6d61 7420 6973 206e 6f74  ry_format is not
-00010b20: 2073 7570 706f 7274 6564 2e22 290a 2020   supported.").  
-00010b30: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00010b40: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00010b50: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00010b60: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00010b70: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
-00010b80: 6e70 7574 5f6d 732e 6173 7479 7065 285f  nput_ms.astype(_
-00010b90: 6474 7970 6544 6963 745b 226c 6f6e 6722  dtypeDict["long"
-00010ba0: 5d29 290a 0a20 2020 2064 6566 2068 616c  ]))..    def hal
-00010bb0: 6628 7365 6c66 2c20 6d65 6d6f 7279 5f66  f(self, memory_f
-00010bc0: 6f72 6d61 743d 4e6f 6e65 293a 0a20 2020  ormat=None):.   
-00010bd0: 2020 2020 2075 6e73 7570 706f 7274 6564       unsupported
-00010be0: 5f61 7474 7228 6d65 6d6f 7279 5f66 6f72  _attr(memory_for
-00010bf0: 6d61 7429 0a20 2020 2020 2020 2069 6620  mat).        if 
-00010c00: 6d65 6d6f 7279 5f66 6f72 6d61 743a 0a20  memory_format:. 
-00010c10: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00010c20: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
-00010c30: 7272 6f72 2822 6d65 6d6f 7279 5f66 6f72  rror("memory_for
-00010c40: 6d61 7420 6973 206e 6f74 2073 7570 706f  mat is not suppo
-00010c50: 7274 6564 2e22 290a 2020 2020 2020 2020  rted.").        
-00010c60: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00010c70: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00010c80: 6629 0a20 2020 2020 2020 2072 6574 7572  f).        retur
-00010c90: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00010ca0: 725f 7465 6e73 6f72 2869 6e70 7574 5f6d  r_tensor(input_m
-00010cb0: 732e 6173 7479 7065 285f 6474 7970 6544  s.astype(_dtypeD
-00010cc0: 6963 745b 2268 616c 6622 5d29 290a 0a20  ict["half"])).. 
-00010cd0: 2020 2064 6566 2069 6e74 2873 656c 662c     def int(self,
-00010ce0: 206d 656d 6f72 795f 666f 726d 6174 3d4e   memory_format=N
-00010cf0: 6f6e 6529 3a0a 2020 2020 2020 2020 756e  one):.        un
-00010d00: 7375 7070 6f72 7465 645f 6174 7472 286d  supported_attr(m
-00010d10: 656d 6f72 795f 666f 726d 6174 290a 2020  emory_format).  
-00010d20: 2020 2020 2020 6966 206d 656d 6f72 795f        if memory_
-00010d30: 666f 726d 6174 3a0a 2020 2020 2020 2020  format:.        
-00010d40: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
-00010d50: 6c65 6d65 6e74 6564 4572 726f 7228 226d  lementedError("m
-00010d60: 656d 6f72 795f 666f 726d 6174 2069 7320  emory_format is 
-00010d70: 6e6f 7420 7375 7070 6f72 7465 642e 2229  not supported.")
-00010d80: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-00010d90: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00010da0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00010db0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00010dc0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00010dd0: 7228 696e 7075 745f 6d73 2e69 6e74 2829  r(input_ms.int()
-00010de0: 290a 0a20 2020 2064 6566 2064 6f75 626c  )..    def doubl
-00010df0: 6528 7365 6c66 2c20 6d65 6d6f 7279 5f66  e(self, memory_f
-00010e00: 6f72 6d61 743d 4e6f 6e65 293a 0a20 2020  ormat=None):.   
-00010e10: 2020 2020 2075 6e73 7570 706f 7274 6564       unsupported
-00010e20: 5f61 7474 7228 6d65 6d6f 7279 5f66 6f72  _attr(memory_for
-00010e30: 6d61 7429 0a20 2020 2020 2020 2069 6620  mat).        if 
-00010e40: 6d65 6d6f 7279 5f66 6f72 6d61 743a 0a20  memory_format:. 
-00010e50: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00010e60: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
-00010e70: 7272 6f72 2822 6d65 6d6f 7279 5f66 6f72  rror("memory_for
-00010e80: 6d61 7420 6973 206e 6f74 2073 7570 706f  mat is not suppo
-00010e90: 7274 6564 2e22 290a 2020 2020 2020 2020  rted.").        
-00010ea0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00010eb0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00010ec0: 6629 0a20 2020 2020 2020 2072 6574 7572  f).        retur
-00010ed0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00010ee0: 725f 7465 6e73 6f72 2869 6e70 7574 5f6d  r_tensor(input_m
-00010ef0: 732e 6173 7479 7065 285f 6474 7970 6544  s.astype(_dtypeD
-00010f00: 6963 745b 2264 6f75 626c 6522 5d29 290a  ict["double"])).
-00010f10: 0a20 2020 2064 6566 2063 6861 7228 7365  .    def char(se
-00010f20: 6c66 2c20 6d65 6d6f 7279 5f66 6f72 6d61  lf, memory_forma
-00010f30: 743d 4e6f 6e65 293a 0a20 2020 2020 2020  t=None):.       
-00010f40: 2075 6e73 7570 706f 7274 6564 5f61 7474   unsupported_att
-00010f50: 7228 6d65 6d6f 7279 5f66 6f72 6d61 7429  r(memory_format)
-00010f60: 0a20 2020 2020 2020 2069 6620 6d65 6d6f  .        if memo
-00010f70: 7279 5f66 6f72 6d61 743a 0a20 2020 2020  ry_format:.     
-00010f80: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
-00010f90: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
-00010fa0: 2822 6d65 6d6f 7279 5f66 6f72 6d61 7420  ("memory_format 
-00010fb0: 6973 206e 6f74 2073 7570 706f 7274 6564  is not supported
-00010fc0: 2e22 290a 2020 2020 2020 2020 696e 7075  .").        inpu
-00010fd0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00010fe0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00010ff0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-00011000: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00011010: 6e73 6f72 2869 6e70 7574 5f6d 732e 6173  nsor(input_ms.as
-00011020: 7479 7065 285f 6474 7970 6544 6963 745b  type(_dtypeDict[
-00011030: 2263 6861 7222 5d29 290a 0a20 2020 2064  "char"]))..    d
-00011040: 6566 2062 7974 6528 7365 6c66 2c20 6d65  ef byte(self, me
-00011050: 6d6f 7279 5f66 6f72 6d61 743d 4e6f 6e65  mory_format=None
-00011060: 293a 0a20 2020 2020 2020 2075 6e73 7570  ):.        unsup
-00011070: 706f 7274 6564 5f61 7474 7228 6d65 6d6f  ported_attr(memo
-00011080: 7279 5f66 6f72 6d61 7429 0a20 2020 2020  ry_format).     
-00011090: 2020 2069 6620 6d65 6d6f 7279 5f66 6f72     if memory_for
-000110a0: 6d61 743a 0a20 2020 2020 2020 2020 2020  mat:.           
-000110b0: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
-000110c0: 656e 7465 6445 7272 6f72 2822 6d65 6d6f  entedError("memo
-000110d0: 7279 5f66 6f72 6d61 7420 6973 206e 6f74  ry_format is not
-000110e0: 2073 7570 706f 7274 6564 2e22 290a 2020   supported.").  
-000110f0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00011100: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00011110: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00011120: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00011130: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
-00011140: 6e70 7574 5f6d 732e 6173 7479 7065 285f  nput_ms.astype(_
-00011150: 6474 7970 6544 6963 745b 2262 7974 6522  dtypeDict["byte"
-00011160: 5d29 290a 0a20 2020 2064 6566 2073 686f  ]))..    def sho
-00011170: 7274 2873 656c 662c 206d 656d 6f72 795f  rt(self, memory_
-00011180: 666f 726d 6174 3d4e 6f6e 6529 3a0a 2020  format=None):.  
-00011190: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
-000111a0: 645f 6174 7472 286d 656d 6f72 795f 666f  d_attr(memory_fo
-000111b0: 726d 6174 290a 2020 2020 2020 2020 6966  rmat).        if
-000111c0: 206d 656d 6f72 795f 666f 726d 6174 3a0a   memory_format:.
-000111d0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-000111e0: 6520 4e6f 7449 6d70 6c65 6d65 6e74 6564  e NotImplemented
-000111f0: 4572 726f 7228 226d 656d 6f72 795f 666f  Error("memory_fo
-00011200: 726d 6174 2069 7320 6e6f 7420 7375 7070  rmat is not supp
-00011210: 6f72 7465 642e 2229 0a20 2020 2020 2020  orted.").       
-00011220: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00011230: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00011240: 6c66 290a 2020 2020 2020 2020 7265 7475  lf).        retu
-00011250: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00011260: 6572 5f74 656e 736f 7228 696e 7075 745f  er_tensor(input_
-00011270: 6d73 2e61 7374 7970 6528 5f64 7479 7065  ms.astype(_dtype
-00011280: 4469 6374 5b22 7368 6f72 7422 5d29 290a  Dict["short"])).
-00011290: 0a0a 2020 2020 6465 6620 6368 756e 6b28  ..    def chunk(
-000112a0: 7365 6c66 2c20 6368 756e 6b73 2c20 6469  self, chunks, di
-000112b0: 6d3d 3029 3a0a 2020 2020 2020 2020 696e  m=0):.        in
-000112c0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-000112d0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-000112e0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-000112f0: 3d20 6d73 2e6f 7073 2e63 6875 6e6b 2869  = ms.ops.chunk(i
-00011300: 6e70 7574 5f6d 732c 2063 6875 6e6b 732c  nput_ms, chunks,
-00011310: 2064 696d 290a 2020 2020 2020 2020 7265   dim).        re
-00011320: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00011330: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-00011340: 7574 290a 0a20 2020 2064 6566 2066 6c61  ut)..    def fla
-00011350: 7474 656e 2873 656c 662c 2073 7461 7274  tten(self, start
-00011360: 5f64 696d 3d30 2c20 656e 645f 6469 6d3d  _dim=0, end_dim=
-00011370: 2d31 293a 0a20 2020 2020 2020 2069 6e70  -1):.        inp
-00011380: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-00011390: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-000113a0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-000113b0: 206d 732e 6f70 732e 666c 6174 7465 6e28   ms.ops.flatten(
-000113c0: 696e 7075 745f 6d73 2c20 6f72 6465 723d  input_ms, order=
-000113d0: 2743 272c 2073 7461 7274 5f64 696d 3d73  'C', start_dim=s
-000113e0: 7461 7274 5f64 696d 2c20 656e 645f 6469  tart_dim, end_di
-000113f0: 6d3d 656e 645f 6469 6d29 0a20 2020 2020  m=end_dim).     
-00011400: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-00011410: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-00011420: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
-00011430: 6620 756e 666c 6174 7465 6e28 7365 6c66  f unflatten(self
-00011440: 2c20 6469 6d2c 2073 697a 6573 293a 0a20  , dim, sizes):. 
-00011450: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00011460: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00011470: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00011480: 2020 6f75 745f 7368 6170 6520 3d20 5f67    out_shape = _g
-00011490: 6574 5f75 6e66 6c61 7474 656e 5f73 697a  et_unflatten_siz
-000114a0: 6528 696e 7075 745f 6d73 2e73 6861 7065  e(input_ms.shape
-000114b0: 2c20 6469 6d2c 2073 697a 6573 290a 2020  , dim, sizes).  
-000114c0: 2020 2020 2020 6f75 7420 3d20 6d73 2e6f        out = ms.o
-000114d0: 7073 2e72 6573 6861 7065 2869 6e70 7574  ps.reshape(input
-000114e0: 5f6d 732c 206f 7574 5f73 6861 7065 290a  _ms, out_shape).
-000114f0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-00011500: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00011510: 656e 736f 7228 6f75 7429 0a0a 2020 2020  ensor(out)..    
-00011520: 6465 6620 7369 6e28 7365 6c66 293a 0a20  def sin(self):. 
-00011530: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00011540: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00011550: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00011560: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00011570: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00011580: 6d73 2e6f 7073 2e73 696e 2869 6e70 7574  ms.ops.sin(input
-00011590: 5f6d 7329 290a 0a20 2020 2064 6566 2073  _ms))..    def s
-000115a0: 696e 5f28 7365 6c66 293a 0a20 2020 2020  in_(self):.     
-000115b0: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-000115c0: 2e73 696e 2829 0a20 2020 2020 2020 2072  .sin().        r
-000115d0: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
-000115e0: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
-000115f0: 662c 206f 7574 7075 742c 2022 7369 6e5f  f, output, "sin_
-00011600: 222c 2022 7369 6e22 290a 0a20 2020 2064  ", "sin")..    d
-00011610: 6566 2067 6528 7365 6c66 2c20 6f74 6865  ef ge(self, othe
-00011620: 7229 3a0a 2020 2020 2020 2020 696e 7075  r):.        inpu
-00011630: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00011640: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00011650: 2020 2020 2020 206f 7468 6572 203d 2063         other = c
-00011660: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00011670: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
-00011680: 6f75 7470 7574 203d 2069 6e70 7574 5f6d  output = input_m
-00011690: 732e 6765 286f 7468 6572 290a 2020 2020  s.ge(other).    
-000116a0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-000116b0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-000116c0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-000116d0: 6566 2067 655f 2873 656c 662c 206f 7468  ef ge_(self, oth
-000116e0: 6572 293a 0a20 2020 2020 2020 206f 7574  er):.        out
-000116f0: 7075 7420 3d20 7365 6c66 2e67 6528 6f74  put = self.ge(ot
-00011700: 6865 7229 0a20 2020 2020 2020 2072 6574  her).        ret
-00011710: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-00011720: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-00011730: 206f 7574 7075 742c 2022 6765 5f22 2c20   output, "ge_", 
-00011740: 2267 6522 290a 0a20 2020 2064 6566 2063  "ge")..    def c
-00011750: 756d 7375 6d28 7365 6c66 2c20 6469 6d2c  umsum(self, dim,
-00011760: 2064 7479 7065 3d4e 6f6e 6529 3a0a 2020   dtype=None):.  
-00011770: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00011780: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00011790: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-000117a0: 2069 6620 6474 7970 6520 6973 206e 6f74   if dtype is not
-000117b0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-000117c0: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
-000117d0: 7075 745f 6d73 2e61 7374 7970 6528 6474  put_ms.astype(dt
-000117e0: 7970 6529 0a20 2020 2020 2020 2065 6c69  ype).        eli
-000117f0: 6620 696e 7075 745f 6d73 2e64 7479 7065  f input_ms.dtype
-00011800: 2069 6e20 6d73 6461 7074 6572 5f64 7479   in msdapter_dty
-00011810: 7065 2e61 6c6c 5f69 6e74 5f74 7970 655f  pe.all_int_type_
-00011820: 7769 7468 5f62 6f6f 6c3a 0a20 2020 2020  with_bool:.     
-00011830: 2020 2020 2020 2023 2054 4f44 4f3a 206d         # TODO: m
-00011840: 732e 6375 6d73 756d 206f 6e6c 7920 7375  s.cumsum only su
-00011850: 7070 6f72 7420 696e 7433 3220 6f6e 2041  pport int32 on A
-00011860: 7363 656e 640a 2020 2020 2020 2020 2020  scend.          
-00011870: 2020 6474 7970 6520 3d20 6d73 7479 7065    dtype = mstype
-00011880: 2e69 6e74 3332 2069 6620 6973 5f75 6e64  .int32 if is_und
-00011890: 6572 5f61 7363 656e 645f 636f 6e74 6578  er_ascend_contex
-000118a0: 7428 2920 656c 7365 206d 7374 7970 652e  t() else mstype.
-000118b0: 696e 7436 340a 2020 2020 2020 2020 2020  int64.          
-000118c0: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
-000118d0: 7574 5f6d 732e 6173 7479 7065 2864 7479  ut_ms.astype(dty
-000118e0: 7065 290a 0a20 2020 2020 2020 2072 6573  pe)..        res
-000118f0: 203d 206d 732e 6f70 732e 6375 6d73 756d   = ms.ops.cumsum
-00011900: 2869 6e70 7574 5f6d 732c 2064 696d 2c20  (input_ms, dim, 
-00011910: 6474 7970 6529 0a20 2020 2020 2020 2072  dtype).        r
-00011920: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00011930: 6170 7465 725f 7465 6e73 6f72 2872 6573  apter_tensor(res
-00011940: 290a 0a20 2020 2064 6566 2063 756d 7375  )..    def cumsu
-00011950: 6d5f 2873 656c 662c 2064 696d 2c20 6474  m_(self, dim, dt
-00011960: 7970 653d 4e6f 6e65 293a 0a20 2020 2020  ype=None):.     
-00011970: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-00011980: 2e63 756d 7375 6d28 6469 6d2c 2064 7479  .cumsum(dim, dty
-00011990: 7065 290a 2020 2020 2020 2020 7265 7475  pe).        retu
-000119a0: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
-000119b0: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
-000119c0: 6f75 7470 7574 2c20 2263 756d 7375 6d5f  output, "cumsum_
-000119d0: 222c 2022 6375 6d73 756d 2229 0a0a 2020  ", "cumsum")..  
-000119e0: 2020 6465 6620 6162 736f 6c75 7465 2873    def absolute(s
-000119f0: 656c 6629 3a0a 2020 2020 2020 2020 7265  elf):.        re
-00011a00: 7475 726e 2073 656c 662e 6162 7328 290a  turn self.abs().
-00011a10: 0a20 2020 2064 6566 2061 6273 6f6c 7574  .    def absolut
-00011a20: 655f 2873 656c 6629 3a0a 2020 2020 2020  e_(self):.      
-00011a30: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
-00011a40: 6162 7328 290a 2020 2020 2020 2020 7265  abs().        re
-00011a50: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
-00011a60: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
-00011a70: 2c20 6f75 7470 7574 2c20 2261 6273 6f6c  , output, "absol
-00011a80: 7574 655f 222c 2022 6162 736f 6c75 7465  ute_", "absolute
-00011a90: 2229 0a0a 2020 2020 6465 6620 6163 6f73  ")..    def acos
-00011aa0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00011ab0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00011ac0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00011ad0: 6629 0a20 2020 2020 2020 2069 6620 696e  f).        if in
-00011ae0: 7075 745f 6d73 2e64 7479 7065 2069 6e20  put_ms.dtype in 
-00011af0: 616c 6c5f 696e 745f 7479 7065 3a0a 2020  all_int_type:.  
-00011b00: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00011b10: 6d73 203d 2069 6e70 7574 5f6d 732e 6173  ms = input_ms.as
-00011b20: 7479 7065 286d 7374 7970 652e 666c 6f61  type(mstype.floa
-00011b30: 7433 3229 0a20 2020 2020 2020 206f 7574  t32).        out
-00011b40: 7075 7420 3d20 6d73 2e6f 7073 2e61 636f  put = ms.ops.aco
-00011b50: 7328 696e 7075 745f 6d73 290a 2020 2020  s(input_ms).    
-00011b60: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00011b70: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00011b80: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00011b90: 6566 2061 636f 735f 2873 656c 6629 3a0a  ef acos_(self):.
-00011ba0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00011bb0: 2073 656c 662e 6163 6f73 2829 0a20 2020   self.acos().   
-00011bc0: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
-00011bd0: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
-00011be0: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
-00011bf0: 2022 6163 6f73 5f22 2c20 2261 636f 7322   "acos_", "acos"
-00011c00: 290a 0a20 2020 2064 6566 2061 7263 636f  )..    def arcco
-00011c10: 7328 7365 6c66 293a 0a20 2020 2020 2020  s(self):.       
-00011c20: 2072 6574 7572 6e20 7365 6c66 2e61 636f   return self.aco
-00011c30: 7328 290a 0a20 2020 2064 6566 2061 7263  s()..    def arc
-00011c40: 636f 735f 2873 656c 6629 3a0a 2020 2020  cos_(self):.    
-00011c50: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-00011c60: 662e 6163 6f73 2829 0a20 2020 2020 2020  f.acos().       
-00011c70: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
-00011c80: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
-00011c90: 656c 662c 206f 7574 7075 742c 2022 6172  elf, output, "ar
-00011ca0: 6363 6f73 5f22 2c20 2261 7263 636f 7322  ccos_", "arccos"
-00011cb0: 290a 0a20 2020 2064 6566 2061 7369 6e68  )..    def asinh
-00011cc0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00011cd0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00011ce0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00011cf0: 6629 0a20 2020 2020 2020 2069 6620 696e  f).        if in
-00011d00: 7075 745f 6d73 2e64 7479 7065 2069 6e20  put_ms.dtype in 
-00011d10: 616c 6c5f 696e 745f 7479 7065 3a0a 2020  all_int_type:.  
-00011d20: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00011d30: 6d73 203d 2069 6e70 7574 5f6d 732e 6173  ms = input_ms.as
-00011d40: 7479 7065 286d 7374 7970 652e 666c 6f61  type(mstype.floa
-00011d50: 7433 3229 0a20 2020 2020 2020 206f 7574  t32).        out
-00011d60: 7075 7420 3d20 6d73 2e6f 7073 2e61 7369  put = ms.ops.asi
-00011d70: 6e68 2869 6e70 7574 5f6d 7329 0a20 2020  nh(input_ms).   
-00011d80: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-00011d90: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00011da0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-00011db0: 6465 6620 6173 696e 685f 2873 656c 6629  def asinh_(self)
-00011dc0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-00011dd0: 203d 2073 656c 662e 6173 696e 6828 290a   = self.asinh().
-00011de0: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-00011df0: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-00011e00: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-00011e10: 7574 2c20 2261 7369 6e68 5f22 2c20 2261  ut, "asinh_", "a
-00011e20: 7369 6e68 2229 0a0a 2020 2020 6465 6620  sinh")..    def 
-00011e30: 6174 616e 6828 7365 6c66 293a 0a20 2020  atanh(self):.   
-00011e40: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00011e50: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00011e60: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00011e70: 6966 2069 6e70 7574 5f6d 732e 6474 7970  if input_ms.dtyp
-00011e80: 6520 696e 2061 6c6c 5f69 6e74 5f74 7970  e in all_int_typ
-00011e90: 653a 0a20 2020 2020 2020 2020 2020 2069  e:.            i
-00011ea0: 6e70 7574 5f6d 7320 3d20 696e 7075 745f  nput_ms = input_
-00011eb0: 6d73 2e61 7374 7970 6528 6d73 7479 7065  ms.astype(mstype
-00011ec0: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
-00011ed0: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-00011ee0: 732e 6174 616e 6828 696e 7075 745f 6d73  s.atanh(input_ms
-00011ef0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00011f00: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00011f10: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-00011f20: 0a20 2020 2064 6566 2061 7461 6e68 5f28  .    def atanh_(
-00011f30: 7365 6c66 293a 0a20 2020 2020 2020 206f  self):.        o
-00011f40: 7574 7075 7420 3d20 7365 6c66 2e61 7461  utput = self.ata
-00011f50: 6e68 2829 0a20 2020 2020 2020 2072 6574  nh().        ret
-00011f60: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-00011f70: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-00011f80: 206f 7574 7075 742c 2022 6174 616e 685f   output, "atanh_
-00011f90: 222c 2022 6174 616e 6822 290a 0a20 2020  ", "atanh")..   
-00011fa0: 2064 6566 2061 6464 6364 6976 2873 656c   def addcdiv(sel
-00011fb0: 662c 2074 656e 736f 7231 2c20 7465 6e73  f, tensor1, tens
-00011fc0: 6f72 322c 202a 2c20 7661 6c75 653d 3129  or2, *, value=1)
-00011fd0: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-00011fe0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00011ff0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-00012000: 2020 2020 2074 656e 736f 7231 203d 2063       tensor1 = c
-00012010: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00012020: 2874 656e 736f 7231 290a 2020 2020 2020  (tensor1).      
-00012030: 2020 7465 6e73 6f72 3220 3d20 6361 7374    tensor2 = cast
-00012040: 5f74 6f5f 6d73 5f74 656e 736f 7228 7465  _to_ms_tensor(te
-00012050: 6e73 6f72 3229 0a20 2020 2020 2020 2069  nsor2).        i
-00012060: 6620 6973 5f75 6e64 6572 5f61 7363 656e  f is_under_ascen
-00012070: 645f 636f 6e74 6578 7428 293a 0a20 2020  d_context():.   
-00012080: 2020 2020 2020 2020 2076 616c 7565 203d           value =
-00012090: 206d 732e 5465 6e73 6f72 2876 616c 7565   ms.Tensor(value
-000120a0: 292e 6173 7479 7065 2869 6e70 7574 5f6d  ).astype(input_m
-000120b0: 732e 6474 7970 6529 0a20 2020 2020 2020  s.dtype).       
-000120c0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-000120d0: 2e61 6464 6364 6976 2869 6e70 7574 5f6d  .addcdiv(input_m
-000120e0: 732c 2074 656e 736f 7231 2c20 7465 6e73  s, tensor1, tens
-000120f0: 6f72 322c 2076 616c 7565 290a 2020 2020  or2, value).    
-00012100: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00012110: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00012120: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00012130: 6566 2061 6464 6364 6976 5f28 7365 6c66  ef addcdiv_(self
-00012140: 2c20 7465 6e73 6f72 312c 2074 656e 736f  , tensor1, tenso
-00012150: 7232 2c20 2a2c 2076 616c 7565 3d31 293a  r2, *, value=1):
-00012160: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00012170: 3d20 7365 6c66 2e61 6464 6364 6976 2874  = self.addcdiv(t
-00012180: 656e 736f 7231 2c20 7465 6e73 6f72 322c  ensor1, tensor2,
-00012190: 2076 616c 7565 3d76 616c 7565 290a 2020   value=value).  
-000121a0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-000121b0: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-000121c0: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-000121d0: 2c20 2261 6464 6364 6976 5f22 2c20 2261  , "addcdiv_", "a
-000121e0: 6464 6364 6976 2229 0a0a 2020 2020 6465  ddcdiv")..    de
-000121f0: 6620 6761 7468 6572 2873 656c 662c 2064  f gather(self, d
-00012200: 696d 2c20 696e 6465 7829 3a0a 2020 2020  im, index):.    
-00012210: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-00012220: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00012230: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
-00012240: 6e64 6578 203d 2063 6173 745f 746f 5f6d  ndex = cast_to_m
-00012250: 735f 7465 6e73 6f72 2869 6e64 6578 290a  s_tensor(index).
-00012260: 2020 2020 2020 2020 696e 7075 745f 7368          input_sh
-00012270: 6170 6520 3d20 696e 7075 745f 6d73 2e73  ape = input_ms.s
-00012280: 6861 7065 0a20 2020 2020 2020 2069 6e64  hape.        ind
-00012290: 6578 5f73 6861 7065 203d 2069 6e64 6578  ex_shape = index
-000122a0: 2e73 6861 7065 0a20 2020 2020 2020 2069  .shape.        i
-000122b0: 6620 5f67 6174 6865 725f 6e6f 5f6e 6565  f _gather_no_nee
-000122c0: 645f 7061 6464 696e 6728 696e 7075 745f  d_padding(input_
-000122d0: 7368 6170 652c 2069 6e64 6578 5f73 6861  shape, index_sha
-000122e0: 7065 2c20 6469 6d29 3a0a 2020 2020 2020  pe, dim):.      
-000122f0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-00012300: 732e 6f70 732e 6761 7468 6572 5f65 6c65  s.ops.gather_ele
-00012310: 6d65 6e74 7328 696e 7075 745f 6d73 2c20  ments(input_ms, 
-00012320: 6469 6d2c 2069 6e64 6578 290a 2020 2020  dim, index).    
-00012330: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00012340: 2020 2020 2020 7061 6464 696e 675f 7061        padding_pa
-00012350: 7474 6572 6e20 3d20 5f67 6174 6865 725f  ttern = _gather_
-00012360: 6765 745f 7061 6464 696e 675f 7061 7474  get_padding_patt
-00012370: 6572 6e28 696e 7075 745f 7368 6170 652c  ern(input_shape,
-00012380: 2069 6e64 6578 5f73 6861 7065 2c20 6469   index_shape, di
-00012390: 6d29 0a20 2020 2020 2020 2020 2020 2070  m).            p
-000123a0: 6164 6465 645f 696e 6465 7820 3d20 6d73  added_index = ms
-000123b0: 2e6f 7073 2e70 6164 2869 6e64 6578 2c20  .ops.pad(index, 
-000123c0: 7061 6464 696e 675f 7061 7474 6572 6e29  padding_pattern)
-000123d0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-000123e0: 7075 7420 3d20 6d73 2e6f 7073 2e67 6174  put = ms.ops.gat
-000123f0: 6865 725f 656c 656d 656e 7473 2869 6e70  her_elements(inp
-00012400: 7574 5f6d 732c 2064 696d 2c20 7061 6464  ut_ms, dim, padd
-00012410: 6564 5f69 6e64 6578 290a 2020 2020 2020  ed_index).      
-00012420: 2020 2020 2020 696e 6465 785f 6d61 736b        index_mask
-00012430: 203d 206d 732e 6f70 732e 7061 6428 6d73   = ms.ops.pad(ms
-00012440: 2e6f 7073 2e6f 6e65 7328 696e 6465 785f  .ops.ones(index_
-00012450: 7368 6170 6529 2c20 7061 6464 696e 675f  shape), padding_
-00012460: 7061 7474 6572 6e29 2e61 7374 7970 6528  pattern).astype(
-00012470: 6d73 2e62 6f6f 6c5f 290a 2020 2020 2020  ms.bool_).      
-00012480: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
-00012490: 7574 7075 745b 696e 6465 785f 6d61 736b  utput[index_mask
-000124a0: 5d2e 7265 7368 6170 6528 696e 6465 785f  ].reshape(index_
-000124b0: 7368 6170 6529 0a20 2020 2020 2020 2072  shape).        r
-000124c0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-000124d0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-000124e0: 7075 7429 0a0a 2020 2020 6465 6620 666d  put)..    def fm
-000124f0: 6f64 2873 656c 662c 2064 6976 6973 6f72  od(self, divisor
-00012500: 293a 0a20 2020 2020 2020 2078 203d 2063  ):.        x = c
-00012510: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00012520: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-00012530: 7468 6572 203d 2063 6173 745f 746f 5f6d  ther = cast_to_m
-00012540: 735f 7465 6e73 6f72 2864 6976 6973 6f72  s_tensor(divisor
-00012550: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-00012560: 203d 206d 732e 6f70 732e 666d 6f64 2878   = ms.ops.fmod(x
-00012570: 2c20 6f74 6865 7229 0a20 2020 2020 2020  , other).       
-00012580: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00012590: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-000125a0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-000125b0: 666d 6f64 5f28 7365 6c66 2c20 6469 7669  fmod_(self, divi
-000125c0: 736f 7229 3a0a 2020 2020 2020 2020 6f75  sor):.        ou
-000125d0: 7470 7574 203d 2073 656c 662e 666d 6f64  tput = self.fmod
-000125e0: 2864 6976 6973 6f72 290a 2020 2020 2020  (divisor).      
-000125f0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
-00012600: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
-00012610: 7365 6c66 2c20 6f75 7470 7574 2c20 2266  self, output, "f
-00012620: 6d6f 645f 222c 2022 666d 6f64 2229 0a0a  mod_", "fmod")..
-00012630: 2020 2020 6465 6620 6c74 2873 656c 662c      def lt(self,
-00012640: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
-00012650: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00012660: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00012670: 6c66 290a 2020 2020 2020 2020 6f74 6865  lf).        othe
-00012680: 7220 3d20 6361 7374 5f74 6f5f 6d73 5f74  r = cast_to_ms_t
-00012690: 656e 736f 7228 6f74 6865 7229 0a20 2020  ensor(other).   
-000126a0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-000126b0: 2e6f 7073 2e6c 6573 7328 696e 7075 745f  .ops.less(input_
-000126c0: 6d73 2c20 6f74 6865 7229 0a20 2020 2020  ms, other).     
-000126d0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-000126e0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-000126f0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
-00012700: 6620 6c74 5f28 7365 6c66 2c20 6f74 6865  f lt_(self, othe
-00012710: 7229 3a0a 2020 2020 2020 2020 6f75 7470  r):.        outp
-00012720: 7574 203d 2073 656c 662e 6c74 286f 7468  ut = self.lt(oth
-00012730: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
-00012740: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
-00012750: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
-00012760: 6f75 7470 7574 2c20 226c 745f 222c 2022  output, "lt_", "
-00012770: 6c74 2229 0a0a 2020 2020 6465 6620 6c65  lt")..    def le
-00012780: 7373 2873 656c 662c 206f 7468 6572 293a  ss(self, other):
-00012790: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000127a0: 7365 6c66 2e6c 7428 6f74 6865 7229 0a0a  self.lt(other)..
-000127b0: 2020 2020 6465 6620 6c65 7373 5f28 7365      def less_(se
-000127c0: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
-000127d0: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-000127e0: 662e 6c74 286f 7468 6572 290a 2020 2020  f.lt(other).    
-000127f0: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
-00012800: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
-00012810: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
-00012820: 226c 6573 735f 222c 2022 6c65 7373 2229  "less_", "less")
-00012830: 0a0a 2020 2020 6465 6620 6c65 7373 5f65  ..    def less_e
-00012840: 7175 616c 2873 656c 662c 206f 7468 6572  qual(self, other
-00012850: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-00012860: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00012870: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00012880: 2020 2020 2020 6f74 6865 7220 3d20 6361        other = ca
-00012890: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-000128a0: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
-000128b0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6c  utput = ms.ops.l
-000128c0: 6573 735f 6571 7561 6c28 696e 7075 745f  ess_equal(input_
-000128d0: 6d73 2c20 6f74 6865 7229 0a20 2020 2020  ms, other).     
-000128e0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-000128f0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-00012900: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
-00012910: 6620 6c65 7373 5f65 7175 616c 5f28 7365  f less_equal_(se
-00012920: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
-00012930: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-00012940: 662e 6c65 7373 5f65 7175 616c 286f 7468  f.less_equal(oth
-00012950: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
-00012960: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
-00012970: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
-00012980: 6f75 7470 7574 2c20 226c 6573 735f 6571  output, "less_eq
-00012990: 7561 6c5f 222c 2022 6c65 7373 5f65 7175  ual_", "less_equ
-000129a0: 616c 2229 0a0a 2020 2020 6465 6620 6e65  al")..    def ne
-000129b0: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-000129c0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-000129d0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-000129e0: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-000129f0: 2020 6f74 6865 7220 3d20 6361 7374 5f74    other = cast_t
-00012a00: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
-00012a10: 7229 0a20 2020 2020 2020 206f 7574 7075  r).        outpu
-00012a20: 7420 3d20 6d73 2e6f 7073 2e6e 6528 696e  t = ms.ops.ne(in
-00012a30: 7075 745f 6d73 2c20 6f74 6865 7229 0a20  put_ms, other). 
-00012a40: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-00012a50: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00012a60: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-00012a70: 2020 6465 6620 6e65 5f28 7365 6c66 2c20    def ne_(self, 
-00012a80: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
-00012a90: 6f75 7470 7574 203d 2073 656c 662e 6e65  output = self.ne
-00012aa0: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
-00012ab0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-00012ac0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-00012ad0: 6c66 2c20 6f75 7470 7574 2c20 226e 655f  lf, output, "ne_
-00012ae0: 222c 2022 6e65 2229 0a0a 2020 2020 6465  ", "ne")..    de
-00012af0: 6620 6e6f 745f 6571 7561 6c28 7365 6c66  f not_equal(self
-00012b00: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-00012b10: 2020 7265 7475 726e 2073 656c 662e 6e65    return self.ne
-00012b20: 286f 7468 6572 290a 0a20 2020 2064 6566  (other)..    def
-00012b30: 206e 6f74 5f65 7175 616c 5f28 7365 6c66   not_equal_(self
-00012b40: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-00012b50: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
-00012b60: 6e65 286f 7468 6572 290a 2020 2020 2020  ne(other).      
-00012b70: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
-00012b80: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
-00012b90: 7365 6c66 2c20 6f75 7470 7574 2c20 226e  self, output, "n
-00012ba0: 6f74 5f65 7175 616c 5f22 2c20 226e 6f74  ot_equal_", "not
-00012bb0: 5f65 7175 616c 2229 0a0a 2020 2020 6465  _equal")..    de
-00012bc0: 6620 6571 7561 6c28 7365 6c66 2c20 6f74  f equal(self, ot
-00012bd0: 6865 7229 3a0a 2020 2020 2020 2020 6966  her):.        if
-00012be0: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
-00012bf0: 6f74 6865 722c 2054 656e 736f 7229 3a0a  other, Tensor):.
-00012c00: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00012c10: 6520 5661 6c75 6545 7272 6f72 2822 606f  e ValueError("`o
-00012c20: 7468 6572 6020 6d75 7374 2062 6520 5465  ther` must be Te
-00012c30: 6e73 6f72 2229 0a20 2020 2020 2020 2078  nsor").        x
-00012c40: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00012c50: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00012c60: 2020 2079 203d 2063 6173 745f 746f 5f6d     y = cast_to_m
-00012c70: 735f 7465 6e73 6f72 286f 7468 6572 290a  s_tensor(other).
-00012c80: 0a20 2020 2020 2020 2069 6620 782e 6474  .        if x.dt
-00012c90: 7970 6520 213d 2079 2e64 7479 7065 3a0a  ype != y.dtype:.
-00012ca0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00012cb0: 726e 2046 616c 7365 0a20 2020 2020 2020  rn False.       
-00012cc0: 2069 6620 782e 7368 6170 6520 3d3d 2079   if x.shape == y
-00012cd0: 2e73 6861 7065 3a0a 2020 2020 2020 2020  .shape:.        
-00012ce0: 2020 2020 7369 7a65 203d 2078 2e73 697a      size = x.siz
-00012cf0: 650a 2020 2020 2020 2020 2020 2020 6f75  e.            ou
-00012d00: 7470 7574 203d 206d 732e 6f70 732e 6571  tput = ms.ops.eq
-00012d10: 7561 6c28 782c 2079 290a 2020 2020 2020  ual(x, y).      
-00012d20: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
-00012d30: 7574 7075 742e 7375 6d28 290a 2020 2020  utput.sum().    
-00012d40: 2020 2020 2020 2020 6966 206f 7574 7075          if outpu
-00012d50: 7420 3d3d 2073 697a 653a 0a20 2020 2020  t == size:.     
-00012d60: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00012d70: 6e20 5472 7565 0a20 2020 2020 2020 2072  n True.        r
-00012d80: 6574 7572 6e20 4661 6c73 650a 0a20 2020  eturn False..   
-00012d90: 2064 6566 2067 7265 6174 6572 2873 656c   def greater(sel
-00012da0: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
-00012db0: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-00012dc0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00012dd0: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
-00012de0: 6865 7220 3d20 6361 7374 5f74 6f5f 6d73  her = cast_to_ms
-00012df0: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
-00012e00: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00012e10: 6d73 2e6f 7073 2e67 7265 6174 6572 2869  ms.ops.greater(i
-00012e20: 6e70 7574 5f6d 732c 206f 7468 6572 290a  nput_ms, other).
-00012e30: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-00012e40: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00012e50: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
-00012e60: 2020 2064 6566 2067 7265 6174 6572 5f28     def greater_(
-00012e70: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
-00012e80: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-00012e90: 656c 662e 6772 6561 7465 7228 6f74 6865  elf.greater(othe
-00012ea0: 7229 0a20 2020 2020 2020 2072 6574 7572  r).        retur
-00012eb0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-00012ec0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-00012ed0: 7574 7075 742c 2022 6772 6561 7465 725f  utput, "greater_
-00012ee0: 222c 2022 6772 6561 7465 7222 290a 0a20  ", "greater").. 
-00012ef0: 2020 2064 6566 2067 7428 7365 6c66 2c20     def gt(self, 
-00012f00: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
-00012f10: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00012f20: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00012f30: 6629 0a20 2020 2020 2020 206f 7468 6572  f).        other
-00012f40: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00012f50: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
-00012f60: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00012f70: 6f70 732e 6774 2869 6e70 7574 5f6d 732c  ops.gt(input_ms,
-00012f80: 206f 7468 6572 290a 2020 2020 2020 2020   other).        
-00012f90: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00012fa0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00012fb0: 7470 7574 290a 0a20 2020 2064 6566 2067  tput)..    def g
-00012fc0: 745f 2873 656c 662c 206f 7468 6572 293a  t_(self, other):
-00012fd0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00012fe0: 3d20 7365 6c66 2e67 7265 6174 6572 286f  = self.greater(o
-00012ff0: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
-00013000: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
-00013010: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
-00013020: 2c20 6f75 7470 7574 2c20 2267 745f 222c  , output, "gt_",
-00013030: 2022 6774 2229 0a0a 2020 2020 6465 6620   "gt")..    def 
-00013040: 6772 6561 7465 725f 6571 7561 6c28 7365  greater_equal(se
-00013050: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
-00013060: 2020 2020 7820 3d20 6361 7374 5f74 6f5f      x = cast_to_
-00013070: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00013080: 2020 2020 2020 2020 7920 3d20 6361 7374          y = cast
-00013090: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
-000130a0: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
-000130b0: 7075 7420 3d20 6d73 2e6f 7073 2e67 7265  put = ms.ops.gre
-000130c0: 6174 6572 5f65 7175 616c 2878 2c20 7929  ater_equal(x, y)
-000130d0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000130e0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-000130f0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00013100: 2020 2020 6465 6620 6772 6561 7465 725f      def greater_
-00013110: 6571 7561 6c5f 2873 656c 662c 206f 7468  equal_(self, oth
-00013120: 6572 293a 0a20 2020 2020 2020 206f 7574  er):.        out
-00013130: 7075 7420 3d20 7365 6c66 2e67 7265 6174  put = self.great
-00013140: 6572 5f65 7175 616c 286f 7468 6572 290a  er_equal(other).
-00013150: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-00013160: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-00013170: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-00013180: 7574 2c20 2267 7265 6174 6572 5f65 7175  ut, "greater_equ
-00013190: 616c 5f22 2c20 2267 7265 6174 6572 5f65  al_", "greater_e
-000131a0: 7175 616c 2229 0a0a 2020 2020 6465 6620  qual")..    def 
-000131b0: 6172 676d 696e 2873 656c 662c 2064 696d  argmin(self, dim
-000131c0: 3d4e 6f6e 652c 206b 6565 7064 696d 3d46  =None, keepdim=F
-000131d0: 616c 7365 293a 0a20 2020 2020 2020 2069  alse):.        i
-000131e0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-000131f0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00013200: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-00013210: 203d 206d 732e 6f70 732e 6172 676d 696e   = ms.ops.argmin
-00013220: 2869 6e70 7574 5f6d 732c 2061 7869 733d  (input_ms, axis=
-00013230: 6469 6d2c 206b 6565 7064 696d 733d 6b65  dim, keepdims=ke
-00013240: 6570 6469 6d29 0a20 2020 2020 2020 2072  epdim).        r
-00013250: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00013260: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00013270: 7075 7429 0a0a 2020 2020 6465 6620 6172  put)..    def ar
-00013280: 676d 6178 2873 656c 662c 2064 696d 3d4e  gmax(self, dim=N
-00013290: 6f6e 652c 206b 6565 7064 696d 3d46 616c  one, keepdim=Fal
-000132a0: 7365 2c20 6178 6973 3d4e 6f6e 6529 3a0a  se, axis=None):.
-000132b0: 2020 2020 2020 2020 6966 2064 696d 2069          if dim i
-000132c0: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-000132d0: 2020 2020 6469 6d20 3d20 6178 6973 0a20      dim = axis. 
-000132e0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-000132f0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00013300: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00013310: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-00013320: 732e 6172 676d 6178 2869 6e70 7574 5f6d  s.argmax(input_m
-00013330: 732c 2064 696d 2c20 6b65 6570 6469 6d29  s, dim, keepdim)
-00013340: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00013350: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00013360: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00013370: 2020 2020 6465 6620 7479 7065 2873 656c      def type(sel
-00013380: 662c 2064 7479 7065 3d4e 6f6e 652c 206e  f, dtype=None, n
-00013390: 6f6e 5f62 6c6f 636b 696e 673d 4661 6c73  on_blocking=Fals
-000133a0: 652c 202a 2a6b 7761 7267 7329 3a0a 2020  e, **kwargs):.  
-000133b0: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
-000133c0: 645f 6174 7472 286e 6f6e 5f62 6c6f 636b  d_attr(non_block
-000133d0: 696e 6729 0a20 2020 2020 2020 2075 6e73  ing).        uns
-000133e0: 7570 706f 7274 6564 5f61 7474 7228 6b77  upported_attr(kw
-000133f0: 6172 6773 290a 2020 2020 2020 2020 6966  args).        if
-00013400: 2064 7479 7065 2069 7320 4e6f 6e65 3a0a   dtype is None:.
-00013410: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00013420: 726e 205f 6765 745f 7479 7065 5f66 726f  rn _get_type_fro
-00013430: 6d5f 6474 7970 6528 7365 6c66 2e64 7479  m_dtype(self.dty
-00013440: 7065 290a 0a20 2020 2020 2020 205f 6474  pe)..        _dt
-00013450: 7970 6520 3d20 205f 6765 745f 6474 7970  ype =  _get_dtyp
-00013460: 655f 6672 6f6d 5f74 7970 6528 6474 7970  e_from_type(dtyp
-00013470: 6529 0a20 2020 2020 2020 2069 6620 5f64  e).        if _d
-00013480: 7479 7065 203d 3d20 7365 6c66 2e64 7479  type == self.dty
-00013490: 7065 3a0a 2020 2020 2020 2020 2020 2020  pe:.            
-000134a0: 7265 7475 726e 2073 656c 660a 2020 2020  return self.    
-000134b0: 2020 2020 7820 3d20 6361 7374 5f74 6f5f      x = cast_to_
-000134c0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-000134d0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-000134e0: 2078 2e61 7374 7970 6528 5f64 7479 7065   x.astype(_dtype
-000134f0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00013500: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00013510: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-00013520: 0a20 2020 2064 6566 2074 7970 655f 6173  .    def type_as
-00013530: 2873 656c 662c 2074 656e 736f 7229 3a0a  (self, tensor):.
-00013540: 2020 2020 2020 2020 7820 3d20 6361 7374          x = cast
-00013550: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00013560: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
-00013570: 7574 203d 2078 2e61 7374 7970 6528 7465  ut = x.astype(te
-00013580: 6e73 6f72 2e64 7479 7065 290a 2020 2020  nsor.dtype).    
-00013590: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-000135a0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-000135b0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-000135c0: 6566 2067 6574 5f64 6576 6963 6528 7365  ef get_device(se
-000135d0: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
-000135e0: 7572 6e20 2d31 0a0a 2020 2020 6465 6620  urn -1..    def 
-000135f0: 6261 6464 626d 6d28 7365 6c66 2c20 6261  baddbmm(self, ba
-00013600: 7463 6831 2c20 6261 7463 6832 2c20 2a2c  tch1, batch2, *,
-00013610: 2062 6574 613d 312c 2061 6c70 6861 3d31   beta=1, alpha=1
-00013620: 293a 0a20 2020 2020 2020 2078 203d 2063  ):.        x = c
-00013630: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00013640: 2873 656c 6629 0a20 2020 2020 2020 2062  (self).        b
-00013650: 6174 6368 3120 3d20 6361 7374 5f74 6f5f  atch1 = cast_to_
-00013660: 6d73 5f74 656e 736f 7228 6261 7463 6831  ms_tensor(batch1
-00013670: 290a 2020 2020 2020 2020 6261 7463 6832  ).        batch2
-00013680: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00013690: 6e73 6f72 2862 6174 6368 3229 0a20 2020  nsor(batch2).   
-000136a0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-000136b0: 2e6f 7073 2e62 6164 6462 6d6d 2878 2c20  .ops.baddbmm(x, 
-000136c0: 6261 7463 6831 2c20 6261 7463 6832 2c20  batch1, batch2, 
-000136d0: 6265 7461 2c20 616c 7068 6129 0a20 2020  beta, alpha).   
-000136e0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-000136f0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00013700: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-00013710: 6465 6620 6261 6464 626d 6d5f 2873 656c  def baddbmm_(sel
-00013720: 662c 2062 6174 6368 312c 2062 6174 6368  f, batch1, batch
-00013730: 322c 202a 2c20 6265 7461 3d31 2c20 616c  2, *, beta=1, al
-00013740: 7068 613d 3129 3a0a 2020 2020 2020 2020  pha=1):.        
-00013750: 6f75 7470 7574 203d 2073 656c 662e 6261  output = self.ba
-00013760: 6464 626d 6d28 6261 7463 6831 2c20 6261  ddbmm(batch1, ba
-00013770: 7463 6832 2c20 6265 7461 3d62 6574 612c  tch2, beta=beta,
-00013780: 2061 6c70 6861 3d61 6c70 6861 290a 2020   alpha=alpha).  
-00013790: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-000137a0: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-000137b0: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-000137c0: 2c20 2262 6164 6462 6d6d 5f22 2c20 2262  , "baddbmm_", "b
-000137d0: 6164 6462 6d6d 2229 0a0a 2020 2020 6465  addbmm")..    de
-000137e0: 6620 746f 706b 2873 656c 662c 206b 2c20  f topk(self, k, 
-000137f0: 6469 6d3d 4e6f 6e65 2c20 6c61 7267 6573  dim=None, larges
-00013800: 743d 5472 7565 2c20 736f 7274 6564 3d54  t=True, sorted=T
-00013810: 7275 6529 3a0a 2020 2020 2020 2020 696e  rue):.        in
-00013820: 7075 745f 7820 3d20 6361 7374 5f74 6f5f  put_x = cast_to_
-00013830: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00013840: 2020 2020 2020 2020 6966 206b 203d 3d20          if k == 
-00013850: 303a 0a20 2020 2020 2020 2020 2020 2076  0:.            v
-00013860: 616c 7565 2c20 696e 6469 6365 203d 2028  alue, indice = (
-00013870: 6d73 2e6f 7073 2e7a 6572 6f73 2828 302c  ms.ops.zeros((0,
-00013880: 292c 2064 7479 7065 3d69 6e70 7574 5f78  ), dtype=input_x
-00013890: 2e64 7479 7065 292c 206d 732e 6f70 732e  .dtype), ms.ops.
-000138a0: 7a65 726f 7328 2830 2c29 2c20 6474 7970  zeros((0,), dtyp
-000138b0: 653d 6d73 2e69 6e74 3332 2929 0a20 2020  e=ms.int32)).   
-000138c0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-000138d0: 2020 2020 2020 2076 616c 7565 2c20 696e         value, in
-000138e0: 6469 6365 203d 206d 732e 6f70 732e 746f  dice = ms.ops.to
-000138f0: 706b 2869 6e70 7574 5f78 2c20 6b2c 2064  pk(input_x, k, d
-00013900: 696d 2c20 6c61 7267 6573 742c 2073 6f72  im, largest, sor
-00013910: 7465 6429 0a20 2020 2020 2020 2069 6620  ted).        if 
-00013920: 7079 6e61 7469 7665 5f6d 6f64 655f 636f  pynative_mode_co
-00013930: 6e64 6974 696f 6e28 293a 0a20 2020 2020  ndition():.     
-00013940: 2020 2020 2020 2070 6f69 6e74 203d 2073         point = s
-00013950: 6574 5f6e 616d 655f 7475 706c 6528 2774  et_name_tuple('t
-00013960: 6f70 6b27 290a 2020 2020 2020 2020 2020  opk').          
-00013970: 2020 726c 7420 3d20 706f 696e 7428 6361    rlt = point(ca
-00013980: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00013990: 6e73 6f72 2876 616c 7565 292c 2063 6173  nsor(value), cas
-000139a0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-000139b0: 736f 7228 696e 6469 6365 2929 0a20 2020  sor(indice)).   
-000139c0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-000139d0: 726c 740a 2020 2020 2020 2020 7265 7475  rlt.        retu
-000139e0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-000139f0: 6572 5f74 656e 736f 7228 2876 616c 7565  er_tensor((value
-00013a00: 2c20 696e 6469 6365 2929 0a0a 2020 2020  , indice))..    
-00013a10: 6465 6620 6d61 7869 6d75 6d28 7365 6c66  def maximum(self
-00013a20: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-00013a30: 2020 7820 3d20 6361 7374 5f74 6f5f 6d73    x = cast_to_ms
-00013a40: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00013a50: 2020 2020 2020 7920 3d20 6361 7374 5f74        y = cast_t
-00013a60: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
-00013a70: 7229 0a20 2020 2020 2020 2023 544f 444f  r).        #TODO
-00013a80: 3a20 4e41 4e20 6973 2064 6966 6665 7265  : NAN is differe
-00013a90: 6e74 0a20 2020 2020 2020 206f 7574 7075  nt.        outpu
-00013aa0: 7420 3d20 6d73 2e6f 7073 2e6d 6178 696d  t = ms.ops.maxim
-00013ab0: 756d 2878 2c20 7929 0a20 2020 2020 2020  um(x, y).       
-00013ac0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00013ad0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00013ae0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-00013af0: 6d69 6e69 6d75 6d28 7365 6c66 2c20 6f74  minimum(self, ot
-00013b00: 6865 7229 3a0a 2020 2020 2020 2020 7820  her):.        x 
-00013b10: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00013b20: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00013b30: 2020 7920 3d20 6361 7374 5f74 6f5f 6d73    y = cast_to_ms
-00013b40: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
-00013b50: 2020 2020 2020 2023 544f 444f 3a20 4e41         #TODO: NA
-00013b60: 4e20 6973 2064 6966 6665 7265 6e74 0a20  N is different. 
-00013b70: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00013b80: 6d73 2e6f 7073 2e6d 696e 696d 756d 2878  ms.ops.minimum(x
-00013b90: 2c20 7929 0a20 2020 2020 2020 2072 6574  , y).        ret
-00013ba0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-00013bb0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-00013bc0: 7429 0a0a 2020 2020 6465 6620 666d 6178  t)..    def fmax
-00013bd0: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-00013be0: 2020 2020 2020 2069 6620 6973 5f75 6e64         if is_und
-00013bf0: 6572 5f61 7363 656e 645f 636f 6e74 6578  er_ascend_contex
-00013c00: 7428 2920 6f72 2069 735f 756e 6465 725f  t() or is_under_
-00013c10: 6770 755f 636f 6e74 6578 7428 293a 0a20  gpu_context():. 
-00013c20: 2020 2020 2020 2020 2020 2066 6d61 785f             fmax_
-00013c30: 6f70 203d 206e 756d 7079 5f63 656c 6c2e  op = numpy_cell.
-00013c40: 4e75 6d70 7946 6d61 7828 2766 6d61 7827  NumpyFmax('fmax'
-00013c50: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
-00013c60: 7470 7574 203d 2066 6d61 785f 6f70 2873  tput = fmax_op(s
-00013c70: 656c 662c 206f 7468 6572 290a 2020 2020  elf, other).    
-00013c80: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00013c90: 2020 2020 2020 7820 3d20 6361 7374 5f74        x = cast_t
-00013ca0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00013cb0: 290a 2020 2020 2020 2020 2020 2020 7920  ).            y 
-00013cc0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00013cd0: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
-00013ce0: 2020 2020 2020 2023 2054 4f44 4f3a 206d         # TODO: m
-00013cf0: 732e 6f70 732e 666d 6178 206f 6e6c 7920  s.ops.fmax only 
-00013d00: 7375 7070 6f72 7420 4350 5520 6e6f 770a  support CPU now.
-00013d10: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00013d20: 7574 203d 206d 732e 6f70 732e 666d 6178  ut = ms.ops.fmax
-00013d30: 2878 2c20 7929 0a20 2020 2020 2020 2072  (x, y).        r
-00013d40: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00013d50: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00013d60: 7075 7429 0a0a 2020 2020 6465 6620 666d  put)..    def fm
-00013d70: 696e 2873 656c 662c 206f 7468 6572 293a  in(self, other):
-00013d80: 0a20 2020 2020 2020 2066 6d69 6e5f 6f70  .        fmin_op
-00013d90: 203d 206e 756d 7079 5f63 656c 6c2e 4e75   = numpy_cell.Nu
-00013da0: 6d70 7946 6d69 6e28 2766 6d69 6e27 290a  mpyFmin('fmin').
-00013db0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00013dc0: 2066 6d69 6e5f 6f70 2873 656c 662c 206f   fmin_op(self, o
-00013dd0: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
-00013de0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00013df0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-00013e00: 7574 290a 0a20 2020 2064 6566 206d 756c  ut)..    def mul
-00013e10: 7469 706c 7928 7365 6c66 2c20 7661 6c75  tiply(self, valu
-00013e20: 6529 3a0a 2020 2020 2020 2020 7820 3d20  e):.        x = 
-00013e30: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00013e40: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00013e50: 7920 3d20 6361 7374 5f74 6f5f 6d73 5f74  y = cast_to_ms_t
-00013e60: 656e 736f 7228 7661 6c75 6529 0a20 2020  ensor(value).   
-00013e70: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00013e80: 2e6f 7073 2e6d 756c 2878 2c20 7929 0a20  .ops.mul(x, y). 
-00013e90: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-00013ea0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00013eb0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-00013ec0: 2020 6465 6620 6d75 6c74 6970 6c79 5f28    def multiply_(
-00013ed0: 7365 6c66 2c20 7661 6c75 6529 3a0a 2020  self, value):.  
-00013ee0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-00013ef0: 656c 662e 6d75 6c74 6970 6c79 2876 616c  elf.multiply(val
-00013f00: 7565 290a 2020 2020 2020 2020 7265 7475  ue).        retu
-00013f10: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
-00013f20: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
-00013f30: 6f75 7470 7574 2c20 226d 756c 7469 706c  output, "multipl
-00013f40: 795f 222c 2022 6d75 6c74 6970 6c79 2229  y_", "multiply")
-00013f50: 0a0a 2020 2020 6465 6620 6e65 6728 7365  ..    def neg(se
-00013f60: 6c66 293a 0a20 2020 2020 2020 2078 203d  lf):.        x =
-00013f70: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00013f80: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00013f90: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-00013fa0: 2e6e 6567 2878 290a 2020 2020 2020 2020  .neg(x).        
-00013fb0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00013fc0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00013fd0: 7470 7574 290a 0a20 2020 2064 6566 206e  tput)..    def n
-00013fe0: 6567 5f28 7365 6c66 293a 0a20 2020 2020  eg_(self):.     
-00013ff0: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-00014000: 2e6e 6567 2829 0a20 2020 2020 2020 2072  .neg().        r
-00014010: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
-00014020: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
-00014030: 662c 206f 7574 7075 742c 2022 6e65 675f  f, output, "neg_
-00014040: 222c 2022 6e65 6722 290a 0a20 2020 2064  ", "neg")..    d
-00014050: 6566 2072 6176 656c 2873 656c 6629 3a0a  ef ravel(self):.
-00014060: 2020 2020 2020 2020 7820 3d20 6361 7374          x = cast
-00014070: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00014080: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
-00014090: 7574 203d 2078 2e72 6176 656c 2829 0a20  ut = x.ravel(). 
-000140a0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-000140b0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-000140c0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-000140d0: 2020 6465 6620 7365 6c65 6374 2873 656c    def select(sel
-000140e0: 662c 2064 696d 2c20 696e 6465 7829 3a0a  f, dim, index):.
-000140f0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00014100: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00014110: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00014120: 2020 205f 696e 7075 745f 696e 6469 6365     _input_indice
-00014130: 7320 3d20 6d73 2e54 656e 736f 7228 696e  s = ms.Tensor(in
-00014140: 6465 7829 0a20 2020 2020 2020 206f 7574  dex).        out
-00014150: 7075 7420 3d20 6d73 2e6f 7073 2e67 6174  put = ms.ops.gat
-00014160: 6865 7228 696e 7075 745f 6d73 2c20 5f69  her(input_ms, _i
-00014170: 6e70 7574 5f69 6e64 6963 6573 2c20 6469  nput_indices, di
-00014180: 6d29 0a20 2020 2020 2020 206f 7574 7075  m).        outpu
-00014190: 745f 7368 6170 6520 3d20 5f67 6574 5f73  t_shape = _get_s
-000141a0: 656c 6563 745f 6f75 745f 7368 6170 6528  elect_out_shape(
-000141b0: 696e 7075 745f 6d73 2e73 6861 7065 2c20  input_ms.shape, 
-000141c0: 6469 6d29 0a20 2020 2020 2020 206f 7574  dim).        out
-000141d0: 7075 7420 3d20 6f75 7470 7574 2e72 6573  put = output.res
-000141e0: 6861 7065 286f 7574 7075 745f 7368 6170  hape(output_shap
-000141f0: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
-00014200: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00014210: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-00014220: 0a0a 2020 2020 6465 6620 7371 7561 7265  ..    def square
-00014230: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00014240: 7820 3d20 6361 7374 5f74 6f5f 6d73 5f74  x = cast_to_ms_t
-00014250: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00014260: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00014270: 6f70 732e 7371 7561 7265 2878 290a 2020  ops.square(x).  
-00014280: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00014290: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-000142a0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-000142b0: 2064 6566 2073 7175 6172 655f 2873 656c   def square_(sel
-000142c0: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
-000142d0: 7574 203d 2073 656c 662e 7371 7561 7265  ut = self.square
-000142e0: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
-000142f0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-00014300: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-00014310: 7574 7075 742c 2022 7371 7561 7265 5f22  utput, "square_"
-00014320: 2c20 2273 7175 6172 6522 290a 0a20 2020  , "square")..   
-00014330: 2064 6566 2062 726f 6164 6361 7374 5f74   def broadcast_t
-00014340: 6f28 7365 6c66 2c20 7368 6170 6529 3a0a  o(self, shape):.
-00014350: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00014360: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00014370: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00014380: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
-00014390: 2873 6861 7065 2c20 6c69 7374 293a 0a20  (shape, list):. 
-000143a0: 2020 2020 2020 2020 2020 2073 6861 7065             shape
-000143b0: 203d 2074 7570 6c65 2873 6861 7065 290a   = tuple(shape).
-000143c0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-000143d0: 206d 732e 6f70 732e 6272 6f61 6463 6173   ms.ops.broadcas
-000143e0: 745f 746f 2869 6e70 7574 5f6d 732c 2073  t_to(input_ms, s
-000143f0: 6861 7065 290a 2020 2020 2020 2020 7265  hape).        re
-00014400: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00014410: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-00014420: 7574 290a 0a20 2020 2064 6566 2064 6976  ut)..    def div
-00014430: 6964 6528 7365 6c66 2c20 7661 6c75 652c  ide(self, value,
-00014440: 202a 2c20 726f 756e 6469 6e67 5f6d 6f64   *, rounding_mod
-00014450: 653d 4e6f 6e65 2920 3a0a 2020 2020 2020  e=None) :.      
-00014460: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
-00014470: 6469 7628 7661 6c75 652c 2072 6f75 6e64  div(value, round
-00014480: 696e 675f 6d6f 6465 3d72 6f75 6e64 696e  ing_mode=roundin
-00014490: 675f 6d6f 6465 290a 2020 2020 2020 2020  g_mode).        
-000144a0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-000144b0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-000144c0: 7470 7574 290a 0a20 2020 2064 6566 2064  tput)..    def d
-000144d0: 6976 6964 655f 2873 656c 662c 2076 616c  ivide_(self, val
-000144e0: 7565 2c20 2a2c 2072 6f75 6e64 696e 675f  ue, *, rounding_
-000144f0: 6d6f 6465 3d4e 6f6e 6529 203a 0a20 2020  mode=None) :.   
-00014500: 2020 2020 206f 7574 7075 7420 3d20 7365       output = se
-00014510: 6c66 2e64 6976 2876 616c 7565 2c20 726f  lf.div(value, ro
-00014520: 756e 6469 6e67 5f6d 6f64 653d 726f 756e  unding_mode=roun
-00014530: 6469 6e67 5f6d 6f64 6529 0a20 2020 2020  ding_mode).     
-00014540: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-00014550: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-00014560: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-00014570: 6469 7669 6465 5f22 2c20 2264 6976 6964  divide_", "divid
-00014580: 6522 290a 0a20 2020 2064 6566 2075 6e69  e")..    def uni
-00014590: 7175 6528 7365 6c66 2c20 736f 7274 6564  que(self, sorted
-000145a0: 3d54 7275 652c 2072 6574 7572 6e5f 696e  =True, return_in
-000145b0: 7665 7273 653d 4661 6c73 652c 2072 6574  verse=False, ret
-000145c0: 7572 6e5f 636f 756e 7473 3d46 616c 7365  urn_counts=False
-000145d0: 2c20 6469 6d3d 4e6f 6e65 293a 0a20 2020  , dim=None):.   
-000145e0: 2020 2020 2075 6e73 7570 706f 7274 6564       unsupported
-000145f0: 5f61 7474 7228 6469 6d29 0a20 2020 2020  _attr(dim).     
-00014600: 2020 2075 6e73 7570 706f 7274 6564 5f61     unsupported_a
-00014610: 7474 7228 7265 7475 726e 5f63 6f75 6e74  ttr(return_count
-00014620: 7329 0a20 2020 2020 2020 2069 6e70 7574  s).        input
-00014630: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00014640: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00014650: 2020 2020 2020 6461 7461 5f74 7970 6520        data_type 
-00014660: 3d20 696e 7075 745f 6d73 2e64 7479 7065  = input_ms.dtype
-00014670: 0a20 2020 2020 2020 2069 6620 736f 7274  .        if sort
-00014680: 6564 2061 6e64 2072 6574 7572 6e5f 696e  ed and return_in
-00014690: 7665 7273 653a 0a20 2020 2020 2020 2020  verse:.         
-000146a0: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-000146b0: 726f 7228 2244 6f6e 2774 2073 7570 706f  ror("Don't suppo
-000146c0: 7274 2073 6f72 7465 643d 5472 7565 2061  rt sorted=True a
-000146d0: 6e64 2072 6574 7572 6e5f 696e 7665 7273  nd return_invers
-000146e0: 653d 5472 7565 2e22 290a 0a20 2020 2020  e=True.")..     
-000146f0: 2020 2072 6573 2c20 6964 7820 3d20 6d73     res, idx = ms
-00014700: 2e6f 7073 2e75 6e69 7175 6528 696e 7075  .ops.unique(inpu
-00014710: 745f 6d73 290a 2020 2020 2020 2020 6966  t_ms).        if
-00014720: 2073 6f72 7465 643a 0a20 2020 2020 2020   sorted:.       
-00014730: 2020 2020 2072 6573 203d 206d 732e 6f70       res = ms.op
-00014740: 732e 6361 7374 2872 6573 2c20 6d73 2e66  s.cast(res, ms.f
-00014750: 6c6f 6174 3332 290a 2020 2020 2020 2020  loat32).        
-00014760: 2020 2020 7265 732c 205f 203d 206d 732e      res, _ = ms.
-00014770: 6f70 732e 736f 7274 2872 6573 290a 2020  ops.sort(res).  
-00014780: 2020 2020 2020 2020 2020 7265 7320 3d20            res = 
-00014790: 6d73 2e6f 7073 2e63 6173 7428 7265 732c  ms.ops.cast(res,
-000147a0: 2064 6174 615f 7479 7065 290a 2020 2020   data_type).    
-000147b0: 2020 2020 6966 2072 6574 7572 6e5f 696e      if return_in
-000147c0: 7665 7273 653a 0a20 2020 2020 2020 2020  verse:.         
-000147d0: 2020 2072 6573 203d 2063 6173 745f 746f     res = cast_to
-000147e0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-000147f0: 7265 7329 0a20 2020 2020 2020 2020 2020  res).           
-00014800: 2069 6478 203d 2063 6173 745f 746f 5f61   idx = cast_to_a
-00014810: 6461 7074 6572 5f74 656e 736f 7228 6964  dapter_tensor(id
-00014820: 7829 0a20 2020 2020 2020 2020 2020 2072  x).            r
-00014830: 6574 7572 6e20 2872 6573 2c20 6964 7829  eturn (res, idx)
-00014840: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00014850: 2020 2020 2020 2020 2020 2072 6573 203d             res =
-00014860: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00014870: 5f74 656e 736f 7228 7265 7329 0a20 2020  _tensor(res).   
-00014880: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00014890: 7265 730a 0a20 2020 2064 6566 206d 6d28  res..    def mm(
-000148a0: 7365 6c66 2c20 6d61 7432 293a 0a20 2020  self, mat2):.   
-000148b0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-000148c0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-000148d0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-000148e0: 696e 7075 7432 203d 2063 6173 745f 746f  input2 = cast_to
-000148f0: 5f6d 735f 7465 6e73 6f72 286d 6174 3229  _ms_tensor(mat2)
-00014900: 0a20 2020 2020 2020 2069 6e70 7574 5f74  .        input_t
-00014910: 7970 6520 3d20 696e 7075 745f 6d73 2e64  ype = input_ms.d
-00014920: 7479 7065 0a20 2020 2020 2020 2069 6620  type.        if 
-00014930: 696e 7075 745f 7479 7065 2069 6e20 616c  input_type in al
-00014940: 6c5f 696e 745f 7479 7065 2061 6e64 2069  l_int_type and i
-00014950: 735f 756e 6465 725f 6770 755f 636f 6e74  s_under_gpu_cont
-00014960: 6578 7428 293a 0a20 2020 2020 2020 2020  ext():.         
-00014970: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
-00014980: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
-00014990: 7479 7065 2e66 6c6f 6174 3332 290a 2020  type.float32).  
-000149a0: 2020 2020 2020 2020 2020 696e 7075 7432            input2
-000149b0: 203d 2069 6e70 7574 322e 6173 7479 7065   = input2.astype
-000149c0: 286d 7374 7970 652e 666c 6f61 7433 3229  (mstype.float32)
-000149d0: 0a20 2020 2020 2020 2020 2020 2023 2054  .            # T
-000149e0: 4f44 4f3a 2072 6570 616c 6365 2077 6974  ODO: repalce wit
-000149f0: 6820 6f75 7470 7574 203d 206d 732e 6f70  h output = ms.op
-00014a00: 732e 6d61 746d 756c 2869 6e70 7574 5f6d  s.matmul(input_m
-00014a10: 732c 2069 6e70 7574 3229 0a20 2020 2020  s, input2).     
-00014a20: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00014a30: 6375 7374 6f6d 5f6d 6174 6d75 6c28 696e  custom_matmul(in
-00014a40: 7075 745f 6d73 2c20 696e 7075 7432 290a  put_ms, input2).
-00014a50: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00014a60: 7574 203d 206d 732e 6f70 732e 6361 7374  ut = ms.ops.cast
-00014a70: 286f 7574 7075 742c 2069 6e70 7574 5f74  (output, input_t
-00014a80: 7970 6529 0a20 2020 2020 2020 2065 6c73  ype).        els
-00014a90: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
-00014aa0: 2054 4f44 4f3a 2072 6570 616c 6365 2077   TODO: repalce w
-00014ab0: 6974 6820 6f75 7470 7574 203d 206d 732e  ith output = ms.
-00014ac0: 6f70 732e 6d61 746d 756c 2869 6e70 7574  ops.matmul(input
-00014ad0: 5f6d 732c 2069 6e70 7574 3229 0a20 2020  _ms, input2).   
-00014ae0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
-00014af0: 3d20 6375 7374 6f6d 5f6d 6174 6d75 6c28  = custom_matmul(
-00014b00: 696e 7075 745f 6d73 2c20 696e 7075 7432  input_ms, input2
-00014b10: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00014b20: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00014b30: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-00014b40: 0a20 2020 2064 6566 206c 6f67 7375 6d65  .    def logsume
-00014b50: 7870 2873 656c 662c 2064 696d 2c20 6b65  xp(self, dim, ke
-00014b60: 6570 6469 6d3d 4661 6c73 6529 3a0a 2020  epdim=False):.  
-00014b70: 2020 2020 2020 6d73 5f69 6e70 7574 203d        ms_input =
-00014b80: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00014b90: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00014ba0: 2069 6620 6d73 5f69 6e70 7574 2e64 7479   if ms_input.dty
-00014bb0: 7065 2021 3d20 6d73 7479 7065 2e66 6c6f  pe != mstype.flo
-00014bc0: 6174 3332 3a0a 2020 2020 2020 2020 2020  at32:.          
-00014bd0: 2020 6d73 5f69 6e70 7574 203d 206d 735f    ms_input = ms_
-00014be0: 696e 7075 742e 6173 7479 7065 286d 7374  input.astype(mst
-00014bf0: 7970 652e 666c 6f61 7433 3229 0a20 2020  ype.float32).   
-00014c00: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00014c10: 2e6f 7073 2e6c 6f67 7375 6d65 7870 286d  .ops.logsumexp(m
-00014c20: 735f 696e 7075 742c 2064 696d 2c20 6b65  s_input, dim, ke
-00014c30: 6570 6469 6d29 0a20 2020 2020 2020 2072  epdim).        r
-00014c40: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00014c50: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00014c60: 7075 7429 0a0a 2020 2020 6465 6620 6164  put)..    def ad
-00014c70: 646d 7628 7365 6c66 2c20 6d61 742c 2076  dmv(self, mat, v
-00014c80: 6563 2c20 2a2c 2062 6574 613d 312c 2061  ec, *, beta=1, a
-00014c90: 6c70 6861 3d31 293a 0a20 2020 2020 2020  lpha=1):.       
-00014ca0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00014cb0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00014cc0: 6c66 290a 2020 2020 2020 2020 6d61 7420  lf).        mat 
-00014cd0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00014ce0: 736f 7228 6d61 7429 0a20 2020 2020 2020  sor(mat).       
-00014cf0: 2076 6563 203d 2063 6173 745f 746f 5f6d   vec = cast_to_m
-00014d00: 735f 7465 6e73 6f72 2876 6563 290a 2020  s_tensor(vec).  
-00014d10: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-00014d20: 732e 6f70 732e 6164 646d 7628 696e 7075  s.ops.addmv(inpu
-00014d30: 745f 6d73 2c20 6d61 742c 2076 6563 2c20  t_ms, mat, vec, 
-00014d40: 6265 7461 3d62 6574 612c 2061 6c70 6861  beta=beta, alpha
-00014d50: 3d61 6c70 6861 290a 2020 2020 2020 2020  =alpha).        
-00014d60: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00014d70: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00014d80: 7470 7574 290a 0a20 2020 2064 6566 2061  tput)..    def a
-00014d90: 6464 6d76 5f28 7365 6c66 2c20 6d61 742c  ddmv_(self, mat,
-00014da0: 2076 6563 2c20 2a2c 2062 6574 613d 312c   vec, *, beta=1,
-00014db0: 2061 6c70 6861 3d31 293a 0a20 2020 2020   alpha=1):.     
-00014dc0: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-00014dd0: 2e61 6464 6d76 286d 6174 2c20 7665 632c  .addmv(mat, vec,
-00014de0: 2062 6574 613d 6265 7461 2c20 616c 7068   beta=beta, alph
-00014df0: 613d 616c 7068 6129 0a20 2020 2020 2020  a=alpha).       
-00014e00: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
-00014e10: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
-00014e20: 656c 662c 206f 7574 7075 742c 2022 6164  elf, output, "ad
-00014e30: 646d 765f 222c 2022 6164 646d 7622 290a  dmv_", "addmv").
-00014e40: 0a20 2020 2064 6566 2064 6f74 2873 656c  .    def dot(sel
-00014e50: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
-00014e60: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-00014e70: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00014e80: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
-00014e90: 6865 7220 3d20 6361 7374 5f74 6f5f 6d73  her = cast_to_ms
-00014ea0: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
-00014eb0: 2020 2020 2020 2023 544f 444f 3a20 6d73         #TODO: ms
-00014ec0: 2e6f 7073 2e74 656e 736f 725f 646f 7420  .ops.tensor_dot 
-00014ed0: 6f6e 6c79 2073 7570 706f 7274 7320 666c  only supports fl
-00014ee0: 6f61 7431 362f 666c 6f61 7433 320a 2020  oat16/float32.  
-00014ef0: 2020 2020 2020 696e 7075 745f 6474 7970        input_dtyp
-00014f00: 6520 3d20 696e 7075 745f 6d73 2e64 7479  e = input_ms.dty
-00014f10: 7065 0a20 2020 2020 2020 2069 6620 696e  pe.        if in
-00014f20: 7075 745f 6474 7970 6520 696e 2028 6d73  put_dtype in (ms
-00014f30: 7479 7065 2e66 6c6f 6174 3332 2c20 6d73  type.float32, ms
-00014f40: 7479 7065 2e66 6c6f 6174 3136 293a 0a20  type.float16):. 
-00014f50: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-00014f60: 7420 3d20 6d73 2e6f 7073 2e74 656e 736f  t = ms.ops.tenso
-00014f70: 725f 646f 7428 696e 7075 745f 6d73 2c20  r_dot(input_ms, 
-00014f80: 6f74 6865 722c 2031 290a 2020 2020 2020  other, 1).      
-00014f90: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00014fa0: 2020 2020 696e 7075 745f 6d73 203d 2069      input_ms = i
-00014fb0: 6e70 7574 5f6d 732e 6173 7479 7065 286d  nput_ms.astype(m
-00014fc0: 732e 666c 6f61 7433 3229 0a20 2020 2020  s.float32).     
-00014fd0: 2020 2020 2020 206f 7468 6572 203d 206f         other = o
-00014fe0: 7468 6572 2e61 7374 7970 6528 6d73 2e66  ther.astype(ms.f
-00014ff0: 6c6f 6174 3332 290a 2020 2020 2020 2020  loat32).        
-00015000: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00015010: 6f70 732e 7465 6e73 6f72 5f64 6f74 2869  ops.tensor_dot(i
-00015020: 6e70 7574 5f6d 732c 206f 7468 6572 2c20  nput_ms, other, 
-00015030: 3129 0a20 2020 2020 2020 2020 2020 206f  1).            o
-00015040: 7574 7075 7420 3d20 6f75 7470 7574 2e61  utput = output.a
-00015050: 7374 7970 6528 696e 7075 745f 6474 7970  stype(input_dtyp
-00015060: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
-00015070: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00015080: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-00015090: 0a0a 2020 2020 6465 6620 696e 7665 7273  ..    def invers
-000150a0: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
-000150b0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-000150c0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-000150d0: 6c66 290a 2020 2020 2020 2020 6966 2073  lf).        if s
-000150e0: 656c 662e 6474 7970 6520 696e 206d 7364  elf.dtype in msd
-000150f0: 6170 7465 725f 6474 7970 652e 616c 6c5f  apter_dtype.all_
-00015100: 696e 745f 7479 7065 3a0a 2020 2020 2020  int_type:.      
-00015110: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00015120: 2069 6e70 7574 5f6d 732e 6173 7479 7065   input_ms.astype
-00015130: 286d 7374 7970 652e 666c 6f61 7433 3229  (mstype.float32)
-00015140: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00015150: 3d20 6d73 2e6f 7073 2e69 6e76 6572 7365  = ms.ops.inverse
-00015160: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
-00015170: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-00015180: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-00015190: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
-000151a0: 6620 6173 696e 2873 656c 6629 3a0a 2020  f asin(self):.  
-000151b0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00000030: 706f 7274 206f 730a 696d 706f 7274 2061  port os.import a
+00000040: 6263 0a69 6d70 6f72 7420 6e75 6d62 6572  bc.import number
+00000050: 730a 696d 706f 7274 206f 7065 7261 746f  s.import operato
+00000060: 720a 6672 6f6d 2063 6f6c 6c65 6374 696f  r.from collectio
+00000070: 6e73 2069 6d70 6f72 7420 4f72 6465 7265  ns import Ordere
+00000080: 6444 6963 740a 2320 6672 6f6d 2066 756e  dDict.# from fun
+00000090: 6374 6f6f 6c73 2069 6d70 6f72 7420 7265  ctools import re
+000000a0: 6475 6365 2c20 6c72 755f 6361 6368 650a  duce, lru_cache.
+000000b0: 6672 6f6d 2063 6f70 7920 696d 706f 7274  from copy import
+000000c0: 2064 6565 7063 6f70 790a 6672 6f6d 2066   deepcopy.from f
+000000d0: 756e 6374 6f6f 6c73 2069 6d70 6f72 7420  unctools import 
+000000e0: 7265 6475 6365 0a69 6d70 6f72 7420 6e75  reduce.import nu
+000000f0: 6d70 7920 6173 206e 700a 696d 706f 7274  mpy as np.import
+00000100: 206d 696e 6473 706f 7265 2061 7320 6d73   mindspore as ms
+00000110: 0a66 726f 6d20 6d69 6e64 7370 6f72 6520  .from mindspore 
+00000120: 696d 706f 7274 2054 656e 736f 7220 6173  import Tensor as
+00000130: 206d 735f 5465 6e73 6f72 0a74 7279 3a0a   ms_Tensor.try:.
+00000140: 2020 2020 6672 6f6d 206d 696e 6473 706f      from mindspo
+00000150: 7265 2e73 6369 7079 2e6f 7073 2069 6d70  re.scipy.ops imp
+00000160: 6f72 7420 536f 6c76 6554 7269 616e 6775  ort SolveTriangu
+00000170: 6c61 7220 2320 6e6f 7420 7375 7070 6f72  lar # not suppor
+00000180: 7420 6f6e 2077 696e 2063 7075 0a65 7863  t on win cpu.exc
+00000190: 6570 7420 496d 706f 7274 4572 726f 723a  ept ImportError:
+000001a0: 0a20 2020 202e 2e2e 0a66 726f 6d20 6d69  .    ....from mi
+000001b0: 6e64 7370 6f72 652e 636f 6d6d 6f6e 2069  ndspore.common i
+000001c0: 6d70 6f72 7420 6474 7970 6520 6173 206d  mport dtype as m
+000001d0: 7374 7970 650a 696d 706f 7274 206d 696e  stype.import min
+000001e0: 6473 706f 7265 2e6f 7073 2061 7320 500a  dspore.ops as P.
+000001f0: 6672 6f6d 206d 696e 6473 706f 7265 2e6f  from mindspore.o
+00000200: 7073 2e70 7269 6d69 7469 7665 2069 6d70  ps.primitive imp
+00000210: 6f72 7420 5f70 7269 6d65 7870 720a 6672  ort _primexpr.fr
+00000220: 6f6d 206d 696e 6473 706f 7265 2e6f 7073  om mindspore.ops
+00000230: 2e5f 7072 696d 6974 6976 655f 6361 6368  ._primitive_cach
+00000240: 6520 696d 706f 7274 205f 6765 745f 6361  e import _get_ca
+00000250: 6368 655f 7072 696d 0a66 726f 6d20 6d69  che_prim.from mi
+00000260: 6e64 7370 6f72 652e 6f70 732e 6f70 6572  ndspore.ops.oper
+00000270: 6174 696f 6e73 2069 6d70 6f72 7420 5f69  ations import _i
+00000280: 6e6e 6572 5f6f 7073 2061 7320 696e 6e65  nner_ops as inne
+00000290: 720a 6672 6f6d 206d 696e 6473 706f 7265  r.from mindspore
+000002a0: 2e63 6f6d 6d6f 6e2e 696e 6974 6961 6c69  .common.initiali
+000002b0: 7a65 7220 696d 706f 7274 205a 6572 6f0a  zer import Zero.
+000002c0: 6672 6f6d 206d 696e 6473 706f 7265 2e5f  from mindspore._
+000002d0: 635f 6578 7072 6573 7369 6f6e 2069 6d70  c_expression imp
+000002e0: 6f72 7420 5465 6e73 6f72 2061 7320 5465  ort Tensor as Te
+000002f0: 6e73 6f72 5f0a 6672 6f6d 206d 696e 6473  nsor_.from minds
+00000300: 706f 7265 2e63 6f6d 6d6f 6e2e 5f73 7475  pore.common._stu
+00000310: 625f 7465 6e73 6f72 2069 6d70 6f72 7420  b_tensor import 
+00000320: 5374 7562 5465 6e73 6f72 0a66 726f 6d20  StubTensor.from 
+00000330: 6d69 6e64 7370 6f72 652e 636f 6d6d 6f6e  mindspore.common
+00000340: 2e61 7069 2069 6d70 6f72 7420 5f63 6f6e  .api import _con
+00000350: 7665 7274 5f70 7974 686f 6e5f 6461 7461  vert_python_data
+00000360: 0a0a 7472 793a 0a20 2020 2066 726f 6d20  ..try:.    from 
+00000370: 6d69 6e64 7370 6f72 652e 6f70 732e 6175  mindspore.ops.au
+00000380: 746f 5f67 656e 6572 6174 6520 696d 706f  to_generate impo
+00000390: 7274 2064 6565 7063 6f70 7920 6173 2064  rt deepcopy as d
+000003a0: 6565 7063 6f70 795f 6f70 0a65 7863 6570  eepcopy_op.excep
+000003b0: 7420 496d 706f 7274 4572 726f 723a 0a20  t ImportError:. 
+000003c0: 2020 2066 726f 6d20 6d69 6e64 7370 6f72     from mindspor
+000003d0: 652e 6f70 7320 696d 706f 7274 2064 6565  e.ops import dee
+000003e0: 7063 6f70 7920 6173 2064 6565 7063 6f70  pcopy as deepcop
+000003f0: 795f 6f70 0a0a 6672 6f6d 206d 696e 6474  y_op..from mindt
+00000400: 6f72 6368 2e75 7469 6c73 2069 6d70 6f72  orch.utils impor
+00000410: 7420 756e 7375 7070 6f72 7465 645f 6174  t unsupported_at
+00000420: 7472 2c20 6973 5f75 6e64 6572 5f67 7075  tr, is_under_gpu
+00000430: 5f63 6f6e 7465 7874 2c20 6765 745f 6261  _context, get_ba
+00000440: 636b 656e 642c 2069 735f 756e 6465 725f  ckend, is_under_
+00000450: 6173 6365 6e64 5f63 6f6e 7465 7874 2c20  ascend_context, 
+00000460: 5f69 6e66 6572 5f73 697a 652c 205c 0a20  _infer_size, \. 
+00000470: 2020 205f 6173 6365 6e64 5f74 656e 736f     _ascend_tenso
+00000480: 725f 6765 6e65 7261 6c5f 6361 7374 2c20  r_general_cast, 
+00000490: 6973 5f75 6e64 6572 5f63 7075 5f63 6f6e  is_under_cpu_con
+000004a0: 7465 7874 2c20 7079 6e61 7469 7665 5f6d  text, pynative_m
+000004b0: 6f64 655f 636f 6e64 6974 696f 6e2c 2073  ode_condition, s
+000004c0: 6574 5f6d 756c 7469 706c 655f 6e61 6d65  et_multiple_name
+000004d0: 5f74 7570 6c65 2c20 5c0a 2020 2020 7365  _tuple, \.    se
+000004e0: 745f 6e61 6d65 5f74 7570 6c65 2c20 6772  t_name_tuple, gr
+000004f0: 6170 685f 6d6f 6465 5f63 6f6e 6469 7469  aph_mode_conditi
+00000500: 6f6e 2c20 6269 7477 6973 655f 6164 6170  on, bitwise_adap
+00000510: 7465 722c 2046 5036 345f 4d41 582c 2046  ter, FP64_MAX, F
+00000520: 5036 345f 4d49 4e2c 2046 5033 325f 4d41  P64_MIN, FP32_MA
+00000530: 582c 2046 5033 325f 4d49 4e2c 205c 0a20  X, FP32_MIN, \. 
+00000540: 2020 2070 726f 6d6f 7465 5f74 7970 655f     promote_type_
+00000550: 6c6f 6f6b 7570 2c20 6765 745f 656d 7074  lookup, get_empt
+00000560: 795f 7465 6e73 6f72 0a69 6d70 6f72 7420  y_tensor.import 
+00000570: 6d69 6e64 746f 7263 682e 746f 7263 682e  mindtorch.torch.
+00000580: 636f 6d6d 6f6e 2e64 7479 7065 2061 7320  common.dtype as 
+00000590: 6d69 6e64 746f 7263 685f 6474 7970 650a  mindtorch_dtype.
+000005a0: 6672 6f6d 206d 696e 6474 6f72 6368 2e74  from mindtorch.t
+000005b0: 6f72 6368 2e63 6f6d 6d6f 6e2e 6474 7970  orch.common.dtyp
+000005c0: 6520 696d 706f 7274 2061 6c6c 5f69 6e74  e import all_int
+000005d0: 5f74 7970 655f 7769 7468 5f62 6f6f 6c2c  _type_with_bool,
+000005e0: 2066 696e 666f 2c20 6969 6e66 6f2c 2061   finfo, iinfo, a
+000005f0: 6c6c 5f69 6e74 5f74 7970 652c 205f 6765  ll_int_type, _ge
+00000600: 745f 7479 7065 5f66 726f 6d5f 6474 7970  t_type_from_dtyp
+00000610: 652c 205c 0a20 2020 205f 6765 745f 6474  e, \.    _get_dt
+00000620: 7970 655f 6672 6f6d 5f74 7970 652c 2061  ype_from_type, a
+00000630: 6c6c 5f66 6c6f 6174 5f61 6e64 5f63 6f6d  ll_float_and_com
+00000640: 706c 6578 5f74 7970 652c 2061 6c6c 5f63  plex_type, all_c
+00000650: 6f6d 706c 6578 5f74 7970 652c 205f 6d73  omplex_type, _ms
+00000660: 6474 7970 6532 7479 7065 4469 6374 2c20  dtype2typeDict, 
+00000670: 5f54 7970 6544 6963 740a 6672 6f6d 206d  _TypeDict.from m
+00000680: 696e 6474 6f72 6368 2e74 6f72 6368 2e74  indtorch.torch.t
+00000690: 7970 6573 2069 6d70 6f72 7420 6465 7669  ypes import devi
+000006a0: 6365 2061 7320 6465 7669 6365 5f63 6c61  ce as device_cla
+000006b0: 7373 0a66 726f 6d20 6d69 6e64 746f 7263  ss.from mindtorc
+000006c0: 682e 746f 7263 682e 7374 6f72 6167 6520  h.torch.storage 
+000006d0: 696d 706f 7274 205f 5479 7065 6453 746f  import _TypedSto
+000006e0: 7261 6765 2c20 5f55 6e74 7970 6564 5374  rage, _UntypedSt
+000006f0: 6f72 6167 650a 6672 6f6d 206d 696e 6474  orage.from mindt
+00000700: 6f72 6368 2e74 6f72 6368 2e6c 6f67 6769  orch.torch.loggi
+00000710: 6e67 2069 6d70 6f72 7420 7761 726e 696e  ng import warnin
+00000720: 672c 2069 6e66 6f0a 696d 706f 7274 206d  g, info.import m
+00000730: 696e 6474 6f72 6368 2e74 6f72 6368 2e5f  indtorch.torch._
+00000740: 7265 6769 7374 6572 5f6e 756d 7079 5f70  register_numpy_p
+00000750: 7269 6d69 7469 7665 2020 6173 206e 756d  rimitive  as num
+00000760: 7079 5f63 656c 6c0a 6672 6f6d 206d 696e  py_cell.from min
+00000770: 6474 6f72 6368 2e74 6f72 6368 2e5f 6465  dtorch.torch._de
+00000780: 6661 756c 745f 6474 7970 6520 696d 706f  fault_dtype impo
+00000790: 7274 205f 6e6f 745f 6465 6661 756c 745f  rt _not_default_
+000007a0: 6670 3332 5f64 7479 7065 2c20 6765 745f  fp32_dtype, get_
+000007b0: 6465 6661 756c 745f 6474 7970 650a 6672  default_dtype.fr
+000007c0: 6f6d 206d 696e 6474 6f72 6368 2e74 6f72  om mindtorch.tor
+000007d0: 6368 2e5f 432e 5369 7a65 2069 6d70 6f72  ch._C.Size impor
+000007e0: 7420 5369 7a65 0a66 726f 6d20 6d69 6e64  t Size.from mind
+000007f0: 746f 7263 682e 746f 7263 682e 5f74 656e  torch.torch._ten
+00000800: 736f 7220 696d 706f 7274 205f 7265 6275  sor import _rebu
+00000810: 696c 645f 6672 6f6d 5f74 7970 655f 7632  ild_from_type_v2
+00000820: 0a66 726f 6d20 6d69 6e64 746f 7263 682e  .from mindtorch.
+00000830: 746f 7263 6820 696d 706f 7274 205f 7574  torch import _ut
+00000840: 696c 730a 0a5f 6474 7970 6544 6963 7420  ils.._dtypeDict 
+00000850: 3d20 7b0a 2020 2020 2766 6c6f 6174 3136  = {.    'float16
+00000860: 273a 206d 7374 7970 652e 666c 6f61 7431  ': mstype.float1
+00000870: 362c 0a20 2020 2027 666c 6f61 7433 3227  6,.    'float32'
+00000880: 3a20 6d73 7479 7065 2e66 6c6f 6174 3332  : mstype.float32
+00000890: 2c0a 2020 2020 2766 6c6f 6174 3634 273a  ,.    'float64':
+000008a0: 206d 7374 7970 652e 666c 6f61 7436 342c   mstype.float64,
+000008b0: 0a20 2020 2027 696e 7438 273a 206d 7374  .    'int8': mst
+000008c0: 7970 652e 696e 7438 2c0a 2020 2020 2769  ype.int8,.    'i
+000008d0: 6e74 3136 273a 206d 7374 7970 652e 696e  nt16': mstype.in
+000008e0: 7431 362c 0a20 2020 2027 696e 7433 3227  t16,.    'int32'
+000008f0: 3a20 6d73 7479 7065 2e69 6e74 3332 2c0a  : mstype.int32,.
+00000900: 2020 2020 2769 6e74 3634 273a 206d 7374      'int64': mst
+00000910: 7970 652e 696e 7436 342c 0a20 2020 2027  ype.int64,.    '
+00000920: 7569 6e74 3827 3a20 6d73 7479 7065 2e75  uint8': mstype.u
+00000930: 696e 7438 2c0a 2020 2020 2762 6f6f 6c27  int8,.    'bool'
+00000940: 3a20 6d73 7479 7065 2e62 6f6f 6c5f 2c0a  : mstype.bool_,.
+00000950: 2020 2020 2763 6f6d 706c 6578 3634 273a      'complex64':
+00000960: 206d 7374 7970 652e 636f 6d70 6c65 7836   mstype.complex6
+00000970: 342c 0a20 2020 2027 636f 6d70 6c65 7831  4,.    'complex1
+00000980: 3238 273a 206d 7374 7970 652e 636f 6d70  28': mstype.comp
+00000990: 6c65 7831 3238 2c0a 2020 2020 276c 6f6e  lex128,.    'lon
+000009a0: 6727 3a20 6d73 7479 7065 2e69 6e74 3634  g': mstype.int64
+000009b0: 2c0a 2020 2020 2768 616c 6627 3a20 6d73  ,.    'half': ms
+000009c0: 7479 7065 2e66 6c6f 6174 3136 2c0a 2020  type.float16,.  
+000009d0: 2020 2769 6e74 273a 206d 7374 7970 652e    'int': mstype.
+000009e0: 696e 7433 322c 0a20 2020 2027 646f 7562  int32,.    'doub
+000009f0: 6c65 273a 206d 7374 7970 652e 666c 6f61  le': mstype.floa
+00000a00: 7436 342c 0a20 2020 2027 666c 6f61 7427  t64,.    'float'
+00000a10: 3a20 6d73 7479 7065 2e66 6c6f 6174 3332  : mstype.float32
+00000a20: 2c0a 2020 2020 2763 6861 7227 3a20 6d73  ,.    'char': ms
+00000a30: 7479 7065 2e69 6e74 382c 0a20 2020 2027  type.int8,.    '
+00000a40: 6279 7465 273a 206d 7374 7970 652e 7569  byte': mstype.ui
+00000a50: 6e74 382c 0a20 2020 2027 7368 6f72 7427  nt8,.    'short'
+00000a60: 3a20 6d73 7479 7065 2e69 6e74 3136 2c0a  : mstype.int16,.
+00000a70: 2020 2020 2762 666c 6f61 7431 3627 3a20      'bfloat16': 
+00000a80: 6d73 7479 7065 2e62 666c 6f61 7431 360a  mstype.bfloat16.
+00000a90: 7d0a 0a6b 4d61 7849 6e74 3820 3d20 3220  }..kMaxInt8 = 2 
+00000aa0: 2a2a 2037 202d 2031 0a6b 4d61 7849 6e74  ** 7 - 1.kMaxInt
+00000ab0: 3136 203d 2032 202a 2a20 3135 202d 2031  16 = 2 ** 15 - 1
+00000ac0: 0a6b 4d61 7849 6e74 3332 203d 2032 202a  .kMaxInt32 = 2 *
+00000ad0: 2a20 3331 202d 2031 0a6b 4d61 7849 6e74  * 31 - 1.kMaxInt
+00000ae0: 3634 203d 2032 202a 2a20 3633 202d 2031  64 = 2 ** 63 - 1
+00000af0: 0a6b 4d61 7855 696e 7438 203d 2032 202a  .kMaxUint8 = 2 *
+00000b00: 2a20 3820 2d20 310a 6b4d 6178 5569 6e74  * 8 - 1.kMaxUint
+00000b10: 3136 203d 2032 202a 2a20 3136 202d 2031  16 = 2 ** 16 - 1
+00000b20: 0a6b 4d61 7855 696e 7433 3220 3d20 3220  .kMaxUint32 = 2 
+00000b30: 2a2a 2033 3220 2d20 310a 6b4d 6178 5569  ** 32 - 1.kMaxUi
+00000b40: 6e74 3634 203d 2032 202a 2a20 3634 202d  nt64 = 2 ** 64 -
+00000b50: 2031 0a6b 4d61 6e74 6973 7361 466c 6f61   1.kMantissaFloa
+00000b60: 7431 3620 3d20 3220 2a2a 2031 310a 6b4d  t16 = 2 ** 11.kM
+00000b70: 616e 7469 7373 6146 6c6f 6174 3332 203d  antissaFloat32 =
+00000b80: 2032 202a 2a20 3234 0a6b 4d61 6e74 6973   2 ** 24.kMantis
+00000b90: 7361 466c 6f61 7436 3420 3d20 3220 2a2a  saFloat64 = 2 **
+00000ba0: 2035 330a 0a73 7472 6964 6564 203d 2046   53..strided = F
+00000bb0: 616c 7365 0a0a 405f 7072 696d 6578 7072  alse..@_primexpr
+00000bc0: 0a23 2040 6c72 755f 6361 6368 6528 5f47  .# @lru_cache(_G
+00000bd0: 4c4f 4241 4c5f 4c52 555f 4341 4348 455f  LOBAL_LRU_CACHE_
+00000be0: 5349 5a45 290a 6465 6620 5f67 6574 5f75  SIZE).def _get_u
+00000bf0: 6e66 6c61 7474 656e 5f73 697a 6528 696e  nflatten_size(in
+00000c00: 7075 745f 7368 6170 652c 2064 696d 2c20  put_shape, dim, 
+00000c10: 7369 7a65 7329 3a0a 2020 2020 696e 7075  sizes):.    inpu
+00000c20: 745f 7261 6e6b 203d 206c 656e 2869 6e70  t_rank = len(inp
+00000c30: 7574 5f73 6861 7065 290a 2020 2020 6966  ut_shape).    if
+00000c40: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
+00000c50: 7369 7a65 732c 2028 7475 706c 652c 206c  sizes, (tuple, l
+00000c60: 6973 7429 293a 0a20 2020 2020 2020 2072  ist)):.        r
+00000c70: 6169 7365 2054 7970 6545 7272 6f72 2866  aise TypeError(f
+00000c80: 2254 7970 6520 6f66 2060 7369 7a65 7360  "Type of `sizes`
+00000c90: 2073 686f 756c 6420 6265 2060 5475 706c   should be `Tupl
+00000ca0: 6560 206f 7220 604c 6973 7460 2c20 6275  e` or `List`, bu
+00000cb0: 7420 676f 7420 7b74 7970 6528 7369 7a65  t got {type(size
+00000cc0: 7329 7d22 290a 0a20 2020 2069 6620 6c65  s)}")..    if le
+00000cd0: 6e28 7369 7a65 7329 203d 3d20 303a 0a20  n(sizes) == 0:. 
+00000ce0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00000cf0: 7565 4572 726f 7228 2260 7369 7a65 7360  ueError("`sizes`
+00000d00: 206d 7573 7420 6265 206e 6f6e 2d65 6d70   must be non-emp
+00000d10: 7479 2229 0a0a 2020 2020 6966 2069 7369  ty")..    if isi
+00000d20: 6e73 7461 6e63 6528 6469 6d2c 2073 7472  nstance(dim, str
+00000d30: 293a 0a20 2020 2020 2020 2072 6169 7365  ):.        raise
+00000d40: 2054 7970 6545 7272 6f72 2822 556e 7469   TypeError("Unti
+00000d50: 6c20 4e6f 772c 2060 6469 6d60 206e 6f74  l Now, `dim` not
+00000d60: 2073 7570 706f 7274 2074 7970 6520 6f66   support type of
+00000d70: 2073 7472 2069 6e20 6075 6e66 6c61 7474   str in `unflatt
+00000d80: 656e 6022 290a 0a20 2020 205f 6469 6d20  en`")..    _dim 
+00000d90: 3d20 6469 6d0a 2020 2020 6966 205f 6469  = dim.    if _di
+00000da0: 6d20 3c20 303a 0a20 2020 2020 2020 205f  m < 0:.        _
+00000db0: 6469 6d20 2b3d 2069 6e70 7574 5f72 616e  dim += input_ran
+00000dc0: 6b0a 0a20 2020 2069 6620 5f64 696d 203c  k..    if _dim <
+00000dd0: 2030 206f 7220 5f64 696d 203e 3d20 696e   0 or _dim >= in
+00000de0: 7075 745f 7261 6e6b 3a0a 2020 2020 2020  put_rank:.      
+00000df0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00000e00: 6f72 2822 6064 696d 6020 7368 6f75 6c64  or("`dim` should
+00000e10: 2062 6520 696e 2072 616e 6765 205b 7b7d   be in range [{}
+00000e20: 2c20 7b7d 292c 2062 7574 2067 6f74 207b  , {}), but got {
+00000e30: 7d22 2e66 6f72 6d61 7428 2d69 6e70 7574  }".format(-input
+00000e40: 5f72 616e 6b2c 2069 6e70 7574 5f72 616e  _rank, input_ran
+00000e50: 6b2c 2064 696d 2929 0a0a 2020 2020 5f73  k, dim))..    _s
+00000e60: 697a 6573 5f6d 756c 203d 2072 6564 7563  izes_mul = reduc
+00000e70: 6528 6f70 6572 6174 6f72 2e6d 756c 2c20  e(operator.mul, 
+00000e80: 6c69 7374 2873 697a 6573 2929 0a20 2020  list(sizes)).   
+00000e90: 2069 6620 2d31 206e 6f74 2069 6e20 7369   if -1 not in si
+00000ea0: 7a65 7320 616e 6420 5f73 697a 6573 5f6d  zes and _sizes_m
+00000eb0: 756c 2021 3d20 696e 7075 745f 7368 6170  ul != input_shap
+00000ec0: 655b 5f64 696d 5d3a 0a20 2020 2020 2020  e[_dim]:.       
+00000ed0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00000ee0: 7228 6622 756e 666c 6174 7465 6e3a 2050  r(f"unflatten: P
+00000ef0: 726f 7669 6465 6420 6073 697a 6573 6020  rovided `sizes` 
+00000f00: 7b73 697a 6573 7d20 646f 6e27 7420 6d75  {sizes} don't mu
+00000f10: 6c74 6970 6c79 2075 7020 746f 2074 6865  ltiply up to the
+00000f20: 220a 2020 2020 2020 2020 2020 2020 6622  ".            f"
+00000f30: 7369 7a65 206f 6620 6469 6d20 7b64 696d  size of dim {dim
+00000f40: 7d20 287b 696e 7075 745f 7368 6170 655b  } ({input_shape[
+00000f50: 5f64 696d 5d7d 2920 696e 2074 6865 2069  _dim]}) in the i
+00000f60: 6e70 7574 2074 656e 736f 7222 290a 0a20  nput tensor").. 
+00000f70: 2020 206f 7574 5f73 6861 7065 203d 2069     out_shape = i
+00000f80: 6e70 7574 5f73 6861 7065 5b3a 5f64 696d  nput_shape[:_dim
+00000f90: 5d20 2b20 7475 706c 6528 7369 7a65 7329  ] + tuple(sizes)
+00000fa0: 202b 2069 6e70 7574 5f73 6861 7065 5b5f   + input_shape[_
+00000fb0: 6469 6d20 2b20 313a 5d0a 2020 2020 7265  dim + 1:].    re
+00000fc0: 7475 726e 206f 7574 5f73 6861 7065 0a0a  turn out_shape..
+00000fd0: 0a40 5f70 7269 6d65 7870 720a 2320 406c  .@_primexpr.# @l
+00000fe0: 7275 5f63 6163 6865 285f 474c 4f42 414c  ru_cache(_GLOBAL
+00000ff0: 5f4c 5255 5f43 4143 4845 5f53 495a 4529  _LRU_CACHE_SIZE)
+00001000: 0a64 6566 205f 6765 745f 736c 6963 655f  .def _get_slice_
+00001010: 7363 6174 7465 725f 636f 6e73 7428 785f  scatter_const(x_
+00001020: 7368 6170 652c 2064 696d 2c20 7374 6172  shape, dim, star
+00001030: 742c 2065 6e64 2c20 7374 6570 293a 0a20  t, end, step):. 
+00001040: 2020 2078 5f72 616e 6b20 3d20 6c65 6e28     x_rank = len(
+00001050: 785f 7368 6170 6529 0a20 2020 2064 696d  x_shape).    dim
+00001060: 203d 2064 696d 2069 6620 6469 6d20 3e3d   = dim if dim >=
+00001070: 2030 2065 6c73 6520 6469 6d20 2b20 785f   0 else dim + x_
+00001080: 7261 6e6b 0a20 2020 2073 7461 7274 203d  rank.    start =
+00001090: 2073 7461 7274 2069 6620 7374 6172 7420   start if start 
+000010a0: 656c 7365 2030 0a20 2020 2065 6e64 203d  else 0.    end =
+000010b0: 2065 6e64 2069 6620 656e 6420 656c 7365   end if end else
+000010c0: 2078 5f73 6861 7065 5b64 696d 5d0a 2020   x_shape[dim].  
+000010d0: 2020 696e 6465 7820 3d20 6c69 7374 2872    index = list(r
+000010e0: 616e 6765 2873 7461 7274 2c20 656e 642c  ange(start, end,
+000010f0: 2073 7465 7029 290a 2020 2020 7265 7475   step)).    retu
+00001100: 726e 2078 5f72 616e 6b2c 2069 6e64 6578  rn x_rank, index
+00001110: 2c20 6469 6d0a 0a0a 405f 7072 696d 6578  , dim...@_primex
+00001120: 7072 0a23 2040 6c72 755f 6361 6368 6528  pr.# @lru_cache(
+00001130: 5f47 4c4f 4241 4c5f 4c52 555f 4341 4348  _GLOBAL_LRU_CACH
+00001140: 455f 5349 5a45 290a 6465 6620 5f67 6574  E_SIZE).def _get
+00001150: 5f73 656c 6563 745f 6f75 745f 7368 6170  _select_out_shap
+00001160: 6528 696e 7075 745f 7368 6170 652c 2064  e(input_shape, d
+00001170: 696d 293a 0a20 2020 2073 6861 7065 203d  im):.    shape =
+00001180: 205b 696e 7075 745f 7368 6170 655b 695d   [input_shape[i]
+00001190: 2066 6f72 2069 2069 6e20 7261 6e67 6528   for i in range(
+000011a0: 6c65 6e28 696e 7075 745f 7368 6170 6529  len(input_shape)
+000011b0: 2920 6966 2069 2021 3d20 6469 6d5d 0a20  ) if i != dim]. 
+000011c0: 2020 2072 6574 7572 6e20 7475 706c 6528     return tuple(
+000011d0: 7368 6170 6529 0a0a 0a40 5f70 7269 6d65  shape)...@_prime
+000011e0: 7870 720a 2320 406c 7275 5f63 6163 6865  xpr.# @lru_cache
+000011f0: 285f 474c 4f42 414c 5f4c 5255 5f43 4143  (_GLOBAL_LRU_CAC
+00001200: 4845 5f53 495a 4529 0a64 6566 205f 6765  HE_SIZE).def _ge
+00001210: 745f 756e 666f 6c64 5f69 6e64 6963 6573  t_unfold_indices
+00001220: 2869 6e70 7574 5f73 6861 7065 2c20 6469  (input_shape, di
+00001230: 6d65 6e73 696f 6e2c 2073 697a 652c 2073  mension, size, s
+00001240: 7465 7029 3a0a 2020 2020 6966 2064 696d  tep):.    if dim
+00001250: 656e 7369 6f6e 203c 2030 3a0a 2020 2020  ension < 0:.    
+00001260: 2020 2020 6469 6d65 6e73 696f 6e20 2b3d      dimension +=
+00001270: 206c 656e 2869 6e70 7574 5f73 6861 7065   len(input_shape
+00001280: 290a 2020 2020 696e 6469 6365 7320 3d20  ).    indices = 
+00001290: 5b5d 0a20 2020 2066 6f72 2069 2069 6e20  [].    for i in 
+000012a0: 7261 6e67 6528 302c 2069 6e70 7574 5f73  range(0, input_s
+000012b0: 6861 7065 5b64 696d 656e 7369 6f6e 5d20  hape[dimension] 
+000012c0: 2d20 7369 7a65 202b 2031 2c20 7374 6570  - size + 1, step
+000012d0: 293a 0a20 2020 2020 2020 2069 6e64 6963  ):.        indic
+000012e0: 6573 2e61 7070 656e 6428 6c69 7374 2872  es.append(list(r
+000012f0: 616e 6765 2869 2c20 6920 2b20 7369 7a65  ange(i, i + size
+00001300: 2929 290a 0a20 2020 2072 6574 7572 6e20  )))..    return 
+00001310: 696e 6469 6365 732c 2064 696d 656e 7369  indices, dimensi
+00001320: 6f6e 0a0a 405f 7072 696d 6578 7072 0a64  on..@_primexpr.d
+00001330: 6566 205f 6368 6563 6b5f 696e 745f 7369  ef _check_int_si
+00001340: 7a65 2873 697a 652c 206f 705f 6e61 6d65  ze(size, op_name
+00001350: 2c20 6172 675f 6e61 6d65 3d27 7369 7a65  , arg_name='size
+00001360: 2729 3a0a 2020 2020 2320 4368 6563 6b20  '):.    # Check 
+00001370: 7768 6574 6865 7220 2761 7267 5f6e 616d  whether 'arg_nam
+00001380: 6527 2069 7320 616e 2069 6e74 6567 6572  e' is an integer
+00001390: 206f 7220 6120 7465 6e73 6f72 2077 6974   or a tensor wit
+000013a0: 6820 496e 7420 7479 7065 2c20 6f72 2061  h Int type, or a
+000013b0: 2074 7570 6c65 2f6c 6973 7420 636f 6d70   tuple/list comp
+000013c0: 6f73 6564 206f 6620 7468 656d 2c0a 2020  osed of them,.  
+000013d0: 2020 2320 7768 696c 6520 636f 6e76 6572    # while conver
+000013e0: 7469 6e67 2074 6865 6d20 756e 6966 6f72  ting them unifor
+000013f0: 6d6c 7920 746f 2069 6e74 6567 6572 2e0a  mly to integer..
+00001400: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+00001410: 6528 7369 7a65 2c20 5465 6e73 6f72 2920  e(size, Tensor) 
+00001420: 616e 6420 7369 7a65 2e64 7479 7065 2069  and size.dtype i
+00001430: 6e20 616c 6c5f 696e 745f 7479 7065 3a0a  n all_int_type:.
+00001440: 2020 2020 2020 2020 7369 7a65 203d 2069          size = i
+00001450: 6e74 2873 697a 6529 0a20 2020 2065 6c69  nt(size).    eli
+00001460: 6620 6973 696e 7374 616e 6365 2873 697a  f isinstance(siz
+00001470: 652c 2028 7475 706c 652c 206c 6973 7429  e, (tuple, list)
+00001480: 293a 0a20 2020 2020 2020 2073 697a 655f  ):.        size_
+00001490: 203d 2028 290a 2020 2020 2020 2020 666f   = ().        fo
+000014a0: 7220 6974 656d 2069 6e20 7369 7a65 3a0a  r item in size:.
+000014b0: 2020 2020 2020 2020 2020 2020 6966 2069              if i
+000014c0: 7369 6e73 7461 6e63 6528 6974 656d 2c20  sinstance(item, 
+000014d0: 696e 7429 3a0a 2020 2020 2020 2020 2020  int):.          
+000014e0: 2020 2020 2020 7369 7a65 5f20 3d20 7369        size_ = si
+000014f0: 7a65 5f20 2b20 2869 7465 6d2c 290a 2020  ze_ + (item,).  
+00001500: 2020 2020 2020 2020 2020 656c 6966 2069            elif i
+00001510: 7369 6e73 7461 6e63 6528 6974 656d 2c20  sinstance(item, 
+00001520: 5465 6e73 6f72 2920 616e 6420 6974 656d  Tensor) and item
+00001530: 2e64 7479 7065 2069 6e20 616c 6c5f 696e  .dtype in all_in
+00001540: 745f 7479 7065 3a0a 2020 2020 2020 2020  t_type:.        
+00001550: 2020 2020 2020 2020 7369 7a65 5f20 3d20          size_ = 
+00001560: 7369 7a65 5f20 2b20 2869 6e74 2869 7465  size_ + (int(ite
+00001570: 6d29 2c29 0a20 2020 2020 2020 2020 2020  m),).           
+00001580: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00001590: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+000015a0: 7565 4572 726f 7228 6622 466f 7220 277b  ueError(f"For '{
+000015b0: 6f70 5f6e 616d 657d 272c 2074 6865 2063  op_name}', the c
+000015c0: 6f6d 706f 6e65 6e74 206f 6620 277b 6172  omponent of '{ar
+000015d0: 675f 6e61 6d65 7d27 206d 7573 7420 6265  g_name}' must be
+000015e0: 206f 6620 7479 7065 2069 6e74 2c20 2220   of type int, " 
+000015f0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00001600: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001610: 2020 2066 2262 7574 2067 6f74 207b 7479     f"but got {ty
+00001620: 7065 2869 7465 6d29 7d2e 2229 0a20 2020  pe(item)}.").   
+00001630: 2020 2020 2073 697a 6520 3d20 7369 7a65       size = size
+00001640: 5f0a 2020 2020 656c 6966 2073 697a 6520  _.    elif size 
+00001650: 616e 6420 6e6f 7420 6973 696e 7374 616e  and not isinstan
+00001660: 6365 2873 697a 652c 2069 6e74 293a 0a20  ce(size, int):. 
+00001670: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00001680: 7565 4572 726f 7228 6622 466f 7220 277b  ueError(f"For '{
+00001690: 6f70 5f6e 616d 657d 272c 2074 6865 2027  op_name}', the '
+000016a0: 7b61 7267 5f6e 616d 657d 2720 6d75 7374  {arg_name}' must
+000016b0: 2062 6520 6f66 2074 7970 6520 696e 742c   be of type int,
+000016c0: 2062 7574 2067 6f74 207b 7479 7065 2873   but got {type(s
+000016d0: 697a 6529 7d2e 2229 0a20 2020 2072 6574  ize)}.").    ret
+000016e0: 7572 6e20 7369 7a65 0a0a 0a64 6566 2063  urn size...def c
+000016f0: 7573 746f 6d5f 6d61 746d 756c 2869 6e70  ustom_matmul(inp
+00001700: 7574 2c20 6f74 6865 7229 3a0a 2020 2020  ut, other):.    
+00001710: 2320 544f 444f 3a20 6d73 2e6f 7073 2e6d  # TODO: ms.ops.m
+00001720: 6174 6d75 6c20 6e6f 7420 7375 7070 6f72  atmul not suppor
+00001730: 7420 696e 742d 6474 7970 6520 696e 7073  t int-dtype inps
+00001740: 656c 662e 6474 7970 6575 7420 6f6e 2047  elf.dtypeut on G
+00001750: 5055 2c20 6f6e 6c79 2073 7570 706f 7274  PU, only support
+00001760: 2066 6c6f 6174 3136 2f66 6c6f 6174 3332   float16/float32
+00001770: 2064 7479 7065 2069 6e70 7574 2e0a 2020   dtype input..  
+00001780: 2020 696e 7075 745f 6474 7970 6520 3d20    input_dtype = 
+00001790: 696e 7075 742e 6474 7970 650a 2020 2020  input.dtype.    
+000017a0: 6f74 6865 725f 6474 7970 6520 3d20 6f74  other_dtype = ot
+000017b0: 6865 722e 6474 7970 650a 2020 2020 6966  her.dtype.    if
+000017c0: 2069 6e70 7574 5f64 7479 7065 2021 3d20   input_dtype != 
+000017d0: 6f74 6865 725f 6474 7970 653a 0a20 2020  other_dtype:.   
+000017e0: 2020 2020 2052 756e 7469 6d65 4572 726f       RuntimeErro
+000017f0: 7228 2246 6f72 206d 6174 6d75 6c2c 2065  r("For matmul, e
+00001800: 7870 6563 7465 6420 7363 616c 6172 2074  xpected scalar t
+00001810: 7970 6520 7b7d 2c20 6275 7420 666f 756e  ype {}, but foun
+00001820: 6420 7b7d 2e22 2e66 6f72 6d61 7428 696e  d {}.".format(in
+00001830: 7075 745f 6474 7970 652c 206f 7468 6572  put_dtype, other
+00001840: 5f64 7479 7065 2929 0a0a 2020 2020 6966  _dtype))..    if
+00001850: 2069 735f 756e 6465 725f 6770 755f 636f   is_under_gpu_co
+00001860: 6e74 6578 7428 2920 616e 6420 696e 7075  ntext() and inpu
+00001870: 745f 6474 7970 6520 6e6f 7420 696e 2028  t_dtype not in (
+00001880: 6d73 2e66 6c6f 6174 3332 2c20 6d73 2e66  ms.float32, ms.f
+00001890: 6c6f 6174 3136 293a 0a20 2020 2020 2020  loat16):.       
+000018a0: 2069 6e70 7574 203d 2069 6e70 7574 2e61   input = input.a
+000018b0: 7374 7970 6528 6d73 2e66 6c6f 6174 3332  stype(ms.float32
+000018c0: 290a 2020 2020 2020 2020 6f74 6865 7220  ).        other 
+000018d0: 3d20 6f74 6865 722e 6173 7479 7065 286d  = other.astype(m
+000018e0: 732e 666c 6f61 7433 3229 0a0a 2020 2020  s.float32)..    
+000018f0: 6e64 696d 315f 6f72 6967 203d 206d 732e  ndim1_orig = ms.
+00001900: 6f70 732e 7261 6e6b 2869 6e70 7574 290a  ops.rank(input).
+00001910: 2020 2020 6e64 696d 325f 6f72 6967 203d      ndim2_orig =
+00001920: 206d 732e 6f70 732e 7261 6e6b 286f 7468   ms.ops.rank(oth
+00001930: 6572 290a 2020 2020 6966 206e 6469 6d31  er).    if ndim1
+00001940: 5f6f 7269 6720 3d3d 206e 6469 6d32 5f6f  _orig == ndim2_o
+00001950: 7269 673a 0a20 2020 2020 2020 2069 6620  rig:.        if 
+00001960: 6e64 696d 315f 6f72 6967 203d 3d20 323a  ndim1_orig == 2:
+00001970: 0a20 2020 2020 2020 2020 2020 205f 6d61  .            _ma
+00001980: 746d 756c 203d 205f 6765 745f 6361 6368  tmul = _get_cach
+00001990: 655f 7072 696d 2850 2e4d 6174 4d75 6c29  e_prim(P.MatMul)
+000019a0: 2846 616c 7365 2c20 4661 6c73 6529 0a20  (False, False). 
+000019b0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+000019c0: 6e20 5f6d 6174 6d75 6c28 696e 7075 742c  n _matmul(input,
+000019d0: 206f 7468 6572 292e 6173 7479 7065 2869   other).astype(i
+000019e0: 6e70 7574 5f64 7479 7065 290a 0a20 2020  nput_dtype)..   
+000019f0: 2072 6574 7572 6e20 6d73 2e6f 7073 2e6d   return ms.ops.m
+00001a00: 6174 6d75 6c28 696e 7075 742c 206f 7468  atmul(input, oth
+00001a10: 6572 292e 6173 7479 7065 2869 6e70 7574  er).astype(input
+00001a20: 5f64 7479 7065 290a 0a40 5f70 7269 6d65  _dtype)..@_prime
+00001a30: 7870 720a 6465 6620 5f67 6574 5f64 6961  xpr.def _get_dia
+00001a40: 676f 6e61 6c5f 7363 6174 7465 725f 696e  gonal_scatter_in
+00001a50: 6465 7828 696e 7075 745f 7368 6170 652c  dex(input_shape,
+00001a60: 206f 6666 7365 742c 2064 696d 312c 2064   offset, dim1, d
+00001a70: 696d 3229 3a0a 2020 2020 6e64 696d 203d  im2):.    ndim =
+00001a80: 206c 656e 2869 6e70 7574 5f73 6861 7065   len(input_shape
+00001a90: 290a 2020 2020 5f66 6c61 6720 3d20 300a  ).    _flag = 0.
+00001aa0: 2020 2020 6966 206f 6666 7365 7420 3e20      if offset > 
+00001ab0: 3020 6f72 2028 6f66 6673 6574 203d 3d20  0 or (offset == 
+00001ac0: 3020 616e 6420 696e 7075 745f 7368 6170  0 and input_shap
+00001ad0: 655b 6469 6d32 5d20 2d20 6f66 6673 6574  e[dim2] - offset
+00001ae0: 203c 2069 6e70 7574 5f73 6861 7065 5b64   < input_shape[d
+00001af0: 696d 315d 293a 0a20 2020 2020 2020 205f  im1]):.        _
+00001b00: 666c 6167 203d 2031 0a20 2020 2020 2020  flag = 1.       
+00001b10: 205f 6172 616e 6765 5f73 697a 6520 3d20   _arange_size = 
+00001b20: 6d69 6e28 696e 7075 745f 7368 6170 655b  min(input_shape[
+00001b30: 6469 6d31 5d2c 2069 6e70 7574 5f73 6861  dim1], input_sha
+00001b40: 7065 5b64 696d 325d 202d 206f 6666 7365  pe[dim2] - offse
+00001b50: 7429 0a20 2020 2065 6c73 653a 0a20 2020  t).    else:.   
+00001b60: 2020 2020 205f 6172 616e 6765 5f73 697a       _arange_siz
+00001b70: 6520 3d20 696e 7075 745f 7368 6170 655b  e = input_shape[
+00001b80: 6469 6d31 5d0a 0a20 2020 2069 6e64 6578  dim1]..    index
+00001b90: 5f73 6861 7065 203d 206c 6973 7428 696e  _shape = list(in
+00001ba0: 7075 745f 7368 6170 6529 0a20 2020 2069  put_shape).    i
+00001bb0: 6e64 6578 5f73 6861 7065 5b64 696d 325d  ndex_shape[dim2]
+00001bc0: 203d 2031 0a20 2020 2069 6620 5f66 6c61   = 1.    if _fla
+00001bd0: 6720 3d3d 2031 3a0a 2020 2020 2020 2020  g == 1:.        
+00001be0: 696e 6465 785f 7368 6170 655b 6469 6d31  index_shape[dim1
+00001bf0: 5d20 3d20 5f61 7261 6e67 655f 7369 7a65  ] = _arange_size
+00001c00: 0a20 2020 2069 6e64 6578 5f73 6861 7065  .    index_shape
+00001c10: 203d 2074 7570 6c65 2869 6e64 6578 5f73   = tuple(index_s
+00001c20: 6861 7065 290a 0a20 2020 2069 6e64 6578  hape)..    index
+00001c30: 203d 206e 702e 6172 616e 6765 285f 6172   = np.arange(_ar
+00001c40: 616e 6765 5f73 697a 6529 0a20 2020 2069  ange_size).    i
+00001c50: 6e64 6578 203d 2069 6e64 6578 202b 206f  ndex = index + o
+00001c60: 6666 7365 740a 2020 2020 696e 6465 7820  ffset.    index 
+00001c70: 3d20 6e70 2e65 7870 616e 645f 6469 6d73  = np.expand_dims
+00001c80: 2869 6e64 6578 2c20 2d31 290a 2020 2020  (index, -1).    
+00001c90: 666f 7220 5f20 696e 2072 616e 6765 2830  for _ in range(0
+00001ca0: 2c20 6469 6d31 293a 0a20 2020 2020 2020  , dim1):.       
+00001cb0: 2069 6e64 6578 203d 206e 702e 6578 7061   index = np.expa
+00001cc0: 6e64 5f64 696d 7328 696e 6465 782c 2030  nd_dims(index, 0
+00001cd0: 290a 2020 2020 666f 7220 6920 696e 2072  ).    for i in r
+00001ce0: 616e 6765 2864 696d 3120 2b20 312c 2064  ange(dim1 + 1, d
+00001cf0: 696d 3229 3a0a 2020 2020 2020 2020 696e  im2):.        in
+00001d00: 6465 7820 3d20 6e70 2e65 7870 616e 645f  dex = np.expand_
+00001d10: 6469 6d73 2869 6e64 6578 2c20 6929 0a20  dims(index, i). 
+00001d20: 2020 2066 6f72 205f 2069 6e20 7261 6e67     for _ in rang
+00001d30: 6528 6469 6d31 202b 2032 2c20 6e64 696d  e(dim1 + 2, ndim
+00001d40: 293a 0a20 2020 2020 2020 2069 6e64 6578  ):.        index
+00001d50: 203d 206e 702e 6578 7061 6e64 5f64 696d   = np.expand_dim
+00001d60: 7328 696e 6465 782c 202d 3129 0a20 2020  s(index, -1).   
+00001d70: 2069 6e64 6578 203d 206e 702e 6272 6f61   index = np.broa
+00001d80: 6463 6173 745f 746f 2869 6e64 6578 2c20  dcast_to(index, 
+00001d90: 696e 6465 785f 7368 6170 6529 0a20 2020  index_shape).   
+00001da0: 2072 6574 7572 6e20 696e 6465 780a 0a40   return index..@
+00001db0: 5f70 7269 6d65 7870 720a 6465 6620 5f6e  _primexpr.def _n
+00001dc0: 6f72 6d5f 6765 745f 636f 6e73 7428 702c  orm_get_const(p,
+00001dd0: 2064 696d 2c20 6e64 696d 293a 0a20 2020   dim, ndim):.   
+00001de0: 2069 6620 7020 6e6f 7420 696e 205b 4e6f   if p not in [No
+00001df0: 6e65 2c20 2766 726f 272c 2027 6e75 6327  ne, 'fro', 'nuc'
+00001e00: 2c20 666c 6f61 7428 2769 6e66 2729 2c20  , float('inf'), 
+00001e10: 666c 6f61 7428 272d 696e 6627 292c 2030  float('-inf'), 0
+00001e20: 2c20 312c 202d 312c 2032 2c20 2d32 5d3a  , 1, -1, 2, -2]:
+00001e30: 0a20 2020 2020 2020 2072 6169 7365 204e  .        raise N
+00001e40: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
+00001e50: 6f72 2822 2754 656e 736f 722e 6e6f 726d  or("'Tensor.norm
+00001e60: 2720 616e 6420 2774 6f72 6368 2e6e 6f72  ' and 'torch.nor
+00001e70: 6d27 206e 6f74 2073 7570 706f 7274 2060  m' not support `
+00001e80: 7060 2062 6573 6964 6520 220a 2020 2020  p` beside ".    
+00001e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001ea0: 2020 2020 2020 2020 2020 2020 2066 2227               f"'
+00001eb0: 6672 6f27 2c20 276e 7563 272c 2066 6c6f  fro', 'nuc', flo
+00001ec0: 6174 2827 696e 6627 292c 2066 6c6f 6174  at('inf'), float
+00001ed0: 2827 2d69 6e66 2729 2c20 302c 2031 2c20  ('-inf'), 0, 1, 
+00001ee0: 2d31 2c20 322c 202d 322e 2c20 6275 7420  -1, 2, -2., but 
+00001ef0: 676f 7420 703d 7b70 7d2e 2229 0a0a 2020  got p={p}.")..  
+00001f00: 2020 5f6d 6174 7269 785f 6e6f 726d 203d    _matrix_norm =
+00001f10: 2046 616c 7365 0a20 2020 2069 6620 7020   False.    if p 
+00001f20: 696e 2028 302c 2031 2c20 2d31 2c20 2d32  in (0, 1, -1, -2
+00001f30: 293a 0a20 2020 2020 2020 2069 6620 6469  ):.        if di
+00001f40: 6d20 6973 204e 6f6e 653a 0a20 2020 2020  m is None:.     
+00001f50: 2020 2020 2020 2069 6620 6e64 696d 203e         if ndim >
+00001f60: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
+00001f70: 2020 2020 5f6d 6174 7269 785f 6e6f 726d      _matrix_norm
+00001f80: 203d 2054 7275 650a 2020 2020 2020 2020   = True.        
+00001f90: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
+00001fa0: 6469 6d2c 2028 7475 706c 652c 206c 6973  dim, (tuple, lis
+00001fb0: 7429 293a 0a20 2020 2020 2020 2020 2020  t)):.           
+00001fc0: 2069 6620 6c65 6e28 6469 6d29 2021 3d20   if len(dim) != 
+00001fd0: 313a 0a20 2020 2020 2020 2020 2020 2020  1:.             
+00001fe0: 2020 205f 6d61 7472 6978 5f6e 6f72 6d20     _matrix_norm 
+00001ff0: 3d20 5472 7565 0a20 2020 2069 6620 5f6d  = True.    if _m
+00002000: 6174 7269 785f 6e6f 726d 3a0a 2020 2020  atrix_norm:.    
+00002010: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
+00002020: 6c65 6d65 6e74 6564 4572 726f 7228 2246  lementedError("F
+00002030: 6f72 2027 5465 6e73 6f72 2e6e 6f72 6d27  or 'Tensor.norm'
+00002040: 2061 6e64 2027 746f 7263 682e 6e6f 726d   and 'torch.norm
+00002050: 272c 2077 6865 6e20 7020 696e 205b 302c  ', when p in [0,
+00002060: 2031 2c20 2d31 2c20 2d32 5d2c 2022 0a20   1, -1, -2], ". 
+00002070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002090: 2022 6f6e 6c79 2073 7570 706f 7274 2076   "only support v
+000020a0: 6563 746f 722d 6e6f 726d 2e20 220a 2020  ector-norm. ".  
+000020b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000020c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000020d0: 2249 6620 6e65 6564 206d 6174 7269 782d  "If need matrix-
+000020e0: 6e6f 726d 2c20 706c 6561 7365 2075 7365  norm, please use
+000020f0: 2074 6f72 6368 2e6c 696e 616c 672e 6e6f   torch.linalg.no
+00002100: 726d 2069 6e73 7465 6164 2e22 290a 2020  rm instead.").  
+00002110: 2020 6966 2070 2069 6e20 2827 6672 6f27    if p in ('fro'
+00002120: 2c20 3229 3a0a 2020 2020 2020 2020 6966  , 2):.        if
+00002130: 2064 696d 2069 7320 4e6f 6e65 206f 7220   dim is None or 
+00002140: 6973 696e 7374 616e 6365 2864 696d 2c20  isinstance(dim, 
+00002150: 696e 7429 3a0a 2020 2020 2020 2020 2020  int):.          
+00002160: 2020 7020 3d20 4e6f 6e65 0a20 2020 2020    p = None.     
+00002170: 2020 2065 6c69 6620 6973 696e 7374 616e     elif isinstan
+00002180: 6365 2864 696d 2c20 286c 6973 742c 2074  ce(dim, (list, t
+00002190: 7570 6c65 2929 2061 6e64 206c 656e 2864  uple)) and len(d
+000021a0: 696d 2920 3d3d 2031 3a0a 2020 2020 2020  im) == 1:.      
+000021b0: 2020 2020 2020 7020 3d20 4e6f 6e65 0a20        p = None. 
+000021c0: 2020 2072 6574 7572 6e20 700a 0a40 5f70     return p..@_p
+000021d0: 7269 6d65 7870 720a 6465 6620 5f67 6174  rimexpr.def _gat
+000021e0: 6865 725f 6e6f 5f6e 6565 645f 7061 6464  her_no_need_padd
+000021f0: 696e 6728 696e 7075 745f 7368 6170 652c  ing(input_shape,
+00002200: 2069 6e64 6578 5f73 6861 7065 2c20 6469   index_shape, di
+00002210: 6d29 3a0a 2020 2020 696e 7075 745f 7368  m):.    input_sh
+00002220: 6170 655f 6c69 7374 203d 206c 6973 7428  ape_list = list(
+00002230: 696e 7075 745f 7368 6170 6529 0a20 2020  input_shape).   
+00002240: 2069 6e64 6578 5f73 6861 7065 5f6c 6973   index_shape_lis
+00002250: 7420 3d20 6c69 7374 2869 6e64 6578 5f73  t = list(index_s
+00002260: 6861 7065 290a 2020 2020 696e 7075 745f  hape).    input_
+00002270: 7368 6170 655f 6c69 7374 2e70 6f70 2864  shape_list.pop(d
+00002280: 696d 290a 2020 2020 696e 6465 785f 7368  im).    index_sh
+00002290: 6170 655f 6c69 7374 2e70 6f70 2864 696d  ape_list.pop(dim
+000022a0: 290a 2020 2020 7265 7475 726e 2069 6e70  ).    return inp
+000022b0: 7574 5f73 6861 7065 5f6c 6973 7420 3d3d  ut_shape_list ==
+000022c0: 2069 6e64 6578 5f73 6861 7065 5f6c 6973   index_shape_lis
+000022d0: 740a 0a0a 405f 7072 696d 6578 7072 0a64  t...@_primexpr.d
+000022e0: 6566 205f 6761 7468 6572 5f67 6574 5f70  ef _gather_get_p
+000022f0: 6164 6469 6e67 5f70 6174 7465 726e 2869  adding_pattern(i
+00002300: 6e70 7574 5f73 6861 7065 2c20 696e 6465  nput_shape, inde
+00002310: 785f 7368 6170 652c 2064 696d 293a 0a20  x_shape, dim):. 
+00002320: 2020 2070 6164 6469 6e67 5f70 6174 7465     padding_patte
+00002330: 726e 203d 2028 290a 2020 2020 666f 7220  rn = ().    for 
+00002340: 6920 696e 2072 616e 6765 286c 656e 2869  i in range(len(i
+00002350: 6e70 7574 5f73 6861 7065 2929 3a0a 2020  nput_shape)):.  
+00002360: 2020 2020 2020 6966 2069 203d 3d20 6469        if i == di
+00002370: 6d3a 0a20 2020 2020 2020 2020 2020 2070  m:.            p
+00002380: 6164 6469 6e67 5f70 6174 7465 726e 203d  adding_pattern =
+00002390: 2028 302c 2030 2920 2b20 7061 6464 696e   (0, 0) + paddin
+000023a0: 675f 7061 7474 6572 6e0a 2020 2020 2020  g_pattern.      
+000023b0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+000023c0: 2020 2020 7061 6464 696e 675f 7061 7474      padding_patt
+000023d0: 6572 6e20 3d20 2830 2c20 696e 7075 745f  ern = (0, input_
+000023e0: 7368 6170 655b 695d 202d 2069 6e64 6578  shape[i] - index
+000023f0: 5f73 6861 7065 5b69 5d29 202b 2070 6164  _shape[i]) + pad
+00002400: 6469 6e67 5f70 6174 7465 726e 0a20 2020  ding_pattern.   
+00002410: 2072 6574 7572 6e20 7061 6464 696e 675f   return padding_
+00002420: 7061 7474 6572 6e0a 0a63 6c61 7373 205f  pattern..class _
+00002430: 5465 6e73 6f72 4d65 7461 2874 7970 6528  TensorMeta(type(
+00002440: 6d73 5f54 656e 736f 7229 2c20 6162 632e  ms_Tensor), abc.
+00002450: 4142 434d 6574 6129 3a0a 2020 2020 2222  ABCMeta):.    ""
+00002460: 220a 2020 2020 4d65 7461 2063 6c61 7373  ".    Meta class
+00002470: 2066 6f72 2054 656e 736f 722e 2055 7365   for Tensor. Use
+00002480: 6420 696e 7465 726e 616c 6c79 2e0a 2020  d internally..  
+00002490: 2020 2222 220a 0a63 6c61 7373 2054 656e    """..class Ten
+000024a0: 736f 7228 5374 7562 5465 6e73 6f72 2c20  sor(StubTensor, 
+000024b0: 6d65 7461 636c 6173 733d 5f54 656e 736f  metaclass=_Tenso
+000024c0: 724d 6574 6129 3a0a 0a20 2020 206c 6179  rMeta):..    lay
+000024d0: 6f75 7420 3d20 7072 6f70 6572 7479 286c  out = property(l
+000024e0: 616d 6264 6120 7365 6c66 3a20 6f62 6a65  ambda self: obje
+000024f0: 6374 2829 2c20 6c61 6d62 6461 2073 656c  ct(), lambda sel
+00002500: 662c 2076 3a20 4e6f 6e65 2c20 6c61 6d62  f, v: None, lamb
+00002510: 6461 2073 656c 663a 204e 6f6e 6529 0a20  da self: None). 
+00002520: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+00002530: 7365 6c66 2c20 2a64 6174 612c 2072 6571  self, *data, req
+00002540: 7569 7265 735f 6772 6164 3d46 616c 7365  uires_grad=False
+00002550: 2c20 6474 7970 653d 4e6f 6e65 2c20 696e  , dtype=None, in
+00002560: 6e65 723d 4661 6c73 652c 2063 6173 745f  ner=False, cast_
+00002570: 7465 6e73 6f72 3d46 616c 7365 293a 0a20  tensor=False):. 
+00002580: 2020 2020 2020 2069 6620 6361 7374 5f74         if cast_t
+00002590: 656e 736f 723a 0a20 2020 2020 2020 2020  ensor:.         
+000025a0: 2020 2069 6620 6c65 6e28 6461 7461 2920     if len(data) 
+000025b0: 213d 2031 3a0a 2020 2020 2020 2020 2020  != 1:.          
+000025c0: 2020 2020 2020 7261 6973 6520 5275 6e74        raise Runt
+000025d0: 696d 6545 7272 6f72 2822 5465 6e73 6f72  imeError("Tensor
+000025e0: 2069 6e69 7420 6461 7461 206c 656e 6768   init data lengh
+000025f0: 7420 6973 206e 6f74 2031 2077 6865 6e20  t is not 1 when 
+00002600: 6361 7374 5f74 656e 736f 723d 5472 7565  cast_tensor=True
+00002610: 2229 0a20 2020 2020 2020 2020 2020 2069  ").            i
+00002620: 6e70 7574 5f64 6174 6120 3d20 6461 7461  nput_data = data
+00002630: 5b30 5d0a 2020 2020 2020 2020 2020 2020  [0].            
+00002640: 6966 2069 7369 6e73 7461 6e63 6528 696e  if isinstance(in
+00002650: 7075 745f 6461 7461 2c20 5374 7562 5465  put_data, StubTe
+00002660: 6e73 6f72 293a 0a20 2020 2020 2020 2020  nsor):.         
+00002670: 2020 2020 2020 2073 656c 662e 7374 7562         self.stub
+00002680: 203d 2069 6e70 7574 5f64 6174 612e 7374   = input_data.st
+00002690: 7562 0a20 2020 2020 2020 2020 2020 2020  ub.             
+000026a0: 2020 2073 656c 662e 7465 6e73 6f72 203d     self.tensor =
+000026b0: 2069 6e70 7574 5f64 6174 612e 7465 6e73   input_data.tens
+000026c0: 6f72 0a20 2020 2020 2020 2020 2020 2020  or.             
+000026d0: 2020 2073 656c 662e 5f67 7261 6420 3d20     self._grad = 
+000026e0: 696e 7075 745f 6461 7461 2e5f 6772 6164  input_data._grad
+000026f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002700: 2073 656c 662e 5f67 7261 645f 666e 203d   self._grad_fn =
+00002710: 2069 6e70 7574 5f64 6174 612e 5f67 7261   input_data._gra
+00002720: 645f 666e 0a20 2020 2020 2020 2020 2020  d_fn.           
+00002730: 2020 2020 2073 656c 662e 5f72 6571 7569       self._requi
+00002740: 7265 735f 6772 6164 203d 2069 6e70 7574  res_grad = input
+00002750: 5f64 6174 612e 5f72 6571 7569 7265 735f  _data._requires_
+00002760: 6772 6164 0a20 2020 2020 2020 2020 2020  grad.           
+00002770: 2020 2020 2073 656c 662e 5f72 6574 6169       self._retai
+00002780: 6e5f 6772 6164 203d 2069 6e70 7574 5f64  n_grad = input_d
+00002790: 6174 612e 5f72 6574 6169 6e5f 6772 6164  ata._retain_grad
+000027a0: 0a20 2020 2020 2020 2020 2020 2065 6c69  .            eli
+000027b0: 6620 6973 696e 7374 616e 6365 2869 6e70  f isinstance(inp
+000027c0: 7574 5f64 6174 612c 206d 735f 5465 6e73  ut_data, ms_Tens
+000027d0: 6f72 293a 0a20 2020 2020 2020 2020 2020  or):.           
+000027e0: 2020 2020 2073 656c 662e 7374 7562 203d       self.stub =
+000027f0: 204e 6f6e 650a 2020 2020 2020 2020 2020   None.          
+00002800: 2020 2020 2020 7365 6c66 2e74 656e 736f        self.tenso
+00002810: 7220 3d20 696e 7075 745f 6461 7461 0a20  r = input_data. 
+00002820: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00002830: 656c 662e 5f67 7261 6420 3d20 696e 7075  elf._grad = inpu
+00002840: 745f 6461 7461 2e5f 6772 6164 0a20 2020  t_data._grad.   
+00002850: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+00002860: 662e 5f67 7261 645f 666e 203d 2069 6e70  f._grad_fn = inp
+00002870: 7574 5f64 6174 612e 5f67 7261 645f 666e  ut_data._grad_fn
+00002880: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002890: 2073 656c 662e 5f72 6571 7569 7265 735f   self._requires_
+000028a0: 6772 6164 203d 2069 6e70 7574 5f64 6174  grad = input_dat
+000028b0: 612e 5f72 6571 7569 7265 735f 6772 6164  a._requires_grad
+000028c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000028d0: 2073 656c 662e 5f72 6574 6169 6e5f 6772   self._retain_gr
+000028e0: 6164 203d 2069 6e70 7574 5f64 6174 612e  ad = input_data.
+000028f0: 5f72 6574 6169 6e5f 6772 6164 0a20 2020  _retain_grad.   
+00002900: 2020 2020 2020 2020 2065 6c69 6620 6973           elif is
+00002910: 696e 7374 616e 6365 2869 6e70 7574 5f64  instance(input_d
+00002920: 6174 612c 2054 656e 736f 725f 293a 0a20  ata, Tensor_):. 
+00002930: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00002940: 656c 662e 7374 7562 203d 204e 6f6e 650a  elf.stub = None.
+00002950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002960: 7365 6c66 2e74 656e 736f 7220 3d20 696e  self.tensor = in
+00002970: 7075 745f 6461 7461 0a20 2020 2020 2020  put_data.       
+00002980: 2020 2020 2020 2020 2073 656c 662e 5f67           self._g
+00002990: 7261 6420 3d20 4e6f 6e65 0a20 2020 2020  rad = None.     
+000029a0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000029b0: 5f67 7261 645f 666e 203d 204e 6f6e 650a  _grad_fn = None.
+000029c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000029d0: 7365 6c66 2e5f 7265 7175 6972 6573 5f67  self._requires_g
+000029e0: 7261 6420 3d20 7265 7175 6972 6573 5f67  rad = requires_g
+000029f0: 7261 640a 2020 2020 2020 2020 2020 2020  rad.            
+00002a00: 2020 2020 7365 6c66 2e5f 7265 7461 696e      self._retain
+00002a10: 5f67 7261 6420 3d20 4661 6c73 650a 2020  _grad = False.  
+00002a20: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+00002a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002a40: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+00002a50: 2866 2254 656e 736f 7220 696e 6974 2064  (f"Tensor init d
+00002a60: 6174 6120 7479 7065 2069 7320 696e 7661  ata type is inva
+00002a70: 696c 643a 207b 7479 7065 2869 6e70 7574  ild: {type(input
+00002a80: 5f64 6174 6129 7d22 290a 2020 2020 2020  _data)}").      
+00002a90: 2020 2020 2020 7365 6c66 2e61 6461 7074        self.adapt
+00002aa0: 6572 5f66 6c61 6720 3d20 5472 7565 0a20  er_flag = True. 
+00002ab0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+00002ac0: 6c61 796f 7574 203d 2073 7472 6964 6564  layout = strided
+00002ad0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00002ae0: 7572 6e0a 0a20 2020 2020 2020 2069 6620  urn..        if 
+00002af0: 6474 7970 6520 6973 206e 6f74 204e 6f6e  dtype is not Non
+00002b00: 653a 0a20 2020 2020 2020 2020 2020 2064  e:.            d
+00002b10: 7479 7065 203d 205f 6474 7970 6544 6963  type = _dtypeDic
+00002b20: 745b 7374 7228 6474 7970 6529 2e73 706c  t[str(dtype).spl
+00002b30: 6974 2827 2e27 295b 2d31 5d2e 6c6f 7765  it('.')[-1].lowe
+00002b40: 7228 295d 0a0a 2020 2020 2020 2020 6966  r()]..        if
+00002b50: 2069 6e6e 6572 2069 7320 5472 7565 3a0a   inner is True:.
+00002b60: 2020 2020 2020 2020 2020 2020 696e 6974              init
+00002b70: 5f74 656e 736f 7220 3d20 6d73 5f54 656e  _tensor = ms_Ten
+00002b80: 736f 7228 2a64 6174 612c 2064 7479 7065  sor(*data, dtype
+00002b90: 3d64 7479 7065 290a 2020 2020 2020 2020  =dtype).        
+00002ba0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00002bb0: 2020 5f69 6e70 7574 5f64 6174 612c 205f    _input_data, _
+00002bc0: 7368 6170 6520 3d20 7365 6c66 2e5f 7072  shape = self._pr
+00002bd0: 6f63 6573 735f 6461 7461 2864 6174 6129  ocess_data(data)
+00002be0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00002bf0: 5f73 6861 7065 3a0a 2020 2020 2020 2020  _shape:.        
+00002c00: 2020 2020 2020 2020 6966 2064 7479 7065          if dtype
+00002c10: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00002c20: 2020 2020 2020 2020 2020 2020 2020 6474                dt
+00002c30: 7970 6520 3d20 6765 745f 6465 6661 756c  ype = get_defaul
+00002c40: 745f 6474 7970 6528 290a 2020 2020 2020  t_dtype().      
+00002c50: 2020 2020 2020 2020 2020 696e 6974 5f66            init_f
+00002c60: 756e 6320 3d20 5a65 726f 2829 0a20 2020  unc = Zero().   
+00002c70: 2020 2020 2020 2020 2020 2020 2069 6e69               ini
+00002c80: 745f 6675 6e63 2e5f 5f65 6e61 626c 655f  t_func.__enable_
+00002c90: 7a65 726f 5f64 696d 5f5f 203d 2054 7275  zero_dim__ = Tru
+00002ca0: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+00002cb0: 2020 696e 6974 5f74 656e 736f 7220 3d20    init_tensor = 
+00002cc0: 6d73 5f54 656e 736f 7228 7368 6170 653d  ms_Tensor(shape=
+00002cd0: 5f73 6861 7065 2c20 6474 7970 653d 6474  _shape, dtype=dt
+00002ce0: 7970 652c 2069 6e69 743d 696e 6974 5f66  ype, init=init_f
+00002cf0: 756e 6329 0a20 2020 2020 2020 2020 2020  unc).           
+00002d00: 2020 2020 2069 6e69 745f 7465 6e73 6f72       init_tensor
+00002d10: 2e69 6e69 745f 6461 7461 2829 0a20 2020  .init_data().   
+00002d20: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+00002d30: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00002d40: 6620 6474 7970 6520 6973 204e 6f6e 653a  f dtype is None:
+00002d50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002d60: 2020 2020 2069 6620 6e6f 7420 6973 696e       if not isin
+00002d70: 7374 616e 6365 285f 696e 7075 745f 6461  stance(_input_da
+00002d80: 7461 2c20 286d 732e 5465 6e73 6f72 2c20  ta, (ms.Tensor, 
+00002d90: 5465 6e73 6f72 5f2c 205f 5479 7065 6453  Tensor_, _TypedS
+00002da0: 746f 7261 6765 2929 3a0a 2020 2020 2020  torage)):.      
+00002db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002dc0: 2020 6474 7970 6520 3d20 6765 745f 6465    dtype = get_de
+00002dd0: 6661 756c 745f 6474 7970 6528 290a 2020  fault_dtype().  
+00002de0: 2020 2020 2020 2020 2020 2020 2020 696e                in
+00002df0: 6974 5f74 656e 736f 7220 3d20 6d73 5f54  it_tensor = ms_T
+00002e00: 656e 736f 7228 696e 7075 745f 6461 7461  ensor(input_data
+00002e10: 3d5f 696e 7075 745f 6461 7461 2c20 6474  =_input_data, dt
+00002e20: 7970 653d 6474 7970 6529 0a20 2020 2020  ype=dtype).     
+00002e30: 2020 2073 7570 6572 2854 656e 736f 722c     super(Tensor,
+00002e40: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
+00002e50: 7465 6e73 6f72 3d69 6e69 745f 7465 6e73  tensor=init_tens
+00002e60: 6f72 290a 2020 2020 2020 2020 7365 6c66  or).        self
+00002e70: 2e61 6461 7074 6572 5f66 6c61 6720 3d20  .adapter_flag = 
+00002e80: 5472 7565 0a20 2020 2020 2020 2073 656c  True.        sel
+00002e90: 662e 6c61 796f 7574 203d 2073 7472 6964  f.layout = strid
+00002ea0: 6564 0a20 2020 2020 2020 2073 656c 662e  ed.        self.
+00002eb0: 7265 7175 6972 6573 5f67 7261 6420 3d20  requires_grad = 
+00002ec0: 7265 7175 6972 6573 5f67 7261 640a 0a0a  requires_grad...
+00002ed0: 2020 2020 6465 6620 5f70 726f 6365 7373      def _process
+00002ee0: 5f64 6174 6128 7365 6c66 2c20 6461 7461  _data(self, data
+00002ef0: 293a 0a20 2020 2020 2020 205f 7368 6170  ):.        _shap
+00002f00: 6520 3d20 4e6f 6e65 0a20 2020 2020 2020  e = None.       
+00002f10: 205f 696e 7075 745f 6461 7461 203d 204e   _input_data = N
+00002f20: 6f6e 650a 2020 2020 2020 2020 6966 206c  one.        if l
+00002f30: 656e 2864 6174 6129 203d 3d20 313a 0a20  en(data) == 1:. 
+00002f40: 2020 2020 2020 2020 2020 2069 6620 6973             if is
+00002f50: 696e 7374 616e 6365 2864 6174 615b 305d  instance(data[0]
+00002f60: 2c20 2869 6e74 2c20 6e70 2e69 6e74 6567  , (int, np.integ
+00002f70: 6572 2929 3a0a 2020 2020 2020 2020 2020  er)):.          
+00002f80: 2020 2020 2020 5f73 6861 7065 203d 2064        _shape = d
+00002f90: 6174 610a 2020 2020 2020 2020 2020 2020  ata.            
+00002fa0: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
+00002fb0: 6461 7461 5b30 5d2c 2053 697a 6529 3a0a  data[0], Size):.
+00002fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002fd0: 5f73 6861 7065 203d 2064 6174 615b 305d  _shape = data[0]
+00002fe0: 0a20 2020 2020 2020 2020 2020 2065 6c69  .            eli
+00002ff0: 6620 6973 696e 7374 616e 6365 2864 6174  f isinstance(dat
+00003000: 615b 305d 2c20 286e 702e 6e64 6172 7261  a[0], (np.ndarra
+00003010: 792c 206d 732e 5465 6e73 6f72 2c20 5465  y, ms.Tensor, Te
+00003020: 6e73 6f72 5f29 293a 0a20 2020 2020 2020  nsor_)):.       
+00003030: 2020 2020 2020 2020 205f 696e 7075 745f           _input_
+00003040: 6461 7461 203d 2064 6174 615b 305d 0a20  data = data[0]. 
+00003050: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+00003060: 6973 696e 7374 616e 6365 2864 6174 615b  isinstance(data[
+00003070: 305d 2c20 2874 7570 6c65 2c20 6c69 7374  0], (tuple, list
+00003080: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
+00003090: 2020 2020 6966 206c 656e 2864 6174 615b      if len(data[
+000030a0: 305d 2920 3d3d 2030 3a0a 2020 2020 2020  0]) == 0:.      
+000030b0: 2020 2020 2020 2020 2020 2020 2020 5f73                _s
+000030c0: 6861 7065 203d 2028 302c 290a 2020 2020  hape = (0,).    
+000030d0: 2020 2020 2020 2020 2020 2020 656c 7365              else
+000030e0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+000030f0: 2020 2020 2020 5f69 6e70 7574 5f64 6174        _input_dat
+00003100: 6120 3d20 6461 7461 5b30 5d0a 2020 2020  a = data[0].    
+00003110: 2020 2020 2020 2020 656c 6966 2069 7369          elif isi
+00003120: 6e73 7461 6e63 6528 6461 7461 5b30 5d2c  nstance(data[0],
+00003130: 205f 5479 7065 6453 746f 7261 6765 293a   _TypedStorage):
+00003140: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003150: 205f 696e 7075 745f 6461 7461 3d64 6174   _input_data=dat
+00003160: 615b 305d 2e5f 7374 6f72 6167 652e 696e  a[0]._storage.in
+00003170: 6e65 725f 6461 7461 0a20 2020 2020 2020  ner_data.       
+00003180: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+00003190: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+000031a0: 2054 7970 6545 7272 6f72 2866 2246 6f72   TypeError(f"For
+000031b0: 2054 656e 736f 722c 2064 6174 6120 6d75   Tensor, data mu
+000031c0: 7374 2062 6520 6120 7365 7175 656e 6365  st be a sequence
+000031d0: 2c20 676f 7420 7b74 7970 6528 6461 7461  , got {type(data
+000031e0: 5b30 5d29 7d22 290a 2020 2020 2020 2020  [0])}").        
+000031f0: 656c 6966 206c 656e 2864 6174 6129 203e  elif len(data) >
+00003200: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
+00003210: 5f73 6861 7065 203d 206c 6973 7428 6461  _shape = list(da
+00003220: 7461 290a 2020 2020 2020 2020 2020 2020  ta).            
+00003230: 666f 7220 692c 2073 2069 6e20 656e 756d  for i, s in enum
+00003240: 6572 6174 6528 6461 7461 293a 0a20 2020  erate(data):.   
+00003250: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00003260: 6973 696e 7374 616e 6365 2873 2c20 2869  isinstance(s, (i
+00003270: 6e74 2c20 6e70 2e69 6e74 6567 6572 2929  nt, np.integer))
+00003280: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00003290: 2020 2020 2020 636f 6e74 696e 7565 0a20        continue. 
+000032a0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+000032b0: 6620 6973 696e 7374 616e 6365 2873 2c20  f isinstance(s, 
+000032c0: 5465 6e73 6f72 293a 0a20 2020 2020 2020  Tensor):.       
+000032d0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000032e0: 732e 6474 7970 6520 6e6f 7420 696e 2061  s.dtype not in a
+000032f0: 6c6c 5f69 6e74 5f74 7970 655f 7769 7468  ll_int_type_with
+00003300: 5f62 6f6f 6c3a 0a20 2020 2020 2020 2020  _bool:.         
+00003310: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00003320: 6169 7365 2054 7970 6545 7272 6f72 2822  aise TypeError("
+00003330: 466f 7220 5465 6e73 6f72 2069 6e70 7574  For Tensor input
+00003340: 2073 6861 7065 2c20 220a 2020 2020 2020   shape, ".      
+00003350: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003370: 2020 6622 656c 656d 656e 7473 2073 686f    f"elements sho
+00003380: 756c 6420 6265 2069 6e74 2074 7970 6520  uld be int type 
+00003390: 6275 7420 676f 7420 7b73 2e64 7479 7065  but got {s.dtype
+000033a0: 7d20 6174 2070 6f73 207b 6920 2b20 317d  } at pos {i + 1}
+000033b0: 2229 0a20 2020 2020 2020 2020 2020 2020  ").             
+000033c0: 2020 2020 2020 205f 7368 6170 655b 695d         _shape[i]
+000033d0: 203d 2069 6e74 2873 290a 2020 2020 2020   = int(s).      
+000033e0: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
+000033f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003400: 2020 2020 7261 6973 6520 5479 7065 4572      raise TypeEr
+00003410: 726f 7228 2246 6f72 2054 656e 736f 722c  ror("For Tensor,
+00003420: 2065 6c65 6d65 6e74 7320 6f66 2073 6861   elements of sha
+00003430: 7065 206d 7573 7420 6265 2069 6e74 206f  pe must be int o
+00003440: 7220 5465 6e73 6f72 2e22 290a 2020 2020  r Tensor.").    
+00003450: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00003460: 2020 2020 2020 5f73 6861 7065 203d 2028        _shape = (
+00003470: 302c 290a 2020 2020 2020 2020 7265 7475  0,).        retu
+00003480: 726e 205f 696e 7075 745f 6461 7461 2c20  rn _input_data, 
+00003490: 5f73 6861 7065 0a0a 2020 2020 6465 6620  _shape..    def 
+000034a0: 5f5f 666f 726d 6174 5f5f 2873 656c 662c  __format__(self,
+000034b0: 2066 6f72 6d61 745f 7370 6563 293a 0a20   format_spec):. 
+000034c0: 2020 2020 2020 2069 6620 7365 6c66 2e64         if self.d
+000034d0: 696d 2829 203d 3d20 3020 616e 6420 6973  im() == 0 and is
+000034e0: 696e 7374 616e 6365 2873 656c 662c 2054  instance(self, T
+000034f0: 656e 736f 7229 3a0a 2020 2020 2020 2020  ensor):.        
+00003500: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+00003510: 6974 656d 2829 2e5f 5f66 6f72 6d61 745f  item().__format_
+00003520: 5f28 666f 726d 6174 5f73 7065 6329 0a20  _(format_spec). 
+00003530: 2020 2020 2020 2072 6574 7572 6e20 6f62         return ob
+00003540: 6a65 6374 2e5f 5f66 6f72 6d61 745f 5f28  ject.__format__(
+00003550: 7365 6c66 2c20 666f 726d 6174 5f73 7065  self, format_spe
+00003560: 6329 0a0a 2020 2020 4063 6c61 7373 6d65  c)..    @classme
+00003570: 7468 6f64 0a20 2020 2064 6566 205f 5f73  thod.    def __s
+00003580: 7562 636c 6173 7368 6f6f 6b5f 5f28 636c  ubclasshook__(cl
+00003590: 732c 2070 6172 616d 293a 0a20 2020 2020  s, param):.     
+000035a0: 2020 2022 2222 0a20 2020 2020 2020 2050     """.        P
+000035b0: 6172 616d 6574 6572 2077 696c 6c20 6265  arameter will be
+000035c0: 2069 6e73 7461 6e63 6520 6f66 2054 656e   instance of Ten
+000035d0: 736f 720a 2020 2020 2020 2020 2222 220a  sor.        """.
+000035e0: 2020 2020 2020 2020 6966 2063 6c73 2069          if cls i
+000035f0: 7320 5465 6e73 6f72 3a0a 2020 2020 2020  s Tensor:.      
+00003600: 2020 2020 2020 6966 2061 6e79 2822 7061        if any("pa
+00003610: 7261 6d5f 696e 666f 2220 696e 2073 2e5f  ram_info" in s._
+00003620: 5f64 6963 745f 5f20 666f 7220 7320 696e  _dict__ for s in
+00003630: 2070 6172 616d 2e5f 5f6d 726f 5f5f 293a   param.__mro__):
+00003640: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003650: 2072 6574 7572 6e20 5472 7565 0a20 2020   return True.   
+00003660: 2020 2020 2072 6574 7572 6e20 4e6f 7449       return NotI
+00003670: 6d70 6c65 6d65 6e74 6564 0a0a 2020 2020  mplemented..    
+00003680: 6465 6620 5f5f 6465 6570 636f 7079 5f5f  def __deepcopy__
+00003690: 2873 656c 662c 206d 656d 6f64 6963 7429  (self, memodict)
+000036a0: 3a0a 2020 2020 2020 2020 7465 6e73 6f72  :.        tensor
+000036b0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+000036c0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+000036d0: 2020 2020 2020 7265 7475 726e 2054 656e        return Ten
+000036e0: 736f 7228 6d73 2e54 656e 736f 722e 5f5f  sor(ms.Tensor.__
+000036f0: 6465 6570 636f 7079 5f5f 2874 656e 736f  deepcopy__(tenso
+00003700: 725f 6d73 2c20 6d65 6d6f 6469 6374 2929  r_ms, memodict))
+00003710: 0a0a 2020 2020 6465 6620 5f5f 6e65 675f  ..    def __neg_
+00003720: 5f28 7365 6c66 293a 0a20 2020 2020 2020  _(self):.       
+00003730: 2074 656e 736f 725f 6d73 203d 2063 6173   tensor_ms = cas
+00003740: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+00003750: 656c 6629 0a20 2020 2020 2020 206f 7574  elf).        out
+00003760: 203d 2074 656e 736f 725f 6d73 2e5f 5f6e   = tensor_ms.__n
+00003770: 6567 5f5f 2829 0a20 2020 2020 2020 2072  eg__().        r
+00003780: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00003790: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+000037a0: 290a 0a20 2020 2064 6566 205f 5f69 6e76  )..    def __inv
+000037b0: 6572 745f 5f28 7365 6c66 293a 0a20 2020  ert__(self):.   
+000037c0: 2020 2020 2074 656e 736f 725f 6d73 203d       tensor_ms =
+000037d0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+000037e0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+000037f0: 2069 6620 7465 6e73 6f72 5f6d 732e 6474   if tensor_ms.dt
+00003800: 7970 6520 213d 206d 732e 626f 6f6c 5f3a  ype != ms.bool_:
+00003810: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00003820: 203d 202d 2031 202d 2074 656e 736f 725f   = - 1 - tensor_
+00003830: 6d73 0a20 2020 2020 2020 2065 6c73 653a  ms.        else:
+00003840: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00003850: 203d 2074 656e 736f 725f 6d73 2e5f 5f69   = tensor_ms.__i
+00003860: 6e76 6572 745f 5f28 290a 2020 2020 2020  nvert__().      
+00003870: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+00003880: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+00003890: 6f75 7429 0a0a 2020 2020 6465 6620 5f5f  out)..    def __
+000038a0: 726f 756e 645f 5f28 7365 6c66 293a 0a20  round__(self):. 
+000038b0: 2020 2020 2020 2074 656e 736f 725f 6d73         tensor_ms
+000038c0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000038d0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+000038e0: 2020 206f 7574 203d 2074 656e 736f 725f     out = tensor_
+000038f0: 6d73 2e5f 5f72 6f75 6e64 5f5f 2829 0a20  ms.__round__(). 
+00003900: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00003910: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00003920: 6e73 6f72 286f 7574 290a 0a20 2020 2064  nsor(out)..    d
+00003930: 6566 205f 5f70 6f73 5f5f 2873 656c 6629  ef __pos__(self)
+00003940: 3a0a 2020 2020 2020 2020 7465 6e73 6f72  :.        tensor
+00003950: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+00003960: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+00003970: 2020 2020 2020 6f75 7420 3d20 7465 6e73        out = tens
+00003980: 6f72 5f6d 732e 5f5f 706f 735f 5f28 290a  or_ms.__pos__().
+00003990: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+000039a0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+000039b0: 656e 736f 7228 6f75 7429 0a0a 2020 2020  ensor(out)..    
+000039c0: 6465 6620 5f5f 6162 735f 5f28 7365 6c66  def __abs__(self
+000039d0: 293a 0a20 2020 2020 2020 2074 656e 736f  ):.        tenso
+000039e0: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
+000039f0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00003a00: 2020 2020 2020 206f 7574 203d 2074 656e         out = ten
+00003a10: 736f 725f 6d73 2e5f 5f61 6273 5f5f 2829  sor_ms.__abs__()
+00003a20: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00003a30: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00003a40: 7465 6e73 6f72 286f 7574 290a 0a20 2020  tensor(out)..   
+00003a50: 2064 6566 205f 5f61 6464 5f5f 2873 656c   def __add__(sel
+00003a60: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
+00003a70: 2020 2074 656e 736f 725f 6d73 203d 2063     tensor_ms = c
+00003a80: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00003a90: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+00003aa0: 7468 6572 5f6d 7320 3d20 6361 7374 5f74  ther_ms = cast_t
+00003ab0: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
+00003ac0: 7229 0a20 2020 2020 2020 2023 2054 4f44  r).        # TOD
+00003ad0: 4f3a 206d 696e 6473 706f 7265 205f 5f61  O: mindspore __a
+00003ae0: 6464 5f5f 2064 6f20 6e6f 7420 7375 7070  dd__ do not supp
+00003af0: 6f72 7420 6c6f 6769 6361 6c5f 6f72 2077  ort logical_or w
+00003b00: 6974 6820 7477 6f20 626f 6f6c 2064 7479  ith two bool dty
+00003b10: 7065 2074 656e 736f 7273 2e0a 2020 2020  pe tensors..    
+00003b20: 2020 2020 6f75 7420 3d20 7465 6e73 6f72      out = tensor
+00003b30: 5f6d 732e 5f5f 6164 645f 5f28 6f74 6865  _ms.__add__(othe
+00003b40: 725f 6d73 290a 2020 2020 2020 2020 7265  r_ms).        re
+00003b50: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00003b60: 7074 6572 5f74 656e 736f 7228 6f75 7429  pter_tensor(out)
+00003b70: 0a0a 2020 2020 6465 6620 5f5f 616e 645f  ..    def __and_
+00003b80: 5f28 7365 6c66 2c20 6f74 6865 7229 3a0a  _(self, other):.
+00003b90: 2020 2020 2020 2020 7465 6e73 6f72 5f6d          tensor_m
+00003ba0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00003bb0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+00003bc0: 2020 2020 6f74 6865 725f 6d73 203d 2063      other_ms = c
+00003bd0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00003be0: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
+00003bf0: 696e 7075 745f 6474 7970 6520 3d20 7465  input_dtype = te
+00003c00: 6e73 6f72 5f6d 732e 6474 7970 650a 2020  nsor_ms.dtype.  
+00003c10: 2020 2020 2020 6966 2069 6e70 7574 5f64        if input_d
+00003c20: 7479 7065 203d 3d20 6d73 7479 7065 2e62  type == mstype.b
+00003c30: 6f6f 6c5f 3a0a 2020 2020 2020 2020 2020  ool_:.          
+00003c40: 2020 2320 6176 6f69 6420 4269 7477 6973    # avoid Bitwis
+00003c50: 6541 6e64 206f 7020 6861 7320 6e6f 7420  eAnd op has not 
+00003c60: 636f 7272 6573 706f 6e64 696e 6720 6270  corresponding bp
+00003c70: 726f 702e 0a20 2020 2020 2020 2020 2020  rop..           
+00003c80: 2074 656e 736f 725f 6d73 203d 2074 656e   tensor_ms = ten
+00003c90: 736f 725f 6d73 2e61 7374 7970 6528 6d73  sor_ms.astype(ms
+00003ca0: 7479 7065 2e69 6e74 3829 0a20 2020 2020  type.int8).     
+00003cb0: 2020 2020 2020 206f 7574 203d 2074 656e         out = ten
+00003cc0: 736f 725f 6d73 2e6d 756c 286f 7468 6572  sor_ms.mul(other
+00003cd0: 5f6d 7329 0a20 2020 2020 2020 2020 2020  _ms).           
+00003ce0: 206f 7574 203d 206f 7574 2e61 7374 7970   out = out.astyp
+00003cf0: 6528 6d73 7479 7065 2e62 6f6f 6c5f 290a  e(mstype.bool_).
+00003d00: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00003d10: 2020 2020 2020 2020 2020 6f75 7420 3d20            out = 
+00003d20: 7465 6e73 6f72 5f6d 732e 5f5f 616e 645f  tensor_ms.__and_
+00003d30: 5f28 6f74 6865 725f 6d73 290a 2020 2020  _(other_ms).    
+00003d40: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+00003d50: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00003d60: 7228 6f75 7429 0a0a 2020 2020 6465 6620  r(out)..    def 
+00003d70: 5f5f 786f 725f 5f28 7365 6c66 2c20 6f74  __xor__(self, ot
+00003d80: 6865 7229 3a0a 2020 2020 2020 2020 7465  her):.        te
+00003d90: 6e73 6f72 5f6d 7320 3d20 6361 7374 5f74  nsor_ms = cast_t
+00003da0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00003db0: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
+00003dc0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00003dd0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+00003de0: 2020 2020 2020 6f75 7420 3d20 7465 6e73        out = tens
+00003df0: 6f72 5f6d 732e 5f5f 786f 725f 5f28 6f74  or_ms.__xor__(ot
+00003e00: 6865 725f 6d73 290a 2020 2020 2020 2020  her_ms).        
+00003e10: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00003e20: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00003e30: 7429 0a0a 2020 2020 6465 6620 5f5f 6f72  t)..    def __or
+00003e40: 5f5f 2873 656c 662c 206f 7468 6572 293a  __(self, other):
+00003e50: 0a20 2020 2020 2020 2074 656e 736f 725f  .        tensor_
+00003e60: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00003e70: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+00003e80: 2020 2020 206f 7468 6572 5f6d 7320 3d20       other_ms = 
+00003e90: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00003ea0: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
+00003eb0: 2069 6e70 7574 5f64 7479 7065 203d 2074   input_dtype = t
+00003ec0: 656e 736f 725f 6d73 2e64 7479 7065 0a20  ensor_ms.dtype. 
+00003ed0: 2020 2020 2020 2069 6620 696e 7075 745f         if input_
+00003ee0: 6474 7970 6520 3d3d 206d 7374 7970 652e  dtype == mstype.
+00003ef0: 626f 6f6c 5f3a 0a20 2020 2020 2020 2020  bool_:.         
+00003f00: 2020 2023 2061 766f 6964 2042 6974 7769     # avoid Bitwi
+00003f10: 7365 4f72 206f 7020 6861 7320 6e6f 7420  seOr op has not 
+00003f20: 636f 7272 6573 706f 6e64 696e 6720 6270  corresponding bp
+00003f30: 726f 702e 0a20 2020 2020 2020 2020 2020  rop..           
+00003f40: 2074 656e 736f 725f 6d73 203d 2074 656e   tensor_ms = ten
+00003f50: 736f 725f 6d73 2e61 7374 7970 6528 6d73  sor_ms.astype(ms
+00003f60: 7479 7065 2e69 6e74 3829 0a20 2020 2020  type.int8).     
+00003f70: 2020 2020 2020 206f 7574 203d 2074 656e         out = ten
+00003f80: 736f 725f 6d73 2e61 6464 286f 7468 6572  sor_ms.add(other
+00003f90: 5f6d 7329 0a20 2020 2020 2020 2020 2020  _ms).           
+00003fa0: 206f 7574 203d 206f 7574 2e61 7374 7970   out = out.astyp
+00003fb0: 6528 6d73 7479 7065 2e62 6f6f 6c5f 290a  e(mstype.bool_).
+00003fc0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00003fd0: 2020 2020 2020 2020 2020 6f75 7420 3d20            out = 
+00003fe0: 7465 6e73 6f72 5f6d 732e 5f5f 6f72 5f5f  tensor_ms.__or__
+00003ff0: 286f 7468 6572 5f6d 7329 0a20 2020 2020  (other_ms).     
+00004000: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00004010: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00004020: 286f 7574 290a 0a20 2020 2064 6566 205f  (out)..    def _
+00004030: 5f72 6164 645f 5f28 7365 6c66 2c20 6f74  _radd__(self, ot
+00004040: 6865 7229 3a0a 2020 2020 2020 2020 7265  her):.        re
+00004050: 7475 726e 2073 656c 662e 5f5f 6164 645f  turn self.__add_
+00004060: 5f28 6f74 6865 7229 0a0a 2020 2020 6465  _(other)..    de
+00004070: 6620 5f5f 6961 6464 5f5f 2873 656c 662c  f __iadd__(self,
+00004080: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
+00004090: 2072 6574 7572 6e20 7365 6c66 2e5f 5f61   return self.__a
+000040a0: 6464 5f5f 286f 7468 6572 290a 0a20 2020  dd__(other)..   
+000040b0: 2064 6566 205f 5f73 7562 5f5f 2873 656c   def __sub__(sel
+000040c0: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
+000040d0: 2020 2074 656e 736f 725f 6d73 203d 2063     tensor_ms = c
+000040e0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+000040f0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+00004100: 7468 6572 5f6d 7320 3d20 6361 7374 5f74  ther_ms = cast_t
+00004110: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
+00004120: 7229 0a20 2020 2020 2020 206f 7574 203d  r).        out =
+00004130: 2074 656e 736f 725f 6d73 2e5f 5f73 7562   tensor_ms.__sub
+00004140: 5f5f 286f 7468 6572 5f6d 7329 0a20 2020  __(other_ms).   
+00004150: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00004160: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00004170: 6f72 286f 7574 290a 0a20 2020 2064 6566  or(out)..    def
+00004180: 205f 5f72 7375 625f 5f28 7365 6c66 2c20   __rsub__(self, 
+00004190: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
+000041a0: 7465 6e73 6f72 5f6d 7320 3d20 6361 7374  tensor_ms = cast
+000041b0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+000041c0: 6c66 290a 2020 2020 2020 2020 6f74 6865  lf).        othe
+000041d0: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
+000041e0: 735f 7465 6e73 6f72 286f 7468 6572 290a  s_tensor(other).
+000041f0: 2020 2020 2020 2020 6f75 7420 3d20 7465          out = te
+00004200: 6e73 6f72 5f6d 732e 5f5f 7273 7562 5f5f  nsor_ms.__rsub__
+00004210: 286f 7468 6572 5f6d 7329 0a20 2020 2020  (other_ms).     
+00004220: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00004230: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00004240: 286f 7574 290a 0a20 2020 2064 6566 205f  (out)..    def _
+00004250: 5f69 7375 625f 5f28 7365 6c66 2c20 6f74  _isub__(self, ot
+00004260: 6865 7229 3a0a 2020 2020 2020 2020 7465  her):.        te
+00004270: 6e73 6f72 5f6d 7320 3d20 6361 7374 5f74  nsor_ms = cast_t
+00004280: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00004290: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
+000042a0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+000042b0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+000042c0: 2020 2020 2020 6f75 7420 3d20 7465 6e73        out = tens
+000042d0: 6f72 5f6d 732e 5f5f 6973 7562 5f5f 286f  or_ms.__isub__(o
+000042e0: 7468 6572 5f6d 7329 0a20 2020 2020 2020  ther_ms).       
+000042f0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+00004300: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+00004310: 7574 290a 0a20 2020 2064 6566 205f 5f6d  ut)..    def __m
+00004320: 756c 5f5f 2873 656c 662c 206f 7468 6572  ul__(self, other
+00004330: 293a 0a20 2020 2020 2020 2023 2054 4f44  ):.        # TOD
+00004340: 4f3a 2049 6e20 6d69 6e64 7370 6f72 6520  O: In mindspore 
+00004350: 7465 6e73 6f72 2e5f 5f6d 756c 5f5f 2c20  tensor.__mul__, 
+00004360: 666c 6f61 7420 7465 6e73 6f72 2063 616e  float tensor can
+00004370: 206e 6f74 206d 756c 2077 6974 6820 636f   not mul with co
+00004380: 6d70 6c65 7820 7465 6e73 6f72 0a20 2020  mplex tensor.   
+00004390: 2020 2020 2074 656e 736f 725f 6d73 203d       tensor_ms =
+000043a0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+000043b0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+000043c0: 206f 7468 6572 5f6d 7320 3d20 6361 7374   other_ms = cast
+000043d0: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
+000043e0: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
+000043f0: 203d 2074 656e 736f 725f 6d73 2e5f 5f6d   = tensor_ms.__m
+00004400: 756c 5f5f 286f 7468 6572 5f6d 7329 0a20  ul__(other_ms). 
+00004410: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00004420: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00004430: 6e73 6f72 286f 7574 290a 0a20 2020 2064  nsor(out)..    d
+00004440: 6566 205f 5f72 6d75 6c5f 5f28 7365 6c66  ef __rmul__(self
+00004450: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+00004460: 2020 7265 7475 726e 2073 656c 662e 5f5f    return self.__
+00004470: 6d75 6c5f 5f28 6f74 6865 7229 0a0a 2020  mul__(other)..  
+00004480: 2020 6465 6620 5f5f 696d 756c 5f5f 2873    def __imul__(s
+00004490: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
+000044a0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+000044b0: 2e5f 5f6d 756c 5f5f 286f 7468 6572 290a  .__mul__(other).
+000044c0: 0a20 2020 2064 6566 205f 5f74 7275 6564  .    def __trued
+000044d0: 6976 5f5f 2873 656c 662c 206f 7468 6572  iv__(self, other
+000044e0: 293a 0a20 2020 2020 2020 2074 656e 736f  ):.        tenso
+000044f0: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
+00004500: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00004510: 2020 2020 2020 206f 7468 6572 5f6d 7320         other_ms 
+00004520: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00004530: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
+00004540: 2020 2074 656e 736f 725f 7479 7065 203d     tensor_type =
+00004550: 2074 656e 736f 725f 6d73 2e64 7479 7065   tensor_ms.dtype
+00004560: 0a20 2020 2020 2020 2069 6620 2749 6e74  .        if 'Int
+00004570: 2720 696e 2073 7472 2874 656e 736f 725f  ' in str(tensor_
+00004580: 7479 7065 293a 0a20 2020 2020 2020 2020  type):.         
+00004590: 2020 2074 656e 736f 725f 6d73 203d 206d     tensor_ms = m
+000045a0: 732e 6f70 732e 6361 7374 2874 656e 736f  s.ops.cast(tenso
+000045b0: 725f 6d73 2c20 6d73 7479 7065 2e66 6c6f  r_ms, mstype.flo
+000045c0: 6174 3332 290a 2020 2020 2020 2020 6f75  at32).        ou
+000045d0: 7420 3d20 7465 6e73 6f72 5f6d 732e 5f5f  t = tensor_ms.__
+000045e0: 7472 7565 6469 765f 5f28 6f74 6865 725f  truediv__(other_
+000045f0: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
+00004600: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00004610: 6572 5f74 656e 736f 7228 6f75 7429 0a0a  er_tensor(out)..
+00004620: 2020 2020 6465 6620 5f5f 7274 7275 6564      def __rtrued
+00004630: 6976 5f5f 2873 656c 662c 206f 7468 6572  iv__(self, other
+00004640: 293a 0a20 2020 2020 2020 2074 656e 736f  ):.        tenso
+00004650: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
+00004660: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00004670: 2020 2020 2020 206f 7468 6572 5f6d 7320         other_ms 
+00004680: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00004690: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
+000046a0: 2020 2074 656e 736f 725f 7479 7065 203d     tensor_type =
+000046b0: 2074 656e 736f 725f 6d73 2e64 7479 7065   tensor_ms.dtype
+000046c0: 0a20 2020 2020 2020 2069 6620 2749 6e74  .        if 'Int
+000046d0: 2720 696e 2073 7472 2874 656e 736f 725f  ' in str(tensor_
+000046e0: 7479 7065 293a 0a20 2020 2020 2020 2020  type):.         
+000046f0: 2020 2074 656e 736f 725f 6d73 203d 206d     tensor_ms = m
+00004700: 732e 6f70 732e 6361 7374 2874 656e 736f  s.ops.cast(tenso
+00004710: 725f 6d73 2c20 6d73 7479 7065 2e66 6c6f  r_ms, mstype.flo
+00004720: 6174 3332 290a 2020 2020 2020 2020 6f75  at32).        ou
+00004730: 7420 3d20 7465 6e73 6f72 5f6d 732e 5f5f  t = tensor_ms.__
+00004740: 7274 7275 6564 6976 5f5f 286f 7468 6572  rtruediv__(other
+00004750: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
+00004760: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+00004770: 7465 725f 7465 6e73 6f72 286f 7574 290a  ter_tensor(out).
+00004780: 0a20 2020 2064 6566 205f 5f6d 6f64 5f5f  .    def __mod__
+00004790: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
+000047a0: 2020 2020 2020 2074 656e 736f 725f 6d73         tensor_ms
+000047b0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000047c0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+000047d0: 2020 206f 7468 6572 5f6d 7320 3d20 6361     other_ms = ca
+000047e0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+000047f0: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
+00004800: 7574 203d 2074 656e 736f 725f 6d73 2e5f  ut = tensor_ms._
+00004810: 5f6d 6f64 5f5f 286f 7468 6572 5f6d 7329  _mod__(other_ms)
+00004820: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00004830: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00004840: 7465 6e73 6f72 286f 7574 290a 0a20 2020  tensor(out)..   
+00004850: 2064 6566 205f 5f72 6d6f 645f 5f28 7365   def __rmod__(se
+00004860: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
+00004870: 2020 2020 7465 6e73 6f72 5f6d 7320 3d20      tensor_ms = 
+00004880: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00004890: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+000048a0: 6f74 6865 725f 6d73 203d 2063 6173 745f  other_ms = cast_
+000048b0: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
+000048c0: 6572 290a 2020 2020 2020 2020 6f75 7420  er).        out 
+000048d0: 3d20 7465 6e73 6f72 5f6d 732e 5f5f 726d  = tensor_ms.__rm
+000048e0: 6f64 5f5f 286f 7468 6572 5f6d 7329 0a20  od__(other_ms). 
+000048f0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00004900: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00004910: 6e73 6f72 286f 7574 290a 0a20 2020 2064  nsor(out)..    d
+00004920: 6566 205f 5f69 6d6f 645f 5f28 7365 6c66  ef __imod__(self
+00004930: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+00004940: 2020 7465 6e73 6f72 5f6d 7320 3d20 6361    tensor_ms = ca
+00004950: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00004960: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
+00004970: 6865 725f 6d73 203d 2063 6173 745f 746f  her_ms = cast_to
+00004980: 5f6d 735f 7465 6e73 6f72 286f 7468 6572  _ms_tensor(other
+00004990: 290a 2020 2020 2020 2020 6f75 7420 3d20  ).        out = 
+000049a0: 7465 6e73 6f72 5f6d 732e 5f5f 696d 6f64  tensor_ms.__imod
+000049b0: 5f5f 286f 7468 6572 5f6d 7329 0a20 2020  __(other_ms).   
+000049c0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+000049d0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+000049e0: 6f72 286f 7574 290a 0a20 2020 2064 6566  or(out)..    def
+000049f0: 205f 5f70 6f77 5f5f 2873 656c 662c 206f   __pow__(self, o
+00004a00: 7468 6572 293a 0a20 2020 2020 2020 2074  ther):.        t
+00004a10: 656e 736f 725f 6d73 203d 2063 6173 745f  ensor_ms = cast_
+00004a20: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00004a30: 6629 0a20 2020 2020 2020 206f 7468 6572  f).        other
+00004a40: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+00004a50: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
+00004a60: 2020 2020 2020 206f 7574 203d 2074 656e         out = ten
+00004a70: 736f 725f 6d73 2e5f 5f70 6f77 5f5f 286f  sor_ms.__pow__(o
+00004a80: 7468 6572 5f6d 7329 0a20 2020 2020 2020  ther_ms).       
+00004a90: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+00004aa0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+00004ab0: 7574 290a 0a20 2020 2064 6566 205f 5f72  ut)..    def __r
+00004ac0: 706f 775f 5f28 7365 6c66 2c20 6f74 6865  pow__(self, othe
+00004ad0: 7229 3a0a 2020 2020 2020 2020 7465 6e73  r):.        tens
+00004ae0: 6f72 5f6d 7320 3d20 6361 7374 5f74 6f5f  or_ms = cast_to_
+00004af0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00004b00: 2020 2020 2020 2020 6f74 6865 725f 6d73          other_ms
+00004b10: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00004b20: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
+00004b30: 2020 2020 6f75 7420 3d20 7465 6e73 6f72      out = tensor
+00004b40: 5f6d 732e 5f5f 7270 6f77 5f5f 286f 7468  _ms.__rpow__(oth
+00004b50: 6572 5f6d 7329 0a20 2020 2020 2020 2072  er_ms).        r
+00004b60: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00004b70: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00004b80: 290a 0a20 2020 2064 6566 205f 5f66 6c6f  )..    def __flo
+00004b90: 6f72 6469 765f 5f28 7365 6c66 2c20 6f74  ordiv__(self, ot
+00004ba0: 6865 7229 3a0a 2020 2020 2020 2020 7465  her):.        te
+00004bb0: 6e73 6f72 5f6d 7320 3d20 6361 7374 5f74  nsor_ms = cast_t
+00004bc0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00004bd0: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
+00004be0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00004bf0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+00004c00: 2020 2020 2020 6f75 7420 3d20 7465 6e73        out = tens
+00004c10: 6f72 5f6d 732e 5f5f 666c 6f6f 7264 6976  or_ms.__floordiv
+00004c20: 5f5f 286f 7468 6572 5f6d 7329 0a20 2020  __(other_ms).   
+00004c30: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00004c40: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00004c50: 6f72 286f 7574 290a 0a20 2020 2064 6566  or(out)..    def
+00004c60: 205f 5f72 666c 6f6f 7264 6976 5f5f 2873   __rfloordiv__(s
+00004c70: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
+00004c80: 2020 2020 2074 656e 736f 725f 6d73 203d       tensor_ms =
+00004c90: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00004ca0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00004cb0: 206f 7468 6572 5f6d 7320 3d20 6361 7374   other_ms = cast
+00004cc0: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
+00004cd0: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
+00004ce0: 203d 2074 656e 736f 725f 6d73 2e5f 5f72   = tensor_ms.__r
+00004cf0: 666c 6f6f 7264 6976 5f5f 286f 7468 6572  floordiv__(other
+00004d00: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
+00004d10: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+00004d20: 7465 725f 7465 6e73 6f72 286f 7574 290a  ter_tensor(out).
+00004d30: 0a20 2020 2064 6566 205f 5f69 666c 6f6f  .    def __ifloo
+00004d40: 7264 6976 5f5f 2873 656c 662c 206f 7468  rdiv__(self, oth
+00004d50: 6572 293a 0a20 2020 2020 2020 2074 656e  er):.        ten
+00004d60: 736f 725f 6d73 203d 2063 6173 745f 746f  sor_ms = cast_to
+00004d70: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+00004d80: 0a20 2020 2020 2020 206f 7468 6572 5f6d  .        other_m
+00004d90: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00004da0: 656e 736f 7228 6f74 6865 7229 0a20 2020  ensor(other).   
+00004db0: 2020 2020 206f 7574 203d 2074 656e 736f       out = tenso
+00004dc0: 725f 6d73 2e5f 5f69 666c 6f6f 7264 6976  r_ms.__ifloordiv
+00004dd0: 5f5f 286f 7468 6572 5f6d 7329 0a20 2020  __(other_ms).   
+00004de0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00004df0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00004e00: 6f72 286f 7574 290a 0a20 2020 2064 6566  or(out)..    def
+00004e10: 205f 5f6c 745f 5f28 7365 6c66 2c20 6f74   __lt__(self, ot
+00004e20: 6865 7229 3a0a 2020 2020 2020 2020 7465  her):.        te
+00004e30: 6e73 6f72 5f6d 7320 3d20 6361 7374 5f74  nsor_ms = cast_t
+00004e40: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00004e50: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
+00004e60: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00004e70: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+00004e80: 2020 2020 2020 6f75 7420 3d20 7465 6e73        out = tens
+00004e90: 6f72 5f6d 732e 5f5f 6c74 5f5f 286f 7468  or_ms.__lt__(oth
+00004ea0: 6572 5f6d 7329 0a20 2020 2020 2020 2072  er_ms).        r
+00004eb0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00004ec0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00004ed0: 290a 0a20 2020 2064 6566 205f 5f6c 655f  )..    def __le_
+00004ee0: 5f28 7365 6c66 2c20 6f74 6865 7229 3a0a  _(self, other):.
+00004ef0: 2020 2020 2020 2020 7465 6e73 6f72 5f6d          tensor_m
+00004f00: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00004f10: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+00004f20: 2020 2020 6f74 6865 725f 6d73 203d 2063      other_ms = c
+00004f30: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00004f40: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
+00004f50: 6f75 7420 3d20 7465 6e73 6f72 5f6d 732e  out = tensor_ms.
+00004f60: 5f5f 6c65 5f5f 286f 7468 6572 5f6d 7329  __le__(other_ms)
+00004f70: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00004f80: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00004f90: 7465 6e73 6f72 286f 7574 290a 0a20 2020  tensor(out)..   
+00004fa0: 2064 6566 205f 5f67 745f 5f28 7365 6c66   def __gt__(self
+00004fb0: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+00004fc0: 2020 7465 6e73 6f72 5f6d 7320 3d20 6361    tensor_ms = ca
+00004fd0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00004fe0: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
+00004ff0: 6865 725f 6d73 203d 2063 6173 745f 746f  her_ms = cast_to
+00005000: 5f6d 735f 7465 6e73 6f72 286f 7468 6572  _ms_tensor(other
+00005010: 290a 2020 2020 2020 2020 6f75 7420 3d20  ).        out = 
+00005020: 7465 6e73 6f72 5f6d 732e 5f5f 6774 5f5f  tensor_ms.__gt__
+00005030: 286f 7468 6572 5f6d 7329 0a20 2020 2020  (other_ms).     
+00005040: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00005050: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00005060: 286f 7574 290a 0a20 2020 2064 6566 205f  (out)..    def _
+00005070: 5f67 655f 5f28 7365 6c66 2c20 6f74 6865  _ge__(self, othe
+00005080: 7229 3a0a 2020 2020 2020 2020 7465 6e73  r):.        tens
+00005090: 6f72 5f6d 7320 3d20 6361 7374 5f74 6f5f  or_ms = cast_to_
+000050a0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+000050b0: 2020 2020 2020 2020 6f74 6865 725f 6d73          other_ms
+000050c0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000050d0: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
+000050e0: 2020 2020 6f75 7420 3d20 7465 6e73 6f72      out = tensor
+000050f0: 5f6d 732e 5f5f 6765 5f5f 286f 7468 6572  _ms.__ge__(other
+00005100: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
+00005110: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+00005120: 7465 725f 7465 6e73 6f72 286f 7574 290a  ter_tensor(out).
+00005130: 0a20 2020 2064 6566 205f 5f65 715f 5f28  .    def __eq__(
+00005140: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
+00005150: 2020 2020 2020 7465 6e73 6f72 5f6d 7320        tensor_ms 
+00005160: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00005170: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+00005180: 2020 6f74 6865 725f 6d73 203d 2063 6173    other_ms = cas
+00005190: 745f 746f 5f6d 735f 7465 6e73 6f72 286f  t_to_ms_tensor(o
+000051a0: 7468 6572 290a 2020 2020 2020 2020 6f75  ther).        ou
+000051b0: 7420 3d20 7465 6e73 6f72 5f6d 732e 5f5f  t = tensor_ms.__
+000051c0: 6571 5f5f 286f 7468 6572 5f6d 7329 0a20  eq__(other_ms). 
+000051d0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+000051e0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+000051f0: 6e73 6f72 286f 7574 290a 0a20 2020 2064  nsor(out)..    d
+00005200: 6566 205f 5f6d 6174 6d75 6c5f 5f28 7365  ef __matmul__(se
+00005210: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
+00005220: 2020 2020 7465 6e73 6f72 5f6d 7320 3d20      tensor_ms = 
+00005230: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00005240: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00005250: 6f74 6865 725f 6d73 203d 2063 6173 745f  other_ms = cast_
+00005260: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
+00005270: 6572 290a 2020 2020 2020 2020 6f75 7420  er).        out 
+00005280: 3d20 7465 6e73 6f72 5f6d 732e 5f5f 6d61  = tensor_ms.__ma
+00005290: 746d 756c 5f5f 286f 7468 6572 5f6d 7329  tmul__(other_ms)
+000052a0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000052b0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+000052c0: 7465 6e73 6f72 286f 7574 290a 0a20 2020  tensor(out)..   
+000052d0: 2064 6566 205f 5f72 6d61 746d 756c 5f5f   def __rmatmul__
+000052e0: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
+000052f0: 2020 2020 2020 2074 656e 736f 725f 6d73         tensor_ms
+00005300: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00005310: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00005320: 2020 206f 7468 6572 5f6d 7320 3d20 6361     other_ms = ca
+00005330: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00005340: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
+00005350: 7574 203d 2074 656e 736f 725f 6d73 2e5f  ut = tensor_ms._
+00005360: 5f72 6d61 746d 756c 5f5f 286f 7468 6572  _rmatmul__(other
+00005370: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
+00005380: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+00005390: 7465 725f 7465 6e73 6f72 286f 7574 290a  ter_tensor(out).
+000053a0: 0a20 2020 2064 6566 205f 5f68 6173 685f  .    def __hash_
+000053b0: 5f28 7365 6c66 293a 0a20 2020 2020 2020  _(self):.       
+000053c0: 2072 6574 7572 6e20 6861 7368 2869 6428   return hash(id(
+000053d0: 7365 6c66 2929 0a0a 2020 2020 6465 6620  self))..    def 
+000053e0: 5f5f 6e65 5f5f 2873 656c 662c 206f 7468  __ne__(self, oth
+000053f0: 6572 293a 0a20 2020 2020 2020 2074 656e  er):.        ten
+00005400: 736f 725f 6d73 203d 2063 6173 745f 746f  sor_ms = cast_to
+00005410: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+00005420: 0a20 2020 2020 2020 206f 7468 6572 5f6d  .        other_m
+00005430: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00005440: 656e 736f 7228 6f74 6865 7229 0a20 2020  ensor(other).   
+00005450: 2020 2020 206f 7574 203d 2074 656e 736f       out = tenso
+00005460: 725f 6d73 2e5f 5f6e 655f 5f28 6f74 6865  r_ms.__ne__(othe
+00005470: 725f 6d73 290a 2020 2020 2020 2020 7265  r_ms).        re
+00005480: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00005490: 7074 6572 5f74 656e 736f 7228 6f75 7429  pter_tensor(out)
+000054a0: 0a0a 2020 2020 2320 5f5f 7365 7469 7465  ..    # __setite
+000054b0: 6d5f 5f20 6e6f 206e 6565 6420 746f 206f  m__ no need to o
+000054c0: 7665 726c 6f61 640a 2020 2020 6465 6620  verload.    def 
+000054d0: 5f5f 6765 7469 7465 6d5f 5f28 7365 6c66  __getitem__(self
+000054e0: 2c20 696e 6465 7829 3a0a 2020 2020 2020  , index):.      
+000054f0: 2020 2320 544f 444f 3a20 6e6f 7420 7375    # TODO: not su
+00005500: 7070 6f72 7420 636f 6d70 6c65 7820 5465  pport complex Te
+00005510: 6e73 6f72 2061 6e64 2046 616c 7365 2062  nsor and False b
+00005520: 6f6f 6c20 696e 6465 7820 6765 7469 7465  ool index getite
+00005530: 6d0a 2020 2020 2020 2020 6465 6620 5f67  m.        def _g
+00005540: 6574 6974 656d 5f68 616e 646c 6572 2874  etitem_handler(t
+00005550: 656e 736f 725f 6d73 2c20 696e 6465 7829  ensor_ms, index)
+00005560: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+00005570: 2069 7369 6e73 7461 6e63 6528 696e 6465   isinstance(inde
+00005580: 782c 2062 6f6f 6c29 3a0a 2020 2020 2020  x, bool):.      
+00005590: 2020 2020 2020 2020 2020 6966 2069 6e64            if ind
+000055a0: 6578 3a0a 2020 2020 2020 2020 2020 2020  ex:.            
+000055b0: 2020 2020 2020 2020 7265 7475 726e 2074          return t
+000055c0: 656e 736f 725f 6d73 2e65 7870 616e 645f  ensor_ms.expand_
+000055d0: 6469 6d73 2830 290a 2020 2020 2020 2020  dims(0).        
+000055e0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+000055f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005600: 2020 696e 6465 7820 3d20 6d73 2e54 656e    index = ms.Ten
+00005610: 736f 7228 4661 6c73 6529 0a20 2020 2020  sor(False).     
+00005620: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00005630: 7574 203d 206d 732e 6f70 732e 6d61 736b  ut = ms.ops.mask
+00005640: 6564 5f73 656c 6563 7428 7465 6e73 6f72  ed_select(tensor
+00005650: 5f6d 732c 2069 6e64 6578 290a 2020 2020  _ms, index).    
+00005660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005670: 7265 7475 726e 206f 7574 0a20 2020 2020  return out.     
+00005680: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+00005690: 616e 6365 2869 6e64 6578 2c20 7475 706c  ance(index, tupl
+000056a0: 6529 2061 6e64 2069 7369 6e73 7461 6e63  e) and isinstanc
+000056b0: 6528 696e 6465 785b 305d 2c20 626f 6f6c  e(index[0], bool
+000056c0: 293a 0a20 2020 2020 2020 2020 2020 2020  ):.             
+000056d0: 2020 2069 6620 4661 6c73 6520 696e 2069     if False in i
+000056e0: 6e64 6578 3a0a 2020 2020 2020 2020 2020  ndex:.          
+000056f0: 2020 2020 2020 2020 2020 696e 6465 7820            index 
+00005700: 3d20 6d73 2e54 656e 736f 7228 4661 6c73  = ms.Tensor(Fals
+00005710: 6529 0a20 2020 2020 2020 2020 2020 2020  e).             
+00005720: 2020 2020 2020 206f 7574 203d 206d 732e         out = ms.
+00005730: 6f70 732e 6d61 736b 6564 5f73 656c 6563  ops.masked_selec
+00005740: 7428 7465 6e73 6f72 5f6d 732c 2069 6e64  t(tensor_ms, ind
+00005750: 6578 290a 2020 2020 2020 2020 2020 2020  ex).            
+00005760: 2020 2020 2020 2020 7265 7475 726e 206f          return o
+00005770: 7574 0a20 2020 2020 2020 2020 2020 2020  ut.             
+00005780: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00005790: 2020 2020 2020 2020 2020 2020 2072 6574               ret
+000057a0: 7572 6e20 7465 6e73 6f72 5f6d 732e 6578  urn tensor_ms.ex
+000057b0: 7061 6e64 5f64 696d 7328 3029 0a20 2020  pand_dims(0).   
+000057c0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+000057d0: 7465 6e73 6f72 5f6d 732e 5f5f 6765 7469  tensor_ms.__geti
+000057e0: 7465 6d5f 5f28 696e 6465 7829 0a0a 2020  tem__(index)..  
+000057f0: 2020 2020 2020 7465 6e73 6f72 5f6d 7320        tensor_ms 
+00005800: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00005810: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+00005820: 2020 6f75 745f 6d73 203d 205f 6765 7469    out_ms = _geti
+00005830: 7465 6d5f 6861 6e64 6c65 7228 7465 6e73  tem_handler(tens
+00005840: 6f72 5f6d 732c 2069 6e64 6578 290a 2020  or_ms, index).  
+00005850: 2020 2020 2020 6f75 7420 3d20 6361 7374        out = cast
+00005860: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00005870: 6f72 286f 7574 5f6d 7329 0a20 2020 2020  or(out_ms).     
+00005880: 2020 2069 6620 6f75 745f 6d73 2069 7320     if out_ms is 
+00005890: 6e6f 7420 7465 6e73 6f72 5f6d 733a 0a20  not tensor_ms:. 
+000058a0: 2020 2020 2020 2020 2020 206f 7574 2e70             out.p
+000058b0: 6172 656e 745f 7465 6e73 6f72 5f20 3d20  arent_tensor_ = 
+000058c0: 7465 6e73 6f72 5f6d 730a 2020 2020 2020  tensor_ms.      
+000058d0: 2020 2020 2020 6f75 742e 696e 6465 785f        out.index_
+000058e0: 6f66 5f70 6172 656e 745f 203d 2069 6e64  of_parent_ = ind
+000058f0: 6578 0a20 2020 2020 2020 2072 6574 7572  ex.        retur
+00005900: 6e20 6f75 740a 0a20 2020 2064 6566 205f  n out..    def _
+00005910: 5f67 6574 7374 6174 655f 5f28 7365 6c66  _getstate__(self
+00005920: 293a 0a20 2020 2020 2020 2073 7461 7465  ):.        state
+00005930: 203d 207b 6b65 793a 2076 616c 7565 2066   = {key: value f
+00005940: 6f72 206b 6579 2c20 7661 6c75 6520 696e  or key, value in
+00005950: 2073 656c 662e 5f5f 6469 6374 5f5f 2e69   self.__dict__.i
+00005960: 7465 6d73 2829 2069 6620 6b65 7920 6e6f  tems() if key no
+00005970: 7420 696e 2054 656e 736f 7228 292e 5f5f  t in Tensor().__
+00005980: 6469 6374 5f5f 7d0a 2020 2020 2020 2020  dict__}.        
+00005990: 7265 7475 726e 2073 7461 7465 0a0a 2020  return state..  
+000059a0: 2020 6465 6620 5f5f 7265 6475 6365 5f65    def __reduce_e
+000059b0: 785f 5f28 7365 6c66 2c20 7072 6f74 6f63  x__(self, protoc
+000059c0: 6f6c 293a 0a20 2020 2020 2020 2073 7461  ol):.        sta
+000059d0: 7465 203d 205f 7574 696c 732e 5f67 6574  te = _utils._get
+000059e0: 5f6f 626a 5f73 7461 7465 2873 656c 6629  _obj_state(self)
+000059f0: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
+00005a00: 7374 616e 6365 2873 656c 662c 2054 656e  stance(self, Ten
+00005a10: 736f 7229 2061 6e64 206e 6f74 2073 7461  sor) and not sta
+00005a20: 7465 3a0a 2020 2020 2020 2020 2020 2020  te:.            
+00005a30: 7265 7475 726e 2073 656c 662e 5f72 6564  return self._red
+00005a40: 7563 655f 6578 5f69 6e74 6572 6e61 6c28  uce_ex_internal(
+00005a50: 290a 2020 2020 2020 2020 6675 6e63 2c20  ).        func, 
+00005a60: 6172 6773 203d 2073 656c 662e 5f72 6564  args = self._red
+00005a70: 7563 655f 6578 5f69 6e74 6572 6e61 6c28  uce_ex_internal(
+00005a80: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00005a90: 2028 5f72 6562 7569 6c64 5f66 726f 6d5f   (_rebuild_from_
+00005aa0: 7479 7065 5f76 322c 2028 6675 6e63 2c20  type_v2, (func, 
+00005ab0: 7479 7065 2873 656c 6629 2c20 6172 6773  type(self), args
+00005ac0: 2c20 7374 6174 6529 290a 0a20 2020 2064  , state))..    d
+00005ad0: 6566 205f 7265 6475 6365 5f65 785f 696e  ef _reduce_ex_in
+00005ae0: 7465 726e 616c 2873 656c 6629 3a0a 2020  ternal(self):.  
+00005af0: 2020 2020 2020 6261 636b 7761 7264 5f68        backward_h
+00005b00: 6f6f 6b73 203d 204f 7264 6572 6564 4469  ooks = OrderedDi
+00005b10: 6374 2829 0a20 2020 2020 2020 2061 7267  ct().        arg
+00005b20: 7320 3d20 280a 2020 2020 2020 2020 2020  s = (.          
+00005b30: 2020 5f54 7970 6564 5374 6f72 6167 6528    _TypedStorage(
+00005b40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00005b50: 2077 7261 705f 7374 6f72 6167 653d 7365   wrap_storage=se
+00005b60: 6c66 2e73 746f 7261 6765 2829 2e5f 756e  lf.storage()._un
+00005b70: 7479 7065 6428 292c 0a20 2020 2020 2020  typed(),.       
+00005b80: 2020 2020 2020 2020 2064 7479 7065 3d73           dtype=s
+00005b90: 656c 662e 6474 7970 6529 2c0a 2020 2020  elf.dtype),.    
+00005ba0: 2020 2020 2020 2020 302c 0a20 2020 2020          0,.     
+00005bb0: 2020 2020 2020 2074 7570 6c65 2873 656c         tuple(sel
+00005bc0: 662e 7369 7a65 2829 292c 0a20 2020 2020  f.size()),.     
+00005bd0: 2020 2020 2020 2073 656c 662e 7374 7269         self.stri
+00005be0: 6465 2829 2c0a 2020 2020 2020 2020 2020  de(),.          
+00005bf0: 2020 7365 6c66 2e72 6571 7569 7265 735f    self.requires_
+00005c00: 6772 6164 2c0a 2020 2020 2020 2020 2020  grad,.          
+00005c10: 2020 6261 636b 7761 7264 5f68 6f6f 6b73    backward_hooks
+00005c20: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00005c30: 2028 5f75 7469 6c73 2e5f 7265 6275 696c   (_utils._rebuil
+00005c40: 645f 7465 6e73 6f72 5f76 322c 2061 7267  d_tensor_v2, arg
+00005c50: 7329 0a0a 2020 2020 6465 6620 5f5f 7365  s)..    def __se
+00005c60: 7473 7461 7465 5f5f 2873 656c 662c 2073  tstate__(self, s
+00005c70: 7461 7465 293a 0a20 2020 2020 2020 2069  tate):.        i
+00005c80: 6620 6973 696e 7374 616e 6365 2873 7461  f isinstance(sta
+00005c90: 7465 2c20 7475 706c 6529 3a0a 2020 2020  te, tuple):.    
+00005ca0: 2020 2020 2020 2020 6966 206c 656e 2873          if len(s
+00005cb0: 7461 7465 2920 3d3d 2034 3a0a 2020 2020  tate) == 4:.    
+00005cc0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00005cd0: 2e73 6574 5f28 2a73 7461 7465 290a 2020  .set_(*state).  
+00005ce0: 2020 2020 2020 2020 2020 2020 2020 7265                re
+00005cf0: 7475 726e 0a20 2020 2020 2020 2020 2020  turn.           
+00005d00: 2065 6c69 6620 6c65 6e28 7374 6174 6529   elif len(state)
+00005d10: 203d 3d20 353a 0a20 2020 2020 2020 2020   == 5:.         
+00005d20: 2020 2020 2020 2064 6174 6120 3d20 7374         data = st
+00005d30: 6174 655b 305d 0a20 2020 2020 2020 2020  ate[0].         
+00005d40: 2020 2020 2020 2054 656e 736f 722e 5f5f         Tensor.__
+00005d50: 696e 6974 5f5f 2873 656c 662c 2064 6174  init__(self, dat
+00005d60: 612c 2064 7479 7065 3d64 6174 612e 6474  a, dtype=data.dt
+00005d70: 7970 652c 2069 6e6e 6572 3d54 7275 652c  ype, inner=True,
+00005d80: 2072 6571 7569 7265 735f 6772 6164 3d73   requires_grad=s
+00005d90: 7461 7465 5b33 5d29 0a20 2020 2020 2020  tate[3]).       
+00005da0: 2020 2020 2020 2020 2072 6574 7572 6e0a           return.
+00005db0: 0a20 2020 2040 7072 6f70 6572 7479 0a20  .    @property. 
+00005dc0: 2020 2064 6566 2067 7261 645f 666e 2873     def grad_fn(s
+00005dd0: 656c 6629 3a0a 2020 2020 2020 2020 7265  elf):.        re
+00005de0: 7475 726e 2073 656c 662e 5f67 7261 645f  turn self._grad_
+00005df0: 666e 0a0a 2020 2020 4067 7261 645f 666e  fn..    @grad_fn
+00005e00: 2e73 6574 7465 720a 2020 2020 6465 6620  .setter.    def 
+00005e10: 6772 6164 5f66 6e28 7365 6c66 2c20 6772  grad_fn(self, gr
+00005e20: 6164 5f66 6e29 3a0a 2020 2020 2020 2020  ad_fn):.        
+00005e30: 7365 6c66 2e5f 6772 6164 5f66 6e20 3d20  self._grad_fn = 
+00005e40: 6772 6164 5f66 6e0a 0a20 2020 2040 7072  grad_fn..    @pr
+00005e50: 6f70 6572 7479 0a20 2020 2064 6566 2067  operty.    def g
+00005e60: 7261 6428 7365 6c66 293a 0a20 2020 2020  rad(self):.     
+00005e70: 2020 205f 4241 434b 5741 5244 5f45 4e56     _BACKWARD_ENV
+00005e80: 203d 206f 732e 656e 7669 726f 6e2e 6765   = os.environ.ge
+00005e90: 7428 2745 4e41 424c 455f 4241 434b 5741  t('ENABLE_BACKWA
+00005ea0: 5244 2729 0a20 2020 2020 2020 2069 6620  RD').        if 
+00005eb0: 5f42 4143 4b57 4152 445f 454e 5620 213d  _BACKWARD_ENV !=
+00005ec0: 2022 3122 3a0a 2020 2020 2020 2020 2020   "1":.          
+00005ed0: 2020 7265 7475 726e 2073 656c 662e 5f67    return self._g
+00005ee0: 7261 640a 2020 2020 2020 2020 7265 7475  rad.        retu
+00005ef0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00005f00: 6572 5f74 656e 736f 7228 5f63 6f6e 7665  er_tensor(_conve
+00005f10: 7274 5f70 7974 686f 6e5f 6461 7461 2873  rt_python_data(s
+00005f20: 656c 662e 5f67 7261 6429 290a 0a20 2020  elf._grad))..   
+00005f30: 2040 6772 6164 2e73 6574 7465 720a 2020   @grad.setter.  
+00005f40: 2020 6465 6620 6772 6164 2873 656c 662c    def grad(self,
+00005f50: 206e 6577 5f67 7261 6429 3a0a 2020 2020   new_grad):.    
+00005f60: 2020 2020 7365 6c66 2e5f 6772 6164 203d      self._grad =
+00005f70: 206e 6577 5f67 7261 640a 0a20 2020 2040   new_grad..    @
+00005f80: 7072 6f70 6572 7479 0a20 2020 2064 6566  property.    def
+00005f90: 2072 6571 7569 7265 735f 6772 6164 2873   requires_grad(s
+00005fa0: 656c 6629 3a0a 2020 2020 2020 2020 7265  elf):.        re
+00005fb0: 7475 726e 2073 656c 662e 5f72 6571 7569  turn self._requi
+00005fc0: 7265 735f 6772 6164 0a0a 2020 2020 4072  res_grad..    @r
+00005fd0: 6571 7569 7265 735f 6772 6164 2e73 6574  equires_grad.set
+00005fe0: 7465 720a 2020 2020 6465 6620 7265 7175  ter.    def requ
+00005ff0: 6972 6573 5f67 7261 6428 7365 6c66 2c20  ires_grad(self, 
+00006000: 7265 7175 6972 6573 5f67 7261 6429 3a0a  requires_grad):.
+00006010: 2020 2020 2020 2020 7365 6c66 2e5f 7265          self._re
+00006020: 7175 6972 6573 5f67 7261 6420 3d20 7265  quires_grad = re
+00006030: 7175 6972 6573 5f67 7261 640a 0a20 2020  quires_grad..   
+00006040: 2040 7072 6f70 6572 7479 0a20 2020 2064   @property.    d
+00006050: 6566 2069 735f 6c65 6166 2873 656c 6629  ef is_leaf(self)
+00006060: 3a0a 2020 2020 2020 2020 7265 7475 726e  :.        return
+00006070: 2073 656c 662e 5f72 6571 7569 7265 735f   self._requires_
+00006080: 6772 6164 2069 7320 4661 6c73 6520 6f72  grad is False or
+00006090: 2073 656c 662e 5f67 7261 645f 666e 2069   self._grad_fn i
+000060a0: 7320 4e6f 6e65 0a0a 2020 2020 6465 6620  s None..    def 
+000060b0: 6465 7461 6368 2873 656c 6629 3a0a 2020  detach(self):.  
+000060c0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+000060d0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+000060e0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+000060f0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00006100: 2e73 746f 705f 6772 6164 6965 6e74 2869  .stop_gradient(i
+00006110: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
+00006120: 206f 7574 7075 742e 7265 7175 6972 6573   output.requires
+00006130: 5f67 7261 6420 3d20 4661 6c73 650a 2020  _grad = False.  
+00006140: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00006150: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00006160: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00006170: 2064 6566 2064 6574 6163 685f 2873 656c   def detach_(sel
+00006180: 6629 3a0a 2020 2020 2020 2020 7265 7475  f):.        retu
+00006190: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+000061a0: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+000061b0: 7365 6c66 2e64 6574 6163 6828 292c 2022  self.detach(), "
+000061c0: 6465 7461 6368 5f22 2c20 2264 6574 6163  detach_", "detac
+000061d0: 6822 290a 0a20 2020 2064 6566 2072 6574  h")..    def ret
+000061e0: 6169 6e5f 6772 6164 2873 656c 6629 3a0a  ain_grad(self):.
+000061f0: 2020 2020 2020 2020 6966 206e 6f74 2073          if not s
+00006200: 656c 662e 5f72 6571 7569 7265 735f 6772  elf._requires_gr
+00006210: 6164 3a0a 2020 2020 2020 2020 2020 2020  ad:.            
+00006220: 5275 6e74 696d 6545 7272 6f72 2822 6361  RuntimeError("ca
+00006230: 6e27 7420 7265 7461 696e 5f67 7261 6420  n't retain_grad 
+00006240: 6f6e 2054 656e 736f 7220 7468 6174 2068  on Tensor that h
+00006250: 6173 2072 6571 7569 7265 735f 6772 6164  as requires_grad
+00006260: 203d 2046 616c 7365 2e22 290a 2020 2020   = False.").    
+00006270: 2020 2020 7365 6c66 2e5f 7265 7461 696e      self._retain
+00006280: 5f67 7261 6420 3d20 7365 6c66 2e5f 6772  _grad = self._gr
+00006290: 6164 5f66 6e20 6973 206e 6f74 204e 6f6e  ad_fn is not Non
+000062a0: 650a 0a20 2020 2040 7072 6f70 6572 7479  e..    @property
+000062b0: 0a20 2020 2064 6566 2072 6574 6169 6e73  .    def retains
+000062c0: 5f67 7261 6428 7365 6c66 293a 0a20 2020  _grad(self):.   
+000062d0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+000062e0: 2e5f 7265 7461 696e 5f67 7261 640a 0a20  ._retain_grad.. 
+000062f0: 2020 2064 6566 2072 6571 7569 7265 735f     def requires_
+00006300: 6772 6164 5f28 7365 6c66 2c20 7265 7175  grad_(self, requ
+00006310: 6972 6573 5f67 7261 643d 5472 7565 293a  ires_grad=True):
+00006320: 0a20 2020 2020 2020 2073 656c 662e 7265  .        self.re
+00006330: 7175 6972 6573 5f67 7261 6420 3d20 7265  quires_grad = re
+00006340: 7175 6972 6573 5f67 7261 640a 2020 2020  quires_grad.    
+00006350: 2020 2020 7265 7475 726e 2073 656c 660a      return self.
+00006360: 0a20 2020 2064 6566 2062 6163 6b77 6172  .    def backwar
+00006370: 6428 7365 6c66 2c20 6772 6164 6965 6e74  d(self, gradient
+00006380: 3d4e 6f6e 652c 2072 6574 6169 6e5f 6772  =None, retain_gr
+00006390: 6170 683d 4e6f 6e65 2c20 6372 6561 7465  aph=None, create
+000063a0: 5f67 7261 7068 3d46 616c 7365 2c20 696e  _graph=False, in
+000063b0: 7075 7473 3d4e 6f6e 6529 3a0a 2020 2020  puts=None):.    
+000063c0: 2020 2020 5f42 4143 4b57 4152 445f 454e      _BACKWARD_EN
+000063d0: 5620 3d20 6f73 2e65 6e76 6972 6f6e 2e67  V = os.environ.g
+000063e0: 6574 2827 454e 4142 4c45 5f42 4143 4b57  et('ENABLE_BACKW
+000063f0: 4152 4427 290a 2020 2020 2020 2020 6966  ARD').        if
+00006400: 205f 4241 434b 5741 5244 5f45 4e56 2021   _BACKWARD_ENV !
+00006410: 3d20 2231 223a 0a20 2020 2020 2020 2020  = "1":.         
+00006420: 2020 2072 6169 7365 204e 6f74 496d 706c     raise NotImpl
+00006430: 656d 656e 7465 6445 7272 6f72 2822 4966  ementedError("If
+00006440: 2079 6f75 2077 616e 7420 746f 2075 7365   you want to use
+00006450: 2074 6865 2060 6261 636b 7761 7264 6020   the `backward` 
+00006460: 6675 6e63 7469 6f6e 2c20 706c 6561 7365  function, please
+00006470: 2063 6f6e 6669 6775 7265 2074 6865 2065   configure the e
+00006480: 6e76 6972 6f6e 6d65 6e74 2022 0a20 2020  nvironment ".   
+00006490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000064a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000064b0: 2020 2022 7661 7269 6162 6c65 2060 6578     "variable `ex
+000064c0: 706f 7274 2045 4e41 424c 455f 4241 434b  port ENABLE_BACK
+000064d0: 5741 5244 3d31 6020 746f 2065 6e61 626c  WARD=1` to enabl
+000064e0: 6520 6974 2066 6972 7374 2e22 290a 2020  e it first.").  
+000064f0: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
+00006500: 645f 6174 7472 2872 6574 6169 6e5f 6772  d_attr(retain_gr
+00006510: 6170 6829 0a20 2020 2020 2020 2075 6e73  aph).        uns
+00006520: 7570 706f 7274 6564 5f61 7474 7228 6372  upported_attr(cr
+00006530: 6561 7465 5f67 7261 7068 290a 2020 2020  eate_graph).    
+00006540: 2020 2020 756e 7375 7070 6f72 7465 645f      unsupported_
+00006550: 6174 7472 2869 6e70 7574 7329 0a20 2020  attr(inputs).   
+00006560: 2020 2020 2073 7570 6572 2829 2e62 6163       super().bac
+00006570: 6b77 6172 6428 6772 6164 6965 6e74 290a  kward(gradient).
+00006580: 0a20 2020 2064 6566 2073 746f 7261 6765  .    def storage
+00006590: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+000065a0: 6966 2067 7261 7068 5f6d 6f64 655f 636f  if graph_mode_co
+000065b0: 6e64 6974 696f 6e28 293a 0a20 2020 2020  ndition():.     
+000065c0: 2020 2020 2020 2077 6172 6e69 6e67 2827         warning('
+000065d0: 4375 7272 656e 746c 792c 2060 7465 6e73  Currently, `tens
+000065e0: 6f72 2e73 746f 7261 6765 2829 6020 6973  or.storage()` is
+000065f0: 206e 6f74 2073 7570 706f 7274 6564 2069   not supported i
+00006600: 6e20 6772 6170 6820 6d6f 6465 2e20 270a  n graph mode. '.
+00006610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006620: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006630: 2020 2020 2020 2750 6c65 6173 6520 7265        'Please re
+00006640: 706c 6163 6520 6053 746f 7261 6765 6020  place `Storage` 
+00006650: 7265 6c61 7465 6420 696e 7465 7266 6163  related interfac
+00006660: 6573 2077 6974 6820 7468 6520 6571 7569  es with the equi
+00006670: 7661 6c65 6e74 2069 6e74 6572 6661 6365  valent interface
+00006680: 2e27 290a 0a20 2020 2020 2020 2069 6620  .')..        if 
+00006690: 7365 6c66 2e64 7479 7065 203d 3d20 6d69  self.dtype == mi
+000066a0: 6e64 746f 7263 685f 6474 7970 652e 6266  ndtorch_dtype.bf
+000066b0: 6c6f 6174 3136 3a0a 2020 2020 2020 2020  loat16:.        
+000066c0: 2020 2020 6f75 7420 3d20 7365 6c66 2e61      out = self.a
+000066d0: 7374 7970 6528 6d69 6e64 746f 7263 685f  stype(mindtorch_
+000066e0: 6474 7970 652e 666c 6f61 7433 3229 2e61  dtype.float32).a
+000066f0: 736e 756d 7079 2829 0a20 2020 2020 2020  snumpy().       
+00006700: 2020 2020 206e 705f 6461 7461 203d 206f       np_data = o
+00006710: 7574 2e61 7374 7970 6528 5f54 7970 6544  ut.astype(_TypeD
+00006720: 6963 742e 6765 7428 7365 6c66 2e64 7479  ict.get(self.dty
+00006730: 7065 2929 0a20 2020 2020 2020 2065 6c73  pe)).        els
+00006740: 653a 0a20 2020 2020 2020 2020 2020 206e  e:.            n
+00006750: 705f 6461 7461 203d 2073 656c 662e 6173  p_data = self.as
+00006760: 6e75 6d70 7928 290a 2020 2020 2020 2020  numpy().        
+00006770: 2320 546f 2065 6e73 7572 6520 7468 6174  # To ensure that
+00006780: 2074 6865 206c 6966 6563 7963 6c65 206f   the lifecycle o
+00006790: 6620 706f 696e 7465 7273 2069 7320 636f  f pointers is co
+000067a0: 6e73 6973 7465 6e74 2077 6974 6820 7365  nsistent with se
+000067b0: 6c66 2e0a 2020 2020 2020 2020 7365 6c66  lf..        self
+000067c0: 2e5f 6e70 5f64 6174 6120 3d20 6e70 5f64  ._np_data = np_d
+000067d0: 6174 610a 2020 2020 2020 2020 696e 6e65  ata.        inne
+000067e0: 725f 6461 7461 203d 206e 702e 6672 6f6d  r_data = np.from
+000067f0: 6275 6666 6572 286e 705f 6461 7461 2c20  buffer(np_data, 
+00006800: 6e70 2e75 696e 7438 290a 2020 2020 2020  np.uint8).      
+00006810: 2020 5f73 746f 7261 6765 203d 205f 556e    _storage = _Un
+00006820: 7479 7065 6453 746f 7261 6765 2869 6e6e  typedStorage(inn
+00006830: 6572 5f64 6174 613d 696e 6e65 725f 6461  er_data=inner_da
+00006840: 7461 2c20 7265 6665 7265 6e63 6564 5f74  ta, referenced_t
+00006850: 656e 736f 723d 7365 6c66 290a 2020 2020  ensor=self).    
+00006860: 2020 2020 7265 7475 726e 205f 5479 7065      return _Type
+00006870: 6453 746f 7261 6765 2877 7261 705f 7374  dStorage(wrap_st
+00006880: 6f72 6167 653d 5f73 746f 7261 6765 2c20  orage=_storage, 
+00006890: 6474 7970 653d 7365 6c66 2e64 7479 7065  dtype=self.dtype
+000068a0: 290a 0a20 2020 2064 6566 2073 746f 7261  )..    def stora
+000068b0: 6765 5f74 7970 6528 7365 6c66 293a 0a20  ge_type(self):. 
+000068c0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+000068d0: 6c66 2e73 746f 7261 6765 2829 2e5f 6765  lf.storage()._ge
+000068e0: 745f 6c65 6761 6379 5f73 746f 7261 6765  t_legacy_storage
+000068f0: 5f63 6c61 7373 2829 0a0a 2020 2020 6465  _class()..    de
+00006900: 6620 6461 7461 5f70 7472 2873 656c 6629  f data_ptr(self)
+00006910: 3a0a 2020 2020 2020 2020 6966 2073 656c  :.        if sel
+00006920: 662e 6474 7970 6520 3d3d 206d 696e 6474  f.dtype == mindt
+00006930: 6f72 6368 5f64 7479 7065 2e62 666c 6f61  orch_dtype.bfloa
+00006940: 7431 363a 0a20 2020 2020 2020 2020 2020  t16:.           
+00006950: 206f 7574 203d 2073 656c 662e 6173 7479   out = self.asty
+00006960: 7065 286d 696e 6474 6f72 6368 5f64 7479  pe(mindtorch_dty
+00006970: 7065 2e66 6c6f 6174 3332 292e 6173 6e75  pe.float32).asnu
+00006980: 6d70 7928 290a 2020 2020 2020 2020 2020  mpy().          
+00006990: 2020 6e70 5f64 6174 6120 3d20 6f75 742e    np_data = out.
+000069a0: 6173 7479 7065 285f 5479 7065 4469 6374  astype(_TypeDict
+000069b0: 2e67 6574 2873 656c 662e 6474 7970 6529  .get(self.dtype)
+000069c0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
+000069d0: 2020 2020 2020 2020 2020 2020 6e70 5f64              np_d
+000069e0: 6174 6120 3d20 7365 6c66 2e61 736e 756d  ata = self.asnum
+000069f0: 7079 2829 0a20 2020 2020 2020 2023 2054  py().        # T
+00006a00: 6f20 656e 7375 7265 2074 6861 7420 7468  o ensure that th
+00006a10: 6520 6c69 6665 6379 636c 6520 6f66 2070  e lifecycle of p
+00006a20: 6f69 6e74 6572 7320 6973 2063 6f6e 7369  ointers is consi
+00006a30: 7374 656e 7420 7769 7468 2073 656c 662e  stent with self.
+00006a40: 0a20 2020 2020 2020 2073 656c 662e 5f6e  .        self._n
+00006a50: 705f 6461 7461 203d 206e 705f 6461 7461  p_data = np_data
+00006a60: 0a20 2020 2020 2020 2070 7472 203d 206e  .        ptr = n
+00006a70: 705f 6461 7461 2e63 7479 7065 732e 6461  p_data.ctypes.da
+00006a80: 7461 0a20 2020 2020 2020 2072 6574 7572  ta.        retur
+00006a90: 6e20 7074 720a 0a20 2020 2040 7072 6f70  n ptr..    @prop
+00006aa0: 6572 7479 0a20 2020 2064 6566 2064 7479  erty.    def dty
+00006ab0: 7065 2873 656c 6629 3a0a 2020 2020 2020  pe(self):.      
+00006ac0: 2020 7820 3d20 6361 7374 5f74 6f5f 6d73    x = cast_to_ms
+00006ad0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+00006ae0: 2020 2020 2020 6474 7970 6520 3d20 782e        dtype = x.
+00006af0: 6474 7970 650a 2020 2020 2020 2020 7265  dtype.        re
+00006b00: 7475 726e 205f 6d73 6474 7970 6532 7479  turn _msdtype2ty
+00006b10: 7065 4469 6374 2e67 6574 2873 7472 2864  peDict.get(str(d
+00006b20: 7479 7065 292c 2064 7479 7065 290a 0a20  type), dtype).. 
+00006b30: 2020 2064 6566 2066 696c 6c5f 6164 6170     def fill_adap
+00006b40: 7465 7228 7365 6c66 2c20 7661 6c29 3a0a  ter(self, val):.
+00006b50: 2020 2020 2020 2020 7661 6c20 3d20 6361          val = ca
+00006b60: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00006b70: 7661 6c29 0a20 2020 2020 2020 206f 7574  val).        out
+00006b80: 7075 7420 3d20 6d73 2e6f 7073 2e66 696c  put = ms.ops.fil
+00006b90: 6c28 7365 6c66 2e64 7479 7065 2c20 7365  l(self.dtype, se
+00006ba0: 6c66 2e73 6861 7065 2c20 7661 6c29 0a20  lf.shape, val). 
+00006bb0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00006bc0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00006bd0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+00006be0: 2020 6465 6620 6669 6c6c 5f28 7365 6c66    def fill_(self
+00006bf0: 2c20 7661 6c29 3a0a 2020 2020 2020 2020  , val):.        
+00006c00: 6f75 7470 7574 203d 2073 656c 662e 6669  output = self.fi
+00006c10: 6c6c 5f61 6461 7074 6572 2876 616c 290a  ll_adapter(val).
+00006c20: 2020 2020 2020 2020 7265 7475 726e 205f          return _
+00006c30: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
+00006c40: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
+00006c50: 7574 2c20 2266 696c 6c5f 222c 2022 6669  ut, "fill_", "fi
+00006c60: 6c6c 5f61 6461 7074 6572 2229 0a0a 2020  ll_adapter")..  
+00006c70: 2020 6465 6620 6e6f 726d 616c 5f61 6461    def normal_ada
+00006c80: 7074 6572 2873 656c 662c 206d 6561 6e3d  pter(self, mean=
+00006c90: 302c 2073 7464 3d31 2c20 2a2c 2067 656e  0, std=1, *, gen
+00006ca0: 6572 6174 6f72 3d4e 6f6e 6529 3a0a 2020  erator=None):.  
+00006cb0: 2020 2020 2020 6966 2067 656e 6572 6174        if generat
+00006cc0: 6f72 2069 7320 6e6f 7420 4e6f 6e65 3a0a  or is not None:.
+00006cd0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00006ce0: 6520 5661 6c75 6545 7272 6f72 2822 6067  e ValueError("`g
+00006cf0: 656e 6572 6174 6f72 6020 6361 6e20 6e6f  enerator` can no
+00006d00: 7420 6265 2073 7570 706f 7274 7465 642e  t be supportted.
+00006d10: 2229 0a20 2020 2020 2020 206f 7574 7075  ").        outpu
+00006d20: 7420 3d20 6d73 2e6f 7073 2e6e 6f72 6d61  t = ms.ops.norma
+00006d30: 6c28 7365 6c66 2e73 6861 7065 2c20 6d65  l(self.shape, me
+00006d40: 616e 2c20 7374 6429 2e61 7374 7970 6528  an, std).astype(
+00006d50: 7365 6c66 2e64 7479 7065 290a 2020 2020  self.dtype).    
+00006d60: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+00006d70: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00006d80: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+00006d90: 6566 206e 6f72 6d61 6c5f 2873 656c 662c  ef normal_(self,
+00006da0: 206d 6561 6e3d 302c 2073 7464 3d31 2c20   mean=0, std=1, 
+00006db0: 2a2c 2067 656e 6572 6174 6f72 3d4e 6f6e  *, generator=Non
+00006dc0: 6529 3a0a 2020 2020 2020 2020 6f75 7470  e):.        outp
+00006dd0: 7574 203d 2073 656c 662e 6e6f 726d 616c  ut = self.normal
+00006de0: 5f61 6461 7074 6572 286d 6561 6e2c 2073  _adapter(mean, s
+00006df0: 7464 2c20 6765 6e65 7261 746f 723d 6765  td, generator=ge
+00006e00: 6e65 7261 746f 7229 0a20 2020 2020 2020  nerator).       
+00006e10: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+00006e20: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+00006e30: 656c 662c 206f 7574 7075 742c 2022 6e6f  elf, output, "no
+00006e40: 726d 616c 5f22 2c20 226e 6f72 6d61 6c5f  rmal_", "normal_
+00006e50: 6164 6170 7465 7222 290a 0a20 2020 2064  adapter")..    d
+00006e60: 6566 2073 697a 6528 7365 6c66 2c20 6469  ef size(self, di
+00006e70: 6d3d 4e6f 6e65 293a 0a20 2020 2020 2020  m=None):.       
+00006e80: 2022 2222 0a20 2020 2020 2020 2074 656e   """.        ten
+00006e90: 736f 722e 7369 7a65 2829 2068 6173 2074  sor.size() has t
+00006ea0: 6865 2073 616d 6520 6675 6e63 7469 6f6e  he same function
+00006eb0: 2061 7320 7465 6e73 6f72 2e73 697a 6528   as tensor.size(
+00006ec0: 2920 696e 2050 7954 6f72 6368 2c0a 2020  ) in PyTorch,.  
+00006ed0: 2020 2020 2020 6275 7420 6469 6666 6572        but differ
+00006ee0: 656e 7420 6672 6f6d 2074 6865 2074 656e  ent from the ten
+00006ef0: 736f 722e 7369 7a65 2069 6e20 4d69 6e64  sor.size in Mind
+00006f00: 5370 6f72 652e 0a20 2020 2020 2020 2022  Spore..        "
+00006f10: 2222 0a20 2020 2020 2020 2069 6620 6469  "".        if di
+00006f20: 6d20 6973 204e 6f6e 653a 0a20 2020 2020  m is None:.     
+00006f30: 2020 2020 2020 2072 6574 7572 6e20 5369         return Si
+00006f40: 7a65 2873 656c 662e 7368 6170 6529 0a20  ze(self.shape). 
+00006f50: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+00006f60: 6c66 2e73 6861 7065 5b64 696d 5d0a 0a20  lf.shape[dim].. 
+00006f70: 2020 2064 6566 2075 6e69 666f 726d 5f61     def uniform_a
+00006f80: 6461 7074 6572 2873 656c 662c 2066 726f  dapter(self, fro
+00006f90: 6d5f 616c 6961 733d 302c 2074 6f3d 3129  m_alias=0, to=1)
+00006fa0: 3a20 2023 544f 444f 3a20 6672 6f6d 5f61  :  #TODO: from_a
+00006fb0: 6c69 6173 2d3e 6672 6f6d 0a20 2020 2020  lias->from.     
+00006fc0: 2020 2066 726f 6d5f 616c 6961 7320 3d20     from_alias = 
+00006fd0: 6d73 2e54 656e 736f 7228 6672 6f6d 5f61  ms.Tensor(from_a
+00006fe0: 6c69 6173 2c20 6d73 2e66 6c6f 6174 3332  lias, ms.float32
+00006ff0: 290a 2020 2020 2020 2020 746f 203d 206d  ).        to = m
+00007000: 732e 5465 6e73 6f72 2874 6f2c 206d 732e  s.Tensor(to, ms.
+00007010: 666c 6f61 7433 3229 0a20 2020 2020 2020  float32).       
+00007020: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00007030: 2e75 6e69 666f 726d 2873 656c 662e 7368  .uniform(self.sh
+00007040: 6170 652c 2066 726f 6d5f 616c 6961 732c  ape, from_alias,
+00007050: 2074 6f29 2e61 7374 7970 6528 7365 6c66   to).astype(self
+00007060: 2e64 7479 7065 290a 2020 2020 2020 2020  .dtype).        
+00007070: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00007080: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00007090: 7470 7574 290a 0a20 2020 2064 6566 2075  tput)..    def u
+000070a0: 6e69 666f 726d 5f28 7365 6c66 2c20 6672  niform_(self, fr
+000070b0: 6f6d 5f61 6c69 6173 3d30 2c20 746f 3d31  om_alias=0, to=1
+000070c0: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+000070d0: 7420 3d20 7365 6c66 2e75 6e69 666f 726d  t = self.uniform
+000070e0: 5f61 6461 7074 6572 2866 726f 6d5f 616c  _adapter(from_al
+000070f0: 6961 732c 2074 6f29 0a20 2020 2020 2020  ias, to).       
+00007100: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+00007110: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+00007120: 656c 662c 206f 7574 7075 742c 2022 756e  elf, output, "un
+00007130: 6966 6f72 6d5f 222c 2022 756e 6966 6f72  iform_", "unifor
+00007140: 6d5f 6164 6170 7465 7222 290a 0a20 2020  m_adapter")..   
+00007150: 2064 6566 2072 616e 646f 6d5f 6164 6170   def random_adap
+00007160: 7465 7228 7365 6c66 2c20 6672 6f6d 5f61  ter(self, from_a
+00007170: 6c69 6173 3d30 2c20 746f 3d4e 6f6e 652c  lias=0, to=None,
+00007180: 202a 2c20 6765 6e65 7261 746f 723d 4e6f   *, generator=No
+00007190: 6e65 293a 2020 2354 4f44 4f3a 2066 726f  ne):  #TODO: fro
+000071a0: 6d5f 616c 6961 732d 3e66 726f 6d0a 2020  m_alias->from.  
+000071b0: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
+000071c0: 645f 6174 7472 2867 656e 6572 6174 6f72  d_attr(generator
+000071d0: 290a 2020 2020 2020 2020 6966 2067 656e  ).        if gen
+000071e0: 6572 6174 6f72 3a0a 2020 2020 2020 2020  erator:.        
+000071f0: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
+00007200: 6c65 6d65 6e74 6564 4572 726f 7228 2267  lementedError("g
+00007210: 656e 6572 6174 6f72 2069 7320 6e6f 7420  enerator is not 
+00007220: 7375 7070 6f72 7465 642e 2229 0a0a 2020  supported.")..  
+00007230: 2020 2020 2020 7365 6c66 5f64 7479 7065        self_dtype
+00007240: 203d 2073 656c 662e 6474 7970 650a 0a20   = self.dtype.. 
+00007250: 2020 2020 2020 2069 6620 6e6f 7420 746f         if not to
+00007260: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+00007270: 2073 656c 665f 6474 7970 6520 3d3d 206d   self_dtype == m
+00007280: 732e 666c 6f61 7436 343a 0a20 2020 2020  s.float64:.     
+00007290: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+000072a0: 6e20 7365 6c66 2e75 6e69 666f 726d 5f61  n self.uniform_a
+000072b0: 6461 7074 6572 2866 726f 6d5f 616c 6961  dapter(from_alia
+000072c0: 732c 206b 4d61 6e74 6973 7361 466c 6f61  s, kMantissaFloa
+000072d0: 7436 3429 0a20 2020 2020 2020 2020 2020  t64).           
+000072e0: 2065 6c69 6620 7365 6c66 5f64 7479 7065   elif self_dtype
+000072f0: 203d 3d20 6d73 2e66 6c6f 6174 3332 3a0a   == ms.float32:.
+00007300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007310: 7265 7475 726e 2073 656c 662e 756e 6966  return self.unif
+00007320: 6f72 6d5f 6164 6170 7465 7228 6672 6f6d  orm_adapter(from
+00007330: 5f61 6c69 6173 2c20 6b4d 616e 7469 7373  _alias, kMantiss
+00007340: 6146 6c6f 6174 3332 290a 2020 2020 2020  aFloat32).      
+00007350: 2020 2020 2020 656c 6966 2073 656c 665f        elif self_
+00007360: 6474 7970 6520 3d3d 206d 732e 666c 6f61  dtype == ms.floa
+00007370: 7431 363a 0a20 2020 2020 2020 2020 2020  t16:.           
+00007380: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+00007390: 2e75 6e69 666f 726d 5f61 6461 7074 6572  .uniform_adapter
+000073a0: 2866 726f 6d5f 616c 6961 732c 206b 4d61  (from_alias, kMa
+000073b0: 6e74 6973 7361 466c 6f61 7431 3629 0a20  ntissaFloat16). 
+000073c0: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+000073d0: 7365 6c66 5f64 7479 7065 203d 3d20 6d73  self_dtype == ms
+000073e0: 2e75 696e 7438 3a0a 2020 2020 2020 2020  .uint8:.        
+000073f0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00007400: 656c 662e 756e 6966 6f72 6d5f 6164 6170  elf.uniform_adap
+00007410: 7465 7228 6672 6f6d 5f61 6c69 6173 2c20  ter(from_alias, 
+00007420: 6b4d 6178 5569 6e74 3829 0a20 2020 2020  kMaxUint8).     
+00007430: 2020 2020 2020 2065 6c69 6620 7365 6c66         elif self
+00007440: 5f64 7479 7065 203d 3d20 6d73 2e69 6e74  _dtype == ms.int
+00007450: 3634 3a0a 2020 2020 2020 2020 2020 2020  64:.            
+00007460: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+00007470: 756e 6966 6f72 6d5f 6164 6170 7465 7228  uniform_adapter(
+00007480: 6672 6f6d 5f61 6c69 6173 2c20 6b4d 6178  from_alias, kMax
+00007490: 496e 7436 3429 0a20 2020 2020 2020 2020  Int64).         
+000074a0: 2020 2065 6c69 6620 7365 6c66 5f64 7479     elif self_dty
+000074b0: 7065 203d 3d20 6d73 2e69 6e74 3332 3a0a  pe == ms.int32:.
+000074c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000074d0: 7265 7475 726e 2073 656c 662e 756e 6966  return self.unif
+000074e0: 6f72 6d5f 6164 6170 7465 7228 6672 6f6d  orm_adapter(from
+000074f0: 5f61 6c69 6173 2c20 6b4d 6178 496e 7433  _alias, kMaxInt3
+00007500: 3229 0a20 2020 2020 2020 2020 2020 2065  2).            e
+00007510: 6c69 6620 7365 6c66 5f64 7479 7065 203d  lif self_dtype =
+00007520: 3d20 6d73 2e69 6e74 3136 3a0a 2020 2020  = ms.int16:.    
+00007530: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00007540: 726e 2073 656c 662e 756e 6966 6f72 6d5f  rn self.uniform_
+00007550: 6164 6170 7465 7228 6672 6f6d 5f61 6c69  adapter(from_ali
+00007560: 6173 2c20 6b4d 6178 496e 7431 3629 0a20  as, kMaxInt16). 
+00007570: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
+00007580: 7365 6c66 5f64 7479 7065 203d 3d20 6d73  self_dtype == ms
+00007590: 2e69 6e74 383a 0a20 2020 2020 2020 2020  .int8:.         
+000075a0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+000075b0: 6c66 2e75 6e69 666f 726d 5f61 6461 7074  lf.uniform_adapt
+000075c0: 6572 2866 726f 6d5f 616c 6961 732c 206b  er(from_alias, k
+000075d0: 4d61 7849 6e74 3829 0a20 2020 2020 2020  MaxInt8).       
+000075e0: 2074 6f20 3d20 746f 202d 2031 2069 6620   to = to - 1 if 
+000075f0: 746f 203e 2031 2065 6c73 6520 746f 0a20  to > 1 else to. 
+00007600: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+00007610: 6c66 2e75 6e69 666f 726d 5f61 6461 7074  lf.uniform_adapt
+00007620: 6572 2866 726f 6d5f 616c 6961 732c 2074  er(from_alias, t
+00007630: 6f29 0a0a 2020 2020 6465 6620 7261 6e64  o)..    def rand
+00007640: 6f6d 5f28 7365 6c66 2c20 6672 6f6d 5f61  om_(self, from_a
+00007650: 6c69 6173 3d30 2c20 746f 3d4e 6f6e 652c  lias=0, to=None,
+00007660: 202a 2c20 6765 6e65 7261 746f 723d 4e6f   *, generator=No
+00007670: 6e65 293a 2020 2354 4f44 4f3a 2066 726f  ne):  #TODO: fro
+00007680: 6d5f 616c 6961 732d 3e66 726f 6d0a 2020  m_alias->from.  
+00007690: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
+000076a0: 656c 662e 7261 6e64 6f6d 5f61 6461 7074  elf.random_adapt
+000076b0: 6572 2866 726f 6d5f 616c 6961 732c 2074  er(from_alias, t
+000076c0: 6f2c 2067 656e 6572 6174 6f72 3d67 656e  o, generator=gen
+000076d0: 6572 6174 6f72 290a 2020 2020 2020 2020  erator).        
+000076e0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
+000076f0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
+00007700: 6c66 2c20 6f75 7470 7574 2c20 2272 616e  lf, output, "ran
+00007710: 646f 6d5f 222c 2022 7261 6e64 6f6d 5f61  dom_", "random_a
+00007720: 6461 7074 6572 2229 0a0a 2020 2020 6465  dapter")..    de
+00007730: 6620 7a65 726f 5f61 6461 7074 6572 2873  f zero_adapter(s
+00007740: 656c 6629 3a0a 2020 2020 2020 2020 6f75  elf):.        ou
+00007750: 7470 7574 203d 206d 732e 6f70 732e 6669  tput = ms.ops.fi
+00007760: 6c6c 2873 656c 662e 6474 7970 652c 2073  ll(self.dtype, s
+00007770: 656c 662e 7368 6170 652c 2030 2e30 290a  elf.shape, 0.0).
+00007780: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00007790: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+000077a0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+000077b0: 2020 2064 6566 207a 6572 6f5f 2873 656c     def zero_(sel
+000077c0: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
+000077d0: 7574 203d 2073 656c 662e 7a65 726f 5f61  ut = self.zero_a
+000077e0: 6461 7074 6572 2829 0a20 2020 2020 2020  dapter().       
+000077f0: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+00007800: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+00007810: 656c 662c 206f 7574 7075 742c 2022 7a65  elf, output, "ze
+00007820: 726f 5f22 2c20 227a 6572 6f5f 6164 6170  ro_", "zero_adap
+00007830: 7465 7222 290a 0a20 2020 2023 544f 444f  ter")..    #TODO
+00007840: 3a20 6164 6170 7465 7220 6e65 6564 7320  : adapter needs 
+00007850: 746f 2073 7570 706f 7274 2062 6f74 6820  to support both 
+00007860: 706f 7369 7469 6f6e 616c 2061 6e64 206b  positional and k
+00007870: 6579 776f 7264 7320 696e 7075 7420 7369  eywords input si
+00007880: 7a65 2074 6f20 6265 2063 6f6e 7369 7374  ze to be consist
+00007890: 656e 7420 7769 7468 2070 7974 6f72 6368  ent with pytorch
+000078a0: 0a20 2020 2023 706f 7369 7469 6f6e 616c  .    #positional
+000078b0: 5f73 697a 6520 7265 7072 6573 656e 7473  _size represents
+000078c0: 2074 6865 2070 6f73 6974 696f 6e61 6c20   the positional 
+000078d0: 6172 6775 6d65 6e74 7320 6f66 2073 697a  arguments of siz
+000078e0: 652c 2073 697a 6520 7265 7072 6573 656e  e, size represen
+000078f0: 7473 2074 6865 206b 6579 776f 7264 7320  ts the keywords 
+00007900: 6172 6775 6d65 6e74 7320 696e 7075 740a  arguments input.
+00007910: 2020 2020 6465 6620 6e65 775f 7a65 726f      def new_zero
+00007920: 7328 7365 6c66 2c20 2a70 6f73 6974 696f  s(self, *positio
+00007930: 6e61 6c5f 7369 7a65 2c20 7369 7a65 3d4e  nal_size, size=N
+00007940: 6f6e 652c 2064 7479 7065 3d4e 6f6e 652c  one, dtype=None,
+00007950: 2064 6576 6963 653d 4e6f 6e65 2c20 7265   device=None, re
+00007960: 7175 6972 6573 5f67 7261 643d 4661 6c73  quires_grad=Fals
+00007970: 6529 3a0a 2020 2020 2020 2020 756e 7375  e):.        unsu
+00007980: 7070 6f72 7465 645f 6174 7472 2864 6576  pported_attr(dev
+00007990: 6963 6529 0a0a 2020 2020 2020 2020 6966  ice)..        if
+000079a0: 206e 6f74 2064 7479 7065 3a0a 2020 2020   not dtype:.    
+000079b0: 2020 2020 2020 2020 6474 7970 6520 3d20          dtype = 
+000079c0: 7365 6c66 2e64 7479 7065 0a20 2020 2020  self.dtype.     
+000079d0: 2020 2069 6620 7369 7a65 2069 7320 4e6f     if size is No
+000079e0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+000079f0: 6966 2069 7369 6e73 7461 6e63 6528 706f  if isinstance(po
+00007a00: 7369 7469 6f6e 616c 5f73 697a 655b 305d  sitional_size[0]
+00007a10: 2c20 2874 7570 6c65 2c20 6c69 7374 2929  , (tuple, list))
+00007a20: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00007a30: 2020 7369 7a65 203d 2070 6f73 6974 696f    size = positio
+00007a40: 6e61 6c5f 7369 7a65 5b30 5d0a 2020 2020  nal_size[0].    
+00007a50: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00007a60: 2020 2020 2020 2020 2020 2020 2020 7369                si
+00007a70: 7a65 203d 2070 6f73 6974 696f 6e61 6c5f  ze = positional_
+00007a80: 7369 7a65 0a20 2020 2020 2020 2069 6620  size.        if 
+00007a90: 6973 696e 7374 616e 6365 2873 697a 655b  isinstance(size[
+00007aa0: 305d 2c20 7475 706c 6529 3a0a 2020 2020  0], tuple):.    
+00007ab0: 2020 2020 2020 2020 7369 7a65 203d 2073          size = s
+00007ac0: 697a 655b 305d 0a0a 2020 2020 2020 2020  ize[0]..        
+00007ad0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+00007ae0: 6669 6c6c 2864 7479 7065 2c20 7369 7a65  fill(dtype, size
+00007af0: 2c20 302e 3029 0a20 2020 2020 2020 206f  , 0.0).        o
+00007b00: 7574 7075 742e 7265 7175 6972 6573 5f67  utput.requires_g
+00007b10: 7261 6420 3d20 7265 7175 6972 6573 5f67  rad = requires_g
+00007b20: 7261 640a 2020 2020 2020 2020 7265 7475  rad.        retu
+00007b30: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00007b40: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+00007b50: 290a 0a20 2020 2064 6566 206e 6577 5f66  )..    def new_f
+00007b60: 756c 6c28 7365 6c66 2c20 7369 7a65 2c20  ull(self, size, 
+00007b70: 6669 6c6c 5f76 616c 7565 2c20 2a2c 2064  fill_value, *, d
+00007b80: 7479 7065 3d4e 6f6e 652c 2064 6576 6963  type=None, devic
+00007b90: 653d 4e6f 6e65 2c20 7265 7175 6972 6573  e=None, requires
+00007ba0: 5f67 7261 643d 4661 6c73 652c 0a20 2020  _grad=False,.   
+00007bb0: 2020 2020 2020 2020 2020 2020 2020 6c61                la
+00007bc0: 796f 7574 3d4e 6f6e 652c 2070 696e 5f6d  yout=None, pin_m
+00007bd0: 656d 6f72 793d 4661 6c73 6529 3a0a 2020  emory=False):.  
+00007be0: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
+00007bf0: 645f 6174 7472 2864 6576 6963 6529 0a20  d_attr(device). 
+00007c00: 2020 2020 2020 2075 6e73 7570 706f 7274         unsupport
+00007c10: 6564 5f61 7474 7228 6c61 796f 7574 290a  ed_attr(layout).
+00007c20: 2020 2020 2020 2020 6966 206c 6179 6f75          if layou
+00007c30: 743a 0a20 2020 2020 2020 2020 2020 2072  t:.            r
+00007c40: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
+00007c50: 7465 6445 7272 6f72 2822 6c61 796f 7574  tedError("layout
+00007c60: 2069 7320 6e6f 7420 7375 7070 6f72 7465   is not supporte
+00007c70: 642e 2229 0a20 2020 2020 2020 2075 6e73  d.").        uns
+00007c80: 7570 706f 7274 6564 5f61 7474 7228 7069  upported_attr(pi
+00007c90: 6e5f 6d65 6d6f 7279 290a 2020 2020 2020  n_memory).      
+00007ca0: 2020 6966 2070 696e 5f6d 656d 6f72 7920    if pin_memory 
+00007cb0: 6973 2054 7275 653a 0a20 2020 2020 2020  is True:.       
+00007cc0: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
+00007cd0: 706c 656d 656e 7465 6445 7272 6f72 2822  plementedError("
+00007ce0: 7069 6e5f 6d65 6d6f 7279 2069 7320 6e6f  pin_memory is no
+00007cf0: 7420 7375 7070 6f72 7465 6420 746f 2054  t supported to T
+00007d00: 7275 652e 2229 0a0a 2020 2020 2020 2020  rue.")..        
+00007d10: 6966 206e 6f74 2064 7479 7065 3a0a 2020  if not dtype:.  
+00007d20: 2020 2020 2020 2020 2020 6474 7970 6520            dtype 
+00007d30: 3d20 7365 6c66 2e64 7479 7065 0a0a 2020  = self.dtype..  
+00007d40: 2020 2020 2020 7369 7a65 203d 205f 6368        size = _ch
+00007d50: 6563 6b5f 696e 745f 7369 7a65 2873 697a  eck_int_size(siz
+00007d60: 652c 2022 6e65 775f 6675 6c6c 2229 0a20  e, "new_full"). 
+00007d70: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00007d80: 6d73 2e6f 7073 2e66 696c 6c28 6474 7970  ms.ops.fill(dtyp
+00007d90: 652c 2073 697a 652c 2066 696c 6c5f 7661  e, size, fill_va
+00007da0: 6c75 6529 0a20 2020 2020 2020 206f 7574  lue).        out
+00007db0: 7075 742e 7265 7175 6972 6573 5f67 7261  put.requires_gra
+00007dc0: 6420 3d20 7265 7175 6972 6573 5f67 7261  d = requires_gra
+00007dd0: 640a 2020 2020 2020 2020 7265 7475 726e  d.        return
+00007de0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00007df0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+00007e00: 0a20 2020 2064 6566 2061 6464 2873 656c  .    def add(sel
+00007e10: 662c 206f 7468 6572 2c20 2a2c 2061 6c70  f, other, *, alp
+00007e20: 6861 3d31 293a 0a20 2020 2020 2020 2023  ha=1):.        #
+00007e30: 2054 4f44 4f3a 206d 732e 6f70 732e 6164   TODO: ms.ops.ad
+00007e40: 6420 7768 656e 2061 6464 2062 6f74 6820  d when add both 
+00007e50: 626f 6f6c 2054 656e 736f 722c 2072 6574  bool Tensor, ret
+00007e60: 7572 6e20 696e 7420 7465 6e73 6f72 2069  urn int tensor i
+00007e70: 6e73 7465 6164 206f 6620 626f 6f6c 2074  nstead of bool t
+00007e80: 656e 736f 722e 0a20 2020 2020 2020 2069  ensor..        i
+00007e90: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+00007ea0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00007eb0: 290a 2020 2020 2020 2020 6f74 6865 7220  ).        other 
+00007ec0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00007ed0: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
+00007ee0: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+00007ef0: 7073 2e61 6464 2869 6e70 7574 5f6d 732c  ps.add(input_ms,
+00007f00: 206f 7468 6572 2a61 6c70 6861 290a 2020   other*alpha).  
+00007f10: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00007f20: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00007f30: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00007f40: 2064 6566 2061 6464 5f28 7365 6c66 2c20   def add_(self, 
+00007f50: 6f74 6865 722c 202a 2c20 616c 7068 613d  other, *, alpha=
+00007f60: 3129 3a0a 2020 2020 2020 2020 6f75 7470  1):.        outp
+00007f70: 7574 203d 2073 656c 662e 6164 6428 6f74  ut = self.add(ot
+00007f80: 6865 722c 2061 6c70 6861 3d61 6c70 6861  her, alpha=alpha
+00007f90: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00007fa0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+00007fb0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+00007fc0: 7470 7574 2c20 2261 6464 5f22 2c20 2261  tput, "add_", "a
+00007fd0: 6464 2229 0a0a 2020 2020 6465 6620 6572  dd")..    def er
+00007fe0: 6669 6e76 2873 656c 6629 3a0a 2020 2020  finv(self):.    
+00007ff0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+00008000: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00008010: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+00008020: 7574 7075 7420 3d20 6d73 2e6f 7073 2e65  utput = ms.ops.e
+00008030: 7266 696e 7628 696e 7075 745f 6d73 290a  rfinv(input_ms).
+00008040: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00008050: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+00008060: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+00008070: 2020 2064 6566 2065 7266 696e 765f 2873     def erfinv_(s
+00008080: 656c 6629 3a0a 2020 2020 2020 2020 6f75  elf):.        ou
+00008090: 7470 7574 203d 2073 656c 662e 6572 6669  tput = self.erfi
+000080a0: 6e76 2829 0a20 2020 2020 2020 2072 6574  nv().        ret
+000080b0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+000080c0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+000080d0: 206f 7574 7075 742c 2022 6572 6669 6e76   output, "erfinv
+000080e0: 5f22 2c20 2265 7266 696e 7622 290a 0a20  _", "erfinv").. 
+000080f0: 2020 2064 6566 2070 6572 6d75 7465 2873     def permute(s
+00008100: 656c 662c 202a 6469 6d73 293a 0a20 2020  elf, *dims):.   
+00008110: 2020 2020 206d 735f 696e 7075 7420 3d20       ms_input = 
+00008120: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00008130: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00008140: 6966 2069 7369 6e73 7461 6e63 6528 6469  if isinstance(di
+00008150: 6d73 2c20 6c69 7374 293a 0a20 2020 2020  ms, list):.     
+00008160: 2020 2020 2020 2064 696d 7320 3d20 7475         dims = tu
+00008170: 706c 6528 6469 6d73 290a 2020 2020 2020  ple(dims).      
+00008180: 2020 6f75 7470 7574 203d 206d 735f 696e    output = ms_in
+00008190: 7075 742e 7065 726d 7574 6528 2a64 696d  put.permute(*dim
+000081a0: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+000081b0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+000081c0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+000081d0: 0a0a 2020 2020 6465 6620 636f 6e74 6967  ..    def contig
+000081e0: 756f 7573 2873 656c 662c 206d 656d 6f72  uous(self, memor
+000081f0: 795f 666f 726d 6174 3d4e 6f6e 6529 3a0a  y_format=None):.
+00008200: 2020 2020 2020 2020 756e 7375 7070 6f72          unsuppor
+00008210: 7465 645f 6174 7472 286d 656d 6f72 795f  ted_attr(memory_
+00008220: 666f 726d 6174 290a 2020 2020 2020 2020  format).        
+00008230: 6d73 5f69 6e70 7574 203d 2063 6173 745f  ms_input = cast_
+00008240: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00008250: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
+00008260: 7420 3d20 6d73 5f69 6e70 7574 2e63 6f6e  t = ms_input.con
+00008270: 7469 6775 6f75 7328 290a 2020 2020 2020  tiguous().      
+00008280: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+00008290: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+000082a0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+000082b0: 206e 6577 5f74 656e 736f 7228 7365 6c66   new_tensor(self
+000082c0: 2c20 6461 7461 2c20 2a2c 2064 7479 7065  , data, *, dtype
+000082d0: 3d4e 6f6e 652c 2064 6576 6963 653d 4e6f  =None, device=No
+000082e0: 6e65 2c20 7265 7175 6972 6573 5f67 7261  ne, requires_gra
+000082f0: 643d 4661 6c73 652c 206c 6179 6f75 743d  d=False, layout=
+00008300: 4e6f 6e65 2c20 7069 6e5f 6d65 6d6f 7279  None, pin_memory
+00008310: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
+00008320: 2075 6e73 7570 706f 7274 6564 5f61 7474   unsupported_att
+00008330: 7228 6c61 796f 7574 290a 2020 2020 2020  r(layout).      
+00008340: 2020 756e 7375 7070 6f72 7465 645f 6174    unsupported_at
+00008350: 7472 2870 696e 5f6d 656d 6f72 7929 0a20  tr(pin_memory). 
+00008360: 2020 2020 2020 2069 6620 6e6f 7420 6474         if not dt
+00008370: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
+00008380: 2064 7479 7065 203d 2073 656c 662e 6474   dtype = self.dt
+00008390: 7970 650a 0a20 2020 2020 2020 2069 6620  ype..        if 
+000083a0: 6973 696e 7374 616e 6365 2864 6174 612c  isinstance(data,
+000083b0: 2054 656e 736f 7229 3a0a 2020 2020 2020   Tensor):.      
+000083c0: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+000083d0: 6545 7272 6f72 2822 546f 2063 6f70 7920  eError("To copy 
+000083e0: 636f 6e73 7472 7563 7420 6672 6f6d 2061  construct from a
+000083f0: 2074 656e 736f 722c 2069 7420 6973 2072   tensor, it is r
+00008400: 6563 6f6d 6d65 6e64 6564 2074 6f20 7573  ecommended to us
+00008410: 6520 736f 7572 6365 5465 6e73 6f72 2e63  e sourceTensor.c
+00008420: 6c6f 6e65 2829 2e64 6574 6163 6828 2920  lone().detach() 
+00008430: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
+00008440: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00008450: 6f72 2073 6f75 7263 6554 656e 736f 722e  or sourceTensor.
+00008460: 636c 6f6e 6528 292e 6465 7461 6368 2829  clone().detach()
+00008470: 2e72 6571 7569 7265 735f 6772 6164 5f28  .requires_grad_(
+00008480: 5472 7565 292c 2022 0a20 2020 2020 2020  True), ".       
+00008490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000084a0: 2020 2020 2020 2272 6174 6865 7220 7468        "rather th
+000084b0: 616e 2074 656e 736f 722e 6e65 775f 7465  an tensor.new_te
+000084c0: 6e73 6f72 2873 6f75 7263 6554 656e 736f  nsor(sourceTenso
+000084d0: 7229 2e22 290a 2020 2020 2020 2020 7265  r).").        re
+000084e0: 7475 726e 2074 656e 736f 7228 6461 7461  turn tensor(data
+000084f0: 2c20 6474 7970 652c 2064 6576 6963 652c  , dtype, device,
+00008500: 2072 6571 7569 7265 735f 6772 6164 290a   requires_grad).
+00008510: 0a20 2020 2064 6566 2063 6f70 795f 6164  .    def copy_ad
+00008520: 6170 7465 7228 7365 6c66 2c20 7372 632c  apter(self, src,
+00008530: 206e 6f6e 5f62 6c6f 636b 696e 673d 4661   non_blocking=Fa
+00008540: 6c73 6529 3a0a 2020 2020 2020 2020 756e  lse):.        un
+00008550: 7375 7070 6f72 7465 645f 6174 7472 286e  supported_attr(n
+00008560: 6f6e 5f62 6c6f 636b 696e 6729 0a20 2020  on_blocking).   
+00008570: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00008580: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00008590: 7228 7372 6329 0a20 2020 2020 2020 2069  r(src).        i
+000085a0: 6620 6c65 6e28 7365 6c66 2e73 6861 7065  f len(self.shape
+000085b0: 2920 3e20 3020 616e 6420 696e 7075 745f  ) > 0 and input_
+000085c0: 6d73 2e73 6861 7065 2021 3d20 7365 6c66  ms.shape != self
+000085d0: 2e73 6861 7065 3a0a 2020 2020 2020 2020  .shape:.        
+000085e0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+000085f0: 6f70 732e 6272 6f61 6463 6173 745f 746f  ops.broadcast_to
+00008600: 2869 6e70 7574 5f6d 732c 2073 656c 662e  (input_ms, self.
+00008610: 7368 6170 6529 0a20 2020 2020 2020 2065  shape).        e
+00008620: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00008630: 206f 7574 7075 7420 3d20 696e 7075 745f   output = input_
+00008640: 6d73 0a20 2020 2020 2020 206f 7574 7075  ms.        outpu
+00008650: 7420 3d20 6f75 7470 7574 2e61 7374 7970  t = output.astyp
+00008660: 6528 7365 6c66 2e64 7479 7065 290a 2020  e(self.dtype).  
+00008670: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00008680: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00008690: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+000086a0: 2064 6566 2063 6f70 795f 2873 656c 662c   def copy_(self,
+000086b0: 2073 7263 2c20 6e6f 6e5f 626c 6f63 6b69   src, non_blocki
+000086c0: 6e67 3d46 616c 7365 293a 0a20 2020 2020  ng=False):.     
+000086d0: 2020 2075 6e73 7570 706f 7274 6564 5f61     unsupported_a
+000086e0: 7474 7228 6e6f 6e5f 626c 6f63 6b69 6e67  ttr(non_blocking
+000086f0: 290a 2020 2020 2020 2020 696e 7075 745f  ).        input_
+00008700: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00008710: 7465 6e73 6f72 2873 7263 290a 2020 2020  tensor(src).    
+00008720: 2020 2020 6966 206c 656e 2873 656c 662e      if len(self.
+00008730: 7368 6170 6529 203e 2030 2061 6e64 2069  shape) > 0 and i
+00008740: 6e70 7574 5f6d 732e 7368 6170 6520 213d  nput_ms.shape !=
+00008750: 2073 656c 662e 7368 6170 653a 0a20 2020   self.shape:.   
+00008760: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00008770: 3d20 6d73 2e6f 7073 2e62 726f 6164 6361  = ms.ops.broadca
+00008780: 7374 5f74 6f28 696e 7075 745f 6d73 2c20  st_to(input_ms, 
+00008790: 7365 6c66 2e73 6861 7065 290a 2020 2020  self.shape).    
+000087a0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000087b0: 2020 2020 2020 6f75 7470 7574 203d 2069        output = i
+000087c0: 6e70 7574 5f6d 730a 2020 2020 2020 2020  nput_ms.        
+000087d0: 6f75 7470 7574 203d 206f 7574 7075 742e  output = output.
+000087e0: 6173 7479 7065 2873 656c 662e 6474 7970  astype(self.dtyp
+000087f0: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
+00008800: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+00008810: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00008820: 7574 7075 742c 2022 636f 7079 5f22 2c20  utput, "copy_", 
+00008830: 2263 6f70 795f 6164 6170 7465 7222 290a  "copy_adapter").
+00008840: 0a20 2020 2064 6566 2065 7870 616e 6428  .    def expand(
+00008850: 7365 6c66 2c20 2a73 697a 6529 3a0a 2020  self, *size):.  
+00008860: 2020 2020 2020 2320 544f 444f 3a20 746f        # TODO: to
+00008870: 2075 7365 206d 732e 6f70 732e 6578 7061   use ms.ops.expa
+00008880: 6e64 2061 6674 6572 2069 7420 7375 7070  nd after it supp
+00008890: 6f72 7420 6f6e 2067 7075 2e20 416e 6420  ort on gpu. And 
+000088a0: 6d73 2e6f 7073 2e65 7870 616e 6420 7375  ms.ops.expand su
+000088b0: 7070 6f72 7420 746f 6f20 6665 7720 6461  pport too few da
+000088c0: 7461 2074 7970 6520 6e6f 770a 2020 2020  ta type now.    
+000088d0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+000088e0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+000088f0: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
+00008900: 6620 6973 696e 7374 616e 6365 2873 697a  f isinstance(siz
+00008910: 655b 305d 2c20 286c 6973 742c 2074 7570  e[0], (list, tup
+00008920: 6c65 2929 3a0a 2020 2020 2020 2020 2020  le)):.          
+00008930: 2020 7369 7a65 203d 2073 697a 655b 305d    size = size[0]
+00008940: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
+00008950: 7374 616e 6365 2873 697a 652c 206c 6973  stance(size, lis
+00008960: 7429 3a0a 2020 2020 2020 2020 2020 2020  t):.            
+00008970: 7369 7a65 203d 2074 7570 6c65 2873 697a  size = tuple(siz
+00008980: 6529 0a20 2020 2020 2020 206f 7574 203d  e).        out =
+00008990: 206d 732e 6f70 732e 6272 6f61 6463 6173   ms.ops.broadcas
+000089a0: 745f 746f 2869 6e70 7574 5f6d 732c 2073  t_to(input_ms, s
+000089b0: 697a 6529 0a20 2020 2020 2020 2072 6574  ize).        ret
+000089c0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+000089d0: 7465 725f 7465 6e73 6f72 286f 7574 290a  ter_tensor(out).
+000089e0: 0a20 2020 2064 6566 2073 6967 6d6f 6964  .    def sigmoid
+000089f0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00008a00: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+00008a10: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00008a20: 6629 0a20 2020 2020 2020 2023 2054 4f44  f).        # TOD
+00008a30: 4f3a 206d 732e 6f70 732e 7369 676d 6f69  O: ms.ops.sigmoi
+00008a40: 6420 6e6f 7420 7375 7070 6f72 7420 666c  d not support fl
+00008a50: 6f61 7436 3420 6f6e 2041 7363 656e 640a  oat64 on Ascend.
+00008a60: 2020 2020 2020 2020 6966 2069 735f 756e          if is_un
+00008a70: 6465 725f 6173 6365 6e64 5f63 6f6e 7465  der_ascend_conte
+00008a80: 7874 2829 2061 6e64 2069 6e70 7574 5f6d  xt() and input_m
+00008a90: 732e 6474 7970 6520 3d3d 206d 732e 666c  s.dtype == ms.fl
+00008aa0: 6f61 7436 343a 0a20 2020 2020 2020 2020  oat64:.         
+00008ab0: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
+00008ac0: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
+00008ad0: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
+00008ae0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00008af0: 732e 6f70 732e 7369 676d 6f69 6428 696e  s.ops.sigmoid(in
+00008b00: 7075 745f 6d73 290a 2020 2020 2020 2020  put_ms).        
+00008b10: 2020 2020 6f75 7470 7574 203d 206f 7574      output = out
+00008b20: 7075 742e 6173 7479 7065 286d 732e 666c  put.astype(ms.fl
+00008b30: 6f61 7436 3429 0a20 2020 2020 2020 2065  oat64).        e
+00008b40: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00008b50: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00008b60: 2e73 6967 6d6f 6964 2869 6e70 7574 5f6d  .sigmoid(input_m
+00008b70: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+00008b80: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00008b90: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00008ba0: 0a0a 2020 2020 6465 6620 7369 676d 6f69  ..    def sigmoi
+00008bb0: 645f 2873 656c 6629 3a0a 2020 2020 2020  d_(self):.      
+00008bc0: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
+00008bd0: 7369 676d 6f69 6428 290a 2020 2020 2020  sigmoid().      
+00008be0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+00008bf0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+00008c00: 7365 6c66 2c20 6f75 7470 7574 2c20 2273  self, output, "s
+00008c10: 6967 6d6f 6964 5f22 2c20 2273 6967 6d6f  igmoid_", "sigmo
+00008c20: 6964 2229 0a0a 2020 2020 6465 6620 666c  id")..    def fl
+00008c30: 6f61 7428 7365 6c66 2c20 6d65 6d6f 7279  oat(self, memory
+00008c40: 5f66 6f72 6d61 743d 4e6f 6e65 293a 0a20  _format=None):. 
+00008c50: 2020 2020 2020 2069 6620 6d65 6d6f 7279         if memory
+00008c60: 5f66 6f72 6d61 743a 0a20 2020 2020 2020  _format:.       
+00008c70: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
+00008c80: 706c 656d 656e 7465 6445 7272 6f72 2822  plementedError("
+00008c90: 6d65 6d6f 7279 5f66 6f72 6d61 7420 6973  memory_format is
+00008ca0: 206e 6f74 2073 7570 706f 7274 6564 2e22   not supported."
+00008cb0: 290a 2020 2020 2020 2020 696e 7075 745f  ).        input_
+00008cc0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00008cd0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+00008ce0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00008cf0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00008d00: 6f72 2869 6e70 7574 5f6d 732e 666c 6f61  or(input_ms.floa
+00008d10: 7428 2929 0a0a 2020 2020 6465 6620 666c  t())..    def fl
+00008d20: 6970 2873 656c 662c 2064 696d 7329 3a0a  ip(self, dims):.
+00008d30: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00008d40: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00008d50: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00008d60: 2020 2069 6620 6e6f 7420 6973 696e 7374     if not isinst
+00008d70: 616e 6365 2864 696d 732c 2028 6c69 7374  ance(dims, (list
+00008d80: 2c20 7475 706c 6529 293a 0a20 2020 2020  , tuple)):.     
+00008d90: 2020 2020 2020 2064 696d 7320 3d20 2864         dims = (d
+00008da0: 696d 732c 290a 2020 2020 2020 2020 6f75  ims,).        ou
+00008db0: 7470 7574 203d 2069 6e70 7574 5f6d 732e  tput = input_ms.
+00008dc0: 666c 6970 2864 696d 7329 0a20 2020 2020  flip(dims).     
+00008dd0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00008de0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00008df0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00008e00: 6620 7369 676e 2873 656c 6629 3a0a 2020  f sign(self):.  
+00008e10: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00008e20: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00008e30: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00008e40: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00008e50: 2e73 6967 6e28 696e 7075 745f 6d73 290a  .sign(input_ms).
+00008e60: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00008e70: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+00008e80: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+00008e90: 2020 2064 6566 2073 6967 6e5f 2873 656c     def sign_(sel
+00008ea0: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
+00008eb0: 7574 203d 2073 656c 662e 7369 676e 2829  ut = self.sign()
+00008ec0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00008ed0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+00008ee0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+00008ef0: 7075 742c 2022 7369 676e 5f22 2c20 2273  put, "sign_", "s
+00008f00: 6967 6e22 290a 0a20 2020 2064 6566 2073  ign")..    def s
+00008f10: 6967 6e62 6974 2873 656c 6629 3a0a 2020  ignbit(self):.  
+00008f20: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00008f30: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00008f40: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00008f50: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00008f60: 2e73 6967 6e62 6974 2869 6e70 7574 5f6d  .signbit(input_m
+00008f70: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+00008f80: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00008f90: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00008fa0: 0a0a 2020 2020 6465 6620 7376 6428 7365  ..    def svd(se
+00008fb0: 6c66 2c20 736f 6d65 3d54 7275 652c 2063  lf, some=True, c
+00008fc0: 6f6d 7075 7465 5f75 763d 5472 7565 293a  ompute_uv=True):
+00008fd0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+00008fe0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00008ff0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+00009000: 2020 2020 6966 2069 735f 756e 6465 725f      if is_under_
+00009010: 6173 6365 6e64 5f63 6f6e 7465 7874 2829  ascend_context()
+00009020: 3a0a 2020 2020 2020 2020 2020 2020 6675  :.            fu
+00009030: 6c6c 5f6d 6174 7269 6365 7320 3d20 6e6f  ll_matrices = no
+00009040: 7420 736f 6d65 0a20 2020 2020 2020 2020  t some.         
+00009050: 2020 2073 7664 5f6f 7020 3d20 6e75 6d70     svd_op = nump
+00009060: 795f 6365 6c6c 2e4e 756d 7079 5376 6428  y_cell.NumpySvd(
+00009070: 2773 7664 2729 0a20 2020 2020 2020 2020  'svd').         
+00009080: 2020 206f 7574 7075 7420 3d20 7376 645f     output = svd_
+00009090: 6f70 2869 6e70 7574 5f6d 732c 2066 756c  op(input_ms, ful
+000090a0: 6c5f 6d61 7472 6963 6573 2c20 636f 6d70  l_matrices, comp
+000090b0: 7574 655f 7576 290a 2020 2020 2020 2020  ute_uv).        
+000090c0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+000090d0: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+000090e0: 732e 7376 6428 696e 7075 745f 6d73 2c20  s.svd(input_ms, 
+000090f0: 6e6f 7420 736f 6d65 2c20 636f 6d70 7574  not some, comput
+00009100: 655f 7576 290a 2020 2020 2020 2020 6966  e_uv).        if
+00009110: 2063 6f6d 7075 7465 5f75 763a 0a20 2020   compute_uv:.   
+00009120: 2020 2020 2020 2020 2073 2c20 752c 2076           s, u, v
+00009130: 203d 206f 7574 7075 740a 2020 2020 2020   = output.      
+00009140: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00009150: 2020 2020 6966 2073 6f6d 653a 0a20 2020      if some:.   
+00009160: 2020 2020 2020 2020 2020 2020 2073 203d               s =
+00009170: 206f 7574 7075 740a 2020 2020 2020 2020   output.        
+00009180: 2020 2020 2020 2020 726f 7720 3d20 696e          row = in
+00009190: 7075 745f 6d73 2e73 6861 7065 5b30 5d0a  put_ms.shape[0].
+000091a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000091b0: 636f 6c20 3d20 696e 7075 745f 6d73 2e73  col = input_ms.s
+000091c0: 6861 7065 5b31 5d0a 2020 2020 2020 2020  hape[1].        
+000091d0: 2020 2020 2020 2020 7520 3d20 6d73 2e6f          u = ms.o
+000091e0: 7073 2e7a 6572 6f73 2828 726f 772c 2072  ps.zeros((row, r
+000091f0: 6f77 292c 2069 6e70 7574 5f6d 732e 6474  ow), input_ms.dt
+00009200: 7970 6529 0a20 2020 2020 2020 2020 2020  ype).           
+00009210: 2020 2020 2076 203d 206d 732e 6f70 732e       v = ms.ops.
+00009220: 7a65 726f 7328 2863 6f6c 2c20 636f 6c29  zeros((col, col)
+00009230: 2c20 696e 7075 745f 6d73 2e64 7479 7065  , input_ms.dtype
+00009240: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+00009250: 203d 2028 752c 2073 2c20 7629 0a20 2020   = (u, s, v).   
+00009260: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00009270: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00009280: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00009290: 6465 6620 7377 6170 6178 6573 2873 656c  def swapaxes(sel
+000092a0: 662c 2061 7869 7330 2c20 6178 6973 3129  f, axis0, axis1)
+000092b0: 3a0a 2020 2020 2020 2020 6966 2073 656c  :.        if sel
+000092c0: 662e 6e65 6c65 6d65 6e74 2829 203d 3d20  f.nelement() == 
+000092d0: 303a 0a20 2020 2020 2020 2020 2020 206f  0:.            o
+000092e0: 7574 5f73 6861 7065 203d 206c 6973 7428  ut_shape = list(
+000092f0: 7365 6c66 2e73 6861 7065 290a 2020 2020  self.shape).    
+00009300: 2020 2020 2020 2020 6f75 745f 7368 6170          out_shap
+00009310: 655b 6178 6973 305d 2c20 6f75 745f 7368  e[axis0], out_sh
+00009320: 6170 655b 6178 6973 315d 203d 206f 7574  ape[axis1] = out
+00009330: 5f73 6861 7065 5b61 7869 7331 5d2c 206f  _shape[axis1], o
+00009340: 7574 5f73 6861 7065 5b61 7869 7330 5d0a  ut_shape[axis0].
+00009350: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00009360: 726e 2073 656c 662e 7265 7368 6170 6528  rn self.reshape(
+00009370: 7475 706c 6528 6f75 745f 7368 6170 6529  tuple(out_shape)
+00009380: 290a 2020 2020 2020 2020 696e 7075 745f  ).        input_
+00009390: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+000093a0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+000093b0: 2020 2020 206f 7574 7075 7420 3d20 696e       output = in
+000093c0: 7075 745f 6d73 2e73 7761 7061 7865 7328  put_ms.swapaxes(
+000093d0: 6178 6973 302c 2061 7869 7331 290a 2020  axis0, axis1).  
+000093e0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+000093f0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00009400: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00009410: 2064 6566 2073 7761 7064 696d 7328 7365   def swapdims(se
+00009420: 6c66 2c20 6469 6d30 2c20 6469 6d31 293a  lf, dim0, dim1):
+00009430: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+00009440: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00009450: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+00009460: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00009470: 6f70 732e 7377 6170 6469 6d73 2869 6e70  ops.swapdims(inp
+00009480: 7574 5f6d 732c 2064 696d 302c 2064 696d  ut_ms, dim0, dim
+00009490: 3129 0a20 2020 2020 2020 2072 6574 7572  1).        retur
+000094a0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+000094b0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+000094c0: 0a0a 2020 2020 6465 6620 7375 6274 7261  ..    def subtra
+000094d0: 6374 2873 656c 662c 206f 7468 6572 2c20  ct(self, other, 
+000094e0: 2a2c 2061 6c70 6861 3d31 293a 0a20 2020  *, alpha=1):.   
+000094f0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00009500: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00009510: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00009520: 6f74 6865 7220 3d20 6361 7374 5f74 6f5f  other = cast_to_
+00009530: 6d73 5f74 656e 736f 7228 6f74 6865 7229  ms_tensor(other)
+00009540: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+00009550: 3d20 6d73 2e6f 7073 2e73 7562 7472 6163  = ms.ops.subtrac
+00009560: 7428 696e 7075 745f 6d73 2c20 6f74 6865  t(input_ms, othe
+00009570: 722c 2061 6c70 6861 3d61 6c70 6861 290a  r, alpha=alpha).
+00009580: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00009590: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+000095a0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+000095b0: 2020 2064 6566 2073 7562 7472 6163 745f     def subtract_
+000095c0: 2873 656c 662c 206f 7468 6572 2c20 2a2c  (self, other, *,
+000095d0: 2061 6c70 6861 3d31 293a 0a20 2020 2020   alpha=1):.     
+000095e0: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
+000095f0: 2e73 7562 7472 6163 7428 6f74 6865 722c  .subtract(other,
+00009600: 2061 6c70 6861 3d61 6c70 6861 290a 2020   alpha=alpha).  
+00009610: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+00009620: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+00009630: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+00009640: 2c20 2273 7562 7472 6163 745f 222c 2022  , "subtract_", "
+00009650: 7375 6274 7261 6374 2229 0a0a 2020 2020  subtract")..    
+00009660: 6465 6620 7472 6163 6528 7365 6c66 293a  def trace(self):
+00009670: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+00009680: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00009690: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+000096a0: 2020 2020 6f75 7470 7574 203d 2069 6e70      output = inp
+000096b0: 7574 5f6d 732e 7472 6163 6528 290a 2020  ut_ms.trace().  
+000096c0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+000096d0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+000096e0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+000096f0: 2064 6566 2063 6569 6c28 7365 6c66 293a   def ceil(self):
+00009700: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+00009710: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00009720: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+00009730: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00009740: 6f70 732e 6365 696c 2869 6e70 7574 5f6d  ops.ceil(input_m
+00009750: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+00009760: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00009770: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00009780: 0a0a 2020 2020 6465 6620 6365 696c 5f28  ..    def ceil_(
+00009790: 7365 6c66 293a 0a20 2020 2020 2020 206f  self):.        o
+000097a0: 7574 7075 7420 3d20 7365 6c66 2e63 6569  utput = self.cei
+000097b0: 6c28 290a 2020 2020 2020 2020 7265 7475  l().        retu
+000097c0: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+000097d0: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+000097e0: 6f75 7470 7574 2c20 2263 6569 6c5f 222c  output, "ceil_",
+000097f0: 2022 6365 696c 2229 0a0a 2020 2020 6465   "ceil")..    de
+00009800: 6620 636f 6e6a 2873 656c 6629 3a0a 2020  f conj(self):.  
+00009810: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00009820: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00009830: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00009840: 206f 7574 7075 7420 3d20 696e 7075 745f   output = input_
+00009850: 6d73 2e63 6f6e 6a28 290a 2020 2020 2020  ms.conj().      
+00009860: 2020 6f75 7470 7574 203d 2063 6173 745f    output = cast_
+00009870: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00009880: 7228 6f75 7470 7574 290a 2020 2020 2020  r(output).      
+00009890: 2020 6f75 7470 7574 2e63 6f6e 6a5f 6269    output.conj_bi
+000098a0: 7420 3d20 5472 7565 0a20 2020 2020 2020  t = True.       
+000098b0: 2072 6574 7572 6e20 6f75 7470 7574 0a0a   return output..
+000098c0: 2020 2020 6465 6620 6973 5f63 6f6e 6a28      def is_conj(
+000098d0: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
+000098e0: 6620 6e6f 7420 6861 7361 7474 7228 7365  f not hasattr(se
+000098f0: 6c66 2c20 2263 6f6e 6a5f 6269 7422 293a  lf, "conj_bit"):
+00009900: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00009910: 7572 6e20 4661 6c73 650a 2020 2020 2020  urn False.      
+00009920: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00009930: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+00009940: 636f 6e6a 5f62 6974 0a0a 2020 2020 6465  conj_bit..    de
+00009950: 6620 7265 736f 6c76 655f 636f 6e6a 2873  f resolve_conj(s
+00009960: 656c 6629 3a0a 2020 2020 2020 2020 6f75  elf):.        ou
+00009970: 7470 7574 203d 2064 6565 7063 6f70 7928  tput = deepcopy(
+00009980: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
+00009990: 7470 7574 2e63 6f6e 6a5f 6269 7420 3d20  tput.conj_bit = 
+000099a0: 4661 6c73 650a 2020 2020 2020 2020 7265  False.        re
+000099b0: 7475 726e 206f 7574 7075 740a 0a20 2020  turn output..   
+000099c0: 2064 6566 2067 6572 2873 656c 662c 2076   def ger(self, v
+000099d0: 6563 3229 3a0a 2020 2020 2020 2020 696e  ec2):.        in
+000099e0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+000099f0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+00009a00: 0a20 2020 2020 2020 2076 6563 3220 3d20  .        vec2 = 
+00009a10: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00009a20: 7228 7665 6332 290a 2020 2020 2020 2020  r(vec2).        
+00009a30: 6966 2069 6e70 7574 5f6d 732e 6474 7970  if input_ms.dtyp
+00009a40: 6520 213d 2076 6563 322e 6474 7970 653a  e != vec2.dtype:
+00009a50: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+00009a60: 7365 2054 7970 6545 7272 6f72 2822 466f  se TypeError("Fo
+00009a70: 7220 746f 7263 682e 6765 7228 292c 2069  r torch.ger(), i
+00009a80: 6e70 7574 5f6d 7320 616e 6420 7665 6332  nput_ms and vec2
+00009a90: 2064 7479 7065 206d 7573 7420 6265 2074   dtype must be t
+00009aa0: 6865 2073 616d 6522 290a 2020 2020 2020  he same").      
+00009ab0: 2020 6966 206e 6f74 2069 6e70 7574 5f6d    if not input_m
+00009ac0: 732e 6973 5f66 6c6f 6174 696e 675f 706f  s.is_floating_po
+00009ad0: 696e 7428 293a 0a20 2020 2020 2020 2020  int():.         
+00009ae0: 2020 205f 6f75 745f 6474 7970 6520 3d20     _out_dtype = 
+00009af0: 696e 7075 745f 6d73 2e64 7479 7065 0a20  input_ms.dtype. 
+00009b00: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00009b10: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
+00009b20: 7374 7970 6528 6d73 2e66 6c6f 6174 3332  stype(ms.float32
+00009b30: 290a 2020 2020 2020 2020 2020 2020 7665  ).            ve
+00009b40: 6332 203d 2076 6563 322e 6173 7479 7065  c2 = vec2.astype
+00009b50: 286d 732e 666c 6f61 7433 3229 0a20 2020  (ms.float32).   
+00009b60: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00009b70: 3d20 6d73 2e6f 7073 2e67 6572 2869 6e70  = ms.ops.ger(inp
+00009b80: 7574 5f6d 732c 2076 6563 3229 0a20 2020  ut_ms, vec2).   
+00009b90: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00009ba0: 3d20 6f75 7470 7574 2e61 7374 7970 6528  = output.astype(
+00009bb0: 5f6f 7574 5f64 7479 7065 290a 2020 2020  _out_dtype).    
+00009bc0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00009bd0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00009be0: 732e 6f70 732e 6765 7228 696e 7075 745f  s.ops.ger(input_
+00009bf0: 6d73 2c20 7665 6332 290a 2020 2020 2020  ms, vec2).      
+00009c00: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+00009c10: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+00009c20: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+00009c30: 206d 6f76 6564 696d 2873 656c 662c 2073   movedim(self, s
+00009c40: 6f75 7263 652c 2064 6573 7469 6e61 7469  ource, destinati
+00009c50: 6f6e 293a 0a20 2020 2020 2020 2069 6e70  on):.        inp
+00009c60: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+00009c70: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00009c80: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00009c90: 206d 732e 6f70 732e 6d6f 7665 6469 6d28   ms.ops.movedim(
+00009ca0: 696e 7075 745f 6d73 2c20 736f 7572 6365  input_ms, source
+00009cb0: 2c20 6465 7374 696e 6174 696f 6e29 0a20  , destination). 
+00009cc0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00009cd0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00009ce0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+00009cf0: 2020 6465 6620 6d6f 7665 6178 6973 2873    def moveaxis(s
+00009d00: 656c 662c 2073 6f75 7263 652c 2064 6573  elf, source, des
+00009d10: 7469 6e61 7469 6f6e 293a 0a20 2020 2020  tination):.     
+00009d20: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+00009d30: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00009d40: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
+00009d50: 7470 7574 203d 206d 732e 6f70 732e 6d6f  tput = ms.ops.mo
+00009d60: 7665 6178 6973 2869 6e70 7574 5f6d 732c  veaxis(input_ms,
+00009d70: 2073 6f75 7263 652c 2064 6573 7469 6e61   source, destina
+00009d80: 7469 6f6e 290a 2020 2020 2020 2020 7265  tion).        re
+00009d90: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00009da0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00009db0: 7574 290a 0a20 2020 2064 6566 206d 756c  ut)..    def mul
+00009dc0: 2873 656c 662c 2076 616c 7565 293a 0a20  (self, value):. 
+00009dd0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+00009de0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00009df0: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+00009e00: 2020 6d73 5f76 616c 7565 203d 2063 6173    ms_value = cas
+00009e10: 745f 746f 5f6d 735f 7465 6e73 6f72 2876  t_to_ms_tensor(v
+00009e20: 616c 7565 290a 2020 2020 2020 2020 6f75  alue).        ou
+00009e30: 7470 7574 203d 206d 732e 6f70 732e 6d75  tput = ms.ops.mu
+00009e40: 6c28 696e 7075 745f 6d73 2c20 6d73 5f76  l(input_ms, ms_v
+00009e50: 616c 7565 290a 2020 2020 2020 2020 7265  alue).        re
+00009e60: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00009e70: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00009e80: 7574 290a 0a20 2020 2064 6566 206d 756c  ut)..    def mul
+00009e90: 5f28 7365 6c66 2c20 7661 6c75 6529 3a0a  _(self, value):.
+00009ea0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00009eb0: 2073 656c 662e 6d75 6c28 7661 6c75 6529   self.mul(value)
+00009ec0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00009ed0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+00009ee0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+00009ef0: 7075 742c 2022 6d75 6c5f 222c 2022 6d75  put, "mul_", "mu
+00009f00: 6c22 290a 0a20 2020 2040 7072 6f70 6572  l")..    @proper
+00009f10: 7479 0a20 2020 2064 6566 2064 6576 6963  ty.    def devic
+00009f20: 6528 7365 6c66 293a 0a20 2020 2020 2020  e(self):.       
+00009f30: 2023 2054 656e 736f 722e 6465 7669 6365   # Tensor.device
+00009f40: 2061 6e64 2074 656e 736f 722e 746f 2864   and tensor.to(d
+00009f50: 6576 6963 6529 2064 6f20 6e6f 7420 6163  evice) do not ac
+00009f60: 7475 616c 6c79 2068 6176 6520 6566 6665  tually have effe
+00009f70: 6374 2069 6e20 6164 6170 7465 720a 2020  ct in adapter.  
+00009f80: 2020 2020 2020 2320 6265 6361 7573 6520        # because 
+00009f90: 6d69 6e64 7370 6f72 6520 646f 206e 6f74  mindspore do not
+00009fa0: 2063 6f6e 7472 6f6c 2061 2073 696e 676c   control a singl
+00009fb0: 6520 7465 6e73 6f72 2074 6f20 6120 6365  e tensor to a ce
+00009fc0: 7274 6169 6e20 6465 6976 6365 0a20 2020  rtain deivce.   
+00009fd0: 2020 2020 2023 2053 6f20 6865 7265 2066       # So here f
+00009fe0: 6f72 2070 6572 666f 726d 616e 6365 2c20  or performance, 
+00009ff0: 7265 7475 726e 2063 6c61 7373 2064 6576  return class dev
+0000a000: 6963 6520 7769 7468 2074 6172 6765 7420  ice with target 
+0000a010: 616e 6420 6964 2e0a 0a20 2020 2020 2020  and id...       
+0000a020: 2023 2054 6865 7265 2069 7320 6120 6275   # There is a bu
+0000a030: 6720 7768 656e 2066 616c 6c62 6163 6b2d  g when fallback-
+0000a040: 6f62 6a65 6374 2063 616c 6c20 7365 7461  object call seta
+0000a050: 7474 7220 616e 6420 6765 7461 7474 7220  ttr and getattr 
+0000a060: 6174 2074 6865 2073 616d 6520 7469 6d65  at the same time
+0000a070: 2069 6e20 6772 6170 6820 6d6f 6465 2c0a   in graph mode,.
+0000a080: 2020 2020 2020 2020 2320 7468 7573 2074          # thus t
+0000a090: 6865 2064 6576 6963 6520 6f62 6a65 6374  he device object
+0000a0a0: 2077 6173 2072 6567 656e 6572 6174 6564   was regenerated
+0000a0b0: 2c20 2061 6e64 2069 7420 7769 6c6c 206e  ,  and it will n
+0000a0c0: 6f74 2074 616b 6520 6566 6665 6374 2069  ot take effect i
+0000a0d0: 6e20 7468 6520 406a 6974 2073 6365 6e65  n the @jit scene
+0000a0e0: 2074 656d 706f 7261 7269 6c79 2e0a 2020   temporarily..  
+0000a0f0: 2020 2020 2020 6966 2067 7261 7068 5f6d        if graph_m
+0000a100: 6f64 655f 636f 6e64 6974 696f 6e28 293a  ode_condition():
+0000a110: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+0000a120: 7572 6e20 6465 7669 6365 5f63 6c61 7373  urn device_class
+0000a130: 2867 6574 5f62 6163 6b65 6e64 2829 2c20  (get_backend(), 
+0000a140: 7365 6c66 2e67 6574 5f64 6576 6963 6528  self.get_device(
+0000a150: 2929 0a20 2020 2020 2020 2069 6620 6e6f  )).        if no
+0000a160: 7420 6765 7461 7474 7228 7365 6c66 2c20  t getattr(self, 
+0000a170: 225f 6465 7669 6365 222c 204e 6f6e 6529  "_device", None)
+0000a180: 3a0a 2020 2020 2020 2020 2020 2020 7365  :.            se
+0000a190: 6c66 2e5f 6465 7669 6365 203d 2064 6576  lf._device = dev
+0000a1a0: 6963 655f 636c 6173 7328 6765 745f 6261  ice_class(get_ba
+0000a1b0: 636b 656e 6428 292c 2073 656c 662e 6765  ckend(), self.ge
+0000a1c0: 745f 6465 7669 6365 2829 290a 2020 2020  t_device()).    
+0000a1d0: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+0000a1e0: 5f64 6576 6963 650a 0a20 2020 2064 6566  _device..    def
+0000a1f0: 2064 6976 2873 656c 662c 2076 616c 7565   div(self, value
+0000a200: 2c20 2a2c 2072 6f75 6e64 696e 675f 6d6f  , *, rounding_mo
+0000a210: 6465 3d4e 6f6e 6529 203a 0a20 2020 2020  de=None) :.     
+0000a220: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+0000a230: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+0000a240: 7365 6c66 290a 2020 2020 2020 2020 7661  self).        va
+0000a250: 6c75 6520 3d20 6361 7374 5f74 6f5f 6d73  lue = cast_to_ms
+0000a260: 5f74 656e 736f 7228 7661 6c75 6529 0a20  _tensor(value). 
+0000a270: 2020 2020 2020 2023 2054 4f44 4f3a 206d         # TODO: m
+0000a280: 732e 6f70 732e 6469 7620 746f 2073 7570  s.ops.div to sup
+0000a290: 706f 7274 2072 6561 6c20 6469 7620 7768  port real div wh
+0000a2a0: 656e 2072 6f75 6e64 696e 675f 6d6f 6465  en rounding_mode
+0000a2b0: 2069 7320 4e6f 6e65 2061 6e64 2069 6e70   is None and inp
+0000a2c0: 7574 2061 7265 2061 6c6c 2069 6e74 2074  ut are all int t
+0000a2d0: 7970 650a 2020 2020 2020 2020 6966 2072  ype.        if r
+0000a2e0: 6f75 6e64 696e 675f 6d6f 6465 2069 7320  ounding_mode is 
+0000a2f0: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+0000a300: 2020 6966 2069 6e70 7574 5f6d 732e 6474    if input_ms.dt
+0000a310: 7970 6520 696e 2061 6c6c 5f69 6e74 5f74  ype in all_int_t
+0000a320: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
+0000a330: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0000a340: 6d73 2e6f 7073 2e63 6173 7428 696e 7075  ms.ops.cast(inpu
+0000a350: 745f 6d73 2c20 6d73 7479 7065 2e66 6c6f  t_ms, mstype.flo
+0000a360: 6174 3332 290a 2020 2020 2020 2020 6f75  at32).        ou
+0000a370: 7470 7574 203d 206d 732e 6f70 732e 6469  tput = ms.ops.di
+0000a380: 7628 696e 7075 745f 6d73 2c20 7661 6c75  v(input_ms, valu
+0000a390: 652c 2072 6f75 6e64 696e 675f 6d6f 6465  e, rounding_mode
+0000a3a0: 3d72 6f75 6e64 696e 675f 6d6f 6465 290a  =rounding_mode).
+0000a3b0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+0000a3c0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+0000a3d0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+0000a3e0: 2020 2064 6566 2064 6976 5f28 7365 6c66     def div_(self
+0000a3f0: 2c20 7661 6c75 652c 202a 2c20 726f 756e  , value, *, roun
+0000a400: 6469 6e67 5f6d 6f64 653d 4e6f 6e65 293a  ding_mode=None):
+0000a410: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0000a420: 3d20 7365 6c66 2e64 6976 2876 616c 7565  = self.div(value
+0000a430: 2c20 726f 756e 6469 6e67 5f6d 6f64 653d  , rounding_mode=
+0000a440: 726f 756e 6469 6e67 5f6d 6f64 6529 0a20  rounding_mode). 
+0000a450: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
+0000a460: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
+0000a470: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
+0000a480: 742c 2022 6469 765f 222c 2022 6469 7622  t, "div_", "div"
+0000a490: 290a 0a20 2020 2064 6566 2063 7075 2873  )..    def cpu(s
+0000a4a0: 656c 6629 3a0a 2020 2020 2020 2020 2354  elf):.        #T
+0000a4b0: 4f44 4f0a 2020 2020 2020 2020 7265 7475  ODO.        retu
+0000a4c0: 726e 2073 656c 660a 0a20 2020 2023 2054  rn self..    # T
+0000a4d0: 6f20 6163 6869 6576 6520 7468 6520 706f  o achieve the po
+0000a4e0: 6c79 6d6f 7270 6869 736d 2054 656e 736f  lymorphism Tenso
+0000a4f0: 722e 6d69 6e28 5465 6e73 6f72 2069 6e70  r.min(Tensor inp
+0000a500: 7574 2c20 5465 6e73 6f72 206f 7468 6572  ut, Tensor other
+0000a510: 2c20 2a2c 2054 656e 736f 7220 6f75 7429  , *, Tensor out)
+0000a520: 0a20 2020 2023 206f 7468 6572 3d4e 6f6e  .    # other=Non
+0000a530: 6520 6973 2075 7365 6420 746f 2072 6570  e is used to rep
+0000a540: 7265 7365 6e74 2074 6865 206b 6579 776f  resent the keywo
+0000a550: 7264 7320 7061 7261 6d20 696e 7075 740a  rds param input.
+0000a560: 2020 2020 6465 6620 6d69 6e28 7365 6c66      def min(self
+0000a570: 2c20 6469 6d3d 4e6f 6e65 2c20 6b65 6570  , dim=None, keep
+0000a580: 6469 6d3d 4661 6c73 652c 206f 7468 6572  dim=False, other
+0000a590: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
+0000a5a0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+0000a5b0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+0000a5c0: 6629 0a20 2020 2020 2020 2074 7970 6520  f).        type 
+0000a5d0: 3d20 696e 7075 745f 6d73 2e64 7479 7065  = input_ms.dtype
+0000a5e0: 0a20 2020 2020 2020 2069 6620 6f74 6865  .        if othe
+0000a5f0: 7220 6973 206e 6f74 204e 6f6e 653a 0a20  r is not None:. 
+0000a600: 2020 2020 2020 2020 2020 206f 7468 6572             other
+0000a610: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0000a620: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
+0000a630: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0000a640: 206d 732e 6f70 732e 6d69 6e69 6d75 6d28   ms.ops.minimum(
+0000a650: 696e 7075 745f 6d73 2c20 6f74 6865 7229  input_ms, other)
+0000a660: 2e61 7374 7970 6528 7479 7065 290a 2020  .astype(type).  
+0000a670: 2020 2020 2020 2020 2020 7265 7475 726e            return
+0000a680: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0000a690: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+0000a6a0: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
+0000a6b0: 7461 6e63 6528 6469 6d2c 2054 656e 736f  tance(dim, Tenso
+0000a6c0: 7229 3a0a 2020 2020 2020 2020 2020 2020  r):.            
+0000a6d0: 6f74 6865 7220 3d20 6361 7374 5f74 6f5f  other = cast_to_
+0000a6e0: 6d73 5f74 656e 736f 7228 6469 6d29 0a20  ms_tensor(dim). 
+0000a6f0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+0000a700: 7420 3d20 6d73 2e6f 7073 2e6d 696e 696d  t = ms.ops.minim
+0000a710: 756d 2869 6e70 7574 5f6d 732c 206f 7468  um(input_ms, oth
+0000a720: 6572 292e 6173 7479 7065 2874 7970 6529  er).astype(type)
+0000a730: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+0000a740: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+0000a750: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+0000a760: 7429 0a20 2020 2020 2020 2069 6620 6469  t).        if di
+0000a770: 6d20 6973 204e 6f6e 653a 0a20 2020 2020  m is None:.     
+0000a780: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0000a790: 696e 7075 745f 6d73 2e6d 696e 2861 7869  input_ms.min(axi
+0000a7a0: 733d 6469 6d2c 206b 6565 7064 696d 733d  s=dim, keepdims=
+0000a7b0: 6b65 6570 6469 6d29 2e61 7374 7970 6528  keepdim).astype(
+0000a7c0: 7479 7065 290a 2020 2020 2020 2020 2020  type).          
+0000a7d0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+0000a7e0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+0000a7f0: 6f75 7470 7574 290a 2020 2020 2020 2020  output).        
+0000a800: 7661 6c75 652c 2069 6e64 6963 6520 3d20  value, indice = 
+0000a810: 6d73 2e6f 7073 2e6d 696e 2869 6e70 7574  ms.ops.min(input
+0000a820: 5f6d 732c 2064 696d 2c20 6b65 6570 6469  _ms, dim, keepdi
+0000a830: 6d29 0a20 2020 2020 2020 2076 616c 7565  m).        value
+0000a840: 203d 2076 616c 7565 2e61 7374 7970 6528   = value.astype(
+0000a850: 7479 7065 290a 2020 2020 2020 2020 696e  type).        in
+0000a860: 6469 6365 203d 2069 6e64 6963 652e 6173  dice = indice.as
+0000a870: 7479 7065 286d 732e 696e 7436 3429 0a20  type(ms.int64). 
+0000a880: 2020 2020 2020 2069 6620 7079 6e61 7469         if pynati
+0000a890: 7665 5f6d 6f64 655f 636f 6e64 6974 696f  ve_mode_conditio
+0000a8a0: 6e28 293a 0a20 2020 2020 2020 2020 2020  n():.           
+0000a8b0: 2070 6f69 6e74 203d 2073 6574 5f6e 616d   point = set_nam
+0000a8c0: 655f 7475 706c 6528 276d 696e 2729 0a20  e_tuple('min'). 
+0000a8d0: 2020 2020 2020 2020 2020 2072 6c74 203d             rlt =
+0000a8e0: 2070 6f69 6e74 2863 6173 745f 746f 5f61   point(cast_to_a
+0000a8f0: 6461 7074 6572 5f74 656e 736f 7228 7661  dapter_tensor(va
+0000a900: 6c75 6529 2c20 6361 7374 5f74 6f5f 6164  lue), cast_to_ad
+0000a910: 6170 7465 725f 7465 6e73 6f72 2869 6e64  apter_tensor(ind
+0000a920: 6963 6529 290a 2020 2020 2020 2020 2020  ice)).          
+0000a930: 2020 7265 7475 726e 2072 6c74 0a20 2020    return rlt.   
+0000a940: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+0000a950: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+0000a960: 6f72 2876 616c 7565 292c 2063 6173 745f  or(value), cast_
+0000a970: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+0000a980: 7228 696e 6469 6365 290a 0a20 2020 2023  r(indice)..    #
+0000a990: 2054 6f20 6163 6869 6576 6520 7468 6520   To achieve the 
+0000a9a0: 706f 6c79 6d6f 7270 6869 736d 2054 656e  polymorphism Ten
+0000a9b0: 736f 722e 6d61 7828 5465 6e73 6f72 2069  sor.max(Tensor i
+0000a9c0: 6e70 7574 2c20 5465 6e73 6f72 206f 7468  nput, Tensor oth
+0000a9d0: 6572 2c20 2a2c 2054 656e 736f 7220 6f75  er, *, Tensor ou
+0000a9e0: 7429 0a20 2020 2023 206f 7468 6572 3d4e  t).    # other=N
+0000a9f0: 6f6e 6520 6973 2075 7365 6420 746f 2072  one is used to r
+0000aa00: 6570 7265 7365 6e74 2074 6865 206b 6579  epresent the key
+0000aa10: 776f 7264 7320 7061 7261 6d20 696e 7075  words param inpu
+0000aa20: 740a 2020 2020 6465 6620 6d61 7828 7365  t.    def max(se
+0000aa30: 6c66 2c20 6469 6d3d 4e6f 6e65 2c20 6b65  lf, dim=None, ke
+0000aa40: 6570 6469 6d3d 4661 6c73 652c 206f 7468  epdim=False, oth
+0000aa50: 6572 3d4e 6f6e 6529 3a0a 2020 2020 2020  er=None):.      
+0000aa60: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+0000aa70: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+0000aa80: 656c 6629 0a20 2020 2020 2020 2074 7970  elf).        typ
+0000aa90: 6520 3d20 696e 7075 745f 6d73 2e64 7479  e = input_ms.dty
+0000aaa0: 7065 0a20 2020 2020 2020 2069 6620 6f74  pe.        if ot
+0000aab0: 6865 7220 6973 206e 6f74 204e 6f6e 653a  her is not None:
+0000aac0: 0a20 2020 2020 2020 2020 2020 206f 7468  .            oth
+0000aad0: 6572 203d 2063 6173 745f 746f 5f6d 735f  er = cast_to_ms_
+0000aae0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+0000aaf0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+0000ab00: 203d 206d 732e 6f70 732e 6d61 7869 6d75   = ms.ops.maximu
+0000ab10: 6d28 696e 7075 745f 6d73 2c20 6f74 6865  m(input_ms, othe
+0000ab20: 7229 2e61 7374 7970 6528 7479 7065 290a  r).astype(type).
+0000ab30: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0000ab40: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0000ab50: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0000ab60: 290a 2020 2020 2020 2020 6966 2069 7369  ).        if isi
+0000ab70: 6e73 7461 6e63 6528 6469 6d2c 2054 656e  nstance(dim, Ten
+0000ab80: 736f 7229 3a0a 2020 2020 2020 2020 2020  sor):.          
+0000ab90: 2020 6f74 6865 7220 3d20 6361 7374 5f74    other = cast_t
+0000aba0: 6f5f 6d73 5f74 656e 736f 7228 6469 6d29  o_ms_tensor(dim)
+0000abb0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0000abc0: 7075 7420 3d20 6d73 2e6f 7073 2e6d 6178  put = ms.ops.max
+0000abd0: 696d 756d 2869 6e70 7574 5f6d 732c 206f  imum(input_ms, o
+0000abe0: 7468 6572 292e 6173 7479 7065 2874 7970  ther).astype(typ
+0000abf0: 6529 0a20 2020 2020 2020 2020 2020 2072  e).            r
+0000ac00: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+0000ac10: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+0000ac20: 7075 7429 0a20 2020 2020 2020 2069 6620  put).        if 
+0000ac30: 6469 6d20 6973 204e 6f6e 653a 0a20 2020  dim is None:.   
+0000ac40: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+0000ac50: 3d20 696e 7075 745f 6d73 2e6d 6178 2861  = input_ms.max(a
+0000ac60: 7869 733d 6469 6d2c 206b 6565 7064 696d  xis=dim, keepdim
+0000ac70: 733d 6b65 6570 6469 6d29 2e61 7374 7970  s=keepdim).astyp
+0000ac80: 6528 7479 7065 290a 2020 2020 2020 2020  e(type).        
+0000ac90: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+0000aca0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+0000acb0: 7228 6f75 7470 7574 290a 2020 2020 2020  r(output).      
+0000acc0: 2020 7661 6c75 652c 2069 6e64 6963 6520    value, indice 
+0000acd0: 3d20 6d73 2e6f 7073 2e6d 6178 2869 6e70  = ms.ops.max(inp
+0000ace0: 7574 5f6d 732c 2064 696d 2c20 6b65 6570  ut_ms, dim, keep
+0000acf0: 6469 6d29 0a20 2020 2020 2020 2076 616c  dim).        val
+0000ad00: 7565 203d 2076 616c 7565 2e61 7374 7970  ue = value.astyp
+0000ad10: 6528 7479 7065 290a 2020 2020 2020 2020  e(type).        
+0000ad20: 696e 6469 6365 203d 2069 6e64 6963 652e  indice = indice.
+0000ad30: 6173 7479 7065 286d 732e 696e 7436 3429  astype(ms.int64)
+0000ad40: 0a20 2020 2020 2020 2069 6620 7079 6e61  .        if pyna
+0000ad50: 7469 7665 5f6d 6f64 655f 636f 6e64 6974  tive_mode_condit
+0000ad60: 696f 6e28 293a 0a20 2020 2020 2020 2020  ion():.         
+0000ad70: 2020 2070 6f69 6e74 203d 2073 6574 5f6e     point = set_n
+0000ad80: 616d 655f 7475 706c 6528 276d 6178 2729  ame_tuple('max')
+0000ad90: 0a20 2020 2020 2020 2020 2020 2072 6c74  .            rlt
+0000ada0: 203d 2070 6f69 6e74 2863 6173 745f 746f   = point(cast_to
+0000adb0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+0000adc0: 7661 6c75 6529 2c20 6361 7374 5f74 6f5f  value), cast_to_
+0000add0: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
+0000ade0: 6e64 6963 6529 290a 2020 2020 2020 2020  ndice)).        
+0000adf0: 2020 2020 7265 7475 726e 2072 6c74 0a20      return rlt. 
+0000ae00: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+0000ae10: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+0000ae20: 6e73 6f72 2876 616c 7565 292c 2063 6173  nsor(value), cas
+0000ae30: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0000ae40: 736f 7228 696e 6469 6365 290a 0a0a 2020  sor(indice)...  
+0000ae50: 2020 6465 6620 6e75 6d65 6c28 7365 6c66    def numel(self
+0000ae60: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0000ae70: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0000ae80: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0000ae90: 2020 2020 2020 7265 7475 726e 2050 2e73        return P.s
+0000aea0: 697a 6528 696e 7075 745f 6d73 290a 0a0a  ize(input_ms)...
+0000aeb0: 2020 2020 6465 6620 7375 6d28 7365 6c66      def sum(self
+0000aec0: 2c20 6469 6d3d 4e6f 6e65 2c20 6b65 6570  , dim=None, keep
+0000aed0: 6469 6d3d 4661 6c73 652c 2064 7479 7065  dim=False, dtype
+0000aee0: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
+0000aef0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+0000af00: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+0000af10: 6629 0a20 2020 2020 2020 2023 2054 4f44  f).        # TOD
+0000af20: 4f3a 206d 696e 6473 706f 7265 2074 656e  O: mindspore ten
+0000af30: 736f 722e 7375 6d20 6361 6e20 6e6f 7420  sor.sum can not 
+0000af40: 6175 746f 6d61 7469 6361 6c6c 7920 7072  automatically pr
+0000af50: 6f6d 6f74 6520 6474 7970 6520 7965 742c  omote dtype yet,
+0000af60: 2077 696c 6c20 6361 7573 6520 6f76 6572   will cause over
+0000af70: 666c 6f77 2e0a 2020 2020 2020 2020 6966  flow..        if
+0000af80: 2064 7479 7065 2069 7320 6e6f 7420 4e6f   dtype is not No
+0000af90: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+0000afa0: 696e 7075 745f 6d73 203d 2069 6e70 7574  input_ms = input
+0000afb0: 5f6d 732e 6173 7479 7065 2864 7479 7065  _ms.astype(dtype
+0000afc0: 2920 6966 2064 7479 7065 2021 3d20 6d73  ) if dtype != ms
+0000afd0: 7479 7065 2e62 6f6f 6c5f 2065 6c73 6520  type.bool_ else 
+0000afe0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+0000aff0: 2020 696e 7075 745f 6d73 2e61 7374 7970    input_ms.astyp
+0000b000: 6528 6d73 7479 7065 2e62 6f6f 6c5f 292e  e(mstype.bool_).
+0000b010: 6173 7479 7065 286d 7374 7970 652e 696e  astype(mstype.in
+0000b020: 7436 3429 0a20 2020 2020 2020 2065 6c69  t64).        eli
+0000b030: 6620 696e 7075 745f 6d73 2e64 7479 7065  f input_ms.dtype
+0000b040: 2069 6e20 6d69 6e64 746f 7263 685f 6474   in mindtorch_dt
+0000b050: 7970 652e 616c 6c5f 696e 745f 7479 7065  ype.all_int_type
+0000b060: 5f77 6974 685f 626f 6f6c 3a0a 2020 2020  _with_bool:.    
+0000b070: 2020 2020 2020 2020 6474 7970 6520 3d20          dtype = 
+0000b080: 6d73 7479 7065 2e69 6e74 3634 0a20 2020  mstype.int64.   
+0000b090: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
+0000b0a0: 7320 3d20 696e 7075 745f 6d73 2e61 7374  s = input_ms.ast
+0000b0b0: 7970 6528 6474 7970 6529 0a0a 2020 2020  ype(dtype)..    
+0000b0c0: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+0000b0d0: 6528 6469 6d2c 206c 6973 7429 3a0a 2020  e(dim, list):.  
+0000b0e0: 2020 2020 2020 2020 2020 6469 6d20 3d20            dim = 
+0000b0f0: 7475 706c 6528 6469 6d29 0a20 2020 2020  tuple(dim).     
+0000b100: 2020 2072 6573 203d 2069 6e70 7574 5f6d     res = input_m
+0000b110: 732e 7375 6d28 6469 6d2c 2064 7479 7065  s.sum(dim, dtype
+0000b120: 2c20 6b65 6570 6469 6d29 0a20 2020 2020  , keepdim).     
+0000b130: 2020 2069 6620 6474 7970 6520 6973 206e     if dtype is n
+0000b140: 6f74 204e 6f6e 6520 616e 6420 6474 7970  ot None and dtyp
+0000b150: 6520 3d3d 206d 7374 7970 652e 626f 6f6c  e == mstype.bool
+0000b160: 5f3a 0a20 2020 2020 2020 2020 2020 2072  _:.            r
+0000b170: 6573 203d 2072 6573 2e61 7374 7970 6528  es = res.astype(
+0000b180: 6d73 7479 7065 2e62 6f6f 6c5f 290a 2020  mstype.bool_).  
+0000b190: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+0000b1a0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0000b1b0: 736f 7228 7265 7329 0a0a 2020 2020 6465  sor(res)..    de
+0000b1c0: 6620 7375 6d5f 746f 5f73 697a 6528 7365  f sum_to_size(se
+0000b1d0: 6c66 2c20 2a73 697a 6529 3a0a 2020 2020  lf, *size):.    
+0000b1e0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+0000b1f0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0000b200: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+0000b210: 7574 7075 7420 3d20 696e 7075 745f 6d73  utput = input_ms
+0000b220: 2e73 756d 5f74 6f5f 7369 7a65 282a 7369  .sum_to_size(*si
+0000b230: 7a65 290a 2020 2020 2020 2020 7265 7475  ze).        retu
+0000b240: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0000b250: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0000b260: 290a 0a20 2020 2064 6566 206d 6561 6e28  )..    def mean(
+0000b270: 7365 6c66 2c20 6469 6d3d 4e6f 6e65 2c20  self, dim=None, 
+0000b280: 6b65 6570 6469 6d3d 4661 6c73 652c 2064  keepdim=False, d
+0000b290: 7479 7065 3d4e 6f6e 652c 2061 7869 733d  type=None, axis=
+0000b2a0: 4e6f 6e65 293a 0a20 2020 2020 2020 2069  None):.        i
+0000b2b0: 6620 6469 6d20 6973 204e 6f6e 653a 0a20  f dim is None:. 
+0000b2c0: 2020 2020 2020 2020 2020 2064 696d 203d             dim =
+0000b2d0: 2061 7869 730a 0a20 2020 2020 2020 2069   axis..        i
+0000b2e0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0000b2f0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0000b300: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
+0000b310: 6620 6474 7970 653a 0a20 2020 2020 2020  f dtype:.       
+0000b320: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0000b330: 7365 6c66 2e61 7374 7970 6528 6474 7970  self.astype(dtyp
+0000b340: 6529 0a0a 2020 2020 2020 2020 6f75 7470  e)..        outp
+0000b350: 7574 203d 206d 732e 6f70 732e 6d65 616e  ut = ms.ops.mean
+0000b360: 2869 6e70 7574 5f6d 732c 2064 696d 2c20  (input_ms, dim, 
+0000b370: 6b65 6570 6469 6d29 0a20 2020 2020 2020  keepdim).       
+0000b380: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0000b390: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0000b3a0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0000b3b0: 7072 6f64 2873 656c 662c 2064 696d 3d4e  prod(self, dim=N
+0000b3c0: 6f6e 652c 206b 6565 7064 696d 3d46 616c  one, keepdim=Fal
+0000b3d0: 7365 2c20 6474 7970 653d 4e6f 6e65 293a  se, dtype=None):
+0000b3e0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+0000b3f0: 7320 3d20 6361 7374 5f74 6f5f 6164 6170  s = cast_to_adap
+0000b400: 7465 725f 7465 6e73 6f72 2873 656c 6629  ter_tensor(self)
+0000b410: 0a20 2020 2020 2020 2069 6620 6474 7970  .        if dtyp
+0000b420: 653a 0a20 2020 2020 2020 2020 2020 2069  e:.            i
+0000b430: 6e70 7574 5f6d 7320 3d20 7365 6c66 2e61  nput_ms = self.a
+0000b440: 7374 7970 6528 6474 7970 6529 0a0a 2020  stype(dtype)..  
+0000b450: 2020 2020 2020 2354 4f44 4f3a 206d 732e        #TODO: ms.
+0000b460: 6f70 732e 7072 6f64 206e 6f74 2073 7570  ops.prod not sup
+0000b470: 706f 7274 2062 6f6f 6c20 7479 7065 206f  port bool type o
+0000b480: 6e20 4173 6365 6e64 2c20 4350 5526 4750  n Ascend, CPU&GP
+0000b490: 5520 7265 7475 726e 2074 7970 6520 6973  U return type is
+0000b4a0: 2062 6f6f 6c0a 2020 2020 2020 2020 6966   bool.        if
+0000b4b0: 2069 6e70 7574 5f6d 732e 6474 7970 6520   input_ms.dtype 
+0000b4c0: 3d3d 206d 732e 626f 6f6c 5f3a 0a20 2020  == ms.bool_:.   
+0000b4d0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+0000b4e0: 3d20 6d73 2e6f 7073 2e70 726f 6428 696e  = ms.ops.prod(in
+0000b4f0: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
+0000b500: 2e69 6e74 3829 2c20 6469 6d2c 206b 6565  .int8), dim, kee
+0000b510: 7064 696d 290a 2020 2020 2020 2020 2020  pdim).          
+0000b520: 2020 6f75 7470 7574 203d 206f 7574 7075    output = outpu
+0000b530: 742e 6173 7479 7065 286d 732e 696e 7436  t.astype(ms.int6
+0000b540: 3429 0a20 2020 2020 2020 2065 6c73 653a  4).        else:
+0000b550: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0000b560: 7075 7420 3d20 6d73 2e6f 7073 2e70 726f  put = ms.ops.pro
+0000b570: 6428 696e 7075 745f 6d73 2c20 6469 6d2c  d(input_ms, dim,
+0000b580: 206b 6565 7064 696d 290a 2020 2020 2020   keepdim).      
+0000b590: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+0000b5a0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+0000b5b0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+0000b5c0: 2073 706c 6974 2873 656c 662c 2073 706c   split(self, spl
+0000b5d0: 6974 5f73 697a 652c 2064 696d 3d30 293a  it_size, dim=0):
+0000b5e0: 0a20 2020 2020 2020 2074 656e 736f 7220  .        tensor 
+0000b5f0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0000b600: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+0000b610: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+0000b620: 732e 7370 6c69 7428 7465 6e73 6f72 2c20  s.split(tensor, 
+0000b630: 7370 6c69 745f 7369 7a65 2c20 6469 6d29  split_size, dim)
+0000b640: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000b650: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+0000b660: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+0000b670: 2020 2020 6465 6620 6e75 6d70 7928 7365      def numpy(se
+0000b680: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
+0000b690: 7572 6e20 7365 6c66 2e61 736e 756d 7079  urn self.asnumpy
+0000b6a0: 2829 0a0a 2020 2020 6465 6620 7669 6577  ()..    def view
+0000b6b0: 2873 656c 662c 202a 7368 6170 652c 2064  (self, *shape, d
+0000b6c0: 7479 7065 3d4e 6f6e 6529 3a0a 2020 2020  type=None):.    
+0000b6d0: 2020 2020 6966 2064 7479 7065 3a0a 2020      if dtype:.  
+0000b6e0: 2020 2020 2020 2020 2020 6f72 695f 7368            ori_sh
+0000b6f0: 6170 6520 3d20 7365 6c66 2e73 6861 7065  ape = self.shape
+0000b700: 0a20 2020 2020 2020 2020 2020 2074 6172  .            tar
+0000b710: 6765 745f 7368 6170 6520 3d20 282d 312c  get_shape = (-1,
+0000b720: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
+0000b730: 206c 656e 286f 7269 5f73 6861 7065 2920   len(ori_shape) 
+0000b740: 3e20 313a 0a20 2020 2020 2020 2020 2020  > 1:.           
+0000b750: 2020 2020 2074 6172 6765 745f 7368 6170       target_shap
+0000b760: 6520 3d20 6f72 695f 7368 6170 655b 3a2d  e = ori_shape[:-
+0000b770: 315d 202b 2074 6172 6765 745f 7368 6170  1] + target_shap
+0000b780: 650a 2020 2020 2020 2020 2020 2020 6f75  e.            ou
+0000b790: 7420 3d20 6e70 2e66 726f 6d62 7566 6665  t = np.frombuffe
+0000b7a0: 7228 7365 6c66 2e6e 756d 7079 2829 2c20  r(self.numpy(), 
+0000b7b0: 5f54 7970 6544 6963 742e 6765 7428 6474  _TypeDict.get(dt
+0000b7c0: 7970 652c 206e 702e 666c 6f61 7433 3229  ype, np.float32)
+0000b7d0: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
+0000b7e0: 2064 7479 7065 203d 3d20 6d69 6e64 746f   dtype == mindto
+0000b7f0: 7263 685f 6474 7970 652e 6266 6c6f 6174  rch_dtype.bfloat
+0000b800: 3136 3a0a 2020 2020 2020 2020 2020 2020  16:.            
+0000b810: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
+0000b820: 7228 6f75 742e 6173 7479 7065 286e 702e  r(out.astype(np.
+0000b830: 666c 6f61 7433 3229 2c20 6474 7970 653d  float32), dtype=
+0000b840: 6474 7970 6529 2e72 6573 6861 7065 2874  dtype).reshape(t
+0000b850: 6172 6765 745f 7368 6170 6529 0a20 2020  arget_shape).   
+0000b860: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0000b870: 7465 6e73 6f72 286f 7574 292e 7265 7368  tensor(out).resh
+0000b880: 6170 6528 7461 7267 6574 5f73 6861 7065  ape(target_shape
+0000b890: 290a 2020 2020 2020 2020 6966 2069 7369  ).        if isi
+0000b8a0: 6e73 7461 6e63 6528 7368 6170 655b 305d  nstance(shape[0]
+0000b8b0: 2c20 2874 7570 6c65 2c20 6c69 7374 2929  , (tuple, list))
+0000b8c0: 3a0a 2020 2020 2020 2020 2020 2020 7368  :.            sh
+0000b8d0: 6170 6520 3d20 7368 6170 655b 305d 0a20  ape = shape[0]. 
+0000b8e0: 2020 2020 2020 2073 6861 7065 203d 205f         shape = _
+0000b8f0: 636f 6e76 6572 745f 7368 6170 655f 746f  convert_shape_to
+0000b900: 5f69 6e74 2873 6861 7065 290a 2020 2020  _int(shape).    
+0000b910: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
+0000b920: 7265 7368 6170 6528 2a73 6861 7065 290a  reshape(*shape).
+0000b930: 0a20 2020 2064 6566 2076 6965 775f 6173  .    def view_as
+0000b940: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
+0000b950: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+0000b960: 6c66 2e76 6965 7728 6f74 6865 722e 7368  lf.view(other.sh
+0000b970: 6170 6529 0a0a 2020 2020 6465 6620 6e64  ape)..    def nd
+0000b980: 696d 656e 7369 6f6e 2873 656c 6629 3a0a  imension(self):.
+0000b990: 2020 2020 2020 2020 7265 7475 726e 206c          return l
+0000b9a0: 656e 2873 656c 662e 7368 6170 6529 0a0a  en(self.shape)..
+0000b9b0: 2020 2020 6465 6620 706f 7728 7365 6c66      def pow(self
+0000b9c0: 2c20 6578 706f 6e65 6e74 293a 0a20 2020  , exponent):.   
+0000b9d0: 2020 2020 2070 6f77 6572 203d 2063 6173       power = cas
+0000b9e0: 745f 746f 5f6d 735f 7465 6e73 6f72 2865  t_to_ms_tensor(e
+0000b9f0: 7870 6f6e 656e 7429 0a20 2020 2020 2020  xponent).       
+0000ba00: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0000ba10: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0000ba20: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
+0000ba30: 7574 203d 2069 6e70 7574 5f6d 732e 706f  ut = input_ms.po
+0000ba40: 7728 706f 7765 7229 0a20 2020 2020 2020  w(power).       
+0000ba50: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0000ba60: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0000ba70: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0000ba80: 706f 775f 2873 656c 662c 2065 7870 6f6e  pow_(self, expon
+0000ba90: 656e 7429 3a0a 2020 2020 2020 2020 6f75  ent):.        ou
+0000baa0: 7470 7574 203d 2073 656c 662e 706f 7728  tput = self.pow(
+0000bab0: 6578 706f 6e65 6e74 290a 2020 2020 2020  exponent).      
+0000bac0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+0000bad0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+0000bae0: 7365 6c66 2c20 6f75 7470 7574 2c20 2270  self, output, "p
+0000baf0: 6f77 5f22 2c20 2270 6f77 2229 0a0a 2020  ow_", "pow")..  
+0000bb00: 2020 6465 6620 7261 6432 6465 6728 7365    def rad2deg(se
+0000bb10: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
+0000bb20: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+0000bb30: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+0000bb40: 2020 2020 2020 2020 6966 206e 6f74 2069          if not i
+0000bb50: 6e70 7574 5f6d 732e 6973 5f66 6c6f 6174  nput_ms.is_float
+0000bb60: 696e 675f 706f 696e 7428 293a 0a20 2020  ing_point():.   
+0000bb70: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
+0000bb80: 7320 3d20 696e 7075 745f 6d73 2e61 7374  s = input_ms.ast
+0000bb90: 7970 6528 6d73 2e66 6c6f 6174 3332 290a  ype(ms.float32).
+0000bba0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0000bbb0: 206d 732e 6f70 732e 7261 6432 6465 6728   ms.ops.rad2deg(
+0000bbc0: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
+0000bbd0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+0000bbe0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+0000bbf0: 6f75 7470 7574 290a 0a20 2020 2040 7072  output)..    @pr
+0000bc00: 6f70 6572 7479 0a20 2020 2064 6566 2072  operty.    def r
+0000bc10: 6561 6c28 7365 6c66 293a 0a20 2020 2020  eal(self):.     
+0000bc20: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+0000bc30: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+0000bc40: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
+0000bc50: 7470 7574 203d 206d 732e 6f70 732e 7265  tput = ms.ops.re
+0000bc60: 616c 2869 6e70 7574 5f6d 7329 0a20 2020  al(input_ms).   
+0000bc70: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+0000bc80: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+0000bc90: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+0000bca0: 4070 726f 7065 7274 790a 2020 2020 6465  @property.    de
+0000bcb0: 6620 6d48 2873 656c 6629 3a0a 2020 2020  f mH(self):.    
+0000bcc0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+0000bcd0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0000bce0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+0000bcf0: 7574 7075 7420 3d20 696e 7075 745f 6d73  utput = input_ms
+0000bd00: 2e6d 480a 2020 2020 2020 2020 7265 7475  .mH.        retu
+0000bd10: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0000bd20: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0000bd30: 290a 0a20 2020 2040 7072 6f70 6572 7479  )..    @property
+0000bd40: 0a20 2020 2064 6566 206d 5428 7365 6c66  .    def mT(self
+0000bd50: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0000bd60: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0000bd70: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0000bd80: 2020 2020 2020 6f75 7470 7574 203d 2069        output = i
+0000bd90: 6e70 7574 5f6d 732e 6d54 0a20 2020 2020  nput_ms.mT.     
+0000bda0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0000bdb0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0000bdc0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0000bdd0: 6620 7265 6369 7072 6f63 616c 2873 656c  f reciprocal(sel
+0000bde0: 6629 3a0a 2020 2020 2020 2020 696e 7075  f):.        inpu
+0000bdf0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+0000be00: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+0000be10: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0000be20: 6d73 2e6f 7073 2e72 6563 6970 726f 6361  ms.ops.reciproca
+0000be30: 6c28 696e 7075 745f 6d73 290a 2020 2020  l(input_ms).    
+0000be40: 2020 2020 2354 4f44 4f3a 2047 5055 2068      #TODO: GPU h
+0000be50: 6173 2070 726f 626c 656d 2068 616e 646c  as problem handl
+0000be60: 696e 6720 626f 756e 6461 7279 2076 616c  ing boundary val
+0000be70: 7565 0a20 2020 2020 2020 2069 6620 6973  ue.        if is
+0000be80: 5f75 6e64 6572 5f67 7075 5f63 6f6e 7465  _under_gpu_conte
+0000be90: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
+0000bea0: 2020 6f75 7470 7574 5f64 7479 7065 203d    output_dtype =
+0000beb0: 206f 7574 7075 742e 6474 7970 650a 2020   output.dtype.  
+0000bec0: 2020 2020 2020 2020 2020 6966 206f 7574            if out
+0000bed0: 7075 745f 6474 7970 6520 3d3d 206d 732e  put_dtype == ms.
+0000bee0: 666c 6f61 7433 323a 0a20 2020 2020 2020  float32:.       
+0000bef0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+0000bf00: 3d20 6d73 2e6f 7073 2e77 6865 7265 2828  = ms.ops.where((
+0000bf10: 6f75 7470 7574 203c 3d20 4650 3332 5f4d  output <= FP32_M
+0000bf20: 494e 2920 7c20 286f 7574 7075 7420 3e3d  IN) | (output >=
+0000bf30: 2046 5033 325f 4d41 5829 2c20 666c 6f61   FP32_MAX), floa
+0000bf40: 7428 2769 6e66 2729 2c20 6f75 7470 7574  t('inf'), output
+0000bf50: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
+0000bf60: 206f 7574 7075 745f 6474 7970 6520 3d3d   output_dtype ==
+0000bf70: 206d 732e 666c 6f61 7436 343a 0a20 2020   ms.float64:.   
+0000bf80: 2020 2020 2020 2020 2020 2020 206f 7574               out
+0000bf90: 7075 7420 3d20 6d73 2e6f 7073 2e77 6865  put = ms.ops.whe
+0000bfa0: 7265 2828 6f75 7470 7574 203c 3d20 4650  re((output <= FP
+0000bfb0: 3634 5f4d 494e 2920 7c20 286f 7574 7075  64_MIN) | (outpu
+0000bfc0: 7420 3e3d 2046 5036 345f 4d41 5829 2c20  t >= FP64_MAX), 
+0000bfd0: 666c 6f61 7428 2769 6e66 2729 2c20 6f75  float('inf'), ou
+0000bfe0: 7470 7574 290a 2020 2020 2020 2020 7265  tput).        re
+0000bff0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0000c000: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+0000c010: 7574 290a 0a20 2020 2064 6566 2072 6563  ut)..    def rec
+0000c020: 6970 726f 6361 6c5f 2873 656c 6629 3a0a  iprocal_(self):.
+0000c030: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0000c040: 2073 656c 662e 7265 6369 7072 6f63 616c   self.reciprocal
+0000c050: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
+0000c060: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+0000c070: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+0000c080: 7574 7075 742c 2022 7265 6369 7072 6f63  utput, "reciproc
+0000c090: 616c 5f22 2c20 2272 6563 6970 726f 6361  al_", "reciproca
+0000c0a0: 6c22 290a 0a20 2020 2064 6566 2072 656d  l")..    def rem
+0000c0b0: 6169 6e64 6572 2873 656c 662c 206f 7468  ainder(self, oth
+0000c0c0: 6572 293a 0a20 2020 2020 2020 2069 6e70  er):.        inp
+0000c0d0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+0000c0e0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+0000c0f0: 2020 2020 2020 2020 6f74 6865 7220 3d20          other = 
+0000c100: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0000c110: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
+0000c120: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+0000c130: 2e72 656d 6169 6e64 6572 2869 6e70 7574  .remainder(input
+0000c140: 5f6d 732c 206f 7468 6572 290a 2020 2020  _ms, other).    
+0000c150: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+0000c160: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+0000c170: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+0000c180: 6566 2072 656d 6169 6e64 6572 5f28 7365  ef remainder_(se
+0000c190: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
+0000c1a0: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+0000c1b0: 662e 7265 6d61 696e 6465 7228 6f74 6865  f.remainder(othe
+0000c1c0: 7229 0a20 2020 2020 2020 2072 6574 7572  r).        retur
+0000c1d0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+0000c1e0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+0000c1f0: 7574 7075 742c 2022 7265 6d61 696e 6465  utput, "remainde
+0000c200: 725f 222c 2022 7265 6d61 696e 6465 7222  r_", "remainder"
+0000c210: 290a 0a20 2020 2064 6566 2072 6570 6561  )..    def repea
+0000c220: 7428 7365 6c66 2c20 2a73 697a 6573 293a  t(self, *sizes):
+0000c230: 0a20 2020 2020 2020 2069 6e70 7574 5f78  .        input_x
+0000c240: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0000c250: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+0000c260: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+0000c270: 2873 697a 6573 5b30 5d2c 206c 6973 7429  (sizes[0], list)
+0000c280: 3a0a 2020 2020 2020 2020 2020 2020 7369  :.            si
+0000c290: 7a65 7320 3d20 7475 706c 6528 2a73 697a  zes = tuple(*siz
+0000c2a0: 6573 290a 2020 2020 2020 2020 656c 6966  es).        elif
+0000c2b0: 2069 7369 6e73 7461 6e63 6528 7369 7a65   isinstance(size
+0000c2c0: 735b 305d 2c20 7475 706c 6529 3a0a 2020  s[0], tuple):.  
+0000c2d0: 2020 2020 2020 2020 2020 7369 7a65 7320            sizes 
+0000c2e0: 3d20 7369 7a65 735b 305d 0a20 2020 2020  = sizes[0].     
+0000c2f0: 2020 2069 6620 696e 7075 745f 782e 6e75     if input_x.nu
+0000c300: 6d65 6c28 2920 3d3d 2030 3a0a 2020 2020  mel() == 0:.    
+0000c310: 2020 2020 2020 2020 696e 7075 745f 7368          input_sh
+0000c320: 6170 6520 3d20 696e 7075 745f 782e 7368  ape = input_x.sh
+0000c330: 6170 650a 2020 2020 2020 2020 2020 2020  ape.            
+0000c340: 6e65 775f 7368 6170 6520 3d20 7369 7a65  new_shape = size
+0000c350: 735b 3a2d 6c65 6e28 696e 7075 745f 7368  s[:-len(input_sh
+0000c360: 6170 6529 5d20 2b20 7475 706c 6528 6e70  ape)] + tuple(np
+0000c370: 2e61 7272 6179 2873 697a 6573 5b2d 6c65  .array(sizes[-le
+0000c380: 6e28 696e 7075 745f 7368 6170 6529 3a5d  n(input_shape):]
+0000c390: 2920 2a20 6e70 2e61 7272 6179 2869 6e70  ) * np.array(inp
+0000c3a0: 7574 5f73 6861 7065 2929 0a20 2020 2020  ut_shape)).     
+0000c3b0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0000c3c0: 5465 6e73 6f72 282a 6e65 775f 7368 6170  Tensor(*new_shap
+0000c3d0: 6529 0a20 2020 2020 2020 2065 6c73 653a  e).        else:
+0000c3e0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0000c3f0: 7075 7420 3d20 6d73 2e6f 7073 2e74 696c  put = ms.ops.til
+0000c400: 6528 696e 7075 745f 782c 2073 697a 6573  e(input_x, sizes
+0000c410: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0000c420: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0000c430: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+0000c440: 0a20 2020 2064 6566 2072 6570 6561 745f  .    def repeat_
+0000c450: 696e 7465 726c 6561 7665 2873 656c 662c  interleave(self,
+0000c460: 2072 6570 6561 7473 2c20 6469 6d3d 4e6f   repeats, dim=No
+0000c470: 6e65 2c20 2a2c 206f 7574 7075 745f 7369  ne, *, output_si
+0000c480: 7a65 3d4e 6f6e 6529 3a0a 2020 2020 2020  ze=None):.      
+0000c490: 2020 756e 7375 7070 6f72 7465 645f 6174    unsupported_at
+0000c4a0: 7472 286f 7574 7075 745f 7369 7a65 290a  tr(output_size).
+0000c4b0: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
+0000c4c0: 7374 616e 6365 2872 6570 6561 7473 2c20  stance(repeats, 
+0000c4d0: 5465 6e73 6f72 293a 0a20 2020 2020 2020  Tensor):.       
+0000c4e0: 2020 2020 206e 6577 5f72 6570 6561 7473       new_repeats
+0000c4f0: 203d 205b 5d0a 2020 2020 2020 2020 2020   = [].          
+0000c500: 2020 666f 7220 696e 6465 7820 696e 2072    for index in r
+0000c510: 6570 6561 7473 3a0a 2020 2020 2020 2020  epeats:.        
+0000c520: 2020 2020 2020 2020 6e65 775f 7265 7065          new_repe
+0000c530: 6174 732e 6170 7065 6e64 2869 6e74 2869  ats.append(int(i
+0000c540: 6e64 6578 2929 0a20 2020 2020 2020 2020  ndex)).         
+0000c550: 2020 2072 6570 6561 7473 203d 206e 6577     repeats = new
+0000c560: 5f72 6570 6561 7473 0a20 2020 2020 2020  _repeats.       
+0000c570: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0000c580: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0000c590: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
+0000c5a0: 7574 203d 2069 6e70 7574 5f6d 732e 7265  ut = input_ms.re
+0000c5b0: 7065 6174 2872 6570 6561 7473 2c20 6469  peat(repeats, di
+0000c5c0: 6d29 0a20 2020 2020 2020 2072 6574 7572  m).        retur
+0000c5d0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0000c5e0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0000c5f0: 0a0a 2020 2020 6465 6620 7265 7368 6170  ..    def reshap
+0000c600: 6528 7365 6c66 2c20 2a5f 7368 6170 652c  e(self, *_shape,
+0000c610: 2073 6861 7065 3d4e 6f6e 6529 3a0a 2020   shape=None):.  
+0000c620: 2020 2020 2020 6966 205f 7368 6170 6520        if _shape 
+0000c630: 616e 6420 7368 6170 653a 0a20 2020 2020  and shape:.     
+0000c640: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+0000c650: 7565 4572 726f 7228 2272 6573 6861 7065  ueError("reshape
+0000c660: 2829 2067 6f74 206d 756c 7469 706c 6520  () got multiple 
+0000c670: 7661 6c75 6573 2066 6f72 2061 7267 756d  values for argum
+0000c680: 656e 7420 2773 6861 7065 2722 290a 2020  ent 'shape'").  
+0000c690: 2020 2020 2020 7368 6170 6520 3d20 5f73        shape = _s
+0000c6a0: 6861 7065 2069 6620 5f73 6861 7065 2065  hape if _shape e
+0000c6b0: 6c73 6520 7368 6170 650a 2020 2020 2020  lse shape.      
+0000c6c0: 2020 6966 206e 6f74 2073 6861 7065 3a0a    if not shape:.
+0000c6d0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0000c6e0: 6520 5661 6c75 6545 7272 6f72 2822 5468  e ValueError("Th
+0000c6f0: 6520 7368 6170 6520 7661 7269 6162 6c65  e shape variable
+0000c700: 2073 686f 756c 6420 6e6f 7420 6265 2065   should not be e
+0000c710: 6d70 7479 2229 0a20 2020 2020 2020 2069  mpty").        i
+0000c720: 6620 6973 696e 7374 616e 6365 2873 6861  f isinstance(sha
+0000c730: 7065 5b30 5d2c 2028 7475 706c 652c 206c  pe[0], (tuple, l
+0000c740: 6973 7429 293a 0a20 2020 2020 2020 2020  ist)):.         
+0000c750: 2020 2073 6861 7065 203d 2073 6861 7065     shape = shape
+0000c760: 5b30 5d0a 2020 2020 2020 2020 6966 2069  [0].        if i
+0000c770: 7369 6e73 7461 6e63 6528 7368 6170 652c  sinstance(shape,
+0000c780: 206c 6973 7429 3a0a 2020 2020 2020 2020   list):.        
+0000c790: 2020 2020 7368 6170 6520 3d20 7475 706c      shape = tupl
+0000c7a0: 6528 7368 6170 6529 0a0a 2020 2020 2020  e(shape)..      
+0000c7b0: 2020 696e 7075 745f 7369 7a65 203d 2073    input_size = s
+0000c7c0: 656c 662e 7368 6170 650a 2020 2020 2020  elf.shape.      
+0000c7d0: 2020 6966 206e 6f74 206d 732e 6f70 732e    if not ms.ops.
+0000c7e0: 6973 5f73 6571 7565 6e63 655f 7661 6c75  is_sequence_valu
+0000c7f0: 655f 756e 6b6e 6f77 6e28 696e 7075 745f  e_unknown(input_
+0000c800: 7369 7a65 2920 616e 6420 6c65 6e28 696e  size) and len(in
+0000c810: 7075 745f 7369 7a65 2920 3e20 3020 616e  put_size) > 0 an
+0000c820: 6420 696e 7075 745f 7369 7a65 5b30 5d20  d input_size[0] 
+0000c830: 3d3d 2030 3a0a 2020 2020 2020 2020 2020  == 0:.          
+0000c840: 2020 2320 6f6e 6c79 2073 7570 706f 7274    # only support
+0000c850: 2066 6972 7374 2065 6c65 6d65 6e74 2069   first element i
+0000c860: 7320 300a 2020 2020 2020 2020 2020 2020  s 0.            
+0000c870: 6e75 6d65 6c20 3d20 6d73 2e6f 7073 2e73  numel = ms.ops.s
+0000c880: 697a 6528 7365 6c66 290a 2020 2020 2020  ize(self).      
+0000c890: 2020 2020 2020 7368 6170 6520 3d20 5f69        shape = _i
+0000c8a0: 6e66 6572 5f73 697a 6528 7368 6170 652c  nfer_size(shape,
+0000c8b0: 206e 756d 656c 290a 2020 2020 2020 2020   numel).        
+0000c8c0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+0000c8d0: 6f70 732e 7a65 726f 7328 7368 6170 652c  ops.zeros(shape,
+0000c8e0: 2073 656c 662e 6474 7970 6529 0a20 2020   self.dtype).   
+0000c8f0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+0000c900: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+0000c910: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0000c920: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+0000c930: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+0000c940: 732e 6f70 732e 7265 7368 6170 6528 696e  s.ops.reshape(in
+0000c950: 7075 745f 6d73 2c20 7368 6170 6529 0a20  put_ms, shape). 
+0000c960: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+0000c970: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+0000c980: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+0000c990: 2020 6465 6620 7265 7368 6170 655f 6173    def reshape_as
+0000c9a0: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
+0000c9b0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+0000c9c0: 6c66 2e72 6573 6861 7065 286f 7468 6572  lf.reshape(other
+0000c9d0: 2e73 6861 7065 290a 0a20 2020 2064 6566  .shape)..    def
+0000c9e0: 2061 7263 7369 6e68 2873 656c 6629 3a0a   arcsinh(self):.
+0000c9f0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+0000ca00: 656c 662e 6173 696e 6828 290a 0a20 2020  elf.asinh()..   
+0000ca10: 2064 6566 2061 7263 7369 6e68 5f28 7365   def arcsinh_(se
+0000ca20: 6c66 293a 0a20 2020 2020 2020 206f 7574  lf):.        out
+0000ca30: 7075 7420 3d20 7365 6c66 2e61 7369 6e68  put = self.asinh
+0000ca40: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
+0000ca50: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+0000ca60: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+0000ca70: 7574 7075 742c 2022 6172 6373 696e 685f  utput, "arcsinh_
+0000ca80: 222c 2022 6172 6373 696e 6822 290a 0a20  ", "arcsinh").. 
+0000ca90: 2020 2064 6566 2061 7263 7461 6e68 2873     def arctanh(s
+0000caa0: 656c 6629 3a0a 2020 2020 2020 2020 7265  elf):.        re
+0000cab0: 7475 726e 2073 656c 662e 6174 616e 6828  turn self.atanh(
+0000cac0: 290a 0a20 2020 2064 6566 2061 7263 7461  )..    def arcta
+0000cad0: 6e68 5f28 7365 6c66 293a 0a20 2020 2020  nh_(self):.     
+0000cae0: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
+0000caf0: 2e61 7461 6e68 2829 0a20 2020 2020 2020  .atanh().       
+0000cb00: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+0000cb10: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+0000cb20: 656c 662c 206f 7574 7075 742c 2022 6172  elf, output, "ar
+0000cb30: 6374 616e 685f 222c 2022 6172 6374 616e  ctanh_", "arctan
+0000cb40: 6822 290a 0a20 2020 2064 6566 2064 6574  h")..    def det
+0000cb50: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+0000cb60: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+0000cb70: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+0000cb80: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
+0000cb90: 7420 3d20 6d73 2e6f 7073 2e64 6574 2869  t = ms.ops.det(i
+0000cba0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
+0000cbb0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0000cbc0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0000cbd0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0000cbe0: 6e65 6761 7469 7665 2873 656c 6629 3a0a  negative(self):.
+0000cbf0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+0000cc00: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0000cc10: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+0000cc20: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0000cc30: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0000cc40: 2869 6e70 7574 5f6d 732e 6e65 6761 7469  (input_ms.negati
+0000cc50: 7665 2829 290a 0a20 2020 2064 6566 206e  ve())..    def n
+0000cc60: 6567 6174 6976 655f 2873 656c 6629 3a0a  egative_(self):.
+0000cc70: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0000cc80: 2073 656c 662e 6e65 6761 7469 7665 2829   self.negative()
+0000cc90: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000cca0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+0000ccb0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+0000ccc0: 7075 742c 2022 6e65 6761 7469 7665 5f22  put, "negative_"
+0000ccd0: 2c20 226e 6567 6174 6976 6522 290a 0a20  , "negative").. 
+0000cce0: 2020 2064 6566 2061 6273 2873 656c 6629     def abs(self)
+0000ccf0: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+0000cd00: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0000cd10: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+0000cd20: 2020 2020 2069 6620 696e 7075 745f 6d73       if input_ms
+0000cd30: 2e64 7479 7065 2069 6e20 5b6d 7374 7970  .dtype in [mstyp
+0000cd40: 652e 636f 6d70 6c65 7836 342c 206d 7374  e.complex64, mst
+0000cd50: 7970 652e 636f 6d70 6c65 7831 3238 5d3a  ype.complex128]:
+0000cd60: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0000cd70: 7075 7420 3d20 5f67 6574 5f63 6163 6865  put = _get_cache
+0000cd80: 5f70 7269 6d28 6d73 2e6f 7073 2e43 6f6d  _prim(ms.ops.Com
+0000cd90: 706c 6578 4162 7329 2829 2869 6e70 7574  plexAbs)()(input
+0000cda0: 5f6d 7329 0a20 2020 2020 2020 2065 6c73  _ms).        els
+0000cdb0: 653a 0a20 2020 2020 2020 2020 2020 206f  e:.            o
+0000cdc0: 7574 7075 7420 3d20 696e 7075 745f 6d73  utput = input_ms
+0000cdd0: 2e61 6273 2829 0a20 2020 2020 2020 2072  .abs().        r
+0000cde0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+0000cdf0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+0000ce00: 7075 7429 0a0a 2020 2020 6465 6620 6162  put)..    def ab
+0000ce10: 735f 2873 656c 6629 3a0a 2020 2020 2020  s_(self):.      
+0000ce20: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
+0000ce30: 6162 7328 290a 2020 2020 2020 2020 7265  abs().        re
+0000ce40: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+0000ce50: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+0000ce60: 2c20 6f75 7470 7574 2c20 2261 6273 5f22  , output, "abs_"
+0000ce70: 2c20 2261 6273 2229 0a0a 2020 2020 4070  , "abs")..    @p
+0000ce80: 726f 7065 7274 790a 2020 2020 6465 6620  roperty.    def 
+0000ce90: 6e64 696d 2873 656c 6629 3a0a 2020 2020  ndim(self):.    
+0000cea0: 2020 2020 7265 7475 726e 206c 656e 2873      return len(s
+0000ceb0: 656c 662e 7368 6170 6529 0a0a 2020 2020  elf.shape)..    
+0000cec0: 6465 6620 616d 6178 2873 656c 662c 2064  def amax(self, d
+0000ced0: 696d 3d4e 6f6e 652c 206b 6565 7064 696d  im=None, keepdim
+0000cee0: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
+0000cef0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0000cf00: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0000cf10: 6c66 290a 2020 2020 2020 2020 6966 2064  lf).        if d
+0000cf20: 696d 2069 7320 6e6f 7420 4e6f 6e65 3a0a  im is not None:.
+0000cf30: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0000cf40: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0000cf50: 6572 5f74 656e 736f 7228 696e 7075 745f  er_tensor(input_
+0000cf60: 6d73 2e61 6d61 7828 6178 6973 3d64 696d  ms.amax(axis=dim
+0000cf70: 2c20 6b65 6570 6469 6d73 3d6b 6565 7064  , keepdims=keepd
+0000cf80: 696d 2929 0a20 2020 2020 2020 2072 6574  im)).        ret
+0000cf90: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+0000cfa0: 7465 725f 7465 6e73 6f72 2869 6e70 7574  ter_tensor(input
+0000cfb0: 5f6d 732e 616d 6178 286b 6565 7064 696d  _ms.amax(keepdim
+0000cfc0: 733d 6b65 6570 6469 6d29 290a 0a20 2020  s=keepdim))..   
+0000cfd0: 2064 6566 2061 6d69 6e28 7365 6c66 2c20   def amin(self, 
+0000cfe0: 6469 6d3d 4e6f 6e65 2c20 6b65 6570 6469  dim=None, keepdi
+0000cff0: 6d3d 4661 6c73 6529 3a0a 2020 2020 2020  m=False):.      
+0000d000: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+0000d010: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+0000d020: 656c 6629 0a20 2020 2020 2020 2069 6620  elf).        if 
+0000d030: 6469 6d20 6973 206e 6f74 204e 6f6e 653a  dim is not None:
+0000d040: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+0000d050: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+0000d060: 7465 725f 7465 6e73 6f72 2869 6e70 7574  ter_tensor(input
+0000d070: 5f6d 732e 616d 696e 2861 7869 733d 6469  _ms.amin(axis=di
+0000d080: 6d2c 206b 6565 7064 696d 733d 6b65 6570  m, keepdims=keep
+0000d090: 6469 6d29 290a 2020 2020 2020 2020 7265  dim)).        re
+0000d0a0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0000d0b0: 7074 6572 5f74 656e 736f 7228 696e 7075  pter_tensor(inpu
+0000d0c0: 745f 6d73 2e61 6d69 6e28 6b65 6570 6469  t_ms.amin(keepdi
+0000d0d0: 6d73 3d6b 6565 7064 696d 2929 0a0a 2020  ms=keepdim))..  
+0000d0e0: 2020 6465 6620 6173 5f73 7472 6964 6564    def as_strided
+0000d0f0: 2873 656c 662c 2073 697a 652c 2073 7472  (self, size, str
+0000d100: 6964 652c 2073 746f 7261 6765 5f6f 6666  ide, storage_off
+0000d110: 7365 743d 4e6f 6e65 293a 0a20 2020 2020  set=None):.     
+0000d120: 2020 2077 6172 6e69 6e67 2822 6173 5f73     warning("as_s
+0000d130: 7472 6964 6564 206e 6f74 2073 7570 706f  trided not suppo
+0000d140: 7274 206f 7574 7075 7420 6173 2061 2076  rt output as a v
+0000d150: 6965 772e 2229 0a20 2020 2020 2020 2069  iew.").        i
+0000d160: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0000d170: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0000d180: 290a 2020 2020 2020 2020 6966 206c 656e  ).        if len
+0000d190: 2873 697a 6529 2021 3d20 6c65 6e28 7374  (size) != len(st
+0000d1a0: 7269 6465 293a 0a20 2020 2020 2020 2020  ride):.         
+0000d1b0: 2020 2072 6169 7365 2052 756e 7469 6d65     raise Runtime
+0000d1c0: 4572 726f 7228 226d 6973 6d61 7463 6820  Error("mismatch 
+0000d1d0: 696e 206c 656e 6774 6820 6f66 2073 7472  in length of str
+0000d1e0: 6964 6573 2061 6e64 2073 6861 7065 2e22  ides and shape."
+0000d1f0: 290a 2020 2020 2020 2020 696e 6465 7820  ).        index 
+0000d200: 3d20 6e70 2e61 7261 6e67 6528 302c 2073  = np.arange(0, s
+0000d210: 697a 655b 305d 2a73 7472 6964 655b 305d  ize[0]*stride[0]
+0000d220: 2c20 7374 7269 6465 5b30 5d29 0a20 2020  , stride[0]).   
+0000d230: 2020 2020 2066 6f72 2069 2069 6e20 7261       for i in ra
+0000d240: 6e67 6528 312c 206c 656e 2873 697a 6529  nge(1, len(size)
+0000d250: 293a 0a20 2020 2020 2020 2020 2020 2074  ):.            t
+0000d260: 6d70 203d 206e 702e 6172 616e 6765 2830  mp = np.arange(0
+0000d270: 2c20 7369 7a65 5b69 5d2a 7374 7269 6465  , size[i]*stride
+0000d280: 5b69 5d2c 2073 7472 6964 655b 695d 290a  [i], stride[i]).
+0000d290: 2020 2020 2020 2020 2020 2020 696e 6465              inde
+0000d2a0: 7820 3d20 6e70 2e65 7870 616e 645f 6469  x = np.expand_di
+0000d2b0: 6d73 2869 6e64 6578 2c20 2d31 290a 2020  ms(index, -1).  
+0000d2c0: 2020 2020 2020 2020 2020 696e 6465 7820            index 
+0000d2d0: 3d20 696e 6465 7820 2b20 746d 700a 2020  = index + tmp.  
+0000d2e0: 2020 2020 2020 6966 2073 746f 7261 6765        if storage
+0000d2f0: 5f6f 6666 7365 7420 6973 206e 6f74 204e  _offset is not N
+0000d300: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+0000d310: 2069 6e64 6578 203d 2069 6e64 6578 202b   index = index +
+0000d320: 2073 746f 7261 6765 5f6f 6666 7365 740a   storage_offset.
+0000d330: 2020 2020 2020 2020 6966 2069 6e64 6578          if index
+0000d340: 2e73 697a 6520 3d3d 2030 3a0a 2020 2020  .size == 0:.    
+0000d350: 2020 2020 2020 2020 696e 7075 745f 696e          input_in
+0000d360: 6469 6365 7320 3d20 6d73 2e6e 756d 7079  dices = ms.numpy
+0000d370: 2e65 6d70 7479 2869 6e64 6578 2e73 6861  .empty(index.sha
+0000d380: 7065 2c20 6474 7970 653d 6d73 7479 7065  pe, dtype=mstype
+0000d390: 2e69 6e74 3332 290a 2020 2020 2020 2020  .int32).        
+0000d3a0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+0000d3b0: 2020 696e 7075 745f 696e 6469 6365 7320    input_indices 
+0000d3c0: 3d20 6d73 2e54 656e 736f 7228 696e 6465  = ms.Tensor(inde
+0000d3d0: 7829 0a20 2020 2020 2020 206f 7574 203d  x).        out =
+0000d3e0: 206d 732e 6f70 732e 6761 7468 6572 2869   ms.ops.gather(i
+0000d3f0: 6e70 7574 5f6d 732e 7265 7368 6170 6528  nput_ms.reshape(
+0000d400: 2d31 292c 2069 6e70 7574 5f69 6e64 6963  -1), input_indic
+0000d410: 6573 2c20 3029 0a20 2020 2020 2020 2072  es, 0).        r
+0000d420: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+0000d430: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+0000d440: 290a 0a20 2020 2064 6566 2062 6d6d 2873  )..    def bmm(s
+0000d450: 656c 662c 2062 6174 6368 3229 3a0a 2020  elf, batch2):.  
+0000d460: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0000d470: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0000d480: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0000d490: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0000d4a0: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
+0000d4b0: 6e70 7574 5f6d 732e 626d 6d28 6261 7463  nput_ms.bmm(batc
+0000d4c0: 6832 2929 0a0a 2020 2020 6465 6620 636c  h2))..    def cl
+0000d4d0: 616d 7028 7365 6c66 2c20 6d69 6e3d 4e6f  amp(self, min=No
+0000d4e0: 6e65 2c20 6d61 783d 4e6f 6e65 293a 0a20  ne, max=None):. 
+0000d4f0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+0000d500: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0000d510: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+0000d520: 2020 6966 2069 735f 756e 6465 725f 6173    if is_under_as
+0000d530: 6365 6e64 5f63 6f6e 7465 7874 2829 2061  cend_context() a
+0000d540: 6e64 2069 6e70 7574 5f6d 732e 6474 7970  nd input_ms.dtyp
+0000d550: 6520 3d3d 206d 732e 666c 6f61 7436 343a  e == ms.float64:
+0000d560: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
+0000d570: 7574 5f6d 7320 3d20 696e 7075 745f 6d73  ut_ms = input_ms
+0000d580: 2e61 7374 7970 6528 6d73 2e66 6c6f 6174  .astype(ms.float
+0000d590: 3332 290a 2020 2020 2020 2020 2020 2020  32).            
+0000d5a0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+0000d5b0: 636c 616d 7028 696e 7075 745f 6d73 2c20  clamp(input_ms, 
+0000d5c0: 6d69 6e2c 206d 6178 290a 2020 2020 2020  min, max).      
+0000d5d0: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
+0000d5e0: 7574 7075 742e 6173 7479 7065 286d 732e  utput.astype(ms.
+0000d5f0: 666c 6f61 7436 3429 0a20 2020 2020 2020  float64).       
+0000d600: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0000d610: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+0000d620: 7073 2e63 6c61 6d70 2869 6e70 7574 5f6d  ps.clamp(input_m
+0000d630: 732c 206d 696e 2c20 6d61 7829 0a20 2020  s, min, max).   
+0000d640: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+0000d650: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+0000d660: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+0000d670: 6465 6620 636c 616d 705f 2873 656c 662c  def clamp_(self,
+0000d680: 206d 696e 3d4e 6f6e 652c 206d 6178 3d4e   min=None, max=N
+0000d690: 6f6e 6529 3a0a 2020 2020 2020 2020 6f75  one):.        ou
+0000d6a0: 7470 7574 203d 2073 656c 662e 636c 616d  tput = self.clam
+0000d6b0: 7028 6d69 6e2c 206d 6178 290a 2020 2020  p(min, max).    
+0000d6c0: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+0000d6d0: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+0000d6e0: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+0000d6f0: 2263 6c61 6d70 5f22 2c20 2263 6c61 6d70  "clamp_", "clamp
+0000d700: 2229 0a0a 2020 2020 6465 6620 6469 6d28  ")..    def dim(
+0000d710: 7365 6c66 293a 0a20 2020 2020 2020 2072  self):.        r
+0000d720: 6574 7572 6e20 6c65 6e28 7365 6c66 2e73  eturn len(self.s
+0000d730: 6861 7065 290a 0a20 2020 2064 6566 2065  hape)..    def e
+0000d740: 7870 616e 645f 6173 2873 656c 662c 206f  xpand_as(self, o
+0000d750: 7468 6572 293a 0a20 2020 2020 2020 2069  ther):.        i
+0000d760: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0000d770: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0000d780: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
+0000d790: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0000d7a0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+0000d7b0: 2020 2020 2020 6f75 7470 7574 203d 2069        output = i
+0000d7c0: 6e70 7574 5f6d 732e 6578 7061 6e64 5f61  nput_ms.expand_a
+0000d7d0: 7328 6f74 6865 725f 6d73 290a 2020 2020  s(other_ms).    
+0000d7e0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+0000d7f0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+0000d800: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+0000d810: 6566 2069 7465 6d28 7365 6c66 293a 0a20  ef item(self):. 
+0000d820: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+0000d830: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0000d840: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+0000d850: 2020 6966 2069 6e70 7574 5f6d 732e 7369    if input_ms.si
+0000d860: 7a65 203e 2031 3a0a 2020 2020 2020 2020  ze > 1:.        
+0000d870: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+0000d880: 7272 6f72 2822 6f6e 6c79 206f 6e65 2065  rror("only one e
+0000d890: 6c65 6d65 6e74 2074 656e 736f 7273 2063  lement tensors c
+0000d8a0: 616e 2062 6520 636f 6e76 6572 7465 6420  an be converted 
+0000d8b0: 746f 2050 7974 686f 6e20 7363 616c 6172  to Python scalar
+0000d8c0: 7322 290a 2020 2020 2020 2020 7265 7475  s").        retu
+0000d8d0: 726e 2069 6e70 7574 5f6d 732e 6974 656d  rn input_ms.item
+0000d8e0: 2829 0a0a 2020 2020 6465 6620 6c6f 6728  ()..    def log(
+0000d8f0: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
+0000d900: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0000d910: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0000d920: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+0000d930: 203d 2069 6e70 7574 5f6d 732e 6c6f 6728   = input_ms.log(
+0000d940: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0000d950: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0000d960: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+0000d970: 0a20 2020 2064 6566 206c 6f67 5f28 7365  .    def log_(se
+0000d980: 6c66 293a 0a20 2020 2020 2020 206f 7574  lf):.        out
+0000d990: 7075 7420 3d20 7365 6c66 2e6c 6f67 2829  put = self.log()
+0000d9a0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000d9b0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+0000d9c0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+0000d9d0: 7075 742c 2022 6c6f 675f 222c 2022 6c6f  put, "log_", "lo
+0000d9e0: 6722 290a 0a20 2020 2064 6566 206c 6f67  g")..    def log
+0000d9f0: 3228 7365 6c66 293a 0a20 2020 2020 2020  2(self):.       
+0000da00: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0000da10: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0000da20: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
+0000da30: 7574 203d 206d 732e 6f70 732e 6c6f 6732  ut = ms.ops.log2
+0000da40: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
+0000da50: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0000da60: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0000da70: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0000da80: 6620 6c6f 6732 5f28 7365 6c66 293a 0a20  f log2_(self):. 
+0000da90: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0000daa0: 7365 6c66 2e6c 6f67 3228 290a 2020 2020  self.log2().    
+0000dab0: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+0000dac0: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+0000dad0: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+0000dae0: 226c 6f67 325f 222c 2022 6c6f 6732 2229  "log2_", "log2")
+0000daf0: 0a0a 2020 2020 2320 544f 444f 3a20 6375  ..    # TODO: cu
+0000db00: 7272 656e 746c 7920 6e6f 7420 7375 7070  rrently not supp
+0000db10: 6f72 7420 7265 7475 726e 2071 7220 6173  ort return qr as
+0000db20: 2073 6563 6f6e 6420 7265 7375 6c74 0a20   second result. 
+0000db30: 2020 2064 6566 206c 7374 7371 2873 656c     def lstsq(sel
+0000db40: 662c 2041 293a 0a20 2020 2020 2020 2069  f, A):.        i
+0000db50: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0000db60: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0000db70: 290a 2020 2020 2020 2020 4120 3d20 6361  ).        A = ca
+0000db80: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+0000db90: 4129 0a20 2020 2020 2020 2069 6620 6973  A).        if is
+0000dba0: 5f75 6e64 6572 5f63 7075 5f63 6f6e 7465  _under_cpu_conte
+0000dbb0: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
+0000dbc0: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+0000dbd0: 732e 6c73 7473 7128 412c 2069 6e70 7574  s.lstsq(A, input
+0000dbe0: 5f6d 7329 0a20 2020 2020 2020 2020 2020  _ms).           
+0000dbf0: 2071 7220 3d20 6d73 2e6f 7073 2e7a 6572   qr = ms.ops.zer
+0000dc00: 6f73 2841 2e73 6861 7065 2c20 412e 6474  os(A.shape, A.dt
+0000dc10: 7970 6529 0a20 2020 2020 2020 2065 6c73  ype).        els
+0000dc20: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
+0000dc30: 544f 444f 3a20 6d73 2e6f 7073 2e6c 7374  TODO: ms.ops.lst
+0000dc40: 7371 206e 6f74 2073 7570 706f 7274 2047  sq not support G
+0000dc50: 5055 2061 6e64 2041 7363 656e 642c 2075  PU and Ascend, u
+0000dc60: 7365 206e 756d 7079 2066 756e 630a 2020  se numpy func.  
+0000dc70: 2020 2020 2020 2020 2020 6c73 7473 715f            lstsq_
+0000dc80: 6f70 203d 206e 756d 7079 5f63 656c 6c2e  op = numpy_cell.
+0000dc90: 4e75 6d70 794c 7374 7371 2827 6c73 7473  NumpyLstsq('lsts
+0000dca0: 7127 290a 2020 2020 2020 2020 2020 2020  q').            
+0000dcb0: 6f75 7470 7574 2c20 7172 203d 206c 7374  output, qr = lst
+0000dcc0: 7371 5f6f 7028 696e 7075 745f 6d73 2c20  sq_op(input_ms, 
+0000dcd0: 4129 0a20 2020 2020 2020 2072 6574 7572  A).        retur
+0000dce0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0000dcf0: 725f 7465 6e73 6f72 2828 6f75 7470 7574  r_tensor((output
+0000dd00: 2c20 7172 2929 0a0a 2020 2020 6465 6620  , qr))..    def 
+0000dd10: 6d61 746d 756c 2873 656c 662c 2074 656e  matmul(self, ten
+0000dd20: 736f 7232 293a 0a20 2020 2020 2020 2069  sor2):.        i
+0000dd30: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0000dd40: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0000dd50: 290a 2020 2020 2020 2020 7465 6e73 6f72  ).        tensor
+0000dd60: 325f 6d73 203d 2063 6173 745f 746f 5f6d  2_ms = cast_to_m
+0000dd70: 735f 7465 6e73 6f72 2874 656e 736f 7232  s_tensor(tensor2
+0000dd80: 290a 2020 2020 2020 2020 2320 544f 444f  ).        # TODO
+0000dd90: 3a20 7265 7061 6c63 6520 7769 7468 206f  : repalce with o
+0000dda0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6d  utput = ms.ops.m
+0000ddb0: 6174 6d75 6c28 696e 7075 745f 6d73 2c20  atmul(input_ms, 
+0000ddc0: 7465 6e73 6f72 325f 6d73 290a 2020 2020  tensor2_ms).    
+0000ddd0: 2020 2020 6f75 7470 7574 203d 2063 7573      output = cus
+0000dde0: 746f 6d5f 6d61 746d 756c 2869 6e70 7574  tom_matmul(input
+0000ddf0: 5f6d 732c 2074 656e 736f 7232 5f6d 7329  _ms, tensor2_ms)
+0000de00: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000de10: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+0000de20: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+0000de30: 2020 2020 6465 6620 7371 7565 657a 6528      def squeeze(
+0000de40: 7365 6c66 2c20 6469 6d3d 4e6f 6e65 293a  self, dim=None):
+0000de50: 0a20 2020 2020 2020 2069 6620 6469 6d20  .        if dim 
+0000de60: 6973 206e 6f74 204e 6f6e 6520 616e 6420  is not None and 
+0000de70: 7365 6c66 2e73 6861 7065 5b64 696d 5d20  self.shape[dim] 
+0000de80: 213d 2031 3a0a 2020 2020 2020 2020 2020  != 1:.          
+0000de90: 2020 7265 7475 726e 2073 656c 660a 2020    return self.  
+0000dea0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0000deb0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0000dec0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0000ded0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+0000dee0: 2e73 7175 6565 7a65 2869 6e70 7574 5f6d  .squeeze(input_m
+0000def0: 732c 2064 696d 290a 2020 2020 2020 2020  s, dim).        
+0000df00: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+0000df10: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+0000df20: 7470 7574 290a 0a20 2020 2064 6566 2073  tput)..    def s
+0000df30: 7175 6565 7a65 5f28 7365 6c66 2c20 6469  queeze_(self, di
+0000df40: 6d3d 4e6f 6e65 293a 0a20 2020 2020 2020  m=None):.       
+0000df50: 206f 7574 7075 7420 3d20 7365 6c66 2e73   output = self.s
+0000df60: 7175 6565 7a65 2864 696d 290a 2020 2020  queeze(dim).    
+0000df70: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+0000df80: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+0000df90: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+0000dfa0: 2273 7175 6565 7a65 5f22 2c20 2273 7175  "squeeze_", "squ
+0000dfb0: 6565 7a65 2229 0a0a 2020 2020 6465 6620  eeze")..    def 
+0000dfc0: 7374 7269 6465 2873 656c 662c 2064 696d  stride(self, dim
+0000dfd0: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
+0000dfe0: 7374 7269 6465 203d 2073 7570 6572 2829  stride = super()
+0000dff0: 2e73 7472 6964 6528 6469 6d29 0a20 2020  .stride(dim).   
+0000e000: 2020 2020 2069 6620 6469 6d20 6973 204e       if dim is N
+0000e010: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+0000e020: 2072 6574 7572 6e20 7475 706c 6528 7374   return tuple(st
+0000e030: 7269 6465 290a 2020 2020 2020 2020 7265  ride).        re
+0000e040: 7475 726e 2073 7472 6964 650a 0a20 2020  turn stride..   
+0000e050: 2064 6566 2073 7562 2873 656c 662c 206f   def sub(self, o
+0000e060: 7468 6572 2c20 2a2c 2061 6c70 6861 3d31  ther, *, alpha=1
+0000e070: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0000e080: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0000e090: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0000e0a0: 2020 2020 2020 696e 7075 745f 6f74 6865        input_othe
+0000e0b0: 7220 3d20 6361 7374 5f74 6f5f 6d73 5f74  r = cast_to_ms_t
+0000e0c0: 656e 736f 7228 6f74 6865 7229 0a20 2020  ensor(other).   
+0000e0d0: 2020 2020 2069 6620 616c 7068 6120 213d       if alpha !=
+0000e0e0: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
+0000e0f0: 6966 2069 7369 6e73 7461 6e63 6528 696e  if isinstance(in
+0000e100: 7075 745f 6f74 6865 722c 206d 732e 5465  put_other, ms.Te
+0000e110: 6e73 6f72 2920 616e 6420 696e 7075 745f  nsor) and input_
+0000e120: 6f74 6865 722e 6474 7970 6520 696e 2061  other.dtype in a
+0000e130: 6c6c 5f63 6f6d 706c 6578 5f74 7970 653a  ll_complex_type:
+0000e140: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000e150: 2023 206d 732e 6f70 732e 6d75 6c20 6f6e   # ms.ops.mul on
+0000e160: 6c79 2073 7570 706f 7274 2074 656e 736f  ly support tenso
+0000e170: 7220 696e 7075 7420 7768 656e 2064 7479  r input when dty
+0000e180: 7065 2069 7320 636f 6d70 6c65 7820 7479  pe is complex ty
+0000e190: 7065 2e0a 2020 2020 2020 2020 2020 2020  pe..            
+0000e1a0: 2020 2020 696e 7075 745f 6f74 6865 7220      input_other 
+0000e1b0: 3d20 696e 7075 745f 6f74 6865 7220 2a20  = input_other * 
+0000e1c0: 6d73 2e6f 7073 2e73 6361 6c61 725f 746f  ms.ops.scalar_to
+0000e1d0: 5f74 656e 736f 7228 616c 7068 612c 2069  _tensor(alpha, i
+0000e1e0: 6e70 7574 5f6f 7468 6572 2e64 7479 7065  nput_other.dtype
+0000e1f0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
+0000e200: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+0000e210: 2020 2020 696e 7075 745f 6f74 6865 7220      input_other 
+0000e220: 3d20 696e 7075 745f 6f74 6865 7220 2a20  = input_other * 
+0000e230: 616c 7068 610a 2020 2020 2020 2020 6f75  alpha.        ou
+0000e240: 7470 7574 203d 206d 732e 6f70 732e 7375  tput = ms.ops.su
+0000e250: 6228 696e 7075 745f 6d73 2c20 696e 7075  b(input_ms, inpu
+0000e260: 745f 6f74 6865 7229 0a20 2020 2020 2020  t_other).       
+0000e270: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0000e280: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0000e290: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0000e2a0: 7375 625f 2873 656c 662c 206f 7468 6572  sub_(self, other
+0000e2b0: 2c20 2a2c 2061 6c70 6861 3d31 293a 0a20  , *, alpha=1):. 
+0000e2c0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0000e2d0: 7365 6c66 2e73 7562 286f 7468 6572 2c20  self.sub(other, 
+0000e2e0: 616c 7068 613d 616c 7068 6129 0a20 2020  alpha=alpha).   
+0000e2f0: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
+0000e300: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
+0000e310: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
+0000e320: 2022 7375 625f 222c 2022 7375 6222 290a   "sub_", "sub").
+0000e330: 0a20 2020 2064 6566 2069 735f 666c 6f61  .    def is_floa
+0000e340: 7469 6e67 5f70 6f69 6e74 2873 656c 6629  ting_point(self)
+0000e350: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+0000e360: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0000e370: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+0000e380: 2020 2020 2072 6574 7572 6e20 696e 7075       return inpu
+0000e390: 745f 6d73 2e69 735f 666c 6f61 7469 6e67  t_ms.is_floating
+0000e3a0: 5f70 6f69 6e74 2829 0a0a 2020 2020 6465  _point()..    de
+0000e3b0: 6620 756e 6269 6e64 2873 656c 662c 2064  f unbind(self, d
+0000e3c0: 696d 3d30 293a 0a20 2020 2020 2020 2069  im=0):.        i
+0000e3d0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0000e3e0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0000e3f0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0000e400: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0000e410: 5f74 656e 736f 7228 696e 7075 745f 6d73  _tensor(input_ms
+0000e420: 2e75 6e62 696e 6428 6469 6d29 290a 0a20  .unbind(dim)).. 
+0000e430: 2020 2064 6566 2075 6e73 7175 6565 7a65     def unsqueeze
+0000e440: 2873 656c 662c 2064 696d 293a 0a20 2020  (self, dim):.   
+0000e450: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0000e460: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0000e470: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+0000e480: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+0000e490: 6461 7074 6572 5f74 656e 736f 7228 696e  dapter_tensor(in
+0000e4a0: 7075 745f 6d73 2e75 6e73 7175 6565 7a65  put_ms.unsqueeze
+0000e4b0: 2864 696d 2929 0a0a 2020 2020 6465 6620  (dim))..    def 
+0000e4c0: 756e 7371 7565 657a 655f 2873 656c 662c  unsqueeze_(self,
+0000e4d0: 2064 696d 293a 0a20 2020 2020 2020 206f   dim):.        o
+0000e4e0: 7574 7075 7420 3d20 7365 6c66 2e75 6e73  utput = self.uns
+0000e4f0: 7175 6565 7a65 2864 696d 290a 2020 2020  queeze(dim).    
+0000e500: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+0000e510: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+0000e520: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+0000e530: 2275 6e73 7175 6565 7a65 5f22 2c20 2275  "unsqueeze_", "u
+0000e540: 6e73 7175 6565 7a65 2229 0a0a 2020 2020  nsqueeze")..    
+0000e550: 6465 6620 6973 5f73 6967 6e65 6428 7365  def is_signed(se
+0000e560: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
+0000e570: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+0000e580: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+0000e590: 2020 2020 2020 2020 7265 7475 726e 2069          return i
+0000e5a0: 6e70 7574 5f6d 732e 6973 5f73 6967 6e65  nput_ms.is_signe
+0000e5b0: 6428 290a 0a20 2020 2064 6566 2074 7261  d()..    def tra
+0000e5c0: 6e73 706f 7365 2873 656c 662c 2064 696d  nspose(self, dim
+0000e5d0: 302c 2064 696d 3129 3a0a 2020 2020 2020  0, dim1):.      
+0000e5e0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+0000e5f0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+0000e600: 656c 6629 0a20 2020 2020 2020 2023 2054  elf).        # T
+0000e610: 6865 2066 756e 6374 696f 6e73 206f 6620  he functions of 
+0000e620: 6d73 2e6f 7073 2e73 7761 7061 7865 7320  ms.ops.swapaxes 
+0000e630: 6172 6520 636f 6e73 6973 7465 6e74 2077  are consistent w
+0000e640: 6974 6820 746f 7263 682e 7472 616e 7370  ith torch.transp
+0000e650: 6f73 650a 2020 2020 2020 2020 6f75 7470  ose.        outp
+0000e660: 7574 203d 206d 732e 6f70 732e 7377 6170  ut = ms.ops.swap
+0000e670: 6178 6573 2869 6e70 7574 5f6d 732c 2064  axes(input_ms, d
+0000e680: 696d 302c 2064 696d 3129 0a20 2020 2020  im0, dim1).     
+0000e690: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0000e6a0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0000e6b0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0000e6c0: 6620 7472 616e 7370 6f73 655f 2873 656c  f transpose_(sel
+0000e6d0: 662c 2064 696d 302c 2064 696d 3129 3a0a  f, dim0, dim1):.
+0000e6e0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0000e6f0: 2073 656c 662e 7472 616e 7370 6f73 6528   self.transpose(
+0000e700: 6469 6d30 2c20 6469 6d31 290a 2020 2020  dim0, dim1).    
+0000e710: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+0000e720: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+0000e730: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+0000e740: 2274 7261 6e73 706f 7365 5f22 2c20 2274  "transpose_", "t
+0000e750: 7261 6e73 706f 7365 2229 0a0a 2020 2020  ranspose")..    
+0000e760: 6465 6620 666c 6f6f 7228 7365 6c66 293a  def floor(self):
+0000e770: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+0000e780: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+0000e790: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+0000e7a0: 2020 2020 6f75 7470 7574 203d 2069 6e70      output = inp
+0000e7b0: 7574 5f6d 732e 666c 6f6f 7228 290a 2020  ut_ms.floor().  
+0000e7c0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+0000e7d0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0000e7e0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+0000e7f0: 2064 6566 2066 6c6f 6f72 5f28 7365 6c66   def floor_(self
+0000e800: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+0000e810: 7420 3d20 7365 6c66 2e66 6c6f 6f72 2829  t = self.floor()
+0000e820: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000e830: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+0000e840: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+0000e850: 7075 742c 2022 666c 6f6f 725f 222c 2022  put, "floor_", "
+0000e860: 666c 6f6f 7222 290a 0a20 2020 2064 6566  floor")..    def
+0000e870: 2069 7366 696e 6974 6528 7365 6c66 293a   isfinite(self):
+0000e880: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+0000e890: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+0000e8a0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+0000e8b0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+0000e8c0: 6f70 732e 6973 6669 6e69 7465 2869 6e70  ops.isfinite(inp
+0000e8d0: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
+0000e8e0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+0000e8f0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+0000e900: 7075 7429 0a0a 2020 2020 6465 6620 6973  put)..    def is
+0000e910: 6e61 6e28 7365 6c66 293a 0a20 2020 2020  nan(self):.     
+0000e920: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+0000e930: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+0000e940: 7365 6c66 290a 2020 2020 2020 2020 7265  self).        re
+0000e950: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0000e960: 7074 6572 5f74 656e 736f 7228 696e 7075  pter_tensor(inpu
+0000e970: 745f 6d73 2e69 736e 616e 2829 290a 0a20  t_ms.isnan()).. 
+0000e980: 2020 2064 6566 2069 735f 636f 6e74 6967     def is_contig
+0000e990: 756f 7573 2873 656c 662c 206d 656d 6f72  uous(self, memor
+0000e9a0: 795f 666f 726d 6174 3d4e 6f6e 6529 3a0a  y_format=None):.
+0000e9b0: 2020 2020 2020 2020 756e 7375 7070 6f72          unsuppor
+0000e9c0: 7465 645f 6174 7472 286d 656d 6f72 795f  ted_attr(memory_
+0000e9d0: 666f 726d 6174 290a 2020 2020 2020 2020  format).        
+0000e9e0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+0000e9f0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+0000ea00: 6629 0a20 2020 2020 2020 2072 6574 7572  f).        retur
+0000ea10: 6e20 696e 7075 745f 6d73 2e69 735f 636f  n input_ms.is_co
+0000ea20: 6e74 6967 756f 7573 2829 0a0a 2020 2020  ntiguous()..    
+0000ea30: 6465 6620 6973 5f70 696e 6e65 6428 7365  def is_pinned(se
+0000ea40: 6c66 293a 0a20 2020 2020 2020 2077 6172  lf):.        war
+0000ea50: 6e69 6e67 2822 6973 5f70 696e 6e65 6420  ning("is_pinned 
+0000ea60: 6973 2061 6c77 6179 7320 4661 6c73 6520  is always False 
+0000ea70: 696e 2054 656e 736f 722e 2229 0a20 2020  in Tensor.").   
+0000ea80: 2020 2020 2072 6574 7572 6e20 4661 6c73       return Fals
+0000ea90: 650a 0a20 2020 2064 6566 2069 735f 7365  e..    def is_se
+0000eaa0: 745f 746f 2873 656c 662c 2074 656e 736f  t_to(self, tenso
+0000eab0: 7229 3a0a 2020 2020 2020 2020 7265 7475  r):.        retu
+0000eac0: 726e 2069 6428 7365 6c66 2e74 656e 736f  rn id(self.tenso
+0000ead0: 7229 203d 3d20 6964 2874 656e 736f 722e  r) == id(tensor.
+0000eae0: 7465 6e73 6f72 290a 0a20 2020 2064 6566  tensor)..    def
+0000eaf0: 2069 735f 7368 6172 6564 2873 656c 6629   is_shared(self)
+0000eb00: 3a0a 2020 2020 2020 2020 7761 726e 696e  :.        warnin
+0000eb10: 6728 2269 735f 7368 6172 6564 2069 7320  g("is_shared is 
+0000eb20: 616c 7761 7973 2046 616c 7365 2069 6e20  always False in 
+0000eb30: 5465 6e73 6f72 2e22 290a 2020 2020 2020  Tensor.").      
+0000eb40: 2020 7265 7475 726e 2046 616c 7365 0a0a    return False..
+0000eb50: 2020 2020 4070 726f 7065 7274 790a 2020      @property.  
+0000eb60: 2020 6465 6620 6973 5f73 7061 7273 6528    def is_sparse(
+0000eb70: 7365 6c66 293a 0a20 2020 2020 2020 2077  self):.        w
+0000eb80: 6172 6e69 6e67 2822 6973 5f73 7061 7273  arning("is_spars
+0000eb90: 6520 6973 2061 6c77 6179 7320 4661 6c73  e is always Fals
+0000eba0: 6520 696e 2054 656e 736f 722e 2229 0a20  e in Tensor."). 
+0000ebb0: 2020 2020 2020 2072 6574 7572 6e20 4661         return Fa
+0000ebc0: 6c73 650a 0a20 2020 2064 6566 2070 696e  lse..    def pin
+0000ebd0: 5f6d 656d 6f72 7928 7365 6c66 293a 0a20  _memory(self):. 
+0000ebe0: 2020 2020 2020 2077 6172 6e69 6e67 2822         warning("
+0000ebf0: 4375 7272 656e 746c 792c 2070 696e 5f6d  Currently, pin_m
+0000ec00: 656d 6f72 7920 6973 206e 6f74 2065 6666  emory is not eff
+0000ec10: 6563 7469 7665 2e22 290a 2020 2020 2020  ective.").      
+0000ec20: 2020 7265 7475 726e 2073 656c 660a 0a20    return self.. 
+0000ec30: 2020 2064 6566 2063 6c6f 6e65 2873 656c     def clone(sel
+0000ec40: 6629 3a0a 2020 2020 2020 2020 696e 7075  f):.        inpu
+0000ec50: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+0000ec60: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+0000ec70: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+0000ec80: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+0000ec90: 6e73 6f72 2869 6e70 7574 5f6d 732e 636f  nsor(input_ms.co
+0000eca0: 7079 2829 290a 0a20 2020 2064 6566 2073  py())..    def s
+0000ecb0: 6574 5f28 7365 6c66 2c20 736f 7572 6365  et_(self, source
+0000ecc0: 3d4e 6f6e 652c 2073 746f 7261 6765 5f6f  =None, storage_o
+0000ecd0: 6666 7365 743d 302c 2073 697a 653d 4e6f  ffset=0, size=No
+0000ece0: 6e65 2c20 7374 7269 6465 3d4e 6f6e 6529  ne, stride=None)
+0000ecf0: 3a0a 2020 2020 2020 2020 756e 7375 7070  :.        unsupp
+0000ed00: 6f72 7465 645f 6174 7472 2873 746f 7261  orted_attr(stora
+0000ed10: 6765 5f6f 6666 7365 7429 0a20 2020 2020  ge_offset).     
+0000ed20: 2020 2075 6e73 7570 706f 7274 6564 5f61     unsupported_a
+0000ed30: 7474 7228 7374 7269 6465 290a 2020 2020  ttr(stride).    
+0000ed40: 2020 2020 6966 2067 7261 7068 5f6d 6f64      if graph_mod
+0000ed50: 655f 636f 6e64 6974 696f 6e28 293a 0a20  e_condition():. 
+0000ed60: 2020 2020 2020 2020 2020 2077 6172 6e69             warni
+0000ed70: 6e67 2827 6054 656e 736f 722e 7365 745f  ng('`Tensor.set_
+0000ed80: 6020 6973 2061 6e20 696e 2d70 6c61 6365  ` is an in-place
+0000ed90: 206f 7065 7261 7469 6f6e 2061 6e64 2022   operation and "
+0000eda0: 782e 7365 745f 2829 2220 6973 206e 6f74  x.set_()" is not
+0000edb0: 2073 7570 706f 7274 6564 2074 6f20 7573   supported to us
+0000edc0: 6520 270a 2020 2020 2020 2020 2020 2020  e '.            
+0000edd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ede0: 2020 2027 696e 204d 696e 6453 706f 7265     'in MindSpore
+0000edf0: 2073 7461 7469 6320 6772 6170 6820 6d6f   static graph mo
+0000ee00: 6465 2e27 290a 0a20 2020 2020 2020 2069  de.')..        i
+0000ee10: 6620 6973 696e 7374 616e 6365 2873 6f75  f isinstance(sou
+0000ee20: 7263 652c 2054 656e 736f 7229 3a0a 2020  rce, Tensor):.  
+0000ee30: 2020 2020 2020 2020 2020 6966 2073 6f75            if sou
+0000ee40: 7263 652e 6474 7970 6520 213d 2073 656c  rce.dtype != sel
+0000ee50: 662e 6474 7970 653a 0a20 2020 2020 2020  f.dtype:.       
+0000ee60: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
+0000ee70: 756e 7469 6d65 4572 726f 7228 2249 6e20  untimeError("In 
+0000ee80: 6074 656e 736f 722e 7365 745f 602c 2073  `tensor.set_`, s
+0000ee90: 6f75 7273 652e 6474 7970 6520 6d75 7374  ourse.dtype must
+0000eea0: 2065 7175 616c 2074 6f20 7365 6c66 2e64   equal to self.d
+0000eeb0: 7479 7065 2e22 290a 2020 2020 2020 2020  type.").        
+0000eec0: 2020 2020 736f 7572 6365 203d 2063 6173      source = cas
+0000eed0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+0000eee0: 6f75 7263 6529 0a20 2020 2020 2020 2020  ource).         
+0000eef0: 2020 2069 6620 7369 7a65 3a0a 2020 2020     if size:.    
+0000ef00: 2020 2020 2020 2020 2020 2020 736f 7572              sour
+0000ef10: 6365 203d 2073 6f75 7263 652e 7265 7368  ce = source.resh
+0000ef20: 6170 6528 7369 7a65 290a 2020 2020 2020  ape(size).      
+0000ef30: 2020 2020 2020 7365 6c66 2e61 7373 6967        self.assig
+0000ef40: 6e5f 7661 6c75 6528 736f 7572 6365 290a  n_value(source).
+0000ef50: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0000ef60: 726e 2073 656c 660a 0a20 2020 2020 2020  rn self..       
+0000ef70: 2069 6620 6973 696e 7374 616e 6365 2873   if isinstance(s
+0000ef80: 6f75 7263 652c 205f 5479 7065 6453 746f  ource, _TypedSto
+0000ef90: 7261 6765 293a 0a20 2020 2020 2020 2020  rage):.         
+0000efa0: 2020 2023 2068 616e 646c 6520 736f 7572     # handle sour
+0000efb0: 6365 2069 7320 6120 5f54 7970 6564 5374  ce is a _TypedSt
+0000efc0: 6f72 6167 650a 2020 2020 2020 2020 2020  orage.          
+0000efd0: 2020 6966 2073 6f75 7263 652e 6474 7970    if source.dtyp
+0000efe0: 6520 213d 2073 656c 662e 6474 7970 653a  e != self.dtype:
+0000eff0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000f000: 2072 6169 7365 2052 756e 7469 6d65 4572   raise RuntimeEr
+0000f010: 726f 7228 2249 6e20 6074 656e 736f 722e  ror("In `tensor.
+0000f020: 7365 745f 602c 205f 5479 7065 6453 746f  set_`, _TypedSto
+0000f030: 7261 6765 2e64 7479 7065 206d 7573 7420  rage.dtype must 
+0000f040: 6571 7561 6c20 746f 2073 656c 662e 6474  equal to self.dt
+0000f050: 7970 652e 2229 0a20 2020 2020 2020 2020  ype.").         
+0000f060: 2020 2073 6f75 7263 652e 5f73 746f 7261     source._stora
+0000f070: 6765 2e72 6566 6572 656e 6365 645f 7465  ge.referenced_te
+0000f080: 6e73 6f72 203d 2073 656c 660a 2020 2020  nsor = self.    
+0000f090: 2020 2020 2020 2020 736f 7572 6365 2e5f          source._
+0000f0a0: 7374 6f72 6167 652e 5f75 7064 6174 655f  storage._update_
+0000f0b0: 7265 6665 7265 6e63 6564 5f74 656e 736f  referenced_tenso
+0000f0c0: 7228 7374 7269 6374 3d46 616c 7365 2c20  r(strict=False, 
+0000f0d0: 7369 7a65 3d73 697a 6529 0a20 2020 2020  size=size).     
+0000f0e0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+0000f0f0: 6c66 0a0a 2020 2020 2020 2020 2320 6861  lf..        # ha
+0000f100: 6e64 6c65 2073 6f75 7263 6520 6973 2061  ndle source is a
+0000f110: 205f 556e 7479 7065 6453 746f 7261 6765   _UntypedStorage
+0000f120: 0a20 2020 2020 2020 2073 6f75 7263 652e  .        source.
+0000f130: 7265 6665 7265 6e63 6564 5f74 656e 736f  referenced_tenso
+0000f140: 7220 3d20 7365 6c66 0a20 2020 2020 2020  r = self.       
+0000f150: 2073 6f75 7263 652e 5f75 7064 6174 655f   source._update_
+0000f160: 7265 6665 7265 6e63 6564 5f74 656e 736f  referenced_tenso
+0000f170: 7228 7374 7269 6374 3d46 616c 7365 2c20  r(strict=False, 
+0000f180: 7369 7a65 3d73 697a 6529 0a20 2020 2020  size=size).     
+0000f190: 2020 2072 6574 7572 6e20 7365 6c66 0a0a     return self..
+0000f1a0: 2020 2020 6465 6620 746f 2873 656c 662c      def to(self,
+0000f1b0: 202a 6172 6773 2c20 2a2a 6b77 6172 6773   *args, **kwargs
+0000f1c0: 293a 0a20 2020 2020 2020 2023 2054 4f44  ):.        # TOD
+0000f1d0: 4f3a 0a20 2020 2020 2020 2023 204e 6f74  O:.        # Not
+0000f1e0: 6520 7468 6174 2074 6869 7320 4150 4920  e that this API 
+0000f1f0: 7265 7175 6972 6573 2074 6865 2075 7365  requires the use
+0000f200: 7220 746f 2065 6e73 7572 6520 7468 6520  r to ensure the 
+0000f210: 636f 7272 6563 746e 6573 7320 6f66 2074  correctness of t
+0000f220: 6865 2069 6e70 7574 2063 7572 7265 6e74  he input current
+0000f230: 6c79 2c0a 2020 2020 2020 2020 2320 616e  ly,.        # an
+0000f240: 6420 6f6e 6c79 2074 6865 2066 756e 6374  d only the funct
+0000f250: 696f 6e20 6f66 206d 6f64 6966 7969 6e67  ion of modifying
+0000f260: 2064 7479 7065 2069 7320 6176 6169 6c61   dtype is availa
+0000f270: 626c 652e 0a0a 2020 2020 2020 2020 6966  ble...        if
+0000f280: 206c 656e 2861 7267 7329 203d 3d20 3020   len(args) == 0 
+0000f290: 616e 6420 6c65 6e28 6b77 6172 6773 2920  and len(kwargs) 
+0000f2a0: 3d3d 2030 3a0a 2020 2020 2020 2020 2020  == 0:.          
+0000f2b0: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+0000f2c0: 6f72 2822 5465 6e73 6f72 2e74 6f20 6973  or("Tensor.to is
+0000f2d0: 206d 6973 7369 6e67 2069 6e70 7574 732c   missing inputs,
+0000f2e0: 2070 6c65 6173 6520 6368 6563 6b2e 2229   please check.")
+0000f2f0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+0000f300: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+0000f310: 656e 736f 7228 7365 6c66 290a 0a20 2020  ensor(self)..   
+0000f320: 2020 2020 2069 6620 2264 7479 7065 2220       if "dtype" 
+0000f330: 696e 206b 7761 7267 733a 0a20 2020 2020  in kwargs:.     
+0000f340: 2020 2020 2020 2073 6574 5f64 7479 7065         set_dtype
+0000f350: 203d 206b 7761 7267 732e 6765 7428 2264   = kwargs.get("d
+0000f360: 7479 7065 2229 0a20 2020 2020 2020 2020  type").         
+0000f370: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0000f380: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0000f390: 2869 6e70 7574 5f6d 732e 6173 7479 7065  (input_ms.astype
+0000f3a0: 2873 6574 5f64 7479 7065 2929 0a20 2020  (set_dtype)).   
+0000f3b0: 2020 2020 2065 6c69 6620 226f 7468 6572       elif "other
+0000f3c0: 2220 696e 206b 7761 7267 733a 0a20 2020  " in kwargs:.   
+0000f3d0: 2020 2020 2020 2020 2073 6574 5f64 7479           set_dty
+0000f3e0: 7065 203d 206b 7761 7267 732e 6765 7428  pe = kwargs.get(
+0000f3f0: 226f 7468 6572 2229 2e64 7479 7065 0a20  "other").dtype. 
+0000f400: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0000f410: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0000f420: 725f 7465 6e73 6f72 2869 6e70 7574 5f6d  r_tensor(input_m
+0000f430: 732e 6173 7479 7065 2873 6574 5f64 7479  s.astype(set_dty
+0000f440: 7065 2929 0a20 2020 2020 2020 2065 6c69  pe)).        eli
+0000f450: 6620 2264 6576 6963 6522 2069 6e20 6b77  f "device" in kw
+0000f460: 6172 6773 3a0a 2020 2020 2020 2020 2020  args:.          
+0000f470: 2020 7265 7475 726e 2073 656c 660a 0a20    return self.. 
+0000f480: 2020 2020 2020 2069 6620 6c65 6e28 6172         if len(ar
+0000f490: 6773 2920 3d3d 2030 3a0a 2020 2020 2020  gs) == 0:.      
+0000f4a0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+0000f4b0: 660a 0a20 2020 2020 2020 2069 6620 6172  f..        if ar
+0000f4c0: 6773 5b30 5d20 696e 205f 6474 7970 6544  gs[0] in _dtypeD
+0000f4d0: 6963 742e 7661 6c75 6573 2829 3a0a 2020  ict.values():.  
+0000f4e0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+0000f4f0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0000f500: 5f74 656e 736f 7228 696e 7075 745f 6d73  _tensor(input_ms
+0000f510: 2e61 7374 7970 6528 6172 6773 5b30 5d29  .astype(args[0])
+0000f520: 290a 2020 2020 2020 2020 656c 6966 2069  ).        elif i
+0000f530: 7369 6e73 7461 6e63 6528 6172 6773 5b30  sinstance(args[0
+0000f540: 5d2c 2054 656e 736f 7229 3a0a 2020 2020  ], Tensor):.    
+0000f550: 2020 2020 2020 2020 7365 745f 6474 7970          set_dtyp
+0000f560: 6520 3d20 6172 6773 5b30 5d2e 6474 7970  e = args[0].dtyp
+0000f570: 650a 2020 2020 2020 2020 2020 2020 7265  e.            re
+0000f580: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0000f590: 7074 6572 5f74 656e 736f 7228 696e 7075  pter_tensor(inpu
+0000f5a0: 745f 6d73 2e61 7374 7970 6528 7365 745f  t_ms.astype(set_
+0000f5b0: 6474 7970 6529 290a 2020 2020 2020 2020  dtype)).        
+0000f5c0: 656c 6966 2061 7267 735b 305d 2061 6e64  elif args[0] and
+0000f5d0: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
+0000f5e0: 6172 6773 5b30 5d2c 2028 7374 722c 2064  args[0], (str, d
+0000f5f0: 6576 6963 655f 636c 6173 732c 2069 6e74  evice_class, int
+0000f600: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
+0000f610: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+0000f620: 2822 5468 6520 696e 7075 7473 206f 6620  ("The inputs of 
+0000f630: 5465 6e73 6f72 2e74 6f20 6973 2061 626e  Tensor.to is abn
+0000f640: 6f72 6d61 6c2c 2070 6c65 6173 6520 6368  ormal, please ch
+0000f650: 6563 6b2e 2229 0a0a 2020 2020 2020 2020  eck.")..        
+0000f660: 6966 206c 656e 2861 7267 7329 203e 2031  if len(args) > 1
+0000f670: 2061 6e64 2061 7267 735b 315d 2069 6e20   and args[1] in 
+0000f680: 5f64 7479 7065 4469 6374 2e76 616c 7565  _dtypeDict.value
+0000f690: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
+0000f6a0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0000f6b0: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
+0000f6c0: 6e70 7574 5f6d 732e 6173 7479 7065 2861  nput_ms.astype(a
+0000f6d0: 7267 735b 315d 2929 0a20 2020 2020 2020  rgs[1])).       
+0000f6e0: 2072 6574 7572 6e20 7365 6c66 0a0a 2020   return self..  
+0000f6f0: 2020 6465 6620 736f 7274 2873 656c 662c    def sort(self,
+0000f700: 2064 696d 3d2d 312c 2064 6573 6365 6e64   dim=-1, descend
+0000f710: 696e 673d 4661 6c73 6529 3a0a 2020 2020  ing=False):.    
+0000f720: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+0000f730: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0000f740: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
+0000f750: 6e70 7574 5f74 7970 6520 3d20 696e 7075  nput_type = inpu
+0000f760: 745f 6d73 2e64 7479 7065 0a20 2020 2020  t_ms.dtype.     
+0000f770: 2020 2069 6620 2749 6e74 2720 696e 2073     if 'Int' in s
+0000f780: 7472 2869 6e70 7574 5f74 7970 6529 3a0a  tr(input_type):.
+0000f790: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+0000f7a0: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
+0000f7b0: 6173 7479 7065 286d 732e 666c 6f61 7433  astype(ms.float3
+0000f7c0: 3229 0a20 2020 2020 2020 2020 2020 2073  2).            s
+0000f7d0: 6f72 745f 7465 6e73 6f72 2c20 736f 7274  ort_tensor, sort
+0000f7e0: 5f69 6e64 6578 203d 206d 732e 6f70 732e  _index = ms.ops.
+0000f7f0: 736f 7274 2869 6e70 7574 5f6d 732c 2064  sort(input_ms, d
+0000f800: 696d 2c20 6465 7363 656e 6469 6e67 290a  im, descending).
+0000f810: 2020 2020 2020 2020 2020 2020 736f 7274              sort
+0000f820: 5f74 656e 736f 7220 3d20 736f 7274 5f74  _tensor = sort_t
+0000f830: 656e 736f 722e 6173 7479 7065 2869 6e70  ensor.astype(inp
+0000f840: 7574 5f74 7970 6529 0a20 2020 2020 2020  ut_type).       
+0000f850: 2020 2020 2073 6f72 745f 696e 6465 7820       sort_index 
+0000f860: 3d20 736f 7274 5f69 6e64 6578 2e61 7374  = sort_index.ast
+0000f870: 7970 6528 6d73 2e69 6e74 3634 290a 2020  ype(ms.int64).  
+0000f880: 2020 2020 2020 2020 2020 7265 7475 726e            return
+0000f890: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0000f8a0: 5f74 656e 736f 7228 2873 6f72 745f 7465  _tensor((sort_te
+0000f8b0: 6e73 6f72 2c20 736f 7274 5f69 6e64 6578  nsor, sort_index
+0000f8c0: 2929 0a20 2020 2020 2020 2065 6c73 653a  )).        else:
+0000f8d0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0000f8e0: 7075 7420 3d20 6d73 2e6f 7073 2e73 6f72  put = ms.ops.sor
+0000f8f0: 7428 696e 7075 745f 6d73 2c20 6469 6d2c  t(input_ms, dim,
+0000f900: 2064 6573 6365 6e64 696e 6729 0a20 2020   descending).   
+0000f910: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+0000f920: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+0000f930: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+0000f940: 6465 6620 6d73 6f72 7428 7365 6c66 293a  def msort(self):
+0000f950: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+0000f960: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+0000f970: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+0000f980: 2020 2020 696e 7075 745f 7479 7065 203d      input_type =
+0000f990: 2069 6e70 7574 5f6d 732e 6474 7970 650a   input_ms.dtype.
+0000f9a0: 2020 2020 2020 2020 6966 2069 6e70 7574          if input
+0000f9b0: 5f74 7970 6520 696e 206d 696e 6474 6f72  _type in mindtor
+0000f9c0: 6368 5f64 7479 7065 2e61 6c6c 5f69 6e74  ch_dtype.all_int
+0000f9d0: 5f74 7970 653a 0a20 2020 2020 2020 2020  _type:.         
+0000f9e0: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
+0000f9f0: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
+0000fa00: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
+0000fa10: 2020 2020 2020 6f75 7470 7574 3d20 6d73        output= ms
+0000fa20: 2e6f 7073 2e6d 736f 7274 2869 6e70 7574  .ops.msort(input
+0000fa30: 5f6d 7329 0a20 2020 2020 2020 2020 2020  _ms).           
+0000fa40: 206f 7574 7075 7420 3d20 6f75 7470 7574   output = output
+0000fa50: 2e61 7374 7970 6528 696e 7075 745f 7479  .astype(input_ty
+0000fa60: 7065 290a 2020 2020 2020 2020 656c 7365  pe).        else
+0000fa70: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
+0000fa80: 7470 7574 203d 206d 732e 6f70 732e 6d73  tput = ms.ops.ms
+0000fa90: 6f72 7428 696e 7075 745f 6d73 290a 2020  ort(input_ms).  
+0000faa0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+0000fab0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0000fac0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+0000fad0: 2064 6566 2061 7267 736f 7274 2873 656c   def argsort(sel
+0000fae0: 662c 2064 696d 3d2d 312c 2064 6573 6365  f, dim=-1, desce
+0000faf0: 6e64 696e 673d 4661 6c73 6529 3a0a 2020  nding=False):.  
+0000fb00: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0000fb10: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0000fb20: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0000fb30: 2069 6620 696e 7075 745f 6d73 2e64 7479   if input_ms.dty
+0000fb40: 7065 2069 6e20 6d69 6e64 746f 7263 685f  pe in mindtorch_
+0000fb50: 6474 7970 652e 616c 6c5f 696e 745f 7479  dtype.all_int_ty
+0000fb60: 7065 3a0a 2020 2020 2020 2020 2020 2020  pe:.            
+0000fb70: 696e 7075 745f 6d73 203d 2069 6e70 7574  input_ms = input
+0000fb80: 5f6d 732e 6173 7479 7065 286d 732e 666c  _ms.astype(ms.fl
+0000fb90: 6f61 7433 3229 0a20 2020 2020 2020 2020  oat32).         
+0000fba0: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+0000fbb0: 7073 2e61 7267 736f 7274 2869 6e70 7574  ps.argsort(input
+0000fbc0: 5f6d 732c 2064 696d 2c20 6465 7363 656e  _ms, dim, descen
+0000fbd0: 6469 6e67 290a 2020 2020 2020 2020 2020  ding).          
+0000fbe0: 2020 6f75 7470 7574 203d 206f 7574 7075    output = outpu
+0000fbf0: 742e 6173 7479 7065 286d 732e 696e 7436  t.astype(ms.int6
+0000fc00: 3429 0a20 2020 2020 2020 2065 6c73 653a  4).        else:
+0000fc10: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0000fc20: 7075 7420 3d20 6d73 2e6f 7073 2e61 7267  put = ms.ops.arg
+0000fc30: 736f 7274 2869 6e70 7574 5f6d 732c 2064  sort(input_ms, d
+0000fc40: 696d 2c20 6465 7363 656e 6469 6e67 290a  im, descending).
+0000fc50: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+0000fc60: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+0000fc70: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+0000fc80: 2020 2064 6566 2073 7172 7428 7365 6c66     def sqrt(self
+0000fc90: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0000fca0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0000fcb0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0000fcc0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+0000fcd0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0000fce0: 736f 7228 6d73 2e6f 7073 2e73 7172 7428  sor(ms.ops.sqrt(
+0000fcf0: 696e 7075 745f 6d73 2929 0a0a 2020 2020  input_ms))..    
+0000fd00: 6465 6620 7371 7274 5f28 7365 6c66 293a  def sqrt_(self):
+0000fd10: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0000fd20: 3d20 7365 6c66 2e73 7172 7428 290a 2020  = self.sqrt().  
+0000fd30: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+0000fd40: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+0000fd50: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+0000fd60: 2c20 2273 7172 745f 222c 2022 7371 7274  , "sqrt_", "sqrt
+0000fd70: 2229 0a0a 2020 2020 6465 6620 7273 7172  ")..    def rsqr
+0000fd80: 7428 7365 6c66 293a 0a20 2020 2020 2020  t(self):.       
+0000fd90: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0000fda0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0000fdb0: 6c66 290a 2020 2020 2020 2020 6966 2069  lf).        if i
+0000fdc0: 6e70 7574 5f6d 732e 6474 7970 6520 696e  nput_ms.dtype in
+0000fdd0: 2061 6c6c 5f69 6e74 5f74 7970 655f 7769   all_int_type_wi
+0000fde0: 7468 5f62 6f6f 6c3a 0a20 2020 2020 2020  th_bool:.       
+0000fdf0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0000fe00: 696e 7075 745f 6d73 2e61 7374 7970 6528  input_ms.astype(
+0000fe10: 6d73 2e66 6c6f 6174 3332 290a 2020 2020  ms.float32).    
+0000fe20: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+0000fe30: 6f70 732e 7273 7172 7428 696e 7075 745f  ops.rsqrt(input_
+0000fe40: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
+0000fe50: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0000fe60: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0000fe70: 290a 0a20 2020 2064 6566 2072 7371 7274  )..    def rsqrt
+0000fe80: 5f28 7365 6c66 293a 0a20 2020 2020 2020  _(self):.       
+0000fe90: 206f 7574 7075 7420 3d20 7365 6c66 2e72   output = self.r
+0000fea0: 7371 7274 2829 0a20 2020 2020 2020 2072  sqrt().        r
+0000feb0: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
+0000fec0: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
+0000fed0: 662c 206f 7574 7075 742c 2022 7273 7172  f, output, "rsqr
+0000fee0: 745f 222c 2022 7273 7172 7422 290a 0a20  t_", "rsqrt").. 
+0000fef0: 2020 2064 6566 2072 6573 697a 6528 7365     def resize(se
+0000ff00: 6c66 2c20 2a73 697a 652c 206d 656d 6f72  lf, *size, memor
+0000ff10: 795f 666f 726d 6174 3d4e 6f6e 6529 3a0a  y_format=None):.
+0000ff20: 2020 2020 2020 2020 756e 7375 7070 6f72          unsuppor
+0000ff30: 7465 645f 6174 7472 286d 656d 6f72 795f  ted_attr(memory_
+0000ff40: 666f 726d 6174 290a 2020 2020 2020 2020  format).        
+0000ff50: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+0000ff60: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+0000ff70: 6629 0a20 2020 2020 2020 2069 6e70 7574  f).        input
+0000ff80: 5f73 697a 6520 3d20 696e 7075 745f 6d73  _size = input_ms
+0000ff90: 2e73 6861 7065 0a20 2020 2020 2020 2069  .shape.        i
+0000ffa0: 6620 6c65 6e28 696e 7075 745f 7369 7a65  f len(input_size
+0000ffb0: 2920 3d3d 2031 2061 6e64 2069 6e70 7574  ) == 1 and input
+0000ffc0: 5f73 697a 655b 305d 203d 3d20 303a 0a20  _size[0] == 0:. 
+0000ffd0: 2020 2020 2020 2020 2020 2069 6620 6973             if is
+0000ffe0: 696e 7374 616e 6365 2873 697a 655b 305d  instance(size[0]
+0000fff0: 2c20 2874 7570 6c65 2c20 6c69 7374 2929  , (tuple, list))
+00010000: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00010010: 2020 7369 7a65 203d 2073 697a 655b 305d    size = size[0]
+00010020: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00010030: 203d 206d 732e 6f70 732e 7a65 726f 7328   = ms.ops.zeros(
+00010040: 7369 7a65 2c20 7365 6c66 2e64 7479 7065  size, self.dtype
+00010050: 290a 2020 2020 2020 2020 656c 6966 206c  ).        elif l
+00010060: 656e 2873 697a 6529 203e 2030 2061 6e64  en(size) > 0 and
+00010070: 2069 7369 6e73 7461 6e63 6528 7369 7a65   isinstance(size
+00010080: 5b30 5d2c 2074 7570 6c65 293a 0a20 2020  [0], tuple):.   
+00010090: 2020 2020 2020 2020 206f 7574 203d 2069           out = i
+000100a0: 6e70 7574 5f6d 732e 7265 7369 7a65 2873  nput_ms.resize(s
+000100b0: 697a 655b 305d 290a 2020 2020 2020 2020  ize[0]).        
+000100c0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+000100d0: 2020 6f75 7420 3d20 696e 7075 745f 6d73    out = input_ms
+000100e0: 2e72 6573 697a 6528 7369 7a65 290a 2020  .resize(size).  
+000100f0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00010100: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00010110: 736f 7228 6f75 7429 0a0a 2020 2020 6465  sor(out)..    de
+00010120: 6620 7265 7369 7a65 5f28 7365 6c66 2c20  f resize_(self, 
+00010130: 2a73 697a 652c 206d 656d 6f72 795f 666f  *size, memory_fo
+00010140: 726d 6174 3d4e 6f6e 6529 3a0a 2020 2020  rmat=None):.    
+00010150: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+00010160: 662e 7265 7369 7a65 282a 7369 7a65 2c20  f.resize(*size, 
+00010170: 6d65 6d6f 7279 5f66 6f72 6d61 743d 6d65  memory_format=me
+00010180: 6d6f 7279 5f66 6f72 6d61 7429 0a20 2020  mory_format).   
+00010190: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
+000101a0: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
+000101b0: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
+000101c0: 2022 7265 7369 7a65 5f22 2c20 2272 6573   "resize_", "res
+000101d0: 697a 6522 290a 0a20 2020 2064 6566 2072  ize")..    def r
+000101e0: 6573 697a 655f 6173 2873 656c 662c 2074  esize_as(self, t
+000101f0: 656e 736f 722c 206d 656d 6f72 795f 666f  ensor, memory_fo
+00010200: 726d 6174 3d4e 6f6e 6529 3a0a 2020 2020  rmat=None):.    
+00010210: 2020 2020 756e 7375 7070 6f72 7465 645f      unsupported_
+00010220: 6174 7472 286d 656d 6f72 795f 666f 726d  attr(memory_form
+00010230: 6174 290a 2020 2020 2020 2020 6966 206e  at).        if n
+00010240: 6f74 2069 7369 6e73 7461 6e63 6528 7465  ot isinstance(te
+00010250: 6e73 6f72 2c20 5465 6e73 6f72 293a 0a20  nsor, Tensor):. 
+00010260: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00010270: 2054 7970 6545 7272 6f72 2822 7265 7369   TypeError("resi
+00010280: 7a65 5f61 7328 293a 2061 7267 756d 656e  ze_as(): argumen
+00010290: 7420 2774 656e 736f 7227 206d 7573 7420  t 'tensor' must 
+000102a0: 6265 2054 656e 736f 722e 2229 0a20 2020  be Tensor.").   
+000102b0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+000102c0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+000102d0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+000102e0: 7369 7a65 203d 2074 656e 736f 722e 7368  size = tensor.sh
+000102f0: 6170 650a 2020 2020 2020 2020 696e 7075  ape.        inpu
+00010300: 745f 7369 7a65 203d 2069 6e70 7574 5f6d  t_size = input_m
+00010310: 732e 7368 6170 650a 2020 2020 2020 2020  s.shape.        
+00010320: 6966 206c 656e 2869 6e70 7574 5f73 697a  if len(input_siz
+00010330: 6529 203d 3d20 3120 616e 6420 696e 7075  e) == 1 and inpu
+00010340: 745f 7369 7a65 5b30 5d20 3d3d 2030 3a0a  t_size[0] == 0:.
+00010350: 2020 2020 2020 2020 2020 2020 6f75 7420              out 
+00010360: 3d20 6d73 2e6f 7073 2e7a 6572 6f73 2873  = ms.ops.zeros(s
+00010370: 697a 652c 2073 656c 662e 6474 7970 6529  ize, self.dtype)
+00010380: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00010390: 2020 2020 2020 2020 2020 206f 7574 203d             out =
+000103a0: 2069 6e70 7574 5f6d 732e 7265 7369 7a65   input_ms.resize
+000103b0: 2873 697a 6529 0a20 2020 2020 2020 2072  (size).        r
+000103c0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+000103d0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+000103e0: 290a 0a20 2020 2064 6566 2072 6573 697a  )..    def resiz
+000103f0: 655f 6173 5f28 7365 6c66 2c20 7465 6e73  e_as_(self, tens
+00010400: 6f72 2c20 6d65 6d6f 7279 5f66 6f72 6d61  or, memory_forma
+00010410: 743d 4e6f 6e65 293a 0a20 2020 2020 2020  t=None):.       
+00010420: 206f 7574 7075 7420 3d20 7365 6c66 2e72   output = self.r
+00010430: 6573 697a 655f 6173 2874 656e 736f 722c  esize_as(tensor,
+00010440: 206d 656d 6f72 795f 666f 726d 6174 290a   memory_format).
+00010450: 2020 2020 2020 2020 7265 7475 726e 205f          return _
+00010460: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
+00010470: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
+00010480: 7574 2c20 2272 6573 697a 655f 6173 5f22  ut, "resize_as_"
+00010490: 2c20 2272 6573 697a 655f 6173 2229 0a0a  , "resize_as")..
+000104a0: 2020 2020 6465 6620 696e 6465 785f 6669      def index_fi
+000104b0: 6c6c 2873 656c 662c 2064 696d 2c20 696e  ll(self, dim, in
+000104c0: 6465 782c 2076 616c 7565 293a 0a20 2020  dex, value):.   
+000104d0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+000104e0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+000104f0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00010500: 696e 6465 7820 3d20 6361 7374 5f74 6f5f  index = cast_to_
+00010510: 6d73 5f74 656e 736f 7228 696e 6465 7829  ms_tensor(index)
+00010520: 0a20 2020 2020 2020 2069 6e64 6578 203d  .        index =
+00010530: 206d 732e 6f70 732e 6361 7374 2869 6e64   ms.ops.cast(ind
+00010540: 6578 2c20 6d73 7479 7065 2e69 6e74 3332  ex, mstype.int32
+00010550: 290a 2020 2020 2020 2020 6f75 7420 3d20  ).        out = 
+00010560: 696e 7075 745f 6d73 2e69 6e64 6578 5f66  input_ms.index_f
+00010570: 696c 6c28 6469 6d2c 2069 6e64 6578 2c20  ill(dim, index, 
+00010580: 7661 6c75 6529 0a20 2020 2020 2020 2072  value).        r
+00010590: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+000105a0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+000105b0: 290a 0a20 2020 2064 6566 2069 6e64 6578  )..    def index
+000105c0: 5f66 696c 6c5f 2873 656c 662c 2064 696d  _fill_(self, dim
+000105d0: 2c20 696e 6465 782c 2076 616c 7565 293a  , index, value):
+000105e0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+000105f0: 3d20 7365 6c66 2e69 6e64 6578 5f66 696c  = self.index_fil
+00010600: 6c28 6469 6d2c 2069 6e64 6578 2c20 7661  l(dim, index, va
+00010610: 6c75 6529 0a20 2020 2020 2020 2072 6574  lue).        ret
+00010620: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+00010630: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+00010640: 206f 7574 7075 742c 2022 696e 6465 785f   output, "index_
+00010650: 6669 6c6c 5f22 2c20 2269 6e64 6578 5f66  fill_", "index_f
+00010660: 696c 6c22 290a 0a20 2020 2064 6566 2069  ill")..    def i
+00010670: 6e64 6578 5f73 656c 6563 7428 7365 6c66  ndex_select(self
+00010680: 2c20 6469 6d2c 2069 6e64 6578 293a 0a20  , dim, index):. 
+00010690: 2020 2020 2020 205f 696e 7075 745f 7061         _input_pa
+000106a0: 7261 6d73 203d 2063 6173 745f 746f 5f6d  rams = cast_to_m
+000106b0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+000106c0: 2020 2020 2020 205f 696e 7075 745f 696e         _input_in
+000106d0: 6469 6365 7320 3d20 6361 7374 5f74 6f5f  dices = cast_to_
+000106e0: 6d73 5f74 656e 736f 7228 696e 6465 7829  ms_tensor(index)
+000106f0: 0a0a 2020 2020 2020 2020 6966 2069 7369  ..        if isi
+00010700: 6e73 7461 6e63 6528 5f69 6e70 7574 5f69  nstance(_input_i
+00010710: 6e64 6963 6573 2c20 6d73 2e54 656e 736f  ndices, ms.Tenso
+00010720: 7229 2061 6e64 205f 696e 7075 745f 696e  r) and _input_in
+00010730: 6469 6365 732e 6e64 696d 203d 3d20 303a  dices.ndim == 0:
+00010740: 0a20 2020 2020 2020 2020 2020 205f 696e  .            _in
+00010750: 7075 745f 696e 6469 6365 7320 3d20 6d73  put_indices = ms
+00010760: 2e6f 7073 2e75 6e73 7175 6565 7a65 285f  .ops.unsqueeze(_
+00010770: 696e 7075 745f 696e 6469 6365 732c 2030  input_indices, 0
+00010780: 290a 0a20 2020 2020 2020 206f 7574 7075  )..        outpu
+00010790: 7420 3d20 6d73 2e6f 7073 2e67 6174 6865  t = ms.ops.gathe
+000107a0: 7228 5f69 6e70 7574 5f70 6172 616d 732c  r(_input_params,
+000107b0: 205f 696e 7075 745f 696e 6469 6365 732c   _input_indices,
+000107c0: 2064 696d 290a 2020 2020 2020 2020 7265   dim).        re
+000107d0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+000107e0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+000107f0: 7574 290a 0a20 2020 2040 7072 6f70 6572  ut)..    @proper
+00010800: 7479 0a20 2020 2064 6566 2064 6174 6128  ty.    def data(
+00010810: 7365 6c66 293a 0a20 2020 2020 2020 2072  self):.        r
+00010820: 6574 7572 6e20 7365 6c66 2e64 6574 6163  eturn self.detac
+00010830: 6828 290a 0a20 2020 2040 6461 7461 2e73  h()..    @data.s
+00010840: 6574 7465 720a 2020 2020 6465 6620 6461  etter.    def da
+00010850: 7461 2873 656c 662c 2064 6174 6129 3a0a  ta(self, data):.
+00010860: 2020 2020 2020 2020 6d73 5f64 6174 6120          ms_data 
+00010870: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00010880: 736f 7228 6461 7461 290a 2020 2020 2020  sor(data).      
+00010890: 2020 7365 6c66 2e61 7373 6967 6e5f 7661    self.assign_va
+000108a0: 6c75 6528 6d73 5f64 6174 6129 0a0a 2020  lue(ms_data)..  
+000108b0: 2020 6465 6620 6e65 7728 7365 6c66 2c20    def new(self, 
+000108c0: 2a73 697a 6529 3a0a 2020 2020 2020 2020  *size):.        
+000108d0: 6966 206c 656e 2873 697a 6529 203e 2030  if len(size) > 0
+000108e0: 2061 6e64 2069 7369 6e73 7461 6e63 6528   and isinstance(
+000108f0: 7369 7a65 5b30 5d2c 2074 7570 6c65 293a  size[0], tuple):
+00010900: 0a20 2020 2020 2020 2020 2020 2073 697a  .            siz
+00010910: 6520 3d20 7369 7a65 5b30 5d0a 2020 2020  e = size[0].    
+00010920: 2020 2020 5f64 7479 7065 203d 2073 656c      _dtype = sel
+00010930: 662e 6474 7970 650a 2020 2020 2020 2020  f.dtype.        
+00010940: 7265 7475 726e 2054 656e 736f 7228 2a73  return Tensor(*s
+00010950: 697a 652c 2064 7479 7065 3d5f 6474 7970  ize, dtype=_dtyp
+00010960: 6529 0a0a 2020 2020 6465 6620 6375 6461  e)..    def cuda
+00010970: 2873 656c 662c 2064 6576 6963 653d 4e6f  (self, device=No
+00010980: 6e65 2c20 6e6f 6e5f 626c 6f63 6b69 6e67  ne, non_blocking
+00010990: 3d46 616c 7365 2c20 6d65 6d6f 7279 5f66  =False, memory_f
+000109a0: 6f72 6d61 743d 4e6f 6e65 293a 0a20 2020  ormat=None):.   
+000109b0: 2020 2020 2075 6e73 7570 706f 7274 6564       unsupported
+000109c0: 5f61 7474 7228 6465 7669 6365 290a 2020  _attr(device).  
+000109d0: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
+000109e0: 645f 6174 7472 286e 6f6e 5f62 6c6f 636b  d_attr(non_block
+000109f0: 696e 6729 0a20 2020 2020 2020 2075 6e73  ing).        uns
+00010a00: 7570 706f 7274 6564 5f61 7474 7228 6d65  upported_attr(me
+00010a10: 6d6f 7279 5f66 6f72 6d61 7429 0a20 2020  mory_format).   
+00010a20: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+00010a30: 0a0a 2020 2020 6465 6620 6973 5f63 7564  ..    def is_cud
+00010a40: 6128 7365 6c66 293a 0a20 2020 2020 2020  a(self):.       
+00010a50: 2072 6574 7572 6e20 6973 5f75 6e64 6572   return is_under
+00010a60: 5f67 7075 5f63 6f6e 7465 7874 2829 0a0a  _gpu_context()..
+00010a70: 2020 2020 6465 6620 6c65 2873 656c 662c      def le(self,
+00010a80: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
+00010a90: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+00010aa0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+00010ab0: 6c66 290a 2020 2020 2020 2020 6966 2069  lf).        if i
+00010ac0: 7369 6e73 7461 6e63 6528 6f74 6865 722c  sinstance(other,
+00010ad0: 2054 656e 736f 7229 3a0a 2020 2020 2020   Tensor):.      
+00010ae0: 2020 2020 2020 6f74 6865 7220 3d20 6361        other = ca
+00010af0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00010b00: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
+00010b10: 7574 203d 206d 732e 6f70 732e 6c65 2869  ut = ms.ops.le(i
+00010b20: 6e70 7574 5f6d 732c 206f 7468 6572 290a  nput_ms, other).
+00010b30: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00010b40: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+00010b50: 656e 736f 7228 6f75 7429 0a0a 2020 2020  ensor(out)..    
+00010b60: 6465 6620 6c65 5f28 7365 6c66 2c20 6f74  def le_(self, ot
+00010b70: 6865 7229 3a0a 2020 2020 2020 2020 6f75  her):.        ou
+00010b80: 7470 7574 203d 2073 656c 662e 6c65 286f  tput = self.le(o
+00010b90: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
+00010ba0: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+00010bb0: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+00010bc0: 2c20 6f75 7470 7574 2c20 226c 655f 222c  , output, "le_",
+00010bd0: 2022 6c65 2229 0a0a 2020 2020 6465 6620   "le")..    def 
+00010be0: 7428 7365 6c66 293a 0a20 2020 2020 2020  t(self):.       
+00010bf0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+00010c00: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+00010c10: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
+00010c20: 7574 203d 206d 732e 6f70 732e 7428 696e  ut = ms.ops.t(in
+00010c30: 7075 745f 6d73 290a 2020 2020 2020 2020  put_ms).        
+00010c40: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00010c50: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00010c60: 7470 7574 290a 0a20 2020 2064 6566 2074  tput)..    def t
+00010c70: 5f28 7365 6c66 293a 0a20 2020 2020 2020  _(self):.       
+00010c80: 206f 7574 7075 7420 3d20 7365 6c66 2e74   output = self.t
+00010c90: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
+00010ca0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+00010cb0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00010cc0: 7574 7075 742c 2022 745f 222c 2022 7422  utput, "t_", "t"
+00010cd0: 290a 0a20 2020 2040 7072 6f70 6572 7479  )..    @property
+00010ce0: 0a20 2020 2064 6566 2054 2873 656c 6629  .    def T(self)
+00010cf0: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+00010d00: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00010d10: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+00010d20: 2020 2020 2069 6620 696e 7075 745f 6d73       if input_ms
+00010d30: 2e6e 756d 656c 2829 203d 3d20 303a 0a20  .numel() == 0:. 
+00010d40: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+00010d50: 7420 3d20 5465 6e73 6f72 282a 2869 6e70  t = Tensor(*(inp
+00010d60: 7574 5f6d 732e 7368 6170 655b 3a3a 2d31  ut_ms.shape[::-1
+00010d70: 5d29 290a 2020 2020 2020 2020 656c 7365  ])).        else
+00010d80: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
+00010d90: 2069 6e70 7574 5f6d 732e 6e64 696d 203c   input_ms.ndim <
+00010da0: 3d20 323a 0a20 2020 2020 2020 2020 2020  = 2:.           
+00010db0: 2020 2020 2077 6172 6e69 6e67 5f6d 7367       warning_msg
+00010dc0: 203d 2028 2254 6865 2075 7365 206f 6620   = ("The use of 
+00010dd0: 5465 6e73 6f72 2e54 2829 206f 6e20 7465  Tensor.T() on te
+00010de0: 6e73 6f72 7320 6f66 2064 696d 656e 7369  nsors of dimensi
+00010df0: 6f6e 206f 7468 6572 2074 6861 6e20 3220  on other than 2 
+00010e00: 746f 2072 6576 6572 7365 2022 0a20 2020  to reverse ".   
+00010e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010e20: 2020 2020 2020 2020 2022 7468 6569 7220           "their 
+00010e30: 7368 6170 6520 6973 2064 6570 7265 6361  shape is depreca
+00010e40: 7465 6420 616e 6420 6974 2077 696c 6c20  ted and it will 
+00010e50: 7468 726f 7720 616e 2065 7272 6f72 2069  throw an error i
+00010e60: 6e20 6120 6675 7475 7265 2072 656c 6561  n a future relea
+00010e70: 7365 2e20 2229 0a20 2020 2020 2020 2020  se. ").         
+00010e80: 2020 2020 2020 2077 6172 6e69 6e67 2877         warning(w
+00010e90: 6172 6e69 6e67 5f6d 7367 290a 2020 2020  arning_msg).    
+00010ea0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00010eb0: 2069 6e70 7574 5f6d 732e 540a 2020 2020   input_ms.T.    
+00010ec0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+00010ed0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00010ee0: 7228 6f75 7470 7574 290a 0a20 2020 2040  r(output)..    @
+00010ef0: 7072 6f70 6572 7479 0a20 2020 2064 6566  property.    def
+00010f00: 2048 2873 656c 6629 3a0a 2020 2020 2020   H(self):.      
+00010f10: 2020 2320 544f 444f 3a20 746f 7263 6820    # TODO: torch 
+00010f20: 6973 2076 6965 7720 6f66 206f 7269 6769  is view of origi
+00010f30: 6e20 5465 6e73 6f72 2c20 6275 7420 6164  n Tensor, but ad
+00010f40: 6170 7465 7220 6372 6561 7465 2061 206e  apter create a n
+00010f50: 6577 2074 656e 736f 720a 2020 2020 2020  ew tensor.      
+00010f60: 2020 6966 206e 6f74 2073 656c 662e 6e64    if not self.nd
+00010f70: 696d 203d 3d20 323a 0a20 2020 2020 2020  im == 2:.       
+00010f80: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+00010f90: 4572 726f 7228 6622 7465 6e73 6f72 2e48  Error(f"tensor.H
+00010fa0: 2069 7320 6f6e 6c79 2073 7570 706f 7274   is only support
+00010fb0: 6564 206f 6e20 6d61 7472 6963 6573 2028  ed on matrices (
+00010fc0: 322d 4420 7465 6e73 6f72 7329 2e20 476f  2-D tensors). Go
+00010fd0: 7420 7b73 656c 662e 6e64 696d 7d2d 4420  t {self.ndim}-D 
+00010fe0: 7465 6e73 6f72 2e22 290a 0a20 2020 2020  tensor.")..     
+00010ff0: 2020 2069 6620 7365 6c66 2e69 735f 636f     if self.is_co
+00011000: 6d70 6c65 7828 293a 0a20 2020 2020 2020  mplex():.       
+00011010: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
+00011020: 2e74 7261 6e73 706f 7365 2830 2c20 3129  .transpose(0, 1)
+00011030: 2e63 6f6e 6a28 290a 2020 2020 2020 2020  .conj().        
+00011040: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
+00011050: 2020 7265 7475 726e 2073 656c 662e 7472    return self.tr
+00011060: 616e 7370 6f73 6528 302c 2031 290a 0a20  anspose(0, 1).. 
+00011070: 2020 2040 7072 6f70 6572 7479 0a20 2020     @property.   
+00011080: 2064 6566 2069 735f 7175 616e 7469 7a65   def is_quantize
+00011090: 6428 7365 6c66 293a 0a20 2020 2020 2020  d(self):.       
+000110a0: 2077 6172 6e69 6e67 2822 7465 6e73 6f72   warning("tensor
+000110b0: 2e69 735f 7175 616e 7469 7a65 6420 6f6e  .is_quantized on
+000110c0: 6c79 2073 7570 7070 6f72 7420 7365 7420  ly suppport set 
+000110d0: 746f 2046 616c 7365 206e 6f77 2e20 536f  to False now. So
+000110e0: 2049 7420 6973 2061 6c77 6179 7320 4661   It is always Fa
+000110f0: 6c73 652e 2229 0a20 2020 2020 2020 2072  lse.").        r
+00011100: 6574 7572 6e20 4661 6c73 650a 0a20 2020  eturn False..   
+00011110: 2040 6973 5f71 7561 6e74 697a 6564 2e73   @is_quantized.s
+00011120: 6574 7465 720a 2020 2020 6465 6620 6973  etter.    def is
+00011130: 5f71 7561 6e74 697a 6564 2873 656c 662c  _quantized(self,
+00011140: 2066 6c61 6729 3a0a 2020 2020 2020 2020   flag):.        
+00011150: 7261 6973 6520 4174 7472 6962 7574 6545  raise AttributeE
+00011160: 7272 6f72 2822 6174 7472 6962 7574 6520  rror("attribute 
+00011170: 2769 735f 7175 616e 7469 7a65 6427 206f  'is_quantized' o
+00011180: 6620 2774 6f72 6368 2e54 656e 736f 7227  f 'torch.Tensor'
+00011190: 206f 626a 6563 7473 2069 7320 6e6f 7420   objects is not 
+000111a0: 7772 6974 6162 6c65 2e22 290a 0a20 2020  writable.")..   
+000111b0: 2064 6566 206e 6f6e 7a65 726f 2873 656c   def nonzero(sel
+000111c0: 6629 3a0a 2020 2020 2020 2020 696e 7075  f):.        inpu
+000111d0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+000111e0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+000111f0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00011200: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00011210: 6e73 6f72 286d 732e 6f70 732e 6e6f 6e7a  nsor(ms.ops.nonz
+00011220: 6572 6f28 696e 7075 745f 6d73 2929 0a0a  ero(input_ms))..
+00011230: 2020 2020 6465 6620 626f 6f6c 2873 656c      def bool(sel
+00011240: 662c 206d 656d 6f72 795f 666f 726d 6174  f, memory_format
+00011250: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
+00011260: 756e 7375 7070 6f72 7465 645f 6174 7472  unsupported_attr
+00011270: 286d 656d 6f72 795f 666f 726d 6174 290a  (memory_format).
+00011280: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00011290: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000112a0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+000112b0: 2020 206f 7574 7075 7420 3d20 696e 7075     output = inpu
+000112c0: 745f 6d73 2e62 6f6f 6c28 290a 2020 2020  t_ms.bool().    
+000112d0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+000112e0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+000112f0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+00011300: 6566 2065 7128 7365 6c66 2c20 6f74 6865  ef eq(self, othe
+00011310: 7229 3a0a 2020 2020 2020 2020 696e 7075  r):.        inpu
+00011320: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+00011330: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00011340: 2020 2020 2020 206f 7468 6572 5f6d 7320         other_ms 
+00011350: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00011360: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
+00011370: 2020 206f 7574 7075 7420 3d20 696e 7075     output = inpu
+00011380: 745f 6d73 2e65 7175 616c 286f 7468 6572  t_ms.equal(other
+00011390: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
+000113a0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+000113b0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+000113c0: 7429 0a0a 2020 2020 6465 6620 6571 5f28  t)..    def eq_(
+000113d0: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
+000113e0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
+000113f0: 656c 662e 6571 286f 7468 6572 290a 2020  elf.eq(other).  
+00011400: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+00011410: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+00011420: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+00011430: 2c20 2265 715f 222c 2022 6571 2229 0a0a  , "eq_", "eq")..
+00011440: 2020 2020 6465 6620 7374 6428 7365 6c66      def std(self
+00011450: 2c20 6469 6d3d 4e6f 6e65 2c20 756e 6269  , dim=None, unbi
+00011460: 6173 6564 3d54 7275 652c 206b 6565 7064  ased=True, keepd
+00011470: 696d 3d46 616c 7365 293a 0a20 2020 2020  im=False):.     
+00011480: 2020 2023 544f 444f 3a20 6e6f 7420 7375     #TODO: not su
+00011490: 7070 6f72 7420 636f 6d70 6c65 7820 696e  pport complex in
+000114a0: 7075 740a 2020 2020 2020 2020 696e 7075  put.        inpu
+000114b0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+000114c0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+000114d0: 2020 2020 2020 205f 6469 6d20 3d20 6469         _dim = di
+000114e0: 6d20 6966 2064 696d 2069 7320 6e6f 7420  m if dim is not 
+000114f0: 4e6f 6e65 2065 6c73 6520 2829 0a20 2020  None else ().   
+00011500: 2020 2020 205f 6464 6f66 203d 2031 2069       _ddof = 1 i
+00011510: 6620 756e 6269 6173 6564 2065 6c73 6520  f unbiased else 
+00011520: 300a 2020 2020 2020 2020 6f75 7470 7574  0.        output
+00011530: 203d 2069 6e70 7574 5f6d 732e 7374 6428   = input_ms.std(
+00011540: 5f64 696d 2c20 5f64 646f 662c 206b 6565  _dim, _ddof, kee
+00011550: 7064 696d 290a 2020 2020 2020 2020 7265  pdim).        re
+00011560: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00011570: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00011580: 7574 290a 0a20 2020 2064 6566 2065 7870  ut)..    def exp
+00011590: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+000115a0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+000115b0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+000115c0: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
+000115d0: 7420 3d20 696e 7075 745f 6d73 2e65 7870  t = input_ms.exp
+000115e0: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
+000115f0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00011600: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00011610: 0a0a 2020 2020 6465 6620 6578 705f 2873  ..    def exp_(s
+00011620: 656c 6629 3a0a 2020 2020 2020 2020 6f75  elf):.        ou
+00011630: 7470 7574 203d 2073 656c 662e 6578 7028  tput = self.exp(
+00011640: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00011650: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+00011660: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+00011670: 7470 7574 2c20 2265 7870 5f22 2c20 2265  tput, "exp_", "e
+00011680: 7870 2229 0a0a 2020 2020 6465 6620 6d61  xp")..    def ma
+00011690: 736b 6564 5f66 696c 6c28 7365 6c66 2c20  sked_fill(self, 
+000116a0: 6d61 736b 2c20 7661 6c75 6529 3a0a 2020  mask, value):.  
+000116b0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+000116c0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+000116d0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+000116e0: 206f 7574 7075 7420 3d20 696e 7075 745f   output = input_
+000116f0: 6d73 2e6d 6173 6b65 645f 6669 6c6c 286d  ms.masked_fill(m
+00011700: 6173 6b2e 626f 6f6c 2829 2c20 7661 6c75  ask.bool(), valu
+00011710: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
+00011720: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00011730: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00011740: 0a0a 2020 2020 6465 6620 6d61 736b 6564  ..    def masked
+00011750: 5f66 696c 6c5f 2873 656c 662c 206d 6173  _fill_(self, mas
+00011760: 6b2c 2076 616c 7565 293a 0a20 2020 2020  k, value):.     
+00011770: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
+00011780: 2e6d 6173 6b65 645f 6669 6c6c 286d 6173  .masked_fill(mas
+00011790: 6b2c 2076 616c 7565 290a 2020 2020 2020  k, value).      
+000117a0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+000117b0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+000117c0: 7365 6c66 2c20 6f75 7470 7574 2c20 226d  self, output, "m
+000117d0: 6173 6b65 645f 6669 6c6c 5f22 2c20 226d  asked_fill_", "m
+000117e0: 6173 6b65 645f 6669 6c6c 2229 0a0a 2020  asked_fill")..  
+000117f0: 2020 6465 6620 746f 6c69 7374 2873 656c    def tolist(sel
+00011800: 6629 3a0a 2020 2020 2020 2020 7265 7475  f):.        retu
+00011810: 726e 2073 656c 662e 6e75 6d70 7928 292e  rn self.numpy().
+00011820: 746f 6c69 7374 2829 0a0a 2020 2020 6465  tolist()..    de
+00011830: 6620 6265 726e 6f75 6c6c 6928 7365 6c66  f bernoulli(self
+00011840: 2c20 2a2c 2067 656e 6572 6174 6f72 3d4e  , *, generator=N
+00011850: 6f6e 6529 3a0a 2020 2020 2020 2020 7265  one):.        re
+00011860: 7475 726e 2073 656c 662e 5f62 6572 6e6f  turn self._berno
+00011870: 756c 6c69 5f61 6461 7074 6572 2873 656c  ulli_adapter(sel
+00011880: 662c 2067 656e 6572 6174 6f72 3d67 656e  f, generator=gen
+00011890: 6572 6174 6f72 290a 0a20 2020 2064 6566  erator)..    def
+000118a0: 2062 6572 6e6f 756c 6c69 5f28 7365 6c66   bernoulli_(self
+000118b0: 2c20 703d 302e 352c 202a 2c20 6765 6e65  , p=0.5, *, gene
+000118c0: 7261 746f 723d 4e6f 6e65 293a 0a20 2020  rator=None):.   
+000118d0: 2020 2020 206f 7574 7075 7420 3d20 7365       output = se
+000118e0: 6c66 2e5f 6265 726e 6f75 6c6c 695f 6164  lf._bernoulli_ad
+000118f0: 6170 7465 7228 702c 2067 656e 6572 6174  apter(p, generat
+00011900: 6f72 3d67 656e 6572 6174 6f72 290a 2020  or=generator).  
+00011910: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+00011920: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+00011930: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+00011940: 2c20 2262 6572 6e6f 756c 6c69 5f22 2c20  , "bernoulli_", 
+00011950: 225f 6265 726e 6f75 6c6c 695f 6164 6170  "_bernoulli_adap
+00011960: 7465 7222 290a 0a20 2020 2064 6566 205f  ter")..    def _
+00011970: 6265 726e 6f75 6c6c 695f 6164 6170 7465  bernoulli_adapte
+00011980: 7228 7365 6c66 2c20 703d 302e 352c 202a  r(self, p=0.5, *
+00011990: 2c20 6765 6e65 7261 746f 723d 4e6f 6e65  , generator=None
+000119a0: 293a 0a20 2020 2020 2020 2069 6620 6765  ):.        if ge
+000119b0: 6e65 7261 746f 723a 0a20 2020 2020 2020  nerator:.       
+000119c0: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
+000119d0: 706c 656d 656e 7465 6445 7272 6f72 2822  plementedError("
+000119e0: 6765 6e65 7261 746f 7220 6973 206e 6f74  generator is not
+000119f0: 2073 7570 706f 7274 6564 2e22 290a 2020   supported.").  
+00011a00: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00011a10: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00011a20: 6f72 2873 656c 6629 0a0a 2020 2020 2020  or(self)..      
+00011a30: 2020 6265 726e 6f75 6c6c 695f 7365 6564    bernoulli_seed
+00011a40: 203d 206d 732e 6765 745f 7365 6564 2829   = ms.get_seed()
+00011a50: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
+00011a60: 6265 726e 6f75 6c6c 695f 7365 6564 3a0a  bernoulli_seed:.
+00011a70: 2020 2020 2020 2020 2020 2020 6265 726e              bern
+00011a80: 6f75 6c6c 695f 7365 6564 203d 202d 310a  oulli_seed = -1.
+00011a90: 2020 2020 2020 2020 6966 206e 6f74 2069          if not i
+00011aa0: 7369 6e73 7461 6e63 6528 702c 2028 5465  sinstance(p, (Te
+00011ab0: 6e73 6f72 2c20 666c 6f61 7429 293a 0a20  nsor, float)):. 
+00011ac0: 2020 2020 2020 2020 2020 2070 203d 2066             p = f
+00011ad0: 6c6f 6174 2870 290a 2020 2020 2020 2020  loat(p).        
+00011ae0: 2354 4f44 4f3a 2041 7363 656e 6420 6375  #TODO: Ascend cu
+00011af0: 7272 656e 746c 7920 6e6f 7420 7375 7070  rrently not supp
+00011b00: 6f72 7420 6f70 732e 6265 726e 6f75 6c6c  ort ops.bernoull
+00011b10: 692c 2075 7365 206e 756d 7079 2e72 616e  i, use numpy.ran
+00011b20: 646f 6d2e 6269 6e6f 6d69 616c 0a20 2020  dom.binomial.   
+00011b30: 2020 2020 2069 6620 6973 5f75 6e64 6572       if is_under
+00011b40: 5f61 7363 656e 645f 636f 6e74 6578 7428  _ascend_context(
+00011b50: 293a 0a20 2020 2020 2020 2020 2020 2069  ):.            i
+00011b60: 6620 6973 696e 7374 616e 6365 2870 2c20  f isinstance(p, 
+00011b70: 6d73 2e54 656e 736f 7229 3a0a 2020 2020  ms.Tensor):.    
+00011b80: 2020 2020 2020 2020 2020 2020 7020 3d20              p = 
+00011b90: 702e 6e75 6d70 7928 290a 2020 2020 2020  p.numpy().      
+00011ba0: 2020 2020 2020 2320 6f6e 2041 7363 656e        # on Ascen
+00011bb0: 642c 2075 7365 206e 756d 7079 2062 696e  d, use numpy bin
+00011bc0: 6f6d 6961 6c20 746f 2064 6f20 666f 7277  omial to do forw
+00011bd0: 6172 6420 636f 6d70 7574 6174 696f 6e0a  ard computation.
+00011be0: 2020 2020 2020 2020 2020 2020 2320 6865              # he
+00011bf0: 7265 2069 7420 646f 6573 6e27 7420 6e65  re it doesn't ne
+00011c00: 6564 2074 6f20 636f 6e73 6964 6572 2074  ed to consider t
+00011c10: 6865 2062 6163 6b77 6172 640a 2020 2020  he backward.    
+00011c20: 2020 2020 2020 2020 2320 6265 6361 7573          # becaus
+00011c30: 6520 746f 7263 682e 6265 726e 6f75 6c6c  e torch.bernoull
+00011c40: 6920 7265 7475 726e 207a 6572 6f20 6772  i return zero gr
+00011c50: 6164 2c20 616e 6420 6d69 6e64 7370 6f72  ad, and mindspor
+00011c60: 6520 7265 7475 726e 207a 6572 6f20 6772  e return zero gr
+00011c70: 6164 2068 6572 6520 6173 2077 656c 6c2e  ad here as well.
+00011c80: 0a20 2020 2020 2020 2020 2020 206e 705f  .            np_
+00011c90: 6f75 7470 7574 203d 206e 702e 7261 6e64  output = np.rand
+00011ca0: 6f6d 2e62 696e 6f6d 6961 6c28 312c 2070  om.binomial(1, p
+00011cb0: 2c20 7369 7a65 3d69 6e70 7574 5f6d 732e  , size=input_ms.
+00011cc0: 7368 6170 6529 0a20 2020 2020 2020 2020  shape).         
+00011cd0: 2020 206f 7574 7075 7420 3d20 6d73 2e54     output = ms.T
+00011ce0: 656e 736f 722e 6672 6f6d 5f6e 756d 7079  ensor.from_numpy
+00011cf0: 286e 705f 6f75 7470 7574 292e 746f 2864  (np_output).to(d
+00011d00: 7479 7065 3d69 6e70 7574 5f6d 732e 6474  type=input_ms.dt
+00011d10: 7970 6529 0a20 2020 2020 2020 2020 2020  ype).           
+00011d20: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+00011d30: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+00011d40: 7574 7075 7429 0a20 2020 2020 2020 2065  utput).        e
+00011d50: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00011d60: 2070 203d 2063 6173 745f 746f 5f6d 735f   p = cast_to_ms_
+00011d70: 7465 6e73 6f72 2870 290a 2020 2020 2020  tensor(p).      
+00011d80: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00011d90: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00011da0: 736f 7228 696e 7075 745f 6d73 2e62 6572  sor(input_ms.ber
+00011db0: 6e6f 756c 6c69 2870 2c20 6265 726e 6f75  noulli(p, bernou
+00011dc0: 6c6c 695f 7365 6564 2929 0a0a 2020 2020  lli_seed))..    
+00011dd0: 6465 6620 726f 756e 6428 7365 6c66 2c20  def round(self, 
+00011de0: 6465 6369 6d61 6c73 3d30 293a 0a20 2020  decimals=0):.   
+00011df0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00011e00: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00011e10: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00011e20: 2320 544f 444f 3a20 6166 7465 7220 6d73  # TODO: after ms
+00011e30: 2e6f 7073 2e72 6f75 6e64 2829 2073 7570  .ops.round() sup
+00011e40: 706f 7274 2060 6465 6369 6d61 6c73 602c  port `decimals`,
+00011e50: 2063 6861 6e67 6520 636f 6465 2062 656c   change code bel
+00011e60: 6f77 2e0a 2020 2020 2020 2020 6966 2064  ow..        if d
+00011e70: 6563 696d 616c 7320 3d3d 2030 3a0a 2020  ecimals == 0:.  
+00011e80: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00011e90: 203d 206d 732e 6f70 732e 726f 756e 6428   = ms.ops.round(
+00011ea0: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
+00011eb0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00011ec0: 2020 2020 7020 3d20 3130 202a 2a20 6465      p = 10 ** de
+00011ed0: 6369 6d61 6c73 0a20 2020 2020 2020 2020  cimals.         
+00011ee0: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
+00011ef0: 7075 745f 6d73 202a 2070 0a20 2020 2020  put_ms * p.     
+00011f00: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00011f10: 6d73 2e6f 7073 2e72 6f75 6e64 2869 6e70  ms.ops.round(inp
+00011f20: 7574 5f6d 7329 202f 2070 0a20 2020 2020  ut_ms) / p.     
+00011f30: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00011f40: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00011f50: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00011f60: 6620 726f 756e 645f 2873 656c 662c 2064  f round_(self, d
+00011f70: 6563 696d 616c 733d 3029 3a0a 2020 2020  ecimals=0):.    
+00011f80: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+00011f90: 662e 726f 756e 6428 6465 6369 6d61 6c73  f.round(decimals
+00011fa0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00011fb0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+00011fc0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+00011fd0: 7470 7574 2c20 2272 6f75 6e64 5f22 2c20  tput, "round_", 
+00011fe0: 2272 6f75 6e64 2229 0a0a 2020 2020 6465  "round")..    de
+00011ff0: 6620 6c6f 6e67 2873 656c 662c 206d 656d  f long(self, mem
+00012000: 6f72 795f 666f 726d 6174 3d4e 6f6e 6529  ory_format=None)
+00012010: 3a0a 2020 2020 2020 2020 756e 7375 7070  :.        unsupp
+00012020: 6f72 7465 645f 6174 7472 286d 656d 6f72  orted_attr(memor
+00012030: 795f 666f 726d 6174 290a 2020 2020 2020  y_format).      
+00012040: 2020 6966 206d 656d 6f72 795f 666f 726d    if memory_form
+00012050: 6174 3a0a 2020 2020 2020 2020 2020 2020  at:.            
+00012060: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
+00012070: 6e74 6564 4572 726f 7228 226d 656d 6f72  ntedError("memor
+00012080: 795f 666f 726d 6174 2069 7320 6e6f 7420  y_format is not 
+00012090: 7375 7070 6f72 7465 642e 2229 0a20 2020  supported.").   
+000120a0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+000120b0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+000120c0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+000120d0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+000120e0: 6461 7074 6572 5f74 656e 736f 7228 696e  dapter_tensor(in
+000120f0: 7075 745f 6d73 2e61 7374 7970 6528 5f64  put_ms.astype(_d
+00012100: 7479 7065 4469 6374 5b22 6c6f 6e67 225d  typeDict["long"]
+00012110: 2929 0a0a 2020 2020 6465 6620 6861 6c66  ))..    def half
+00012120: 2873 656c 662c 206d 656d 6f72 795f 666f  (self, memory_fo
+00012130: 726d 6174 3d4e 6f6e 6529 3a0a 2020 2020  rmat=None):.    
+00012140: 2020 2020 756e 7375 7070 6f72 7465 645f      unsupported_
+00012150: 6174 7472 286d 656d 6f72 795f 666f 726d  attr(memory_form
+00012160: 6174 290a 2020 2020 2020 2020 6966 206d  at).        if m
+00012170: 656d 6f72 795f 666f 726d 6174 3a0a 2020  emory_format:.  
+00012180: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00012190: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
+000121a0: 726f 7228 226d 656d 6f72 795f 666f 726d  ror("memory_form
+000121b0: 6174 2069 7320 6e6f 7420 7375 7070 6f72  at is not suppor
+000121c0: 7465 642e 2229 0a20 2020 2020 2020 2069  ted.").        i
+000121d0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+000121e0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+000121f0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00012200: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00012210: 5f74 656e 736f 7228 696e 7075 745f 6d73  _tensor(input_ms
+00012220: 2e61 7374 7970 6528 5f64 7479 7065 4469  .astype(_dtypeDi
+00012230: 6374 5b22 6861 6c66 225d 2929 0a0a 2020  ct["half"]))..  
+00012240: 2020 6465 6620 696e 7428 7365 6c66 2c20    def int(self, 
+00012250: 6d65 6d6f 7279 5f66 6f72 6d61 743d 4e6f  memory_format=No
+00012260: 6e65 293a 0a20 2020 2020 2020 2075 6e73  ne):.        uns
+00012270: 7570 706f 7274 6564 5f61 7474 7228 6d65  upported_attr(me
+00012280: 6d6f 7279 5f66 6f72 6d61 7429 0a20 2020  mory_format).   
+00012290: 2020 2020 2069 6620 6d65 6d6f 7279 5f66       if memory_f
+000122a0: 6f72 6d61 743a 0a20 2020 2020 2020 2020  ormat:.         
+000122b0: 2020 2072 6169 7365 204e 6f74 496d 706c     raise NotImpl
+000122c0: 656d 656e 7465 6445 7272 6f72 2822 6d65  ementedError("me
+000122d0: 6d6f 7279 5f66 6f72 6d61 7420 6973 206e  mory_format is n
+000122e0: 6f74 2073 7570 706f 7274 6564 2e22 290a  ot supported.").
+000122f0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00012300: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00012310: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00012320: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00012330: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00012340: 2869 6e70 7574 5f6d 732e 696e 7428 2929  (input_ms.int())
+00012350: 0a0a 2020 2020 6465 6620 646f 7562 6c65  ..    def double
+00012360: 2873 656c 662c 206d 656d 6f72 795f 666f  (self, memory_fo
+00012370: 726d 6174 3d4e 6f6e 6529 3a0a 2020 2020  rmat=None):.    
+00012380: 2020 2020 756e 7375 7070 6f72 7465 645f      unsupported_
+00012390: 6174 7472 286d 656d 6f72 795f 666f 726d  attr(memory_form
+000123a0: 6174 290a 2020 2020 2020 2020 6966 206d  at).        if m
+000123b0: 656d 6f72 795f 666f 726d 6174 3a0a 2020  emory_format:.  
+000123c0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+000123d0: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
+000123e0: 726f 7228 226d 656d 6f72 795f 666f 726d  ror("memory_form
+000123f0: 6174 2069 7320 6e6f 7420 7375 7070 6f72  at is not suppor
+00012400: 7465 642e 2229 0a20 2020 2020 2020 2069  ted.").        i
+00012410: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+00012420: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00012430: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00012440: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00012450: 5f74 656e 736f 7228 696e 7075 745f 6d73  _tensor(input_ms
+00012460: 2e61 7374 7970 6528 5f64 7479 7065 4469  .astype(_dtypeDi
+00012470: 6374 5b22 646f 7562 6c65 225d 2929 0a0a  ct["double"]))..
+00012480: 2020 2020 6465 6620 6368 6172 2873 656c      def char(sel
+00012490: 662c 206d 656d 6f72 795f 666f 726d 6174  f, memory_format
+000124a0: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
+000124b0: 756e 7375 7070 6f72 7465 645f 6174 7472  unsupported_attr
+000124c0: 286d 656d 6f72 795f 666f 726d 6174 290a  (memory_format).
+000124d0: 2020 2020 2020 2020 6966 206d 656d 6f72          if memor
+000124e0: 795f 666f 726d 6174 3a0a 2020 2020 2020  y_format:.      
+000124f0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+00012500: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+00012510: 226d 656d 6f72 795f 666f 726d 6174 2069  "memory_format i
+00012520: 7320 6e6f 7420 7375 7070 6f72 7465 642e  s not supported.
+00012530: 2229 0a20 2020 2020 2020 2069 6e70 7574  ").        input
+00012540: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+00012550: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+00012560: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00012570: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00012580: 736f 7228 696e 7075 745f 6d73 2e61 7374  sor(input_ms.ast
+00012590: 7970 6528 5f64 7479 7065 4469 6374 5b22  ype(_dtypeDict["
+000125a0: 6368 6172 225d 2929 0a0a 2020 2020 6465  char"]))..    de
+000125b0: 6620 6279 7465 2873 656c 662c 206d 656d  f byte(self, mem
+000125c0: 6f72 795f 666f 726d 6174 3d4e 6f6e 6529  ory_format=None)
+000125d0: 3a0a 2020 2020 2020 2020 756e 7375 7070  :.        unsupp
+000125e0: 6f72 7465 645f 6174 7472 286d 656d 6f72  orted_attr(memor
+000125f0: 795f 666f 726d 6174 290a 2020 2020 2020  y_format).      
+00012600: 2020 6966 206d 656d 6f72 795f 666f 726d    if memory_form
+00012610: 6174 3a0a 2020 2020 2020 2020 2020 2020  at:.            
+00012620: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
+00012630: 6e74 6564 4572 726f 7228 226d 656d 6f72  ntedError("memor
+00012640: 795f 666f 726d 6174 2069 7320 6e6f 7420  y_format is not 
+00012650: 7375 7070 6f72 7465 642e 2229 0a20 2020  supported.").   
+00012660: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00012670: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00012680: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00012690: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+000126a0: 6461 7074 6572 5f74 656e 736f 7228 696e  dapter_tensor(in
+000126b0: 7075 745f 6d73 2e61 7374 7970 6528 5f64  put_ms.astype(_d
+000126c0: 7479 7065 4469 6374 5b22 6279 7465 225d  typeDict["byte"]
+000126d0: 2929 0a0a 2020 2020 6465 6620 7368 6f72  ))..    def shor
+000126e0: 7428 7365 6c66 2c20 6d65 6d6f 7279 5f66  t(self, memory_f
+000126f0: 6f72 6d61 743d 4e6f 6e65 293a 0a20 2020  ormat=None):.   
+00012700: 2020 2020 2075 6e73 7570 706f 7274 6564       unsupported
+00012710: 5f61 7474 7228 6d65 6d6f 7279 5f66 6f72  _attr(memory_for
+00012720: 6d61 7429 0a20 2020 2020 2020 2069 6620  mat).        if 
+00012730: 6d65 6d6f 7279 5f66 6f72 6d61 743a 0a20  memory_format:. 
+00012740: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00012750: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+00012760: 7272 6f72 2822 6d65 6d6f 7279 5f66 6f72  rror("memory_for
+00012770: 6d61 7420 6973 206e 6f74 2073 7570 706f  mat is not suppo
+00012780: 7274 6564 2e22 290a 2020 2020 2020 2020  rted.").        
+00012790: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+000127a0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+000127b0: 6629 0a20 2020 2020 2020 2072 6574 7572  f).        retur
+000127c0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+000127d0: 725f 7465 6e73 6f72 2869 6e70 7574 5f6d  r_tensor(input_m
+000127e0: 732e 6173 7479 7065 285f 6474 7970 6544  s.astype(_dtypeD
+000127f0: 6963 745b 2273 686f 7274 225d 2929 0a0a  ict["short"]))..
+00012800: 0a20 2020 2064 6566 2063 6875 6e6b 2873  .    def chunk(s
+00012810: 656c 662c 2063 6875 6e6b 732c 2064 696d  elf, chunks, dim
+00012820: 3d30 293a 0a20 2020 2020 2020 2069 6e70  =0):.        inp
+00012830: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+00012840: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00012850: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00012860: 206d 732e 6f70 732e 6368 756e 6b28 696e   ms.ops.chunk(in
+00012870: 7075 745f 6d73 2c20 6368 756e 6b73 2c20  put_ms, chunks, 
+00012880: 6469 6d29 0a20 2020 2020 2020 2072 6574  dim).        ret
+00012890: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+000128a0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+000128b0: 7429 0a0a 2020 2020 6465 6620 666c 6174  t)..    def flat
+000128c0: 7465 6e28 7365 6c66 2c20 7374 6172 745f  ten(self, start_
+000128d0: 6469 6d3d 302c 2065 6e64 5f64 696d 3d2d  dim=0, end_dim=-
+000128e0: 3129 3a0a 2020 2020 2020 2020 696e 7075  1):.        inpu
+000128f0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+00012900: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00012910: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00012920: 6d73 2e6f 7073 2e66 6c61 7474 656e 2869  ms.ops.flatten(i
+00012930: 6e70 7574 5f6d 732c 206f 7264 6572 3d27  nput_ms, order='
+00012940: 4327 2c20 7374 6172 745f 6469 6d3d 7374  C', start_dim=st
+00012950: 6172 745f 6469 6d2c 2065 6e64 5f64 696d  art_dim, end_dim
+00012960: 3d65 6e64 5f64 696d 290a 2020 2020 2020  =end_dim).      
+00012970: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+00012980: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+00012990: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+000129a0: 2075 6e66 6c61 7474 656e 2873 656c 662c   unflatten(self,
+000129b0: 2064 696d 2c20 7369 7a65 7329 3a0a 2020   dim, sizes):.  
+000129c0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+000129d0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+000129e0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+000129f0: 206f 7574 5f73 6861 7065 203d 205f 6765   out_shape = _ge
+00012a00: 745f 756e 666c 6174 7465 6e5f 7369 7a65  t_unflatten_size
+00012a10: 2869 6e70 7574 5f6d 732e 7368 6170 652c  (input_ms.shape,
+00012a20: 2064 696d 2c20 7369 7a65 7329 0a20 2020   dim, sizes).   
+00012a30: 2020 2020 206f 7574 203d 206d 732e 6f70       out = ms.op
+00012a40: 732e 7265 7368 6170 6528 696e 7075 745f  s.reshape(input_
+00012a50: 6d73 2c20 6f75 745f 7368 6170 6529 0a20  ms, out_shape). 
+00012a60: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00012a70: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00012a80: 6e73 6f72 286f 7574 290a 0a20 2020 2064  nsor(out)..    d
+00012a90: 6566 2073 696e 2873 656c 6629 3a0a 2020  ef sin(self):.  
+00012aa0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00012ab0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00012ac0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00012ad0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+00012ae0: 6164 6170 7465 725f 7465 6e73 6f72 286d  adapter_tensor(m
+00012af0: 732e 6f70 732e 7369 6e28 696e 7075 745f  s.ops.sin(input_
+00012b00: 6d73 2929 0a0a 2020 2020 6465 6620 7369  ms))..    def si
+00012b10: 6e5f 2873 656c 6629 3a0a 2020 2020 2020  n_(self):.      
+00012b20: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
+00012b30: 7369 6e28 290a 2020 2020 2020 2020 7265  sin().        re
+00012b40: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+00012b50: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+00012b60: 2c20 6f75 7470 7574 2c20 2273 696e 5f22  , output, "sin_"
+00012b70: 2c20 2273 696e 2229 0a0a 2020 2020 6465  , "sin")..    de
+00012b80: 6620 6765 2873 656c 662c 206f 7468 6572  f ge(self, other
+00012b90: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+00012ba0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+00012bb0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+00012bc0: 2020 2020 2020 6f74 6865 7220 3d20 6361        other = ca
+00012bd0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00012be0: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
+00012bf0: 7574 7075 7420 3d20 696e 7075 745f 6d73  utput = input_ms
+00012c00: 2e67 6528 6f74 6865 7229 0a20 2020 2020  .ge(other).     
+00012c10: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00012c20: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00012c30: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00012c40: 6620 6765 5f28 7365 6c66 2c20 6f74 6865  f ge_(self, othe
+00012c50: 7229 3a0a 2020 2020 2020 2020 6f75 7470  r):.        outp
+00012c60: 7574 203d 2073 656c 662e 6765 286f 7468  ut = self.ge(oth
+00012c70: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
+00012c80: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+00012c90: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+00012ca0: 6f75 7470 7574 2c20 2267 655f 222c 2022  output, "ge_", "
+00012cb0: 6765 2229 0a0a 2020 2020 6465 6620 6375  ge")..    def cu
+00012cc0: 6d73 756d 2873 656c 662c 2064 696d 2c20  msum(self, dim, 
+00012cd0: 6474 7970 653d 4e6f 6e65 293a 0a20 2020  dtype=None):.   
+00012ce0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00012cf0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00012d00: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00012d10: 6966 2064 7479 7065 2069 7320 6e6f 7420  if dtype is not 
+00012d20: 4e6f 6e65 3a0a 2020 2020 2020 2020 2020  None:.          
+00012d30: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
+00012d40: 7574 5f6d 732e 6173 7479 7065 2864 7479  ut_ms.astype(dty
+00012d50: 7065 290a 2020 2020 2020 2020 656c 6966  pe).        elif
+00012d60: 2069 6e70 7574 5f6d 732e 6474 7970 6520   input_ms.dtype 
+00012d70: 696e 206d 696e 6474 6f72 6368 5f64 7479  in mindtorch_dty
+00012d80: 7065 2e61 6c6c 5f69 6e74 5f74 7970 655f  pe.all_int_type_
+00012d90: 7769 7468 5f62 6f6f 6c3a 0a20 2020 2020  with_bool:.     
+00012da0: 2020 2020 2020 2023 2054 4f44 4f3a 206d         # TODO: m
+00012db0: 732e 6375 6d73 756d 206f 6e6c 7920 7375  s.cumsum only su
+00012dc0: 7070 6f72 7420 696e 7433 3220 6f6e 2041  pport int32 on A
+00012dd0: 7363 656e 640a 2020 2020 2020 2020 2020  scend.          
+00012de0: 2020 6474 7970 6520 3d20 6d73 7479 7065    dtype = mstype
+00012df0: 2e69 6e74 3332 2069 6620 6973 5f75 6e64  .int32 if is_und
+00012e00: 6572 5f61 7363 656e 645f 636f 6e74 6578  er_ascend_contex
+00012e10: 7428 2920 656c 7365 206d 7374 7970 652e  t() else mstype.
+00012e20: 696e 7436 340a 2020 2020 2020 2020 2020  int64.          
+00012e30: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
+00012e40: 7574 5f6d 732e 6173 7479 7065 2864 7479  ut_ms.astype(dty
+00012e50: 7065 290a 0a20 2020 2020 2020 2072 6573  pe)..        res
+00012e60: 203d 206d 732e 6f70 732e 6375 6d73 756d   = ms.ops.cumsum
+00012e70: 2869 6e70 7574 5f6d 732c 2064 696d 2c20  (input_ms, dim, 
+00012e80: 6474 7970 6529 0a20 2020 2020 2020 2072  dtype).        r
+00012e90: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00012ea0: 6170 7465 725f 7465 6e73 6f72 2872 6573  apter_tensor(res
+00012eb0: 290a 0a20 2020 2064 6566 2063 756d 7375  )..    def cumsu
+00012ec0: 6d5f 2873 656c 662c 2064 696d 2c20 6474  m_(self, dim, dt
+00012ed0: 7970 653d 4e6f 6e65 293a 0a20 2020 2020  ype=None):.     
+00012ee0: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
+00012ef0: 2e63 756d 7375 6d28 6469 6d2c 2064 7479  .cumsum(dim, dty
+00012f00: 7065 290a 2020 2020 2020 2020 7265 7475  pe).        retu
+00012f10: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+00012f20: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+00012f30: 6f75 7470 7574 2c20 2263 756d 7375 6d5f  output, "cumsum_
+00012f40: 222c 2022 6375 6d73 756d 2229 0a0a 2020  ", "cumsum")..  
+00012f50: 2020 6465 6620 6162 736f 6c75 7465 2873    def absolute(s
+00012f60: 656c 6629 3a0a 2020 2020 2020 2020 7265  elf):.        re
+00012f70: 7475 726e 2073 656c 662e 6162 7328 290a  turn self.abs().
+00012f80: 0a20 2020 2064 6566 2061 6273 6f6c 7574  .    def absolut
+00012f90: 655f 2873 656c 6629 3a0a 2020 2020 2020  e_(self):.      
+00012fa0: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
+00012fb0: 6162 7328 290a 2020 2020 2020 2020 7265  abs().        re
+00012fc0: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+00012fd0: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+00012fe0: 2c20 6f75 7470 7574 2c20 2261 6273 6f6c  , output, "absol
+00012ff0: 7574 655f 222c 2022 6162 736f 6c75 7465  ute_", "absolute
+00013000: 2229 0a0a 2020 2020 6465 6620 6163 6f73  ")..    def acos
+00013010: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00013020: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+00013030: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00013040: 6629 0a20 2020 2020 2020 2069 6620 696e  f).        if in
+00013050: 7075 745f 6d73 2e64 7479 7065 2069 6e20  put_ms.dtype in 
+00013060: 616c 6c5f 696e 745f 7479 7065 3a0a 2020  all_int_type:.  
+00013070: 2020 2020 2020 2020 2020 696e 7075 745f            input_
+00013080: 6d73 203d 2069 6e70 7574 5f6d 732e 6173  ms = input_ms.as
+00013090: 7479 7065 286d 7374 7970 652e 666c 6f61  type(mstype.floa
+000130a0: 7433 3229 0a20 2020 2020 2020 206f 7574  t32).        out
+000130b0: 7075 7420 3d20 6d73 2e6f 7073 2e61 636f  put = ms.ops.aco
+000130c0: 7328 696e 7075 745f 6d73 290a 2020 2020  s(input_ms).    
+000130d0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+000130e0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+000130f0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+00013100: 6566 2061 636f 735f 2873 656c 6629 3a0a  ef acos_(self):.
+00013110: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00013120: 2073 656c 662e 6163 6f73 2829 0a20 2020   self.acos().   
+00013130: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
+00013140: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
+00013150: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
+00013160: 2022 6163 6f73 5f22 2c20 2261 636f 7322   "acos_", "acos"
+00013170: 290a 0a20 2020 2064 6566 2061 7263 636f  )..    def arcco
+00013180: 7328 7365 6c66 293a 0a20 2020 2020 2020  s(self):.       
+00013190: 2072 6574 7572 6e20 7365 6c66 2e61 636f   return self.aco
+000131a0: 7328 290a 0a20 2020 2064 6566 2061 7263  s()..    def arc
+000131b0: 636f 735f 2873 656c 6629 3a0a 2020 2020  cos_(self):.    
+000131c0: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+000131d0: 662e 6163 6f73 2829 0a20 2020 2020 2020  f.acos().       
+000131e0: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+000131f0: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+00013200: 656c 662c 206f 7574 7075 742c 2022 6172  elf, output, "ar
+00013210: 6363 6f73 5f22 2c20 2261 7263 636f 7322  ccos_", "arccos"
+00013220: 290a 0a20 2020 2064 6566 2061 7369 6e68  )..    def asinh
+00013230: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00013240: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+00013250: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00013260: 6629 0a20 2020 2020 2020 2069 6620 696e  f).        if in
+00013270: 7075 745f 6d73 2e64 7479 7065 2069 6e20  put_ms.dtype in 
+00013280: 616c 6c5f 696e 745f 7479 7065 3a0a 2020  all_int_type:.  
+00013290: 2020 2020 2020 2020 2020 696e 7075 745f            input_
+000132a0: 6d73 203d 2069 6e70 7574 5f6d 732e 6173  ms = input_ms.as
+000132b0: 7479 7065 286d 7374 7970 652e 666c 6f61  type(mstype.floa
+000132c0: 7433 3229 0a20 2020 2020 2020 206f 7574  t32).        out
+000132d0: 7075 7420 3d20 6d73 2e6f 7073 2e61 7369  put = ms.ops.asi
+000132e0: 6e68 2869 6e70 7574 5f6d 7329 0a20 2020  nh(input_ms).   
+000132f0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00013300: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00013310: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00013320: 6465 6620 6173 696e 685f 2873 656c 6629  def asinh_(self)
+00013330: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
+00013340: 203d 2073 656c 662e 6173 696e 6828 290a   = self.asinh().
+00013350: 2020 2020 2020 2020 7265 7475 726e 205f          return _
+00013360: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
+00013370: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
+00013380: 7574 2c20 2261 7369 6e68 5f22 2c20 2261  ut, "asinh_", "a
+00013390: 7369 6e68 2229 0a0a 2020 2020 6465 6620  sinh")..    def 
+000133a0: 6174 616e 6828 7365 6c66 293a 0a20 2020  atanh(self):.   
+000133b0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+000133c0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+000133d0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+000133e0: 6966 2069 6e70 7574 5f6d 732e 6474 7970  if input_ms.dtyp
+000133f0: 6520 696e 2061 6c6c 5f69 6e74 5f74 7970  e in all_int_typ
+00013400: 653a 0a20 2020 2020 2020 2020 2020 2069  e:.            i
+00013410: 6e70 7574 5f6d 7320 3d20 696e 7075 745f  nput_ms = input_
+00013420: 6d73 2e61 7374 7970 6528 6d73 7479 7065  ms.astype(mstype
+00013430: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
+00013440: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+00013450: 732e 6174 616e 6828 696e 7075 745f 6d73  s.atanh(input_ms
+00013460: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00013470: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00013480: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+00013490: 0a20 2020 2064 6566 2061 7461 6e68 5f28  .    def atanh_(
+000134a0: 7365 6c66 293a 0a20 2020 2020 2020 206f  self):.        o
+000134b0: 7574 7075 7420 3d20 7365 6c66 2e61 7461  utput = self.ata
+000134c0: 6e68 2829 0a20 2020 2020 2020 2072 6574  nh().        ret
+000134d0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+000134e0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+000134f0: 206f 7574 7075 742c 2022 6174 616e 685f   output, "atanh_
+00013500: 222c 2022 6174 616e 6822 290a 0a20 2020  ", "atanh")..   
+00013510: 2064 6566 2061 6464 6364 6976 2873 656c   def addcdiv(sel
+00013520: 662c 2074 656e 736f 7231 2c20 7465 6e73  f, tensor1, tens
+00013530: 6f72 322c 202a 2c20 7661 6c75 653d 3129  or2, *, value=1)
+00013540: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+00013550: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00013560: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+00013570: 2020 2020 2074 656e 736f 7231 203d 2063       tensor1 = c
+00013580: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00013590: 2874 656e 736f 7231 290a 2020 2020 2020  (tensor1).      
+000135a0: 2020 7465 6e73 6f72 3220 3d20 6361 7374    tensor2 = cast
+000135b0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7465  _to_ms_tensor(te
+000135c0: 6e73 6f72 3229 0a20 2020 2020 2020 2069  nsor2).        i
+000135d0: 6620 6973 5f75 6e64 6572 5f61 7363 656e  f is_under_ascen
+000135e0: 645f 636f 6e74 6578 7428 293a 0a20 2020  d_context():.   
+000135f0: 2020 2020 2020 2020 2076 616c 7565 203d           value =
+00013600: 206d 732e 5465 6e73 6f72 2876 616c 7565   ms.Tensor(value
+00013610: 292e 6173 7479 7065 2869 6e70 7574 5f6d  ).astype(input_m
+00013620: 732e 6474 7970 6529 0a20 2020 2020 2020  s.dtype).       
+00013630: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00013640: 2e61 6464 6364 6976 2869 6e70 7574 5f6d  .addcdiv(input_m
+00013650: 732c 2074 656e 736f 7231 2c20 7465 6e73  s, tensor1, tens
+00013660: 6f72 322c 2076 616c 7565 290a 2020 2020  or2, value).    
+00013670: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+00013680: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00013690: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+000136a0: 6566 2061 6464 6364 6976 5f28 7365 6c66  ef addcdiv_(self
+000136b0: 2c20 7465 6e73 6f72 312c 2074 656e 736f  , tensor1, tenso
+000136c0: 7232 2c20 2a2c 2076 616c 7565 3d31 293a  r2, *, value=1):
+000136d0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+000136e0: 3d20 7365 6c66 2e61 6464 6364 6976 2874  = self.addcdiv(t
+000136f0: 656e 736f 7231 2c20 7465 6e73 6f72 322c  ensor1, tensor2,
+00013700: 2076 616c 7565 3d76 616c 7565 290a 2020   value=value).  
+00013710: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+00013720: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+00013730: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+00013740: 2c20 2261 6464 6364 6976 5f22 2c20 2261  , "addcdiv_", "a
+00013750: 6464 6364 6976 2229 0a0a 2020 2020 6465  ddcdiv")..    de
+00013760: 6620 6761 7468 6572 2873 656c 662c 2064  f gather(self, d
+00013770: 696d 2c20 696e 6465 7829 3a0a 2020 2020  im, index):.    
+00013780: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+00013790: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+000137a0: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
+000137b0: 6e64 6578 203d 2063 6173 745f 746f 5f6d  ndex = cast_to_m
+000137c0: 735f 7465 6e73 6f72 2869 6e64 6578 290a  s_tensor(index).
+000137d0: 2020 2020 2020 2020 696e 7075 745f 7368          input_sh
+000137e0: 6170 6520 3d20 696e 7075 745f 6d73 2e73  ape = input_ms.s
+000137f0: 6861 7065 0a20 2020 2020 2020 2069 6e64  hape.        ind
+00013800: 6578 5f73 6861 7065 203d 2069 6e64 6578  ex_shape = index
+00013810: 2e73 6861 7065 0a20 2020 2020 2020 2069  .shape.        i
+00013820: 6620 5f67 6174 6865 725f 6e6f 5f6e 6565  f _gather_no_nee
+00013830: 645f 7061 6464 696e 6728 696e 7075 745f  d_padding(input_
+00013840: 7368 6170 652c 2069 6e64 6578 5f73 6861  shape, index_sha
+00013850: 7065 2c20 6469 6d29 3a0a 2020 2020 2020  pe, dim):.      
+00013860: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00013870: 732e 6f70 732e 6761 7468 6572 5f65 6c65  s.ops.gather_ele
+00013880: 6d65 6e74 7328 696e 7075 745f 6d73 2c20  ments(input_ms, 
+00013890: 6469 6d2c 2069 6e64 6578 290a 2020 2020  dim, index).    
+000138a0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+000138b0: 2020 2020 2020 7061 6464 696e 675f 7061        padding_pa
+000138c0: 7474 6572 6e20 3d20 5f67 6174 6865 725f  ttern = _gather_
+000138d0: 6765 745f 7061 6464 696e 675f 7061 7474  get_padding_patt
+000138e0: 6572 6e28 696e 7075 745f 7368 6170 652c  ern(input_shape,
+000138f0: 2069 6e64 6578 5f73 6861 7065 2c20 6469   index_shape, di
+00013900: 6d29 0a20 2020 2020 2020 2020 2020 2070  m).            p
+00013910: 6164 6465 645f 696e 6465 7820 3d20 6d73  added_index = ms
+00013920: 2e6f 7073 2e70 6164 2869 6e64 6578 2c20  .ops.pad(index, 
+00013930: 7061 6464 696e 675f 7061 7474 6572 6e29  padding_pattern)
+00013940: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00013950: 7075 7420 3d20 6d73 2e6f 7073 2e67 6174  put = ms.ops.gat
+00013960: 6865 725f 656c 656d 656e 7473 2869 6e70  her_elements(inp
+00013970: 7574 5f6d 732c 2064 696d 2c20 7061 6464  ut_ms, dim, padd
+00013980: 6564 5f69 6e64 6578 290a 2020 2020 2020  ed_index).      
+00013990: 2020 2020 2020 696e 6465 785f 6d61 736b        index_mask
+000139a0: 203d 206d 732e 6f70 732e 7061 6428 6d73   = ms.ops.pad(ms
+000139b0: 2e6f 7073 2e6f 6e65 7328 696e 6465 785f  .ops.ones(index_
+000139c0: 7368 6170 6529 2c20 7061 6464 696e 675f  shape), padding_
+000139d0: 7061 7474 6572 6e29 2e61 7374 7970 6528  pattern).astype(
+000139e0: 6d73 2e62 6f6f 6c5f 290a 2020 2020 2020  ms.bool_).      
+000139f0: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
+00013a00: 7574 7075 745b 696e 6465 785f 6d61 736b  utput[index_mask
+00013a10: 5d2e 7265 7368 6170 6528 696e 6465 785f  ].reshape(index_
+00013a20: 7368 6170 6529 0a20 2020 2020 2020 2072  shape).        r
+00013a30: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00013a40: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00013a50: 7075 7429 0a0a 2020 2020 6465 6620 666d  put)..    def fm
+00013a60: 6f64 2873 656c 662c 2064 6976 6973 6f72  od(self, divisor
+00013a70: 293a 0a20 2020 2020 2020 2078 203d 2063  ):.        x = c
+00013a80: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00013a90: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+00013aa0: 7468 6572 203d 2063 6173 745f 746f 5f6d  ther = cast_to_m
+00013ab0: 735f 7465 6e73 6f72 2864 6976 6973 6f72  s_tensor(divisor
+00013ac0: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+00013ad0: 203d 206d 732e 6f70 732e 666d 6f64 2878   = ms.ops.fmod(x
+00013ae0: 2c20 6f74 6865 7229 0a20 2020 2020 2020  , other).       
+00013af0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+00013b00: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+00013b10: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+00013b20: 666d 6f64 5f28 7365 6c66 2c20 6469 7669  fmod_(self, divi
+00013b30: 736f 7229 3a0a 2020 2020 2020 2020 6f75  sor):.        ou
+00013b40: 7470 7574 203d 2073 656c 662e 666d 6f64  tput = self.fmod
+00013b50: 2864 6976 6973 6f72 290a 2020 2020 2020  (divisor).      
+00013b60: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+00013b70: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+00013b80: 7365 6c66 2c20 6f75 7470 7574 2c20 2266  self, output, "f
+00013b90: 6d6f 645f 222c 2022 666d 6f64 2229 0a0a  mod_", "fmod")..
+00013ba0: 2020 2020 6465 6620 6c74 2873 656c 662c      def lt(self,
+00013bb0: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
+00013bc0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+00013bd0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+00013be0: 6c66 290a 2020 2020 2020 2020 6f74 6865  lf).        othe
+00013bf0: 7220 3d20 6361 7374 5f74 6f5f 6d73 5f74  r = cast_to_ms_t
+00013c00: 656e 736f 7228 6f74 6865 7229 0a20 2020  ensor(other).   
+00013c10: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+00013c20: 2e6f 7073 2e6c 6573 7328 696e 7075 745f  .ops.less(input_
+00013c30: 6d73 2c20 6f74 6865 7229 0a20 2020 2020  ms, other).     
+00013c40: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00013c50: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00013c60: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00013c70: 6620 6c74 5f28 7365 6c66 2c20 6f74 6865  f lt_(self, othe
+00013c80: 7229 3a0a 2020 2020 2020 2020 6f75 7470  r):.        outp
+00013c90: 7574 203d 2073 656c 662e 6c74 286f 7468  ut = self.lt(oth
+00013ca0: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
+00013cb0: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+00013cc0: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+00013cd0: 6f75 7470 7574 2c20 226c 745f 222c 2022  output, "lt_", "
+00013ce0: 6c74 2229 0a0a 2020 2020 6465 6620 6c65  lt")..    def le
+00013cf0: 7373 2873 656c 662c 206f 7468 6572 293a  ss(self, other):
+00013d00: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00013d10: 7365 6c66 2e6c 7428 6f74 6865 7229 0a0a  self.lt(other)..
+00013d20: 2020 2020 6465 6620 6c65 7373 5f28 7365      def less_(se
+00013d30: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
+00013d40: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+00013d50: 662e 6c74 286f 7468 6572 290a 2020 2020  f.lt(other).    
+00013d60: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+00013d70: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+00013d80: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+00013d90: 226c 6573 735f 222c 2022 6c65 7373 2229  "less_", "less")
+00013da0: 0a0a 2020 2020 6465 6620 6c65 7373 5f65  ..    def less_e
+00013db0: 7175 616c 2873 656c 662c 206f 7468 6572  qual(self, other
+00013dc0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+00013dd0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+00013de0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+00013df0: 2020 2020 2020 6f74 6865 7220 3d20 6361        other = ca
+00013e00: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00013e10: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
+00013e20: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6c  utput = ms.ops.l
+00013e30: 6573 735f 6571 7561 6c28 696e 7075 745f  ess_equal(input_
+00013e40: 6d73 2c20 6f74 6865 7229 0a20 2020 2020  ms, other).     
+00013e50: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00013e60: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00013e70: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00013e80: 6620 6c65 7373 5f65 7175 616c 5f28 7365  f less_equal_(se
+00013e90: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
+00013ea0: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+00013eb0: 662e 6c65 7373 5f65 7175 616c 286f 7468  f.less_equal(oth
+00013ec0: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
+00013ed0: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+00013ee0: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+00013ef0: 6f75 7470 7574 2c20 226c 6573 735f 6571  output, "less_eq
+00013f00: 7561 6c5f 222c 2022 6c65 7373 5f65 7175  ual_", "less_equ
+00013f10: 616c 2229 0a0a 2020 2020 6465 6620 6e65  al")..    def ne
+00013f20: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
+00013f30: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+00013f40: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00013f50: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+00013f60: 2020 6f74 6865 7220 3d20 6361 7374 5f74    other = cast_t
+00013f70: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
+00013f80: 7229 0a20 2020 2020 2020 206f 7574 7075  r).        outpu
+00013f90: 7420 3d20 6d73 2e6f 7073 2e6e 6528 696e  t = ms.ops.ne(in
+00013fa0: 7075 745f 6d73 2c20 6f74 6865 7229 0a20  put_ms, other). 
+00013fb0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00013fc0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00013fd0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+00013fe0: 2020 6465 6620 6e65 5f28 7365 6c66 2c20    def ne_(self, 
+00013ff0: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
+00014000: 6f75 7470 7574 203d 2073 656c 662e 6e65  output = self.ne
+00014010: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
+00014020: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
+00014030: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
+00014040: 6c66 2c20 6f75 7470 7574 2c20 226e 655f  lf, output, "ne_
+00014050: 222c 2022 6e65 2229 0a0a 2020 2020 6465  ", "ne")..    de
+00014060: 6620 6e6f 745f 6571 7561 6c28 7365 6c66  f not_equal(self
+00014070: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+00014080: 2020 7265 7475 726e 2073 656c 662e 6e65    return self.ne
+00014090: 286f 7468 6572 290a 0a20 2020 2064 6566  (other)..    def
+000140a0: 206e 6f74 5f65 7175 616c 5f28 7365 6c66   not_equal_(self
+000140b0: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+000140c0: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
+000140d0: 6e65 286f 7468 6572 290a 2020 2020 2020  ne(other).      
+000140e0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+000140f0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+00014100: 7365 6c66 2c20 6f75 7470 7574 2c20 226e  self, output, "n
+00014110: 6f74 5f65 7175 616c 5f22 2c20 226e 6f74  ot_equal_", "not
+00014120: 5f65 7175 616c 2229 0a0a 2020 2020 6465  _equal")..    de
+00014130: 6620 6571 7561 6c28 7365 6c66 2c20 6f74  f equal(self, ot
+00014140: 6865 7229 3a0a 2020 2020 2020 2020 6966  her):.        if
+00014150: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
+00014160: 6f74 6865 722c 2054 656e 736f 7229 3a0a  other, Tensor):.
+00014170: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00014180: 6520 5661 6c75 6545 7272 6f72 2822 606f  e ValueError("`o
+00014190: 7468 6572 6020 6d75 7374 2062 6520 5465  ther` must be Te
+000141a0: 6e73 6f72 2229 0a20 2020 2020 2020 2078  nsor").        x
+000141b0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000141c0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+000141d0: 2020 2079 203d 2063 6173 745f 746f 5f6d     y = cast_to_m
+000141e0: 735f 7465 6e73 6f72 286f 7468 6572 290a  s_tensor(other).
+000141f0: 0a20 2020 2020 2020 2069 6620 782e 6474  .        if x.dt
+00014200: 7970 6520 213d 2079 2e64 7479 7065 3a0a  ype != y.dtype:.
+00014210: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00014220: 726e 2046 616c 7365 0a20 2020 2020 2020  rn False.       
+00014230: 2069 6620 782e 7368 6170 6520 3d3d 2079   if x.shape == y
+00014240: 2e73 6861 7065 3a0a 2020 2020 2020 2020  .shape:.        
+00014250: 2020 2020 7369 7a65 203d 2078 2e73 697a      size = x.siz
+00014260: 650a 2020 2020 2020 2020 2020 2020 6f75  e.            ou
+00014270: 7470 7574 203d 206d 732e 6f70 732e 6571  tput = ms.ops.eq
+00014280: 7561 6c28 782c 2079 290a 2020 2020 2020  ual(x, y).      
+00014290: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
+000142a0: 7574 7075 742e 7375 6d28 290a 2020 2020  utput.sum().    
+000142b0: 2020 2020 2020 2020 6966 206f 7574 7075          if outpu
+000142c0: 7420 3d3d 2073 697a 653a 0a20 2020 2020  t == size:.     
+000142d0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+000142e0: 6e20 5472 7565 0a20 2020 2020 2020 2072  n True.        r
+000142f0: 6574 7572 6e20 4661 6c73 650a 0a20 2020  eturn False..   
+00014300: 2064 6566 2067 7265 6174 6572 2873 656c   def greater(sel
+00014310: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
+00014320: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+00014330: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00014340: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
+00014350: 6865 7220 3d20 6361 7374 5f74 6f5f 6d73  her = cast_to_ms
+00014360: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
+00014370: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00014380: 6d73 2e6f 7073 2e67 7265 6174 6572 2869  ms.ops.greater(i
+00014390: 6e70 7574 5f6d 732c 206f 7468 6572 290a  nput_ms, other).
+000143a0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+000143b0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+000143c0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+000143d0: 2020 2064 6566 2067 7265 6174 6572 5f28     def greater_(
+000143e0: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
+000143f0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
+00014400: 656c 662e 6772 6561 7465 7228 6f74 6865  elf.greater(othe
+00014410: 7229 0a20 2020 2020 2020 2072 6574 7572  r).        retur
+00014420: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+00014430: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00014440: 7574 7075 742c 2022 6772 6561 7465 725f  utput, "greater_
+00014450: 222c 2022 6772 6561 7465 7222 290a 0a20  ", "greater").. 
+00014460: 2020 2064 6566 2067 7428 7365 6c66 2c20     def gt(self, 
+00014470: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
+00014480: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+00014490: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+000144a0: 6629 0a20 2020 2020 2020 206f 7468 6572  f).        other
+000144b0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000144c0: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
+000144d0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+000144e0: 6f70 732e 6774 2869 6e70 7574 5f6d 732c  ops.gt(input_ms,
+000144f0: 206f 7468 6572 290a 2020 2020 2020 2020   other).        
+00014500: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00014510: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00014520: 7470 7574 290a 0a20 2020 2064 6566 2067  tput)..    def g
+00014530: 745f 2873 656c 662c 206f 7468 6572 293a  t_(self, other):
+00014540: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+00014550: 3d20 7365 6c66 2e67 7265 6174 6572 286f  = self.greater(o
+00014560: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
+00014570: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+00014580: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+00014590: 2c20 6f75 7470 7574 2c20 2267 745f 222c  , output, "gt_",
+000145a0: 2022 6774 2229 0a0a 2020 2020 6465 6620   "gt")..    def 
+000145b0: 6772 6561 7465 725f 6571 7561 6c28 7365  greater_equal(se
+000145c0: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
+000145d0: 2020 2020 7820 3d20 6361 7374 5f74 6f5f      x = cast_to_
+000145e0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+000145f0: 2020 2020 2020 2020 7920 3d20 6361 7374          y = cast
+00014600: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
+00014610: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
+00014620: 7075 7420 3d20 6d73 2e6f 7073 2e67 7265  put = ms.ops.gre
+00014630: 6174 6572 5f65 7175 616c 2878 2c20 7929  ater_equal(x, y)
+00014640: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00014650: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00014660: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+00014670: 2020 2020 6465 6620 6772 6561 7465 725f      def greater_
+00014680: 6571 7561 6c5f 2873 656c 662c 206f 7468  equal_(self, oth
+00014690: 6572 293a 0a20 2020 2020 2020 206f 7574  er):.        out
+000146a0: 7075 7420 3d20 7365 6c66 2e67 7265 6174  put = self.great
+000146b0: 6572 5f65 7175 616c 286f 7468 6572 290a  er_equal(other).
+000146c0: 2020 2020 2020 2020 7265 7475 726e 205f          return _
+000146d0: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
+000146e0: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
+000146f0: 7574 2c20 2267 7265 6174 6572 5f65 7175  ut, "greater_equ
+00014700: 616c 5f22 2c20 2267 7265 6174 6572 5f65  al_", "greater_e
+00014710: 7175 616c 2229 0a0a 2020 2020 6465 6620  qual")..    def 
+00014720: 6172 676d 696e 2873 656c 662c 2064 696d  argmin(self, dim
+00014730: 3d4e 6f6e 652c 206b 6565 7064 696d 3d46  =None, keepdim=F
+00014740: 616c 7365 293a 0a20 2020 2020 2020 2069  alse):.        i
+00014750: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+00014760: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00014770: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+00014780: 203d 206d 732e 6f70 732e 6172 676d 696e   = ms.ops.argmin
+00014790: 2869 6e70 7574 5f6d 732c 2061 7869 733d  (input_ms, axis=
+000147a0: 6469 6d2c 206b 6565 7064 696d 733d 6b65  dim, keepdims=ke
+000147b0: 6570 6469 6d29 0a20 2020 2020 2020 2072  epdim).        r
+000147c0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+000147d0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+000147e0: 7075 7429 0a0a 2020 2020 6465 6620 6172  put)..    def ar
+000147f0: 676d 6178 2873 656c 662c 2064 696d 3d4e  gmax(self, dim=N
+00014800: 6f6e 652c 206b 6565 7064 696d 3d46 616c  one, keepdim=Fal
+00014810: 7365 2c20 6178 6973 3d4e 6f6e 6529 3a0a  se, axis=None):.
+00014820: 2020 2020 2020 2020 6966 2064 696d 2069          if dim i
+00014830: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+00014840: 2020 2020 6469 6d20 3d20 6178 6973 0a20      dim = axis. 
+00014850: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+00014860: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00014870: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+00014880: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+00014890: 732e 6172 676d 6178 2869 6e70 7574 5f6d  s.argmax(input_m
+000148a0: 732c 2064 696d 2c20 6b65 6570 6469 6d29  s, dim, keepdim)
+000148b0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000148c0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+000148d0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+000148e0: 2020 2020 6465 6620 7479 7065 2873 656c      def type(sel
+000148f0: 662c 2064 7479 7065 3d4e 6f6e 652c 206e  f, dtype=None, n
+00014900: 6f6e 5f62 6c6f 636b 696e 673d 4661 6c73  on_blocking=Fals
+00014910: 652c 202a 2a6b 7761 7267 7329 3a0a 2020  e, **kwargs):.  
+00014920: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
+00014930: 645f 6174 7472 286e 6f6e 5f62 6c6f 636b  d_attr(non_block
+00014940: 696e 6729 0a20 2020 2020 2020 2075 6e73  ing).        uns
+00014950: 7570 706f 7274 6564 5f61 7474 7228 6b77  upported_attr(kw
+00014960: 6172 6773 290a 2020 2020 2020 2020 6966  args).        if
+00014970: 2064 7479 7065 2069 7320 4e6f 6e65 3a0a   dtype is None:.
+00014980: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00014990: 726e 2027 746f 7263 682e 2720 2b20 5f67  rn 'torch.' + _g
+000149a0: 6574 5f74 7970 655f 6672 6f6d 5f64 7479  et_type_from_dty
+000149b0: 7065 2873 656c 662e 6474 7970 6529 0a0a  pe(self.dtype)..
+000149c0: 2020 2020 2020 2020 5f64 7479 7065 203d          _dtype =
+000149d0: 2020 5f67 6574 5f64 7479 7065 5f66 726f    _get_dtype_fro
+000149e0: 6d5f 7479 7065 2864 7479 7065 290a 2020  m_type(dtype).  
+000149f0: 2020 2020 2020 6966 205f 6474 7970 6520        if _dtype 
+00014a00: 3d3d 2073 656c 662e 6474 7970 653a 0a20  == self.dtype:. 
+00014a10: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00014a20: 6e20 7365 6c66 0a20 2020 2020 2020 2078  n self.        x
+00014a30: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00014a40: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00014a50: 2020 206f 7574 7075 7420 3d20 782e 6173     output = x.as
+00014a60: 7479 7065 285f 6474 7970 6529 0a20 2020  type(_dtype).   
+00014a70: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00014a80: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00014a90: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00014aa0: 6465 6620 7479 7065 5f61 7328 7365 6c66  def type_as(self
+00014ab0: 2c20 7465 6e73 6f72 293a 0a20 2020 2020  , tensor):.     
+00014ac0: 2020 2078 203d 2063 6173 745f 746f 5f6d     x = cast_to_m
+00014ad0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00014ae0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00014af0: 782e 6173 7479 7065 2874 656e 736f 722e  x.astype(tensor.
+00014b00: 6474 7970 6529 0a20 2020 2020 2020 2072  dtype).        r
+00014b10: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00014b20: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00014b30: 7075 7429 0a0a 2020 2020 6465 6620 6765  put)..    def ge
+00014b40: 745f 6465 7669 6365 2873 656c 6629 3a0a  t_device(self):.
+00014b50: 2020 2020 2020 2020 6966 2067 7261 7068          if graph
+00014b60: 5f6d 6f64 655f 636f 6e64 6974 696f 6e28  _mode_condition(
+00014b70: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+00014b80: 6574 7572 6e20 300a 2020 2020 2020 2020  eturn 0.        
+00014b90: 6966 206e 6f74 2067 6574 6174 7472 2873  if not getattr(s
+00014ba0: 656c 662c 2022 5f64 6576 6963 655f 696e  elf, "_device_in
+00014bb0: 6465 7822 2c20 4e6f 6e65 293a 0a20 2020  dex", None):.   
+00014bc0: 2020 2020 2020 2020 2069 6620 6973 5f75           if is_u
+00014bd0: 6e64 6572 5f63 7075 5f63 6f6e 7465 7874  nder_cpu_context
+00014be0: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+00014bf0: 2020 2020 696e 6465 7820 3d20 2d31 0a20      index = -1. 
+00014c00: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00014c10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014c20: 2069 6e64 6578 203d 206d 732e 636f 6e74   index = ms.cont
+00014c30: 6578 742e 6765 745f 636f 6e74 6578 7428  ext.get_context(
+00014c40: 2764 6576 6963 655f 6964 2729 0a20 2020  'device_id').   
+00014c50: 2020 2020 2020 2020 2073 656c 662e 5f64           self._d
+00014c60: 6576 6963 655f 696e 6465 7820 3d20 696e  evice_index = in
+00014c70: 6465 780a 2020 2020 2020 2020 7265 7475  dex.        retu
+00014c80: 726e 2073 656c 662e 5f64 6576 6963 655f  rn self._device_
+00014c90: 696e 6465 780a 0a20 2020 2064 6566 2062  index..    def b
+00014ca0: 6164 6462 6d6d 2873 656c 662c 2062 6174  addbmm(self, bat
+00014cb0: 6368 312c 2062 6174 6368 322c 202a 2c20  ch1, batch2, *, 
+00014cc0: 6265 7461 3d31 2c20 616c 7068 613d 3129  beta=1, alpha=1)
+00014cd0: 3a0a 2020 2020 2020 2020 7820 3d20 6361  :.        x = ca
+00014ce0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00014cf0: 7365 6c66 290a 2020 2020 2020 2020 6261  self).        ba
+00014d00: 7463 6831 203d 2063 6173 745f 746f 5f6d  tch1 = cast_to_m
+00014d10: 735f 7465 6e73 6f72 2862 6174 6368 3129  s_tensor(batch1)
+00014d20: 0a20 2020 2020 2020 2062 6174 6368 3220  .        batch2 
+00014d30: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00014d40: 736f 7228 6261 7463 6832 290a 2020 2020  sor(batch2).    
+00014d50: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00014d60: 6f70 732e 6261 6464 626d 6d28 782c 2062  ops.baddbmm(x, b
+00014d70: 6174 6368 312c 2062 6174 6368 322c 2062  atch1, batch2, b
+00014d80: 6574 612c 2061 6c70 6861 290a 2020 2020  eta, alpha).    
+00014d90: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+00014da0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00014db0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+00014dc0: 6566 2062 6164 6462 6d6d 5f28 7365 6c66  ef baddbmm_(self
+00014dd0: 2c20 6261 7463 6831 2c20 6261 7463 6832  , batch1, batch2
+00014de0: 2c20 2a2c 2062 6574 613d 312c 2061 6c70  , *, beta=1, alp
+00014df0: 6861 3d31 293a 0a20 2020 2020 2020 206f  ha=1):.        o
+00014e00: 7574 7075 7420 3d20 7365 6c66 2e62 6164  utput = self.bad
+00014e10: 6462 6d6d 2862 6174 6368 312c 2062 6174  dbmm(batch1, bat
+00014e20: 6368 322c 2062 6574 613d 6265 7461 2c20  ch2, beta=beta, 
+00014e30: 616c 7068 613d 616c 7068 6129 0a20 2020  alpha=alpha).   
+00014e40: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
+00014e50: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
+00014e60: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
+00014e70: 2022 6261 6464 626d 6d5f 222c 2022 6261   "baddbmm_", "ba
+00014e80: 6464 626d 6d22 290a 0a20 2020 2064 6566  ddbmm")..    def
+00014e90: 2074 6f70 6b28 7365 6c66 2c20 6b2c 2064   topk(self, k, d
+00014ea0: 696d 3d4e 6f6e 652c 206c 6172 6765 7374  im=None, largest
+00014eb0: 3d54 7275 652c 2073 6f72 7465 643d 5472  =True, sorted=Tr
+00014ec0: 7565 293a 0a20 2020 2020 2020 2069 6e70  ue):.        inp
+00014ed0: 7574 5f78 203d 2063 6173 745f 746f 5f6d  ut_x = cast_to_m
+00014ee0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00014ef0: 2020 2020 2020 2069 6620 6b20 3d3d 2030         if k == 0
+00014f00: 3a0a 2020 2020 2020 2020 2020 2020 7661  :.            va
+00014f10: 6c75 652c 2069 6e64 6963 6520 3d20 286d  lue, indice = (m
+00014f20: 732e 6f70 732e 7a65 726f 7328 2830 2c29  s.ops.zeros((0,)
+00014f30: 2c20 6474 7970 653d 696e 7075 745f 782e  , dtype=input_x.
+00014f40: 6474 7970 6529 2c20 6d73 2e6f 7073 2e7a  dtype), ms.ops.z
+00014f50: 6572 6f73 2828 302c 292c 2064 7479 7065  eros((0,), dtype
+00014f60: 3d6d 732e 696e 7433 3229 290a 2020 2020  =ms.int32)).    
+00014f70: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00014f80: 2020 2020 2020 7661 6c75 652c 2069 6e64        value, ind
+00014f90: 6963 6520 3d20 6d73 2e6f 7073 2e74 6f70  ice = ms.ops.top
+00014fa0: 6b28 696e 7075 745f 782c 206b 2c20 6469  k(input_x, k, di
+00014fb0: 6d2c 206c 6172 6765 7374 2c20 736f 7274  m, largest, sort
+00014fc0: 6564 290a 2020 2020 2020 2020 6966 2070  ed).        if p
+00014fd0: 796e 6174 6976 655f 6d6f 6465 5f63 6f6e  ynative_mode_con
+00014fe0: 6469 7469 6f6e 2829 3a0a 2020 2020 2020  dition():.      
+00014ff0: 2020 2020 2020 706f 696e 7420 3d20 7365        point = se
+00015000: 745f 6e61 6d65 5f74 7570 6c65 2827 746f  t_name_tuple('to
+00015010: 706b 2729 0a20 2020 2020 2020 2020 2020  pk').           
+00015020: 2072 6c74 203d 2070 6f69 6e74 2863 6173   rlt = point(cas
+00015030: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00015040: 736f 7228 7661 6c75 6529 2c20 6361 7374  sor(value), cast
+00015050: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00015060: 6f72 2869 6e64 6963 6529 290a 2020 2020  or(indice)).    
+00015070: 2020 2020 2020 2020 7265 7475 726e 2072          return r
+00015080: 6c74 0a20 2020 2020 2020 2072 6574 7572  lt.        retur
+00015090: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+000150a0: 725f 7465 6e73 6f72 2828 7661 6c75 652c  r_tensor((value,
+000150b0: 2069 6e64 6963 6529 290a 0a20 2020 2064   indice))..    d
+000150c0: 6566 206d 6178 696d 756d 2873 656c 662c  ef maximum(self,
+000150d0: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
+000150e0: 2078 203d 2063 6173 745f 746f 5f6d 735f   x = cast_to_ms_
+000150f0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+00015100: 2020 2020 2079 203d 2063 6173 745f 746f       y = cast_to
+00015110: 5f6d 735f 7465 6e73 6f72 286f 7468 6572  _ms_tensor(other
+00015120: 290a 2020 2020 2020 2020 2354 4f44 4f3a  ).        #TODO:
+00015130: 204e 414e 2069 7320 6469 6666 6572 656e   NAN is differen
+00015140: 740a 2020 2020 2020 2020 6f75 7470 7574  t.        output
+00015150: 203d 206d 732e 6f70 732e 6d61 7869 6d75   = ms.ops.maximu
+00015160: 6d28 782c 2079 290a 2020 2020 2020 2020  m(x, y).        
+00015170: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00015180: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00015190: 7470 7574 290a 0a20 2020 2064 6566 206d  tput)..    def m
+000151a0: 696e 696d 756d 2873 656c 662c 206f 7468  inimum(self, oth
+000151b0: 6572 293a 0a20 2020 2020 2020 2078 203d  er):.        x =
 000151c0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
 000151d0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-000151e0: 2069 6620 7365 6c66 2e64 7479 7065 2069   if self.dtype i
-000151f0: 6e20 6d73 6461 7074 6572 5f64 7479 7065  n msdapter_dtype
-00015200: 2e61 6c6c 5f69 6e74 5f74 7970 653a 0a20  .all_int_type:. 
-00015210: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00015220: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
-00015230: 7374 7970 6528 6d73 7479 7065 2e66 6c6f  stype(mstype.flo
-00015240: 6174 3332 290a 2020 2020 2020 2020 6f75  at32).        ou
-00015250: 7470 7574 203d 206d 732e 6f70 732e 6173  tput = ms.ops.as
-00015260: 696e 2869 6e70 7574 5f6d 7329 0a20 2020  in(input_ms).   
-00015270: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-00015280: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00015290: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-000152a0: 6465 6620 6173 696e 5f28 7365 6c66 293a  def asin_(self):
-000152b0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-000152c0: 3d20 7365 6c66 2e61 7369 6e28 290a 2020  = self.asin().  
-000152d0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-000152e0: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-000152f0: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-00015300: 2c20 2261 7369 6e5f 222c 2022 6173 696e  , "asin_", "asin
-00015310: 2229 0a0a 2020 2020 6465 6620 6174 616e  ")..    def atan
-00015320: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00015330: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00015340: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00015350: 6629 0a20 2020 2020 2020 2069 6620 696e  f).        if in
-00015360: 7075 745f 6d73 2e64 7479 7065 2069 6e20  put_ms.dtype in 
-00015370: 616c 6c5f 696e 745f 7479 7065 3a0a 2020  all_int_type:.  
-00015380: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00015390: 6d73 203d 2069 6e70 7574 5f6d 732e 6173  ms = input_ms.as
-000153a0: 7479 7065 286d 7374 7970 652e 666c 6f61  type(mstype.floa
-000153b0: 7433 3229 0a20 2020 2020 2020 206f 7574  t32).        out
-000153c0: 7075 7420 3d20 6d73 2e6f 7073 2e61 7461  put = ms.ops.ata
-000153d0: 6e28 696e 7075 745f 6d73 290a 2020 2020  n(input_ms).    
-000153e0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-000153f0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00015400: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00015410: 6566 2061 7461 6e5f 2873 656c 6629 3a0a  ef atan_(self):.
-00015420: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00015430: 2073 656c 662e 6174 616e 2829 0a20 2020   self.atan().   
-00015440: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
-00015450: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
-00015460: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
-00015470: 2022 6174 616e 5f22 2c20 2261 7461 6e22   "atan_", "atan"
-00015480: 290a 0a20 2020 2064 6566 2061 7461 6e32  )..    def atan2
-00015490: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-000154a0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-000154b0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-000154c0: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-000154d0: 2020 6f74 6865 7220 3d20 6361 7374 5f74    other = cast_t
-000154e0: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
-000154f0: 7229 0a20 2020 2020 2020 2069 6620 696e  r).        if in
-00015500: 7075 745f 6d73 2e64 7479 7065 2069 6e20  put_ms.dtype in 
-00015510: 616c 6c5f 696e 745f 7479 7065 3a0a 2020  all_int_type:.  
-00015520: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00015530: 6d73 203d 2069 6e70 7574 5f6d 732e 6173  ms = input_ms.as
-00015540: 7479 7065 286d 7374 7970 652e 666c 6f61  type(mstype.floa
-00015550: 7433 3229 0a20 2020 2020 2020 2020 2020  t32).           
-00015560: 206f 7468 6572 203d 206f 7468 6572 2e61   other = other.a
-00015570: 7374 7970 6528 6d73 7479 7065 2e66 6c6f  stype(mstype.flo
-00015580: 6174 3332 290a 2020 2020 2020 2020 6f75  at32).        ou
-00015590: 7470 7574 203d 206d 732e 6f70 732e 6174  tput = ms.ops.at
-000155a0: 616e 3228 696e 7075 745f 6d73 2c20 6f74  an2(input_ms, ot
-000155b0: 6865 7229 0a20 2020 2020 2020 2072 6574  her).        ret
-000155c0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-000155d0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-000155e0: 7429 0a0a 2020 2020 6465 6620 6174 616e  t)..    def atan
-000155f0: 325f 2873 656c 662c 206f 7468 6572 293a  2_(self, other):
-00015600: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00015610: 3d20 7365 6c66 2e61 7461 6e32 286f 7468  = self.atan2(oth
-00015620: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
-00015630: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
-00015640: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
-00015650: 6f75 7470 7574 2c20 2261 7461 6e32 5f22  output, "atan2_"
-00015660: 2c20 2261 7461 6e32 2229 0a0a 0a20 2020  , "atan2")...   
-00015670: 2064 6566 2063 6f75 6e74 5f6e 6f6e 7a65   def count_nonze
-00015680: 726f 2873 656c 662c 2064 696d 3d4e 6f6e  ro(self, dim=Non
-00015690: 6529 3a0a 2020 2020 2020 2020 696e 7075  e):.        inpu
-000156a0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-000156b0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-000156c0: 2020 2020 2020 2069 6620 6469 6d20 6973         if dim is
-000156d0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-000156e0: 2020 2064 696d 203d 2028 290a 2020 2020     dim = ().    
-000156f0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00015700: 6f70 732e 636f 756e 745f 6e6f 6e7a 6572  ops.count_nonzer
-00015710: 6f28 696e 7075 745f 6d73 2c20 6469 6d29  o(input_ms, dim)
-00015720: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00015730: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00015740: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00015750: 2020 2020 6465 6620 7363 6174 7465 7228      def scatter(
-00015760: 7365 6c66 2c20 6469 6d2c 2069 6e64 6578  self, dim, index
-00015770: 2c20 7372 632c 2072 6564 7563 653d 4e6f  , src, reduce=No
-00015780: 6e65 293a 0a20 2020 2020 2020 2069 6620  ne):.        if 
-00015790: 6e6f 7420 7265 6475 6365 3a0a 2020 2020  not reduce:.    
-000157a0: 2020 2020 2020 2020 7265 6475 6365 203d          reduce =
-000157b0: 2027 6e6f 6e65 270a 2020 2020 2020 2020   'none'.        
-000157c0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-000157d0: 2020 2320 544f 444f 3a20 746f 2073 7570    # TODO: to sup
-000157e0: 706f 7274 6564 2027 6d75 6c74 6970 6c79  ported 'multiply
-000157f0: 270a 2020 2020 2020 2020 2020 2020 6966  '.            if
-00015800: 2072 6564 7563 6520 6e6f 7420 696e 2028   reduce not in (
-00015810: 276e 6f6e 6527 2c20 2761 6464 2729 3a0a  'none', 'add'):.
-00015820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015830: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-00015840: 2822 466f 7220 7465 6e73 6f72 2e73 6361  ("For tensor.sca
-00015850: 7474 6572 206f 7220 7363 6174 7465 725f  tter or scatter_
-00015860: 2c20 6072 6564 7563 6560 206f 6e6c 7920  , `reduce` only 
-00015870: 7375 7070 6f72 7420 276e 6f6e 6527 2c20  support 'none', 
-00015880: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-00015890: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000158a0: 2020 2066 2227 6164 6427 2c20 6275 7420     f"'add', but 
-000158b0: 676f 7420 277b 7265 6475 6365 7d27 2e22  got '{reduce}'."
-000158c0: 290a 0a20 2020 2020 2020 2020 2020 2023  )..            #
-000158d0: 2054 4f44 4f3a 2061 6464 206e 6f74 2073   TODO: add not s
-000158e0: 7570 706f 7274 6564 206f 6e20 4173 6365  upported on Asce
-000158f0: 6e64 2079 6574 0a20 2020 2020 2020 2020  nd yet.         
-00015900: 2020 2069 6620 7265 6475 6365 203d 3d20     if reduce == 
-00015910: 2761 6464 2720 616e 6420 6973 5f75 6e64  'add' and is_und
-00015920: 6572 5f61 7363 656e 645f 636f 6e74 6578  er_ascend_contex
-00015930: 7428 293a 0a20 2020 2020 2020 2020 2020  t():.           
-00015940: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
-00015950: 706c 656d 656e 7465 6445 7272 6f72 2822  plementedError("
-00015960: 466f 7220 7465 6e73 6f72 2e73 6361 7474  For tensor.scatt
-00015970: 6572 206f 7220 7363 6174 7465 725f 2c20  er or scatter_, 
-00015980: 6072 6564 7563 6560 203d 3d20 2761 6464  `reduce` == 'add
-00015990: 2720 6e6f 7420 7375 7070 6f72 7465 6420  ' not supported 
-000159a0: 6f6e 2041 7363 656e 6422 290a 0a20 2020  on Ascend")..   
-000159b0: 2020 2020 2069 6e70 7574 5f6d 732c 2069       input_ms, i
-000159c0: 6e64 6578 2c20 7372 6320 3d20 6361 7374  ndex, src = cast
-000159d0: 5f74 6f5f 6d73 5f74 656e 736f 7228 2873  _to_ms_tensor((s
-000159e0: 656c 662c 2069 6e64 6578 2c20 7372 6329  elf, index, src)
-000159f0: 290a 0a20 2020 2020 2020 2069 6620 6973  )..        if is
-00015a00: 696e 7374 616e 6365 2873 7263 2c20 6e75  instance(src, nu
-00015a10: 6d62 6572 732e 4e75 6d62 6572 293a 0a20  mbers.Number):. 
-00015a20: 2020 2020 2020 2020 2020 2073 7263 203d             src =
-00015a30: 206d 732e 6f70 732e 7363 616c 6172 5f74   ms.ops.scalar_t
-00015a40: 6f5f 7465 6e73 6f72 2873 7263 2c20 6474  o_tensor(src, dt
-00015a50: 7970 653d 696e 7075 745f 6d73 2e64 7479  ype=input_ms.dty
-00015a60: 7065 290a 2020 2020 2020 2020 2020 2020  pe).            
-00015a70: 7372 6320 3d20 6d73 2e6f 7073 2e62 726f  src = ms.ops.bro
-00015a80: 6164 6361 7374 5f74 6f28 7372 632c 2069  adcast_to(src, i
-00015a90: 6e64 6578 2e73 6861 7065 290a 2020 2020  ndex.shape).    
-00015aa0: 2020 2020 656c 6966 2069 7369 6e73 7461      elif isinsta
-00015ab0: 6e63 6528 7372 632c 206d 732e 5465 6e73  nce(src, ms.Tens
-00015ac0: 6f72 293a 0a20 2020 2020 2020 2020 2020  or):.           
-00015ad0: 2073 7263 5f73 6861 7065 203d 2073 7263   src_shape = src
-00015ae0: 2e73 6861 7065 0a20 2020 2020 2020 2020  .shape.         
-00015af0: 2020 2069 6e64 6578 5f73 6861 7065 203d     index_shape =
-00015b00: 2069 6e64 6578 2e73 6861 7065 0a20 2020   index.shape.   
-00015b10: 2020 2020 2020 2020 2069 6620 7372 635f           if src_
-00015b20: 7368 6170 6520 213d 2069 6e64 6578 5f73  shape != index_s
-00015b30: 6861 7065 3a0a 2020 2020 2020 2020 2020  hape:.          
-00015b40: 2020 2020 2020 2320 544f 444f 0a20 2020        # TODO.   
-00015b50: 2020 2020 2020 2020 2020 2020 2072 6169               rai
-00015b60: 7365 204e 6f74 496d 706c 656d 656e 7465  se NotImplemente
-00015b70: 6445 7272 6f72 2822 466f 7220 7363 6174  dError("For scat
-00015b80: 7465 722c 206e 6f74 2073 7570 706f 7274  ter, not support
-00015b90: 2073 7263 2e73 6861 7065 2021 3d20 696e   src.shape != in
-00015ba0: 6465 782e 7368 6170 6520 7965 7422 290a  dex.shape yet").
-00015bb0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00015bc0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00015bd0: 5479 7065 4572 726f 7228 6622 466f 7220  TypeError(f"For 
-00015be0: 7363 6174 7465 722c 2060 7372 6360 206d  scatter, `src` m
-00015bf0: 7573 7420 6265 206e 756d 6265 7220 6f72  ust be number or
-00015c00: 2074 656e 736f 722c 2062 7574 2067 6f74   tensor, but got
-00015c10: 207b 7479 7065 2873 7263 297d 2229 0a0a   {type(src)}")..
-00015c20: 2020 2020 2020 2020 6966 2069 735f 756e          if is_un
-00015c30: 6465 725f 6173 6365 6e64 5f63 6f6e 7465  der_ascend_conte
-00015c40: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
-00015c50: 2020 696e 7075 745f 6474 7970 6520 3d20    input_dtype = 
-00015c60: 696e 7075 745f 6d73 2e64 7479 7065 0a20  input_ms.dtype. 
-00015c70: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00015c80: 5f6d 7320 3d20 5f61 7363 656e 645f 7465  _ms = _ascend_te
-00015c90: 6e73 6f72 5f67 656e 6572 616c 5f63 6173  nsor_general_cas
-00015ca0: 7428 696e 7075 745f 6d73 290a 2020 2020  t(input_ms).    
-00015cb0: 2020 2020 2020 2020 7372 6320 3d20 5f61          src = _a
-00015cc0: 7363 656e 645f 7465 6e73 6f72 5f67 656e  scend_tensor_gen
-00015cd0: 6572 616c 5f63 6173 7428 7372 6329 0a20  eral_cast(src). 
-00015ce0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-00015cf0: 7420 3d20 6d73 2e6f 7073 2e74 656e 736f  t = ms.ops.tenso
-00015d00: 725f 7363 6174 7465 725f 656c 656d 656e  r_scatter_elemen
-00015d10: 7473 2869 6e70 7574 5f6d 732c 2069 6e64  ts(input_ms, ind
-00015d20: 6578 2c20 7372 632c 2064 696d 2c20 7265  ex, src, dim, re
-00015d30: 6475 6365 290a 2020 2020 2020 2020 2020  duce).          
-00015d40: 2020 6f75 7470 7574 203d 206f 7574 7075    output = outpu
-00015d50: 742e 6173 7479 7065 2869 6e70 7574 5f64  t.astype(input_d
-00015d60: 7479 7065 290a 2020 2020 2020 2020 656c  type).        el
-00015d70: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00015d80: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-00015d90: 7465 6e73 6f72 5f73 6361 7474 6572 5f65  tensor_scatter_e
-00015da0: 6c65 6d65 6e74 7328 696e 7075 745f 6d73  lements(input_ms
-00015db0: 2c20 696e 6465 782c 2073 7263 2c20 6469  , index, src, di
-00015dc0: 6d2c 2072 6564 7563 6529 0a0a 2020 2020  m, reduce)..    
-00015dd0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00015de0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00015df0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00015e00: 6566 2073 6361 7474 6572 5f28 7365 6c66  ef scatter_(self
-00015e10: 2c20 6469 6d2c 2069 6e64 6578 2c20 7372  , dim, index, sr
-00015e20: 632c 2072 6564 7563 653d 4e6f 6e65 293a  c, reduce=None):
-00015e30: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00015e40: 3d20 7365 6c66 2e73 6361 7474 6572 2864  = self.scatter(d
-00015e50: 696d 2c20 696e 6465 782c 2073 7263 2c20  im, index, src, 
-00015e60: 7265 6475 6365 290a 2020 2020 2020 2020  reduce).        
-00015e70: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-00015e80: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-00015e90: 6c66 2c20 6f75 7470 7574 2c20 2273 6361  lf, output, "sca
-00015ea0: 7474 6572 5f22 2c20 2273 6361 7474 6572  tter_", "scatter
-00015eb0: 2229 0a0a 2020 2020 6465 6620 6163 6f73  ")..    def acos
-00015ec0: 6828 7365 6c66 293a 0a20 2020 2020 2020  h(self):.       
-00015ed0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00015ee0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00015ef0: 6c66 290a 2020 2020 2020 2020 6966 2069  lf).        if i
-00015f00: 6e70 7574 5f6d 732e 6474 7970 6520 696e  nput_ms.dtype in
-00015f10: 2061 6c6c 5f69 6e74 5f74 7970 653a 0a20   all_int_type:. 
-00015f20: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00015f30: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
-00015f40: 7374 7970 6528 6d73 7479 7065 2e66 6c6f  stype(mstype.flo
-00015f50: 6174 3332 290a 2020 2020 2020 2020 6f75  at32).        ou
-00015f60: 7470 7574 203d 206d 732e 6f70 732e 6163  tput = ms.ops.ac
-00015f70: 6f73 6828 696e 7075 745f 6d73 290a 2020  osh(input_ms).  
-00015f80: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00015f90: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00015fa0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-00015fb0: 2064 6566 2061 636f 7368 5f28 7365 6c66   def acosh_(self
-00015fc0: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
-00015fd0: 7420 3d20 7365 6c66 2e61 636f 7368 2829  t = self.acosh()
-00015fe0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00015ff0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-00016000: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-00016010: 7075 742c 2022 6163 6f73 685f 222c 2022  put, "acosh_", "
-00016020: 6163 6f73 6822 290a 0a20 2020 2064 6566  acosh")..    def
-00016030: 206e 6577 5f6f 6e65 7328 7365 6c66 2c20   new_ones(self, 
-00016040: 2a73 697a 652c 2064 7479 7065 3d4e 6f6e  *size, dtype=Non
-00016050: 652c 2064 6576 6963 653d 4e6f 6e65 2c20  e, device=None, 
-00016060: 7265 7175 6972 6573 5f67 7261 643d 4661  requires_grad=Fa
-00016070: 6c73 652c 206c 6179 6f75 743d 4e6f 6e65  lse, layout=None
-00016080: 2c20 7069 6e5f 6d65 6d6f 7279 3d46 616c  , pin_memory=Fal
-00016090: 7365 293a 0a20 2020 2020 2020 2075 6e73  se):.        uns
-000160a0: 7570 706f 7274 6564 5f61 7474 7228 6465  upported_attr(de
-000160b0: 7669 6365 290a 2020 2020 2020 2020 756e  vice).        un
-000160c0: 7375 7070 6f72 7465 645f 6174 7472 2872  supported_attr(r
-000160d0: 6571 7569 7265 735f 6772 6164 290a 2020  equires_grad).  
-000160e0: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
-000160f0: 645f 6174 7472 286c 6179 6f75 7429 0a20  d_attr(layout). 
-00016100: 2020 2020 2020 2075 6e73 7570 706f 7274         unsupport
-00016110: 6564 5f61 7474 7228 7069 6e5f 6d65 6d6f  ed_attr(pin_memo
-00016120: 7279 290a 0a20 2020 2020 2020 2069 6620  ry)..        if 
-00016130: 6474 7970 6520 6973 204e 6f6e 653a 0a20  dtype is None:. 
-00016140: 2020 2020 2020 2020 2020 2064 7479 7065             dtype
-00016150: 203d 2073 656c 662e 6474 7970 650a 0a20   = self.dtype.. 
-00016160: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-00016170: 616e 6365 2873 697a 655b 305d 2c20 2874  ance(size[0], (t
-00016180: 7570 6c65 2c20 6c69 7374 2929 3a0a 2020  uple, list)):.  
-00016190: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-000161a0: 203d 206d 732e 6f70 732e 6f6e 6573 282a   = ms.ops.ones(*
-000161b0: 7369 7a65 2c20 6474 7970 653d 6474 7970  size, dtype=dtyp
-000161c0: 6529 0a20 2020 2020 2020 2065 6c73 653a  e).        else:
-000161d0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-000161e0: 7075 7420 3d20 6d73 2e6f 7073 2e6f 6e65  put = ms.ops.one
-000161f0: 7328 7369 7a65 2c20 6474 7970 653d 6474  s(size, dtype=dt
-00016200: 7970 6529 0a0a 2020 2020 2020 2020 7265  ype)..        re
-00016210: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00016220: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-00016230: 7574 290a 0a20 2020 2064 6566 206e 6577  ut)..    def new
-00016240: 5f65 6d70 7479 2873 656c 662c 202a 7369  _empty(self, *si
-00016250: 7a65 2c20 6474 7970 653d 4e6f 6e65 2c20  ze, dtype=None, 
-00016260: 6c61 796f 7574 3d4e 6f6e 652c 0a20 2020  layout=None,.   
-00016270: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00016280: 6576 6963 653d 4e6f 6e65 2c20 7265 7175  evice=None, requ
-00016290: 6972 6573 5f67 7261 643d 4661 6c73 652c  ires_grad=False,
-000162a0: 2070 696e 5f6d 656d 6f72 793d 4661 6c73   pin_memory=Fals
-000162b0: 652c 0a20 2020 2020 2020 2020 2020 2020  e,.             
-000162c0: 2020 2020 206d 656d 6f72 795f 666f 726d       memory_form
-000162d0: 6174 3d4e 6f6e 6529 3a0a 2020 2020 2020  at=None):.      
-000162e0: 2020 756e 7375 7070 6f72 7465 645f 6174    unsupported_at
-000162f0: 7472 286c 6179 6f75 7429 0a20 2020 2020  tr(layout).     
-00016300: 2020 2075 6e73 7570 706f 7274 6564 5f61     unsupported_a
-00016310: 7474 7228 6465 7669 6365 290a 2020 2020  ttr(device).    
-00016320: 2020 2020 756e 7375 7070 6f72 7465 645f      unsupported_
-00016330: 6174 7472 2872 6571 7569 7265 735f 6772  attr(requires_gr
-00016340: 6164 290a 2020 2020 2020 2020 756e 7375  ad).        unsu
-00016350: 7070 6f72 7465 645f 6174 7472 2870 696e  pported_attr(pin
-00016360: 5f6d 656d 6f72 7929 0a20 2020 2020 2020  _memory).       
-00016370: 2075 6e73 7570 706f 7274 6564 5f61 7474   unsupported_att
-00016380: 7228 6d65 6d6f 7279 5f66 6f72 6d61 7429  r(memory_format)
-00016390: 0a20 2020 2020 2020 2069 6620 6474 7970  .        if dtyp
-000163a0: 6520 6973 204e 6f6e 653a 0a20 2020 2020  e is None:.     
-000163b0: 2020 2020 2020 2064 7479 7065 203d 2073         dtype = s
-000163c0: 656c 662e 6474 7970 650a 0a20 2020 2020  elf.dtype..     
-000163d0: 2020 205f 7369 7a65 203d 2073 697a 650a     _size = size.
-000163e0: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
-000163f0: 7461 6e63 6528 7369 7a65 5b30 5d2c 2028  tance(size[0], (
-00016400: 7475 706c 652c 206c 6973 7429 293a 0a20  tuple, list)):. 
-00016410: 2020 2020 2020 2020 2020 205f 7369 7a65             _size
-00016420: 203d 2073 697a 655b 305d 0a20 2020 2020   = size[0].     
-00016430: 2020 206f 7574 7075 7420 3d20 6d73 2e6e     output = ms.n
-00016440: 756d 7079 2e65 6d70 7479 285f 7369 7a65  umpy.empty(_size
-00016450: 2c20 6474 7970 6529 0a20 2020 2020 2020  , dtype).       
-00016460: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00016470: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00016480: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-00016490: 6164 6463 6d75 6c28 7365 6c66 2c20 7465  addcmul(self, te
-000164a0: 6e73 6f72 312c 2074 656e 736f 7232 2c20  nsor1, tensor2, 
-000164b0: 2a2c 2076 616c 7565 3d31 293a 0a20 2020  *, value=1):.   
-000164c0: 2020 2020 2023 546f 646f 3a20 7573 6520       #Todo: use 
-000164d0: 6d73 2e6f 7073 2e61 6464 636d 756c 2061  ms.ops.addcmul a
-000164e0: 6674 6572 2069 7420 6861 7320 6265 656e  fter it has been
-000164f0: 2066 6978 6564 0a20 2020 2020 2020 2069   fixed.        i
-00016500: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-00016510: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00016520: 290a 2020 2020 2020 2020 7465 6e73 6f72  ).        tensor
-00016530: 3120 3d20 6361 7374 5f74 6f5f 6d73 5f74  1 = cast_to_ms_t
-00016540: 656e 736f 7228 7465 6e73 6f72 3129 0a20  ensor(tensor1). 
-00016550: 2020 2020 2020 2074 656e 736f 7232 203d         tensor2 =
-00016560: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00016570: 6f72 2874 656e 736f 7232 290a 2020 2020  or(tensor2).    
-00016580: 2020 2020 6966 2069 735f 756e 6465 725f      if is_under_
-00016590: 6173 6365 6e64 5f63 6f6e 7465 7874 2829  ascend_context()
-000165a0: 3a0a 2020 2020 2020 2020 2020 2020 7661  :.            va
-000165b0: 6c75 6520 3d20 6d73 2e54 656e 736f 7228  lue = ms.Tensor(
-000165c0: 7661 6c75 6529 2e61 7374 7970 6528 696e  value).astype(in
-000165d0: 7075 745f 6d73 2e64 7479 7065 290a 2020  put_ms.dtype).  
-000165e0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-000165f0: 732e 6f70 732e 6164 6463 6d75 6c28 696e  s.ops.addcmul(in
-00016600: 7075 745f 6d73 2c20 7465 6e73 6f72 312c  put_ms, tensor1,
-00016610: 2074 656e 736f 7232 2c20 7661 6c75 6529   tensor2, value)
-00016620: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00016630: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00016640: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00016650: 2020 2020 6465 6620 6164 6463 6d75 6c5f      def addcmul_
-00016660: 2873 656c 662c 2074 656e 736f 7231 2c20  (self, tensor1, 
-00016670: 7465 6e73 6f72 322c 202a 2c20 7661 6c75  tensor2, *, valu
-00016680: 653d 3129 3a0a 2020 2020 2020 2020 6f75  e=1):.        ou
-00016690: 7470 7574 203d 2073 656c 662e 6164 6463  tput = self.addc
-000166a0: 6d75 6c28 7465 6e73 6f72 312c 2074 656e  mul(tensor1, ten
-000166b0: 736f 7232 2c20 7661 6c75 653d 7661 6c75  sor2, value=valu
-000166c0: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
-000166d0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-000166e0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-000166f0: 7574 7075 742c 2022 6164 6463 6d75 6c5f  utput, "addcmul_
-00016700: 222c 2022 6164 6463 6d75 6c22 290a 0a20  ", "addcmul").. 
-00016710: 2020 2064 6566 2061 7263 636f 7368 2873     def arccosh(s
-00016720: 656c 6629 3a0a 2020 2020 2020 2020 7265  elf):.        re
-00016730: 7475 726e 2073 656c 662e 6163 6f73 6828  turn self.acosh(
-00016740: 290a 0a20 2020 2064 6566 2061 7263 636f  )..    def arcco
-00016750: 7368 5f28 7365 6c66 293a 0a20 2020 2020  sh_(self):.     
-00016760: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-00016770: 2e61 636f 7368 2829 0a20 2020 2020 2020  .acosh().       
-00016780: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
-00016790: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
-000167a0: 656c 662c 206f 7574 7075 742c 2022 6172  elf, output, "ar
-000167b0: 6363 6f73 685f 222c 2022 6172 6363 6f73  ccosh_", "arccos
-000167c0: 6822 290a 0a20 2020 2064 6566 2061 7263  h")..    def arc
-000167d0: 7369 6e28 7365 6c66 293a 0a20 2020 2020  sin(self):.     
-000167e0: 2020 2072 6574 7572 6e20 7365 6c66 2e61     return self.a
-000167f0: 7369 6e28 290a 0a20 2020 2064 6566 2061  sin()..    def a
-00016800: 7263 7369 6e5f 2873 656c 6629 3a0a 2020  rcsin_(self):.  
-00016810: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-00016820: 656c 662e 6173 696e 2829 0a20 2020 2020  elf.asin().     
-00016830: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-00016840: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-00016850: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-00016860: 6172 6373 696e 5f22 2c20 2261 7263 7369  arcsin_", "arcsi
-00016870: 6e22 290a 0a20 2020 2064 6566 2061 7263  n")..    def arc
-00016880: 7461 6e28 7365 6c66 293a 0a20 2020 2020  tan(self):.     
-00016890: 2020 2072 6574 7572 6e20 7365 6c66 2e61     return self.a
-000168a0: 7461 6e28 290a 0a20 2020 2064 6566 2061  tan()..    def a
-000168b0: 7263 7461 6e5f 2873 656c 6629 3a0a 2020  rctan_(self):.  
-000168c0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-000168d0: 656c 662e 6174 616e 2829 0a20 2020 2020  elf.atan().     
-000168e0: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-000168f0: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-00016900: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-00016910: 6172 6374 616e 5f22 2c20 2261 7263 7461  arctan_", "arcta
-00016920: 6e22 290a 0a20 2020 2064 6566 2061 7263  n")..    def arc
-00016930: 7461 6e32 2873 656c 662c 206f 7468 6572  tan2(self, other
-00016940: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-00016950: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00016960: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00016970: 2020 2020 2020 6f74 6865 7220 3d20 6361        other = ca
-00016980: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00016990: 6f74 6865 7229 0a20 2020 2020 2020 2069  other).        i
-000169a0: 6620 696e 7075 745f 6d73 2e64 7479 7065  f input_ms.dtype
-000169b0: 2069 6e20 616c 6c5f 696e 745f 7479 7065   in all_int_type
-000169c0: 3a0a 2020 2020 2020 2020 2020 2020 696e  :.            in
-000169d0: 7075 745f 6d73 203d 2069 6e70 7574 5f6d  put_ms = input_m
-000169e0: 732e 6173 7479 7065 286d 7374 7970 652e  s.astype(mstype.
-000169f0: 666c 6f61 7433 3229 0a20 2020 2020 2020  float32).       
-00016a00: 2069 6620 6f74 6865 722e 6474 7970 6520   if other.dtype 
-00016a10: 696e 2061 6c6c 5f69 6e74 5f74 7970 653a  in all_int_type:
-00016a20: 0a20 2020 2020 2020 2020 2020 206f 7468  .            oth
-00016a30: 6572 203d 206f 7468 6572 2e61 7374 7970  er = other.astyp
-00016a40: 6528 6d73 7479 7065 2e66 6c6f 6174 3332  e(mstype.float32
-00016a50: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-00016a60: 203d 206d 732e 6f70 732e 6174 616e 3228   = ms.ops.atan2(
-00016a70: 696e 7075 745f 6d73 2c20 6f74 6865 7229  input_ms, other)
-00016a80: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00016a90: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00016aa0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00016ab0: 2020 2020 6465 6620 6172 6374 616e 325f      def arctan2_
-00016ac0: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-00016ad0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00016ae0: 7365 6c66 2e61 7263 7461 6e32 286f 7468  self.arctan2(oth
-00016af0: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
-00016b00: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
-00016b10: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
-00016b20: 6f75 7470 7574 2c20 2261 7263 7461 6e32  output, "arctan2
-00016b30: 5f22 2c20 2261 7263 7461 6e32 2229 0a0a  _", "arctan2")..
-00016b40: 2020 2020 6465 6620 6269 7477 6973 655f      def bitwise_
-00016b50: 6e6f 7428 7365 6c66 293a 0a20 2020 2020  not(self):.     
-00016b60: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-00016b70: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00016b80: 7365 6c66 290a 2020 2020 2020 2020 7479  self).        ty
-00016b90: 7065 203d 2069 6e70 7574 5f6d 732e 6474  pe = input_ms.dt
-00016ba0: 7970 650a 2020 2020 2020 2020 6966 2073  ype.        if s
-00016bb0: 7472 2874 7970 6529 2021 3d20 2742 6f6f  tr(type) != 'Boo
-00016bc0: 6c27 3a0a 2020 2020 2020 2020 2020 2020  l':.            
-00016bd0: 6f75 7470 7574 203d 2030 202d 2069 6e70  output = 0 - inp
-00016be0: 7574 5f6d 7320 2d20 310a 2020 2020 2020  ut_ms - 1.      
-00016bf0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-00016c00: 2020 2020 6f75 7470 7574 203d 2031 202d      output = 1 -
-00016c10: 2069 6e70 7574 5f6d 730a 2020 2020 2020   input_ms.      
-00016c20: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
-00016c30: 7574 7075 742e 6173 7479 7065 286d 732e  utput.astype(ms.
-00016c40: 626f 6f6c 5f29 0a20 2020 2020 2020 2072  bool_).        r
-00016c50: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00016c60: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00016c70: 7075 7429 0a0a 2020 2020 6465 6620 6269  put)..    def bi
-00016c80: 7477 6973 655f 6e6f 745f 2873 656c 6629  twise_not_(self)
-00016c90: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-00016ca0: 203d 2073 656c 662e 6269 7477 6973 655f   = self.bitwise_
-00016cb0: 6e6f 7428 7365 6c66 290a 2020 2020 2020  not(self).      
-00016cc0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
-00016cd0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
-00016ce0: 7365 6c66 2c20 6f75 7470 7574 2c20 2262  self, output, "b
-00016cf0: 6974 7769 7365 5f6e 6f74 5f22 2c20 2262  itwise_not_", "b
-00016d00: 6974 7769 7365 5f6e 6f74 2229 0a0a 2020  itwise_not")..  
-00016d10: 2020 6465 6620 6269 7477 6973 655f 616e    def bitwise_an
-00016d20: 6428 7365 6c66 2c20 6f74 6865 7229 3a0a  d(self, other):.
-00016d30: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00016d40: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00016d50: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00016d60: 2020 206f 7468 6572 203d 2063 6173 745f     other = cast_
-00016d70: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
-00016d80: 6572 290a 2020 2020 2020 2020 2354 4f44  er).        #TOD
-00016d90: 4f3a 2063 7572 7265 6e74 6c79 2062 6974  O: currently bit
-00016da0: 7769 7365 206f 7065 7261 7469 6f6e 7320  wise operations 
-00016db0: 6f6e 2041 7363 656e 6420 6e6f 7420 7375  on Ascend not su
-00016dc0: 7070 6f72 7420 626f 6f6c 2074 7970 650a  pport bool type.
-00016dd0: 2020 2020 2020 2020 6966 2069 735f 756e          if is_un
-00016de0: 6465 725f 6173 6365 6e64 5f63 6f6e 7465  der_ascend_conte
-00016df0: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
-00016e00: 2020 696e 7075 745f 6d73 2c20 6f74 6865    input_ms, othe
-00016e10: 722c 206f 7574 7075 745f 6474 7970 6520  r, output_dtype 
-00016e20: 3d20 6269 7477 6973 655f 6164 6170 7465  = bitwise_adapte
-00016e30: 7228 696e 7075 745f 6d73 2c20 6f74 6865  r(input_ms, othe
-00016e40: 7229 0a20 2020 2020 2020 2020 2020 206f  r).            o
-00016e50: 7574 7075 7420 3d20 6d73 2e6f 7073 2e62  utput = ms.ops.b
-00016e60: 6974 7769 7365 5f61 6e64 2869 6e70 7574  itwise_and(input
-00016e70: 5f6d 732c 206f 7468 6572 290a 2020 2020  _ms, other).    
-00016e80: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00016e90: 206f 7574 7075 742e 6173 7479 7065 286f   output.astype(o
-00016ea0: 7574 7075 745f 6474 7970 6529 0a20 2020  utput_dtype).   
-00016eb0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00016ec0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00016ed0: 6d73 2e6f 7073 2e62 6974 7769 7365 5f61  ms.ops.bitwise_a
-00016ee0: 6e64 2869 6e70 7574 5f6d 732c 206f 7468  nd(input_ms, oth
-00016ef0: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
-00016f00: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00016f10: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00016f20: 290a 0a20 2020 2064 6566 2062 6974 7769  )..    def bitwi
-00016f30: 7365 5f61 6e64 5f28 7365 6c66 2c20 6f74  se_and_(self, ot
-00016f40: 6865 7229 3a0a 2020 2020 2020 2020 6f75  her):.        ou
-00016f50: 7470 7574 203d 2073 656c 662e 6269 7477  tput = self.bitw
-00016f60: 6973 655f 616e 6428 6f74 6865 7229 0a20  ise_and(other). 
-00016f70: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-00016f80: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-00016f90: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-00016fa0: 742c 2022 6269 7477 6973 655f 616e 645f  t, "bitwise_and_
-00016fb0: 222c 2022 6269 7477 6973 655f 616e 6422  ", "bitwise_and"
-00016fc0: 290a 0a20 2020 2064 6566 2062 6974 7769  )..    def bitwi
-00016fd0: 7365 5f6f 7228 7365 6c66 2c20 6f74 6865  se_or(self, othe
-00016fe0: 7229 3a0a 2020 2020 2020 2020 696e 7075  r):.        inpu
-00016ff0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00017000: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00017010: 2020 2020 2020 206f 7468 6572 203d 2063         other = c
-00017020: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00017030: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
-00017040: 2354 4f44 4f3a 2063 7572 7265 6e74 6c79  #TODO: currently
-00017050: 2062 6974 7769 7365 206f 7065 7261 7469   bitwise operati
-00017060: 6f6e 7320 6f6e 2041 7363 656e 6420 6e6f  ons on Ascend no
-00017070: 7420 7375 7070 6f72 7420 626f 6f6c 2074  t support bool t
-00017080: 7970 650a 2020 2020 2020 2020 6966 2069  ype.        if i
-00017090: 735f 756e 6465 725f 6173 6365 6e64 5f63  s_under_ascend_c
-000170a0: 6f6e 7465 7874 2829 3a0a 2020 2020 2020  ontext():.      
-000170b0: 2020 2020 2020 696e 7075 745f 6d73 2c20        input_ms, 
-000170c0: 6f74 6865 722c 206f 7574 7075 745f 6474  other, output_dt
-000170d0: 7970 6520 3d20 6269 7477 6973 655f 6164  ype = bitwise_ad
-000170e0: 6170 7465 7228 696e 7075 745f 6d73 2c20  apter(input_ms, 
-000170f0: 6f74 6865 7229 0a20 2020 2020 2020 2020  other).         
-00017100: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
-00017110: 7073 2e62 6974 7769 7365 5f6f 7228 696e  ps.bitwise_or(in
-00017120: 7075 745f 6d73 2c20 6f74 6865 7229 0a20  put_ms, other). 
-00017130: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-00017140: 7420 3d20 6f75 7470 7574 2e61 7374 7970  t = output.astyp
-00017150: 6528 6f75 7470 7574 5f64 7479 7065 290a  e(output_dtype).
-00017160: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00017170: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00017180: 203d 206d 732e 6f70 732e 6269 7477 6973   = ms.ops.bitwis
-00017190: 655f 6f72 2869 6e70 7574 5f6d 732c 206f  e_or(input_ms, o
-000171a0: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
-000171b0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-000171c0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-000171d0: 7574 290a 0a20 2020 2064 6566 2062 6974  ut)..    def bit
-000171e0: 7769 7365 5f6f 725f 2873 656c 662c 206f  wise_or_(self, o
-000171f0: 7468 6572 293a 0a20 2020 2020 2020 206f  ther):.        o
-00017200: 7574 7075 7420 3d20 7365 6c66 2e62 6974  utput = self.bit
-00017210: 7769 7365 5f6f 7228 6f74 6865 7229 0a20  wise_or(other). 
-00017220: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-00017230: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-00017240: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-00017250: 742c 2022 6269 7477 6973 655f 6f72 5f22  t, "bitwise_or_"
-00017260: 2c20 2262 6974 7769 7365 5f6f 7222 290a  , "bitwise_or").
-00017270: 0a20 2020 2064 6566 2062 6974 7769 7365  .    def bitwise
-00017280: 5f78 6f72 2873 656c 662c 206f 7468 6572  _xor(self, other
-00017290: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-000172a0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-000172b0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-000172c0: 2020 2020 2020 6f74 6865 7220 3d20 6361        other = ca
-000172d0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-000172e0: 6f74 6865 7229 0a20 2020 2020 2020 2023  other).        #
-000172f0: 544f 444f 3a20 6375 7272 656e 746c 7920  TODO: currently 
-00017300: 6269 7477 6973 6520 6f70 6572 6174 696f  bitwise operatio
-00017310: 6e73 206f 6e20 4173 6365 6e64 206e 6f74  ns on Ascend not
-00017320: 2073 7570 706f 7274 2062 6f6f 6c20 7479   support bool ty
-00017330: 7065 0a20 2020 2020 2020 2069 6620 6973  pe.        if is
-00017340: 5f75 6e64 6572 5f61 7363 656e 645f 636f  _under_ascend_co
-00017350: 6e74 6578 7428 293a 0a20 2020 2020 2020  ntext():.       
-00017360: 2020 2020 2069 6e70 7574 5f6d 732c 206f       input_ms, o
-00017370: 7468 6572 2c20 6f75 7470 7574 5f64 7479  ther, output_dty
-00017380: 7065 203d 2062 6974 7769 7365 5f61 6461  pe = bitwise_ada
-00017390: 7074 6572 2869 6e70 7574 5f6d 732c 206f  pter(input_ms, o
-000173a0: 7468 6572 290a 2020 2020 2020 2020 2020  ther).          
-000173b0: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-000173c0: 732e 6269 7477 6973 655f 786f 7228 696e  s.bitwise_xor(in
-000173d0: 7075 745f 6d73 2c20 6f74 6865 7229 0a20  put_ms, other). 
-000173e0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-000173f0: 7420 3d20 6f75 7470 7574 2e61 7374 7970  t = output.astyp
-00017400: 6528 6f75 7470 7574 5f64 7479 7065 290a  e(output_dtype).
-00017410: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00017420: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00017430: 203d 206d 732e 6f70 732e 6269 7477 6973   = ms.ops.bitwis
-00017440: 655f 786f 7228 696e 7075 745f 6d73 2c20  e_xor(input_ms, 
-00017450: 6f74 6865 7229 0a20 2020 2020 2020 2072  other).        r
-00017460: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00017470: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00017480: 7075 7429 0a0a 2020 2020 6465 6620 6269  put)..    def bi
-00017490: 7477 6973 655f 786f 725f 2873 656c 662c  twise_xor_(self,
-000174a0: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
-000174b0: 206f 7574 7075 7420 3d20 7365 6c66 2e62   output = self.b
-000174c0: 6974 7769 7365 5f78 6f72 286f 7468 6572  itwise_xor(other
-000174d0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-000174e0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
-000174f0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
-00017500: 7470 7574 2c20 2262 6974 7769 7365 5f78  tput, "bitwise_x
-00017510: 6f72 5f22 2c20 2262 6974 7769 7365 5f78  or_", "bitwise_x
-00017520: 6f72 2229 0a0a 2020 2020 6465 6620 6164  or")..    def ad
-00017530: 6462 6d6d 2873 656c 662c 2062 6174 6368  dbmm(self, batch
-00017540: 312c 2062 6174 6368 322c 202a 2c20 6265  1, batch2, *, be
-00017550: 7461 3d31 2c20 616c 7068 613d 3129 3a0a  ta=1, alpha=1):.
-00017560: 2020 2020 2020 2020 5f69 6e70 7574 2c20          _input, 
-00017570: 5f62 6174 6368 312c 205f 6261 7463 6832  _batch1, _batch2
-00017580: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00017590: 6e73 6f72 2828 7365 6c66 2c20 6261 7463  nsor((self, batc
-000175a0: 6831 2c20 6261 7463 6832 2929 0a20 2020  h1, batch2)).   
-000175b0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-000175c0: 2e6f 7073 2e61 6464 626d 6d28 5f69 6e70  .ops.addbmm(_inp
-000175d0: 7574 2c20 5f62 6174 6368 312c 205f 6261  ut, _batch1, _ba
-000175e0: 7463 6832 2c20 6265 7461 3d62 6574 612c  tch2, beta=beta,
-000175f0: 2061 6c70 6861 3d61 6c70 6861 290a 2020   alpha=alpha).  
-00017600: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00017610: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00017620: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-00017630: 2064 6566 2061 6464 626d 6d5f 2873 656c   def addbmm_(sel
-00017640: 662c 2062 6174 6368 312c 2062 6174 6368  f, batch1, batch
-00017650: 322c 202a 2c20 6265 7461 3d31 2c20 616c  2, *, beta=1, al
-00017660: 7068 613d 3129 3a0a 2020 2020 2020 2020  pha=1):.        
-00017670: 6f75 7470 7574 203d 2073 656c 662e 6164  output = self.ad
-00017680: 6462 6d6d 2862 6174 6368 312c 2062 6174  dbmm(batch1, bat
-00017690: 6368 322c 2062 6574 613d 6265 7461 2c20  ch2, beta=beta, 
-000176a0: 616c 7068 613d 616c 7068 6129 0a20 2020  alpha=alpha).   
-000176b0: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
-000176c0: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
-000176d0: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
-000176e0: 2022 6164 6462 6d6d 5f22 2c20 2261 6464   "addbmm_", "add
-000176f0: 626d 6d22 290a 0a20 2020 2064 6566 2061  bmm")..    def a
-00017700: 6464 6d6d 2873 656c 662c 206d 6174 312c  ddmm(self, mat1,
-00017710: 206d 6174 322c 202a 2c20 6265 7461 3d31   mat2, *, beta=1
-00017720: 2c20 616c 7068 613d 3129 3a0a 2020 2020  , alpha=1):.    
-00017730: 2020 2020 5f69 6e70 7574 2c20 5f6d 6174      _input, _mat
-00017740: 312c 205f 6d61 7432 203d 2063 6173 745f  1, _mat2 = cast_
-00017750: 746f 5f6d 735f 7465 6e73 6f72 2828 7365  to_ms_tensor((se
-00017760: 6c66 2c20 6d61 7431 2c20 6d61 7432 2929  lf, mat1, mat2))
-00017770: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00017780: 3d20 6d73 2e6f 7073 2e61 6464 6d6d 285f  = ms.ops.addmm(_
-00017790: 696e 7075 742c 205f 6d61 7431 2c20 5f6d  input, _mat1, _m
-000177a0: 6174 322c 2062 6574 613d 6265 7461 2c20  at2, beta=beta, 
-000177b0: 616c 7068 613d 616c 7068 6129 0a20 2020  alpha=alpha).   
-000177c0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-000177d0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-000177e0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-000177f0: 6465 6620 6164 646d 6d5f 2873 656c 662c  def addmm_(self,
-00017800: 206d 6174 312c 206d 6174 322c 202a 2c20   mat1, mat2, *, 
-00017810: 6265 7461 3d31 2c20 616c 7068 613d 3129  beta=1, alpha=1)
-00017820: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-00017830: 203d 2073 656c 662e 6164 646d 6d28 6d61   = self.addmm(ma
-00017840: 7431 2c20 6d61 7432 2c20 6265 7461 3d62  t1, mat2, beta=b
-00017850: 6574 612c 2061 6c70 6861 3d61 6c70 6861  eta, alpha=alpha
-00017860: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00017870: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
-00017880: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
-00017890: 7470 7574 2c20 2261 6464 6d6d 5f22 2c20  tput, "addmm_", 
-000178a0: 2261 6464 6d6d 2229 0a0a 2020 2020 6465  "addmm")..    de
-000178b0: 6620 6164 6472 2873 656c 662c 2076 6563  f addr(self, vec
-000178c0: 312c 2076 6563 322c 202a 2c20 6265 7461  1, vec2, *, beta
-000178d0: 3d31 2c20 616c 7068 613d 3129 3a0a 2020  =1, alpha=1):.  
-000178e0: 2020 2020 2020 5f69 6e70 7574 2c20 5f76        _input, _v
-000178f0: 6563 312c 205f 7665 6332 203d 2063 6173  ec1, _vec2 = cas
-00017900: 745f 746f 5f6d 735f 7465 6e73 6f72 2828  t_to_ms_tensor((
-00017910: 7365 6c66 2c20 7665 6331 2c20 7665 6332  self, vec1, vec2
-00017920: 2929 0a20 2020 2020 2020 206f 7574 7075  )).        outpu
-00017930: 7420 3d20 6d73 2e6f 7073 2e61 6464 7228  t = ms.ops.addr(
-00017940: 5f69 6e70 7574 2c20 5f76 6563 312c 205f  _input, _vec1, _
-00017950: 7665 6332 2c20 6265 7461 3d62 6574 612c  vec2, beta=beta,
-00017960: 2061 6c70 6861 3d61 6c70 6861 290a 2020   alpha=alpha).  
-00017970: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00017980: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00017990: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-000179a0: 2064 6566 2061 6464 725f 2873 656c 662c   def addr_(self,
-000179b0: 2076 6563 312c 2076 6563 322c 202a 2c20   vec1, vec2, *, 
-000179c0: 6265 7461 3d31 2c20 616c 7068 613d 3129  beta=1, alpha=1)
-000179d0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-000179e0: 203d 2073 656c 662e 6164 6472 2876 6563   = self.addr(vec
-000179f0: 312c 2076 6563 322c 2062 6574 613d 6265  1, vec2, beta=be
-00017a00: 7461 2c20 616c 7068 613d 616c 7068 6129  ta, alpha=alpha)
-00017a10: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00017a20: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-00017a30: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-00017a40: 7075 742c 2022 6164 6472 5f22 2c20 2261  put, "addr_", "a
-00017a50: 6464 7222 290a 0a20 2020 2064 6566 2061  ddr")..    def a
-00017a60: 6c6c 2873 656c 662c 2064 696d 3d28 292c  ll(self, dim=(),
-00017a70: 206b 6565 7064 696d 3d46 616c 7365 293a   keepdim=False):
-00017a80: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-00017a90: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00017aa0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00017ab0: 2020 2020 2320 7465 6e73 6f72 2e61 6c6c      # tensor.all
-00017ac0: 206f 6e6c 7920 7375 7070 6f72 7420 626f   only support bo
-00017ad0: 6f6c 2064 7479 7065 0a20 2020 2020 2020  ol dtype.       
-00017ae0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-00017af0: 2e61 6c6c 2869 6e70 7574 5f6d 732c 2061  .all(input_ms, a
-00017b00: 7869 733d 6469 6d2c 206b 6565 705f 6469  xis=dim, keep_di
-00017b10: 6d73 3d6b 6565 7064 696d 290a 2020 2020  ms=keepdim).    
-00017b20: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00017b30: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00017b40: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00017b50: 6566 2069 7363 6c6f 7365 2873 656c 662c  ef isclose(self,
-00017b60: 206f 7468 6572 2c20 7274 6f6c 3d31 652d   other, rtol=1e-
-00017b70: 3035 2c20 6174 6f6c 3d31 652d 3038 2c20  05, atol=1e-08, 
-00017b80: 6571 7561 6c5f 6e61 6e3d 4661 6c73 6529  equal_nan=False)
-00017b90: 3a0a 2020 2020 2020 2020 5f69 6e70 7574  :.        _input
-00017ba0: 2c20 5f6f 7468 6572 203d 2063 6173 745f  , _other = cast_
-00017bb0: 746f 5f6d 735f 7465 6e73 6f72 2828 7365  to_ms_tensor((se
-00017bc0: 6c66 2c20 6f74 6865 7229 290a 2020 2020  lf, other)).    
-00017bd0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00017be0: 6f70 732e 6973 636c 6f73 6528 5f69 6e70  ops.isclose(_inp
-00017bf0: 7574 2c20 5f6f 7468 6572 2c20 7274 6f6c  ut, _other, rtol
-00017c00: 3d72 746f 6c2c 2061 746f 6c3d 6174 6f6c  =rtol, atol=atol
-00017c10: 2c20 6571 7561 6c5f 6e61 6e3d 6571 7561  , equal_nan=equa
-00017c20: 6c5f 6e61 6e29 0a20 2020 2020 2020 2072  l_nan).        r
-00017c30: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00017c40: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00017c50: 7075 7429 0a0a 2020 2020 6465 6620 616c  put)..    def al
-00017c60: 6c63 6c6f 7365 2873 656c 662c 206f 7468  lclose(self, oth
-00017c70: 6572 2c20 7274 6f6c 3d31 652d 3035 2c20  er, rtol=1e-05, 
-00017c80: 6174 6f6c 3d31 652d 3038 2c20 6571 7561  atol=1e-08, equa
-00017c90: 6c5f 6e61 6e3d 4661 6c73 6529 3a0a 2020  l_nan=False):.  
-00017ca0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-00017cb0: 656c 662e 6973 636c 6f73 6528 6f74 6865  elf.isclose(othe
-00017cc0: 722c 2072 746f 6c3d 7274 6f6c 2c20 6174  r, rtol=rtol, at
-00017cd0: 6f6c 3d61 746f 6c2c 2065 7175 616c 5f6e  ol=atol, equal_n
-00017ce0: 616e 3d65 7175 616c 5f6e 616e 290a 2020  an=equal_nan).  
-00017cf0: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
-00017d00: 7574 7075 742e 616c 6c28 290a 2020 2020  utput.all().    
-00017d10: 2020 2020 7265 7475 726e 206f 7574 7075      return outpu
-00017d20: 742e 6974 656d 2829 0a0a 2020 2020 6465  t.item()..    de
-00017d30: 6620 6368 6f6c 6573 6b79 2873 656c 662c  f cholesky(self,
-00017d40: 2075 7070 6572 3d46 616c 7365 293a 0a20   upper=False):. 
-00017d50: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00017d60: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00017d70: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00017d80: 2020 6f75 7470 7574 203d 2069 6e70 7574    output = input
-00017d90: 5f6d 732e 6368 6f6c 6573 6b79 2875 7070  _ms.cholesky(upp
-00017da0: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
-00017db0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00017dc0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00017dd0: 290a 0a20 2020 2064 6566 2063 686f 6c65  )..    def chole
-00017de0: 736b 795f 696e 7665 7273 6528 7365 6c66  sky_inverse(self
-00017df0: 2c20 7570 7065 723d 4661 6c73 6529 3a0a  , upper=False):.
-00017e00: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00017e10: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00017e20: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00017e30: 2020 2023 2054 4f44 4f3a 206d 732e 7465     # TODO: ms.te
-00017e40: 6e73 6f72 2e63 686f 6c65 736b 795f 696e  nsor.cholesky_in
-00017e50: 7665 7273 6520 6e6f 7420 7375 7070 6f72  verse not suppor
-00017e60: 7420 4750 552e 0a20 2020 2020 2020 206f  t GPU..        o
-00017e70: 7574 7075 7420 3d20 696e 7075 745f 6d73  utput = input_ms
-00017e80: 2e63 686f 6c65 736b 795f 696e 7665 7273  .cholesky_invers
-00017e90: 6528 7570 7065 7229 0a20 2020 2020 2020  e(upper).       
-00017ea0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00017eb0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00017ec0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-00017ed0: 6368 6f6c 6573 6b79 5f73 6f6c 7665 2873  cholesky_solve(s
-00017ee0: 656c 662c 2069 6e70 7574 322c 2075 7070  elf, input2, upp
-00017ef0: 6572 3d46 616c 7365 293a 0a20 2020 2020  er=False):.     
-00017f00: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-00017f10: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00017f20: 7365 6c66 290a 2020 2020 2020 2020 696e  self).        in
-00017f30: 7075 7432 203d 2063 6173 745f 746f 5f6d  put2 = cast_to_m
-00017f40: 735f 7465 6e73 6f72 2869 6e70 7574 3229  s_tensor(input2)
-00017f50: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00017f60: 3d20 6d73 2e6f 7073 2e63 686f 6c65 736b  = ms.ops.cholesk
-00017f70: 795f 736f 6c76 6528 696e 7075 745f 6d73  y_solve(input_ms
-00017f80: 2c20 696e 7075 7432 2c20 7570 7065 7229  , input2, upper)
-00017f90: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00017fa0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00017fb0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00017fc0: 2020 2020 6465 6620 6e65 6c65 6d65 6e74      def nelement
-00017fd0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00017fe0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00017ff0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00018000: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
-00018010: 7420 3d20 696e 7075 745f 6d73 2e6e 656c  t = input_ms.nel
-00018020: 656d 656e 7428 290a 2020 2020 2020 2020  ement().        
-00018030: 7265 7475 726e 206f 7574 7075 740a 0a20  return output.. 
-00018040: 2020 2064 6566 2061 6d69 6e6d 6178 2873     def aminmax(s
-00018050: 656c 662c 202a 2c20 6469 6d3d 4e6f 6e65  elf, *, dim=None
-00018060: 2c20 6b65 6570 6469 6d3d 4661 6c73 6529  , keepdim=False)
-00018070: 3a0a 2020 2020 2020 2020 5f69 6e70 7574  :.        _input
-00018080: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00018090: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-000180a0: 2020 205f 6d69 6e20 3d20 5f69 6e70 7574     _min = _input
-000180b0: 2e6d 696e 2861 7869 733d 6469 6d2c 206b  .min(axis=dim, k
-000180c0: 6565 7064 696d 733d 6b65 6570 6469 6d29  eepdims=keepdim)
-000180d0: 0a20 2020 2020 2020 205f 6d61 7820 3d20  .        _max = 
-000180e0: 5f69 6e70 7574 2e6d 6178 2861 7869 733d  _input.max(axis=
-000180f0: 6469 6d2c 206b 6565 7064 696d 733d 6b65  dim, keepdims=ke
-00018100: 6570 6469 6d29 0a20 2020 2020 2020 2072  epdim).        r
-00018110: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-00018120: 6170 7465 725f 7465 6e73 6f72 2828 5f6d  apter_tensor((_m
-00018130: 696e 2c20 5f6d 6178 2929 0a0a 2020 2020  in, _max))..    
-00018140: 6465 6620 616e 7928 7365 6c66 2c20 6469  def any(self, di
-00018150: 6d3d 2829 2c20 6b65 6570 6469 6d3d 4661  m=(), keepdim=Fa
-00018160: 6c73 6529 3a0a 2020 2020 2020 2020 696e  lse):.        in
-00018170: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-00018180: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00018190: 0a20 2020 2020 2020 2069 6620 696e 7075  .        if inpu
-000181a0: 745f 6d73 2e64 7479 7065 2021 3d20 6d73  t_ms.dtype != ms
-000181b0: 2e62 6f6f 6c5f 3a0a 2020 2020 2020 2020  .bool_:.        
-000181c0: 2020 2020 696e 7075 745f 6d73 203d 2069      input_ms = i
-000181d0: 6e70 7574 5f6d 732e 6173 7479 7065 286d  nput_ms.astype(m
-000181e0: 732e 626f 6f6c 5f29 0a20 2020 2020 2020  s.bool_).       
-000181f0: 206f 7574 7075 7420 3d20 696e 7075 745f   output = input_
-00018200: 6d73 2e61 6e79 2861 7869 733d 6469 6d2c  ms.any(axis=dim,
-00018210: 206b 6565 705f 6469 6d73 3d6b 6565 7064   keep_dims=keepd
-00018220: 696d 290a 2020 2020 2020 2020 7265 7475  im).        retu
-00018230: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00018240: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00018250: 290a 0a20 2020 2064 6566 2062 696e 636f  )..    def binco
-00018260: 756e 7428 7365 6c66 2c20 7765 6967 6874  unt(self, weight
-00018270: 733d 4e6f 6e65 2c20 6d69 6e6c 656e 6774  s=None, minlengt
-00018280: 683d 3029 3a0a 2020 2020 2020 2020 696e  h=0):.        in
-00018290: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-000182a0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-000182b0: 0a20 2020 2020 2020 2074 7970 6520 3d20  .        type = 
-000182c0: 2769 6e74 3634 270a 2020 2020 2020 2020  'int64'.        
-000182d0: 6966 2069 6e70 7574 5f6d 732e 6474 7970  if input_ms.dtyp
-000182e0: 6520 3d3d 206d 732e 7569 6e74 383a 0a20  e == ms.uint8:. 
-000182f0: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00018300: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
-00018310: 7374 7970 6528 6d73 2e69 6e74 3136 290a  stype(ms.int16).
-00018320: 2020 2020 2020 2020 6966 2077 6569 6768          if weigh
-00018330: 7473 2069 7320 6e6f 7420 4e6f 6e65 3a0a  ts is not None:.
-00018340: 2020 2020 2020 2020 2020 2020 7765 6967              weig
-00018350: 6874 7320 3d20 6361 7374 5f74 6f5f 6d73  hts = cast_to_ms
-00018360: 5f74 656e 736f 7228 7765 6967 6874 7329  _tensor(weights)
-00018370: 0a20 2020 2020 2020 2020 2020 2074 7970  .            typ
-00018380: 6520 3d20 7765 6967 6874 732e 6474 7970  e = weights.dtyp
-00018390: 650a 2020 2020 2020 2020 6f75 7470 7574  e.        output
-000183a0: 203d 206d 732e 6f70 732e 6269 6e63 6f75   = ms.ops.bincou
-000183b0: 6e74 2869 6e70 7574 5f6d 732c 2077 6569  nt(input_ms, wei
-000183c0: 6768 7473 2c20 6d69 6e6c 656e 6774 6829  ghts, minlength)
-000183d0: 2e61 7374 7970 6528 7479 7065 290a 2020  .astype(type).  
-000183e0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-000183f0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00018400: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-00018410: 2064 6566 2062 6974 7769 7365 5f6c 6566   def bitwise_lef
-00018420: 745f 7368 6966 7428 7365 6c66 2c20 6f74  t_shift(self, ot
-00018430: 6865 7229 3a0a 2020 2020 2020 2020 696e  her):.        in
-00018440: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-00018450: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00018460: 0a20 2020 2020 2020 206f 7468 6572 203d  .        other =
-00018470: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00018480: 6f72 286f 7468 6572 290a 2020 2020 2020  or(other).      
-00018490: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-000184a0: 732e 6269 7477 6973 655f 6c65 6674 5f73  s.bitwise_left_s
-000184b0: 6869 6674 2869 6e70 7574 5f6d 732c 206f  hift(input_ms, o
-000184c0: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
-000184d0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-000184e0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-000184f0: 7574 290a 0a20 2020 2064 6566 2062 6974  ut)..    def bit
-00018500: 7769 7365 5f6c 6566 745f 7368 6966 745f  wise_left_shift_
-00018510: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-00018520: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00018530: 7365 6c66 2e62 6974 7769 7365 5f6c 6566  self.bitwise_lef
-00018540: 745f 7368 6966 7428 6f74 6865 7229 0a20  t_shift(other). 
-00018550: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-00018560: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-00018570: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-00018580: 742c 2022 6269 7477 6973 655f 6c65 6674  t, "bitwise_left
-00018590: 5f73 6869 6674 5f22 2c20 2262 6974 7769  _shift_", "bitwi
-000185a0: 7365 5f6c 6566 745f 7368 6966 7422 290a  se_left_shift").
-000185b0: 0a20 2020 2064 6566 2062 6974 7769 7365  .    def bitwise
-000185c0: 5f72 6967 6874 5f73 6869 6674 2873 656c  _right_shift(sel
-000185d0: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
-000185e0: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-000185f0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00018600: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
-00018610: 6865 7220 3d20 6361 7374 5f74 6f5f 6d73  her = cast_to_ms
-00018620: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
-00018630: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00018640: 6d73 2e6f 7073 2e62 6974 7769 7365 5f72  ms.ops.bitwise_r
-00018650: 6967 6874 5f73 6869 6674 2869 6e70 7574  ight_shift(input
-00018660: 5f6d 732c 206f 7468 6572 290a 2020 2020  _ms, other).    
-00018670: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00018680: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00018690: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-000186a0: 6566 2062 6974 7769 7365 5f72 6967 6874  ef bitwise_right
-000186b0: 5f73 6869 6674 5f28 7365 6c66 2c20 6f74  _shift_(self, ot
-000186c0: 6865 7229 3a0a 2020 2020 2020 2020 6f75  her):.        ou
-000186d0: 7470 7574 203d 2073 656c 662e 6269 7477  tput = self.bitw
-000186e0: 6973 655f 7269 6768 745f 7368 6966 7428  ise_right_shift(
-000186f0: 6f74 6865 7229 0a20 2020 2020 2020 2072  other).        r
-00018700: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
-00018710: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
-00018720: 662c 206f 7574 7075 742c 2022 6269 7477  f, output, "bitw
-00018730: 6973 655f 7269 6768 745f 7368 6966 745f  ise_right_shift_
-00018740: 222c 2022 6269 7477 6973 655f 7269 6768  ", "bitwise_righ
-00018750: 745f 7368 6966 7422 290a 0a20 2020 2064  t_shift")..    d
-00018760: 6566 2063 6c69 7028 7365 6c66 2c20 6d69  ef clip(self, mi
-00018770: 6e3d 4e6f 6e65 2c20 6d61 783d 4e6f 6e65  n=None, max=None
-00018780: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-00018790: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-000187a0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-000187b0: 2020 2020 2020 6f75 7470 7574 203d 2069        output = i
-000187c0: 6e70 7574 5f6d 732e 636c 6970 286d 696e  nput_ms.clip(min
-000187d0: 2c20 6d61 7829 0a20 2020 2020 2020 2072  , max).        r
-000187e0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-000187f0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-00018800: 7075 7429 0a0a 2020 2020 6465 6620 636c  put)..    def cl
-00018810: 6970 5f28 7365 6c66 2c20 6d69 6e3d 4e6f  ip_(self, min=No
-00018820: 6e65 2c20 6d61 783d 4e6f 6e65 293a 0a20  ne, max=None):. 
-00018830: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00018840: 7365 6c66 2e63 6c69 7028 6d69 6e3d 6d69  self.clip(min=mi
-00018850: 6e2c 206d 6178 3d6d 6178 290a 2020 2020  n, max=max).    
-00018860: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
-00018870: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
-00018880: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
-00018890: 2263 6c69 705f 222c 2022 636c 6970 2229  "clip_", "clip")
-000188a0: 0a0a 2020 2020 6465 6620 636f 7079 7369  ..    def copysi
-000188b0: 676e 2873 656c 662c 206f 7468 6572 293a  gn(self, other):
-000188c0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-000188d0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-000188e0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-000188f0: 2020 2020 696e 7075 745f 7479 7065 203d      input_type =
-00018900: 2069 6e70 7574 5f6d 732e 6474 7970 650a   input_ms.dtype.
-00018910: 2020 2020 2020 2020 6973 5f6e 756d 203d          is_num =
-00018920: 2054 7275 650a 2020 2020 2020 2020 2320   True.        # 
-00018930: 666f 7220 6772 6170 680a 2020 2020 2020  for graph.      
-00018940: 2020 6f74 6865 725f 7479 7065 203d 204e    other_type = N
-00018950: 6f6e 650a 2020 2020 2020 2020 6966 2069  one.        if i
-00018960: 7369 6e73 7461 6e63 6528 6f74 6865 722c  sinstance(other,
-00018970: 2054 656e 736f 7229 3a0a 2020 2020 2020   Tensor):.      
-00018980: 2020 2020 2020 6973 5f6e 756d 203d 2046        is_num = F
-00018990: 616c 7365 0a20 2020 2020 2020 2020 2020  alse.           
-000189a0: 206f 7468 6572 203d 2063 6173 745f 746f   other = cast_to
-000189b0: 5f6d 735f 7465 6e73 6f72 286f 7468 6572  _ms_tensor(other
-000189c0: 290a 2020 2020 2020 2020 2020 2020 6f74  ).            ot
-000189d0: 6865 725f 7479 7065 203d 206f 7468 6572  her_type = other
-000189e0: 2e64 7479 7065 0a20 2020 2020 2020 2020  .dtype.         
-000189f0: 2020 2023 544f 444f 3a20 6375 7272 656e     #TODO: curren
-00018a00: 746c 7920 7468 6520 7072 696d 5b54 696c  tly the prim[Til
-00018a10: 655d 2068 6173 2070 726f 626c 656d 2062  e] has problem b
-00018a20: 726f 6164 6361 7374 696e 670a 2020 2020  roadcasting.    
-00018a30: 2020 2020 2020 2020 6966 2069 6e70 7574          if input
-00018a40: 5f6d 732e 6e64 696d 203c 206f 7468 6572  _ms.ndim < other
-00018a50: 2e6e 6469 6d3a 0a20 2020 2020 2020 2020  .ndim:.         
-00018a60: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00018a70: 3d20 6d73 2e6f 7073 2e62 726f 6164 6361  = ms.ops.broadca
-00018a80: 7374 5f74 6f28 696e 7075 745f 6d73 2c20  st_to(input_ms, 
-00018a90: 6f74 6865 722e 7368 6170 6529 0a20 2020  other.shape).   
-00018aa0: 2020 2020 2020 2020 2069 6620 6f74 6865           if othe
-00018ab0: 722e 6e64 696d 203c 2069 6e70 7574 5f6d  r.ndim < input_m
-00018ac0: 732e 6e64 696d 3a0a 2020 2020 2020 2020  s.ndim:.        
-00018ad0: 2020 2020 2020 2020 6f74 6865 7220 3d20          other = 
-00018ae0: 6d73 2e6f 7073 2e62 726f 6164 6361 7374  ms.ops.broadcast
-00018af0: 5f74 6f28 6f74 6865 722c 2069 6e70 7574  _to(other, input
-00018b00: 5f6d 732e 7368 6170 6529 0a20 2020 2020  _ms.shape).     
-00018b10: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
-00018b20: 7073 2e63 6f70 7973 6967 6e28 696e 7075  ps.copysign(inpu
-00018b30: 745f 6d73 2c20 6f74 6865 7229 0a20 2020  t_ms, other).   
-00018b40: 2020 2020 2069 6620 2749 6e74 2720 696e       if 'Int' in
-00018b50: 2073 7472 2869 6e70 7574 5f74 7970 6529   str(input_type)
-00018b60: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
-00018b70: 2069 735f 6e75 6d20 6f72 2027 496e 7427   is_num or 'Int'
-00018b80: 2069 6e20 7374 7228 6f74 6865 725f 7479   in str(other_ty
-00018b90: 7065 293a 0a20 2020 2020 2020 2020 2020  pe):.           
-00018ba0: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
-00018bb0: 7470 7574 2e61 7374 7970 6528 6d73 2e66  tput.astype(ms.f
-00018bc0: 6c6f 6174 3332 290a 2020 2020 2020 2020  loat32).        
-00018bd0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-00018be0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00018bf0: 203d 206f 7574 7075 742e 6173 7479 7065   = output.astype
-00018c00: 286f 7468 6572 5f74 7970 6529 0a20 2020  (other_type).   
-00018c10: 2020 2020 2065 6c69 6620 6973 5f6e 756d       elif is_num
-00018c20: 206f 7220 2749 6e74 2720 696e 2073 7472   or 'Int' in str
-00018c30: 286f 7468 6572 5f74 7970 6529 3a0a 2020  (other_type):.  
-00018c40: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00018c50: 203d 206f 7574 7075 742e 6173 7479 7065   = output.astype
-00018c60: 2869 6e70 7574 5f74 7970 6529 0a20 2020  (input_type).   
-00018c70: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00018c80: 2020 2020 2020 2074 7970 6531 203d 2069         type1 = i
-00018c90: 6e70 7574 5f74 7970 6520 6966 2069 6e70  nput_type if inp
-00018ca0: 7574 5f6d 732e 6974 656d 7369 7a65 203e  ut_ms.itemsize >
-00018cb0: 206f 7468 6572 2e69 7465 6d73 697a 6520   other.itemsize 
-00018cc0: 656c 7365 206f 7468 6572 5f74 7970 650a  else other_type.
-00018cd0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00018ce0: 7574 203d 206f 7574 7075 742e 6173 7479  ut = output.asty
-00018cf0: 7065 2874 7970 6531 290a 2020 2020 2020  pe(type1).      
-00018d00: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00018d10: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00018d20: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00018d30: 2063 6f70 7973 6967 6e5f 2873 656c 662c   copysign_(self,
-00018d40: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
-00018d50: 206f 7574 7075 7420 3d20 7365 6c66 2e63   output = self.c
-00018d60: 6f70 7973 6967 6e28 6f74 6865 7229 0a20  opysign(other). 
-00018d70: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-00018d80: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-00018d90: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-00018da0: 742c 2022 636f 7079 7369 676e 5f22 2c20  t, "copysign_", 
-00018db0: 2263 6f70 7973 6967 6e22 290a 0a20 2020  "copysign")..   
-00018dc0: 2064 6566 2063 6f73 2873 656c 6629 3a0a   def cos(self):.
-00018dd0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00018de0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00018df0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00018e00: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
-00018e10: 7073 2e63 6f73 2869 6e70 7574 5f6d 7329  ps.cos(input_ms)
-00018e20: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00018e30: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00018e40: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00018e50: 2020 2020 6465 6620 636f 735f 2873 656c      def cos_(sel
-00018e60: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
-00018e70: 7574 203d 2073 656c 662e 636f 7328 290a  ut = self.cos().
-00018e80: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-00018e90: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-00018ea0: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-00018eb0: 7574 2c20 2263 6f73 5f22 2c20 2263 6f73  ut, "cos_", "cos
-00018ec0: 2229 0a0a 2020 2020 6465 6620 636f 7368  ")..    def cosh
-00018ed0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-00018ee0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00018ef0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00018f00: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
-00018f10: 7420 3d20 6d73 2e6f 7073 2e63 6f73 6828  t = ms.ops.cosh(
-00018f20: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
-00018f30: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00018f40: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00018f50: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00018f60: 2063 6f73 685f 2873 656c 6629 3a0a 2020   cosh_(self):.  
-00018f70: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-00018f80: 656c 662e 636f 7368 2829 0a20 2020 2020  elf.cosh().     
-00018f90: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-00018fa0: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-00018fb0: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-00018fc0: 636f 7368 5f22 2c20 2263 6f73 6822 290a  cosh_", "cosh").
-00018fd0: 0a20 2020 2064 6566 2063 756d 6d61 7828  .    def cummax(
-00018fe0: 7365 6c66 2c20 6469 6d29 3a0a 2020 2020  self, dim):.    
-00018ff0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-00019000: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-00019010: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-00019020: 7574 7075 7420 3d20 6d73 2e6f 7073 2e63  utput = ms.ops.c
-00019030: 756d 6d61 7828 696e 7075 745f 6d73 2c20  ummax(input_ms, 
-00019040: 6178 6973 3d64 696d 290a 2020 2020 2020  axis=dim).      
-00019050: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00019060: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00019070: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00019080: 2063 756d 6d69 6e28 7365 6c66 2c20 6469   cummin(self, di
-00019090: 6d29 3a0a 2020 2020 2020 2020 696e 7075  m):.        inpu
-000190a0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-000190b0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-000190c0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-000190d0: 6d73 2e6f 7073 2e63 756d 6d69 6e28 696e  ms.ops.cummin(in
-000190e0: 7075 745f 6d73 2c20 6469 6d29 0a20 2020  put_ms, dim).   
-000190f0: 2020 2020 2023 2074 6865 206f 7574 7075       # the outpu
-00019100: 7420 6474 7970 6520 696e 206d 732e 6f70  t dtype in ms.op
-00019110: 732e 6375 6d6d 696e 2069 7320 6469 6666  s.cummin is diff
-00019120: 6572 656e 7420 7769 7468 206d 732e 6f70  erent with ms.op
-00019130: 732e 6375 6d6d 6178 0a20 2020 2020 2020  s.cummax.       
-00019140: 206f 7574 7075 745b 315d 203d 206f 7574   output[1] = out
-00019150: 7075 745b 315d 2e61 7374 7970 6528 6d73  put[1].astype(ms
-00019160: 2e63 6f6d 6d6f 6e2e 6474 7970 652e 696e  .common.dtype.in
-00019170: 7436 3429 0a20 2020 2020 2020 2072 6574  t64).        ret
-00019180: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-00019190: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-000191a0: 7429 0a0a 2020 2020 6465 6620 6375 6d70  t)..    def cump
-000191b0: 726f 6428 7365 6c66 2c20 6469 6d2c 202a  rod(self, dim, *
-000191c0: 2c20 6474 7970 653d 4e6f 6e65 293a 0a20  , dtype=None):. 
-000191d0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-000191e0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-000191f0: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00019200: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-00019210: 732e 6375 6d70 726f 6428 696e 7075 745f  s.cumprod(input_
-00019220: 6d73 2c20 6469 6d2c 2064 7479 7065 3d64  ms, dim, dtype=d
-00019230: 7479 7065 290a 2020 2020 2020 2020 7265  type).        re
-00019240: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00019250: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-00019260: 7574 290a 0a20 2020 2064 6566 2063 756d  ut)..    def cum
-00019270: 7072 6f64 5f28 7365 6c66 2c20 6469 6d2c  prod_(self, dim,
-00019280: 202a 2c20 6474 7970 653d 4e6f 6e65 293a   *, dtype=None):
-00019290: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-000192a0: 3d20 7365 6c66 2e63 756d 7072 6f64 2864  = self.cumprod(d
-000192b0: 696d 2c20 6474 7970 653d 6474 7970 6529  im, dtype=dtype)
-000192c0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-000192d0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-000192e0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-000192f0: 7075 742c 2022 6375 6d70 726f 645f 222c  put, "cumprod_",
-00019300: 2022 6375 6d70 726f 6422 290a 0a20 2020   "cumprod")..   
-00019310: 2064 6566 2064 6567 3272 6164 2873 656c   def deg2rad(sel
-00019320: 6629 3a0a 2020 2020 2020 2020 696e 7075  f):.        inpu
-00019330: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00019340: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00019350: 2020 2020 2020 2069 6620 696e 7075 745f         if input_
-00019360: 6d73 2e64 7479 7065 206e 6f74 2069 6e20  ms.dtype not in 
-00019370: 286d 732e 666c 6f61 7431 362c 206d 732e  (ms.float16, ms.
-00019380: 666c 6f61 7433 322c 206d 732e 666c 6f61  float32, ms.floa
-00019390: 7436 3429 3a0a 2020 2020 2020 2020 2020  t64):.          
-000193a0: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
-000193b0: 7574 5f6d 732e 6173 7479 7065 286d 732e  ut_ms.astype(ms.
-000193c0: 666c 6f61 7433 3229 0a20 2020 2020 2020  float32).       
-000193d0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-000193e0: 2e64 6567 3272 6164 2869 6e70 7574 5f6d  .deg2rad(input_m
-000193f0: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
-00019400: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00019410: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-00019420: 0a0a 2020 2020 6465 6620 6469 6167 2873  ..    def diag(s
-00019430: 656c 662c 2064 6961 676f 6e61 6c3d 3029  elf, diagonal=0)
-00019440: 3a0a 2020 2020 2020 2020 2320 544f 444f  :.        # TODO
-00019450: 0a20 2020 2020 2020 2023 204d 6179 2062  .        # May b
-00019460: 6520 7573 6520 6d69 6e64 7370 6f72 652e  e use mindspore.
-00019470: 6f70 732e 6469 6167 2069 6e73 7465 6164  ops.diag instead
-00019480: 2e20 4e6f 7761 6461 7973 2c20 7468 6973  . Nowadays, this
-00019490: 206f 7065 7261 746f 7220 646f 206e 6f74   operator do not
-000194a0: 2073 7570 706f 7274 2043 5055 2e0a 2020   support CPU..  
-000194b0: 2020 2020 2020 2320 6d73 2e6e 756d 7079        # ms.numpy
-000194c0: 2e64 6961 6720 6861 7320 6275 6720 6f6e  .diag has bug on
-000194d0: 2061 7363 656e 642c 2075 7365 206d 732e   ascend, use ms.
-000194e0: 6f70 732e 6469 6167 2066 6f72 2064 6961  ops.diag for dia
-000194f0: 676f 6e61 6c3d 4e6f 6e65 2061 6e64 2031  gonal=None and 1
-00019500: 4420 696e 7075 740a 2020 2020 2020 2020  D input.        
-00019510: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00019520: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00019530: 6629 0a20 2020 2020 2020 2069 6620 6973  f).        if is
-00019540: 5f75 6e64 6572 5f61 7363 656e 645f 636f  _under_ascend_co
-00019550: 6e74 6578 7428 2920 616e 6420 696e 7075  ntext() and inpu
-00019560: 745f 6d73 2e6e 6469 6d20 3d3d 2031 2061  t_ms.ndim == 1 a
-00019570: 6e64 2064 6961 676f 6e61 6c20 3d3d 2030  nd diagonal == 0
-00019580: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
-00019590: 7470 7574 203d 206d 732e 6f70 732e 6469  tput = ms.ops.di
-000195a0: 6167 2869 6e70 7574 5f6d 7329 0a20 2020  ag(input_ms).   
-000195b0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-000195c0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-000195d0: 206d 732e 6e75 6d70 792e 6469 6167 2869   ms.numpy.diag(i
-000195e0: 6e70 7574 5f6d 732c 2064 6961 676f 6e61  nput_ms, diagona
-000195f0: 6c29 0a20 2020 2020 2020 2072 6574 7572  l).        retur
-00019600: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00019610: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-00019620: 0a0a 2020 2020 6465 6620 6469 6167 666c  ..    def diagfl
-00019630: 6174 2873 656c 662c 206f 6666 7365 743d  at(self, offset=
-00019640: 3029 3a0a 2020 2020 2020 2020 696e 7075  0):.        inpu
-00019650: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00019660: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00019670: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00019680: 6d73 2e6f 7073 2e64 6961 6766 6c61 7428  ms.ops.diagflat(
-00019690: 696e 7075 745f 6d73 2c20 6f66 6673 6574  input_ms, offset
-000196a0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-000196b0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-000196c0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-000196d0: 0a20 2020 2064 6566 2064 6961 676f 6e61  .    def diagona
-000196e0: 6c28 7365 6c66 2c20 6f66 6673 6574 3d30  l(self, offset=0
-000196f0: 2c20 6469 6d31 3d30 2c20 6469 6d32 3d31  , dim1=0, dim2=1
-00019700: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-00019710: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00019720: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00019730: 2020 2020 2020 2354 4f44 4f20 666c 6f61        #TODO floa
-00019740: 7436 3420 6e6f 7420 7375 7070 6f72 7420  t64 not support 
-00019750: 6966 206f 6666 7365 7420 213d 2030 0a20  if offset != 0. 
-00019760: 2020 2020 2020 2069 6620 6f66 6673 6574         if offset
-00019770: 2021 3d20 303a 0a20 2020 2020 2020 2020   != 0:.         
-00019780: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
-00019790: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
-000197a0: 7479 7065 2e66 6c6f 6174 3332 290a 2020  type.float32).  
-000197b0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-000197c0: 732e 6f70 732e 6469 6167 6f6e 616c 2869  s.ops.diagonal(i
-000197d0: 6e70 7574 5f6d 732c 206f 6666 7365 742c  nput_ms, offset,
-000197e0: 2064 696d 312c 2064 696d 3229 0a20 2020   dim1, dim2).   
-000197f0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-00019800: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00019810: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-00019820: 6465 6620 6973 5f63 6f6d 706c 6578 2873  def is_complex(s
-00019830: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
-00019840: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-00019850: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00019860: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00019870: 696e 7075 745f 6d73 2e69 735f 636f 6d70  input_ms.is_comp
-00019880: 6c65 7828 290a 0a20 2020 2064 6566 2069  lex()..    def i
-00019890: 7369 6e66 2873 656c 6629 3a0a 2020 2020  sinf(self):.    
-000198a0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-000198b0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-000198c0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-000198d0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e69  utput = ms.ops.i
-000198e0: 7369 6e66 2869 6e70 7574 5f6d 7329 0a20  sinf(input_ms). 
-000198f0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-00019900: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00019910: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-00019920: 2020 6465 6620 6973 6e65 6769 6e66 2873    def isneginf(s
-00019930: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
-00019940: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-00019950: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00019960: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00019970: 3d20 6d73 2e6f 7073 2e69 736e 6567 696e  = ms.ops.isnegin
-00019980: 6628 696e 7075 745f 6d73 290a 2020 2020  f(input_ms).    
-00019990: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-000199a0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-000199b0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-000199c0: 6566 2069 7370 6f73 696e 6628 7365 6c66  ef isposinf(self
-000199d0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-000199e0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-000199f0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00019a00: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-00019a10: 732e 6f70 732e 6973 706f 7369 6e66 2869  s.ops.isposinf(i
-00019a20: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-00019a30: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00019a40: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00019a50: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-00019a60: 6973 7265 616c 2873 656c 6629 3a0a 2020  isreal(self):.  
-00019a70: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00019a80: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00019a90: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00019aa0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-00019ab0: 2e69 7372 6561 6c28 696e 7075 745f 6d73  .isreal(input_ms
-00019ac0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00019ad0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00019ae0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-00019af0: 0a20 2020 2064 6566 2076 6172 2873 656c  .    def var(sel
-00019b00: 662c 2064 696d 3d4e 6f6e 652c 2075 6e62  f, dim=None, unb
-00019b10: 6961 7365 643d 5472 7565 2c20 6b65 6570  iased=True, keep
-00019b20: 6469 6d3d 4661 6c73 6529 3a0a 2020 2020  dim=False):.    
-00019b30: 2020 2020 2332 2e30 2020 5465 6e73 6f72      #2.0  Tensor
-00019b40: 2e76 6172 2864 696d 3d4e 6f6e 652c 202a  .var(dim=None, *
-00019b50: 2c20 636f 7272 6563 7469 6f6e 3d31 2c20  , correction=1, 
-00019b60: 6b65 6570 6469 6d3d 4661 6c73 6529 0a20  keepdim=False). 
-00019b70: 2020 2020 2020 2023 312e 3132 2054 656e         #1.12 Ten
-00019b80: 736f 722e 7661 7228 6469 6d2c 2075 6e62  sor.var(dim, unb
-00019b90: 6961 7365 643d 5472 7565 2c20 6b65 6570  iased=True, keep
-00019ba0: 6469 6d3d 4661 6c73 6529 0a20 2020 2020  dim=False).     
-00019bb0: 2020 2023 312e 3132 2054 656e 736f 722e     #1.12 Tensor.
-00019bc0: 7661 7228 756e 6269 6173 6564 3d54 7275  var(unbiased=Tru
-00019bd0: 6529 0a20 2020 2020 2020 2069 6620 6469  e).        if di
-00019be0: 6d20 6973 206e 6f74 204e 6f6e 6520 616e  m is not None an
-00019bf0: 6420 6973 696e 7374 616e 6365 2864 696d  d isinstance(dim
-00019c00: 2c20 626f 6f6c 293a 0a20 2020 2020 2020  , bool):.       
-00019c10: 2020 2020 2072 6169 7365 2054 7970 6545       raise TypeE
-00019c20: 7272 6f72 2822 7661 7228 2920 7265 6365  rror("var() rece
-00019c30: 6976 6564 2061 6e20 696e 7661 6c69 6420  ived an invalid 
-00019c40: 636f 6d62 696e 6174 696f 6e20 6f66 2061  combination of a
-00019c50: 7267 756d 656e 7473 3a20 676f 7420 2864  rguments: got (d
-00019c60: 696d 3d62 6f6f 6c29 2c22 202b 0a20 2020  im=bool)," +.   
-00019c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019c80: 2020 2020 2020 2020 2022 6275 7420 6578           "but ex
-00019c90: 7065 6374 6564 206f 6e65 206f 663a 2028  pected one of: (
-00019ca0: 7475 706c 6520 6f66 2069 6e74 7320 6469  tuple of ints di
-00019cb0: 6d2c 2062 6f6f 6c20 756e 6269 6173 6564  m, bool unbiased
-00019cc0: 2c20 626f 6f6c 206b 6565 7064 696d 2922  , bool keepdim)"
-00019cd0: 290a 2020 2020 2020 2020 696e 7075 745f  ).        input_
-00019ce0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00019cf0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-00019d00: 2020 2020 2023 6d73 2e6f 7073 2e76 6172       #ms.ops.var
-00019d10: 2075 6e73 7570 706f 7274 2064 646f 663d   unsupport ddof=
-00019d20: 302f 3120 6f6e 2047 5055 0a20 2020 2020  0/1 on GPU.     
-00019d30: 2020 2064 646f 6620 3d20 3120 6966 2075     ddof = 1 if u
-00019d40: 6e62 6961 7365 6420 6973 2054 7275 6520  nbiased is True 
-00019d50: 656c 7365 2030 0a20 2020 2020 2020 206f  else 0.        o
-00019d60: 7574 7075 7420 3d20 696e 7075 745f 6d73  utput = input_ms
-00019d70: 2e76 6172 2861 7869 733d 6469 6d2c 2064  .var(axis=dim, d
-00019d80: 646f 663d 6464 6f66 2c20 6b65 6570 6469  dof=ddof, keepdi
-00019d90: 6d73 3d6b 6565 7064 696d 290a 2020 2020  ms=keepdim).    
-00019da0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00019db0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00019dc0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00019dd0: 6566 2064 6966 6628 7365 6c66 2c20 6e3d  ef diff(self, n=
-00019de0: 312c 2064 696d 3d2d 312c 2070 7265 7065  1, dim=-1, prepe
-00019df0: 6e64 3d4e 6f6e 652c 2061 7070 656e 643d  nd=None, append=
-00019e00: 4e6f 6e65 293a 0a20 2020 2020 2020 2069  None):.        i
-00019e10: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-00019e20: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00019e30: 290a 2020 2020 2020 2020 2354 4f44 4f3a  ).        #TODO:
-00019e40: 206d 732e 6f70 732e 6469 6666 206f 6e6c   ms.ops.diff onl
-00019e50: 7920 7375 7070 6f72 7420 6e3d 310a 2020  y support n=1.  
-00019e60: 2020 2020 2020 6966 206e 203d 3d20 313a        if n == 1:
-00019e70: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00019e80: 7075 7420 3d20 6d73 2e6f 7073 2e64 6966  put = ms.ops.dif
-00019e90: 6628 696e 7075 745f 6d73 2c20 6e2c 2064  f(input_ms, n, d
-00019ea0: 696d 2c20 7072 6570 656e 642c 2061 7070  im, prepend, app
-00019eb0: 656e 6429 0a20 2020 2020 2020 2065 6c73  end).        els
-00019ec0: 653a 0a20 2020 2020 2020 2020 2020 206f  e:.            o
-00019ed0: 7574 7075 7420 3d20 6d73 2e6e 756d 7079  utput = ms.numpy
-00019ee0: 2e64 6966 6628 696e 7075 745f 6d73 2c20  .diff(input_ms, 
-00019ef0: 6e2c 2064 696d 2c20 7072 6570 656e 642c  n, dim, prepend,
-00019f00: 2061 7070 656e 6429 0a20 2020 2020 2020   append).       
-00019f10: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00019f20: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00019f30: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-00019f40: 6469 6761 6d6d 6128 7365 6c66 293a 0a20  digamma(self):. 
-00019f50: 2020 2020 2020 2023 2054 4f44 4f3a 2057         # TODO: W
-00019f60: 6865 6e20 696e 7075 7420 6474 7970 6520  hen input dtype 
-00019f70: 6973 2066 6c6f 6174 3634 2c20 7265 7375  is float64, resu
-00019f80: 6c74 206d 6179 2062 6520 696e 6163 6375  lt may be inaccu
-00019f90: 7261 7465 0a20 2020 2020 2020 2069 6e70  rate.        inp
-00019fa0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-00019fb0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-00019fc0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00019fd0: 206d 732e 6f70 732e 6469 6761 6d6d 6128   ms.ops.digamma(
-00019fe0: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
-00019ff0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0001a000: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0001a010: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-0001a020: 2064 6967 616d 6d61 5f28 7365 6c66 293a   digamma_(self):
-0001a030: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-0001a040: 3d20 7365 6c66 2e64 6967 616d 6d61 2829  = self.digamma()
-0001a050: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001a060: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-0001a070: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-0001a080: 7075 742c 2022 6469 6761 6d6d 615f 222c  put, "digamma_",
-0001a090: 2022 6469 6761 6d6d 6122 290a 0a20 2020   "digamma")..   
-0001a0a0: 2023 544f 444f 3a20 6569 6720 6375 7272   #TODO: eig curr
-0001a0b0: 656e 746c 7920 6e6f 7420 7375 7070 6f72  ently not suppor
-0001a0c0: 7420 6f6e 2047 5055 0a20 2020 2064 6566  t on GPU.    def
-0001a0d0: 2065 6967 2873 656c 6629 3a0a 2020 2020   eig(self):.    
-0001a0e0: 2020 2020 6966 2069 735f 756e 6465 725f      if is_under_
-0001a0f0: 6770 755f 636f 6e74 6578 7428 293a 0a20  gpu_context():. 
-0001a100: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-0001a110: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
-0001a120: 7272 6f72 2822 666f 7220 6164 6170 7465  rror("for adapte
-0001a130: 722c 2065 6967 206e 6f74 2073 7570 706f  r, eig not suppo
-0001a140: 7274 6564 206f 6e20 4750 5522 290a 2020  rted on GPU").  
-0001a150: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-0001a160: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0001a170: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-0001a180: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-0001a190: 2e65 6967 2869 6e70 7574 5f6d 7329 0a20  .eig(input_ms). 
-0001a1a0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-0001a1b0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-0001a1c0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-0001a1d0: 2020 6465 6620 6469 7374 2873 656c 662c    def dist(self,
-0001a1e0: 206f 7468 6572 2c20 703d 3229 3a0a 2020   other, p=2):.  
-0001a1f0: 2020 2020 2020 5f69 6e70 7574 203d 2063        _input = c
-0001a200: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0001a210: 2873 656c 6629 0a20 2020 2020 2020 205f  (self).        _
-0001a220: 6f74 6865 7220 3d20 6361 7374 5f74 6f5f  other = cast_to_
-0001a230: 6d73 5f74 656e 736f 7228 6f74 6865 7229  ms_tensor(other)
-0001a240: 0a0a 2020 2020 2020 2020 5f69 6e70 7574  ..        _input
-0001a250: 5f64 7479 7065 203d 205f 696e 7075 742e  _dtype = _input.
-0001a260: 6474 7970 650a 2020 2020 2020 2020 5f6f  dtype.        _o
-0001a270: 7468 6572 5f64 7479 7065 203d 205f 6f74  ther_dtype = _ot
-0001a280: 6865 722e 6474 7970 650a 2020 2020 2020  her.dtype.      
-0001a290: 2020 6966 205f 696e 7075 745f 6474 7970    if _input_dtyp
-0001a2a0: 6520 696e 2028 6d73 2e66 6c6f 6174 3136  e in (ms.float16
-0001a2b0: 2c20 6d73 2e66 6c6f 6174 3332 2920 616e  , ms.float32) an
-0001a2c0: 6420 5f6f 7468 6572 5f64 7479 7065 2021  d _other_dtype !
-0001a2d0: 3d20 6d73 2e66 6c6f 6174 3634 3a0a 2020  = ms.float64:.  
-0001a2e0: 2020 2020 2020 2020 2020 6966 205f 6f74            if _ot
-0001a2f0: 6865 725f 6474 7970 6520 3d3d 206d 732e  her_dtype == ms.
-0001a300: 666c 6f61 7433 323a 0a20 2020 2020 2020  float32:.       
-0001a310: 2020 2020 2020 2020 205f 696e 7075 7420           _input 
-0001a320: 3d20 5f69 6e70 7574 2e61 7374 7970 6528  = _input.astype(
-0001a330: 5f6f 7468 6572 5f64 7479 7065 290a 2020  _other_dtype).  
-0001a340: 2020 2020 2020 2020 2020 656c 7365 3a0a            else:.
-0001a350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a360: 5f6f 7468 6572 203d 205f 6f74 6865 722e  _other = _other.
-0001a370: 6173 7479 7065 285f 696e 7075 745f 6474  astype(_input_dt
-0001a380: 7970 6529 0a20 2020 2020 2020 2020 2020  ype).           
-0001a390: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-0001a3a0: 2e64 6973 7428 5f69 6e70 7574 2c20 5f6f  .dist(_input, _o
-0001a3b0: 7468 6572 2c20 703d 7029 0a20 2020 2020  ther, p=p).     
-0001a3c0: 2020 2065 6c69 6620 5f69 6e70 7574 5f64     elif _input_d
-0001a3d0: 7479 7065 203d 3d20 6d73 2e66 6c6f 6174  type == ms.float
-0001a3e0: 3634 206f 7220 5f6f 7468 6572 5f64 7479  64 or _other_dty
-0001a3f0: 7065 203d 3d20 6d73 2e66 6c6f 6174 3634  pe == ms.float64
-0001a400: 3a0a 2020 2020 2020 2020 2020 2020 5f69  :.            _i
-0001a410: 6e70 7574 203d 205f 696e 7075 742e 6173  nput = _input.as
-0001a420: 7479 7065 286d 732e 666c 6f61 7433 3229  type(ms.float32)
-0001a430: 0a20 2020 2020 2020 2020 2020 205f 6f74  .            _ot
-0001a440: 6865 7220 3d20 5f6f 7468 6572 2e61 7374  her = _other.ast
-0001a450: 7970 6528 6d73 2e66 6c6f 6174 3332 290a  ype(ms.float32).
-0001a460: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-0001a470: 7574 203d 206d 732e 6f70 732e 6469 7374  ut = ms.ops.dist
-0001a480: 285f 696e 7075 742c 205f 6f74 6865 722c  (_input, _other,
-0001a490: 2070 3d70 290a 2020 2020 2020 2020 2020   p=p).          
-0001a4a0: 2020 6f75 7470 7574 203d 206f 7574 7075    output = outpu
-0001a4b0: 742e 6173 7479 7065 286d 732e 666c 6f61  t.astype(ms.floa
-0001a4c0: 7436 3429 0a20 2020 2020 2020 2065 6c73  t64).        els
-0001a4d0: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
-0001a4e0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-0001a4f0: 6622 466f 7220 746f 7263 682e 6469 7374  f"For torch.dist
-0001a500: 2c20 696e 7075 7420 7368 6f75 6c64 2062  , input should b
-0001a510: 6520 666c 6f61 7469 6e67 2054 656e 736f  e floating Tenso
-0001a520: 722c 2062 7574 2067 6f74 207b 5f69 6e70  r, but got {_inp
-0001a530: 7574 5f64 7479 7065 7d2e 2229 0a0a 2020  ut_dtype}.")..  
-0001a540: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-0001a550: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-0001a560: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-0001a570: 2064 6566 2064 7370 6c69 7428 7365 6c66   def dsplit(self
-0001a580: 2c20 696e 6469 6365 735f 6f72 5f73 6563  , indices_or_sec
-0001a590: 7469 6f6e 7329 3a0a 2020 2020 2020 2020  tions):.        
-0001a5a0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-0001a5b0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-0001a5c0: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
-0001a5d0: 7420 3d20 6d73 2e6f 7073 2e64 7370 6c69  t = ms.ops.dspli
-0001a5e0: 7428 696e 7075 745f 6d73 2c20 696e 6469  t(input_ms, indi
-0001a5f0: 6365 735f 6f72 5f73 6563 7469 6f6e 7329  ces_or_sections)
-0001a600: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001a610: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-0001a620: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-0001a630: 2020 2020 6465 6620 6572 6628 7365 6c66      def erf(self
-0001a640: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-0001a650: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-0001a660: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-0001a670: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-0001a680: 732e 6f70 732e 6572 6628 696e 7075 745f  s.ops.erf(input_
-0001a690: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-0001a6a0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-0001a6b0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-0001a6c0: 290a 0a20 2020 2064 6566 2065 7266 5f28  )..    def erf_(
-0001a6d0: 7365 6c66 293a 0a20 2020 2020 2020 206f  self):.        o
-0001a6e0: 7574 7075 7420 3d20 7365 6c66 2e65 7266  utput = self.erf
-0001a6f0: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
-0001a700: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-0001a710: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-0001a720: 7574 7075 742c 2022 6572 665f 222c 2022  utput, "erf_", "
-0001a730: 6572 6622 290a 0a20 2020 2064 6566 2065  erf")..    def e
-0001a740: 7266 6328 7365 6c66 293a 0a20 2020 2020  rfc(self):.     
-0001a750: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-0001a760: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-0001a770: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
-0001a780: 7470 7574 203d 206d 732e 6f70 732e 6572  tput = ms.ops.er
-0001a790: 6663 2869 6e70 7574 5f6d 7329 0a20 2020  fc(input_ms).   
-0001a7a0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0001a7b0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0001a7c0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0001a7d0: 6465 6620 6572 6663 5f28 7365 6c66 293a  def erfc_(self):
-0001a7e0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-0001a7f0: 3d20 7365 6c66 2e65 7266 6328 290a 2020  = self.erfc().  
-0001a800: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-0001a810: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-0001a820: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-0001a830: 2c20 2265 7266 635f 222c 2022 6572 6663  , "erfc_", "erfc
-0001a840: 2229 0a0a 2020 2020 6465 6620 6578 706d  ")..    def expm
-0001a850: 3128 7365 6c66 293a 0a20 2020 2020 2020  1(self):.       
-0001a860: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-0001a870: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-0001a880: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
-0001a890: 7574 203d 206d 732e 6f70 732e 6578 706d  ut = ms.ops.expm
-0001a8a0: 3128 696e 7075 745f 6d73 290a 2020 2020  1(input_ms).    
-0001a8b0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-0001a8c0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-0001a8d0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-0001a8e0: 6566 2065 7870 6d31 5f28 7365 6c66 293a  ef expm1_(self):
-0001a8f0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-0001a900: 3d20 7365 6c66 2e65 7870 6d31 2829 0a20  = self.expm1(). 
-0001a910: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-0001a920: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-0001a930: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-0001a940: 742c 2022 6578 706d 315f 222c 2022 6578  t, "expm1_", "ex
-0001a950: 706d 3122 290a 0a20 2020 2064 6566 2074  pm1")..    def t
-0001a960: 7275 6e63 2873 656c 6629 3a0a 2020 2020  runc(self):.    
-0001a970: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-0001a980: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0001a990: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-0001a9a0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e74  utput = ms.ops.t
-0001a9b0: 7275 6e63 2869 6e70 7574 5f6d 7329 0a20  runc(input_ms). 
-0001a9c0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-0001a9d0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-0001a9e0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-0001a9f0: 2020 6465 6620 7472 756e 635f 2873 656c    def trunc_(sel
-0001aa00: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
-0001aa10: 7574 203d 2073 656c 662e 7472 756e 6328  ut = self.trunc(
-0001aa20: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0001aa30: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
-0001aa40: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
-0001aa50: 7470 7574 2c20 2274 7275 6e63 5f22 2c20  tput, "trunc_", 
-0001aa60: 2274 7275 6e63 2229 0a0a 2020 2020 6465  "trunc")..    de
-0001aa70: 6620 6669 7828 7365 6c66 293a 0a20 2020  f fix(self):.   
-0001aa80: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-0001aa90: 2e74 7275 6e63 2829 0a0a 2020 2020 6465  .trunc()..    de
-0001aaa0: 6620 6669 785f 2873 656c 6629 3a0a 2020  f fix_(self):.  
-0001aab0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-0001aac0: 656c 662e 6669 7828 290a 2020 2020 2020  elf.fix().      
-0001aad0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
-0001aae0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
-0001aaf0: 7365 6c66 2c20 6f75 7470 7574 2c20 2266  self, output, "f
-0001ab00: 6978 5f22 2c20 2266 6978 2229 0a0a 2020  ix_", "fix")..  
-0001ab10: 2020 6465 6620 666c 6970 6c72 2873 656c    def fliplr(sel
-0001ab20: 6629 3a0a 2020 2020 2020 2020 696e 7075  f):.        inpu
-0001ab30: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-0001ab40: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-0001ab50: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001ab60: 6d73 2e6f 7073 2e66 6c69 706c 7228 696e  ms.ops.fliplr(in
-0001ab70: 7075 745f 6d73 290a 2020 2020 2020 2020  put_ms).        
-0001ab80: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0001ab90: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-0001aba0: 7470 7574 290a 0a20 2020 2064 6566 2066  tput)..    def f
-0001abb0: 6c6f 6174 5f70 6f77 6572 2873 656c 662c  loat_power(self,
-0001abc0: 2065 7870 6f6e 656e 7429 3a0a 2020 2020   exponent):.    
-0001abd0: 2020 2020 2320 544f 444f 3a20 6e6f 7420      # TODO: not 
-0001abe0: 7375 7070 6f72 7420 636f 6d70 6c65 7820  support complex 
-0001abf0: 696e 7075 7420 616e 6420 6578 706f 6e65  input and expone
-0001ac00: 6e74 206e 6f77 0a20 2020 2020 2020 2069  nt now.        i
-0001ac10: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0001ac20: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0001ac30: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-0001ac40: 203d 206d 732e 6f70 732e 666c 6f61 745f   = ms.ops.float_
-0001ac50: 706f 7765 7228 696e 7075 745f 6d73 2c20  power(input_ms, 
-0001ac60: 6578 706f 6e65 6e74 290a 2020 2020 2020  exponent).      
-0001ac70: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0001ac80: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0001ac90: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-0001aca0: 2066 6c6f 6174 5f70 6f77 6572 5f28 7365   float_power_(se
-0001acb0: 6c66 2c20 6578 706f 6e65 6e74 293a 0a20  lf, exponent):. 
-0001acc0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001acd0: 7365 6c66 2e66 6c6f 6174 5f70 6f77 6572  self.float_power
-0001ace0: 2865 7870 6f6e 656e 7429 0a20 2020 2020  (exponent).     
-0001acf0: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-0001ad00: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-0001ad10: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-0001ad20: 666c 6f61 745f 706f 7765 725f 222c 2022  float_power_", "
-0001ad30: 666c 6f61 745f 706f 7765 7222 290a 0a20  float_power").. 
-0001ad40: 2020 2064 6566 206e 6172 726f 7728 7365     def narrow(se
-0001ad50: 6c66 2c20 6469 6d65 6e73 696f 6e2c 2073  lf, dimension, s
-0001ad60: 7461 7274 2c20 6c65 6e67 7468 293a 0a20  tart, length):. 
-0001ad70: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0001ad80: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-0001ad90: 736f 7228 7365 6c66 290a 0a20 2020 2020  sor(self)..     
-0001ada0: 2020 2064 6566 205f 6765 745f 7465 6e73     def _get_tens
-0001adb0: 6f72 5f64 6174 6128 7829 3a0a 2020 2020  or_data(x):.    
-0001adc0: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
-0001add0: 7461 6e63 6528 782c 2054 656e 736f 7229  tance(x, Tensor)
-0001ade0: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001adf0: 2020 6966 2078 2e6e 6469 6d20 213d 2030    if x.ndim != 0
-0001ae00: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-0001ae10: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
-0001ae20: 6545 7272 6f72 2822 6974 206d 7573 7420  eError("it must 
-0001ae30: 6265 2061 6e20 302d 6469 6d20 696e 7465  be an 0-dim inte
-0001ae40: 6772 616c 2054 656e 736f 722e 2229 0a20  gral Tensor."). 
-0001ae50: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0001ae60: 6574 7572 6e20 696e 7428 7829 0a20 2020  eturn int(x).   
-0001ae70: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0001ae80: 780a 0a20 2020 2020 2020 2064 696d 656e  x..        dimen
-0001ae90: 7369 6f6e 203d 205f 6765 745f 7465 6e73  sion = _get_tens
-0001aea0: 6f72 5f64 6174 6128 6469 6d65 6e73 696f  or_data(dimensio
-0001aeb0: 6e29 0a20 2020 2020 2020 2073 7461 7274  n).        start
-0001aec0: 203d 205f 6765 745f 7465 6e73 6f72 5f64   = _get_tensor_d
-0001aed0: 6174 6128 7374 6172 7429 0a20 2020 2020  ata(start).     
-0001aee0: 2020 206c 656e 6774 6820 3d20 5f67 6574     length = _get
-0001aef0: 5f74 656e 736f 725f 6461 7461 286c 656e  _tensor_data(len
-0001af00: 6774 6829 0a20 2020 2020 2020 206f 7574  gth).        out
-0001af10: 7075 7420 3d20 6d73 2e6f 7073 2e6e 6172  put = ms.ops.nar
-0001af20: 726f 7728 696e 7075 745f 6d73 2c20 6469  row(input_ms, di
-0001af30: 6d65 6e73 696f 6e2c 2073 7461 7274 2c20  mension, start, 
-0001af40: 6c65 6e67 7468 290a 2020 2020 2020 2020  length).        
-0001af50: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0001af60: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-0001af70: 7470 7574 290a 0a20 2020 2064 6566 206e  tput)..    def n
-0001af80: 6172 726f 775f 636f 7079 2873 656c 662c  arrow_copy(self,
-0001af90: 2064 696d 656e 7369 6f6e 2c20 7374 6172   dimension, star
-0001afa0: 742c 206c 656e 6774 6829 3a0a 2020 2020  t, length):.    
-0001afb0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-0001afc0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0001afd0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-0001afe0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6e  utput = ms.ops.n
-0001aff0: 6172 726f 7728 696e 7075 745f 6d73 2c20  arrow(input_ms, 
-0001b000: 6469 6d65 6e73 696f 6e2c 2073 7461 7274  dimension, start
-0001b010: 2c20 6c65 6e67 7468 290a 2020 2020 2020  , length).      
-0001b020: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0001b030: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0001b040: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-0001b050: 206e 6f72 6d28 7365 6c66 2c20 703d 2766   norm(self, p='f
-0001b060: 726f 272c 2064 696d 3d4e 6f6e 652c 206b  ro', dim=None, k
-0001b070: 6565 7064 696d 3d46 616c 7365 2c20 6474  eepdim=False, dt
-0001b080: 7970 653d 4e6f 6e65 293a 0a20 2020 2020  ype=None):.     
-0001b090: 2020 2023 2054 4f44 4f3a 206d 732e 6f70     # TODO: ms.op
-0001b0a0: 732e 6e6f 726d 2062 656e 6368 6d61 726b  s.norm benchmark
-0001b0b0: 696e 6720 746f 7263 682e 6c69 6e61 6c67  ing torch.linalg
-0001b0c0: 2e6e 6f72 6d2e 2073 6f6d 6520 6d61 7472  .norm. some matr
-0001b0d0: 6978 2d6e 6f72 6d20 7265 7375 6c74 206e  ix-norm result n
-0001b0e0: 6f74 2072 6967 6874 2e0a 2020 2020 2020  ot right..      
-0001b0f0: 2020 2320 6070 6020 6361 6e20 6e6f 7420    # `p` can not 
-0001b100: 7375 7070 6f72 7420 7661 6c75 6520 6265  support value be
-0001b110: 7369 6465 205b 2766 726f 272c 2027 6e75  side ['fro', 'nu
-0001b120: 6327 2c20 696e 662c 202d 696e 662c 2030  c', inf, -inf, 0
-0001b130: 2c20 312c 202d 312c 2032 2c20 2d32 5d0a  , 1, -1, 2, -2].
-0001b140: 2020 2020 2020 2020 7761 726e 696e 6728          warning(
-0001b150: 2260 746f 7263 682e 6e6f 726d 6020 6f72  "`torch.norm` or
-0001b160: 2060 7465 6e73 6f72 2e6e 6f72 6d60 2069   `tensor.norm` i
-0001b170: 7320 6465 7072 6563 6174 6564 2c20 706c  s deprecated, pl
-0001b180: 6561 7365 2075 7365 2060 6c69 6e61 6c67  ease use `linalg
-0001b190: 2e76 6563 746f 725f 6e6f 726d 2829 6020  .vector_norm()` 
-0001b1a0: 220a 2020 2020 2020 2020 2020 2020 2020  ".              
-0001b1b0: 2020 226f 7220 606c 696e 616c 672e 6d61    "or `linalg.ma
-0001b1c0: 7472 6978 5f6e 6f72 6d28 2960 2069 6e73  trix_norm()` ins
-0001b1d0: 7465 6164 2e22 290a 2020 2020 2020 2020  tead.").        
-0001b1e0: 7020 3d20 5f6e 6f72 6d5f 6765 745f 636f  p = _norm_get_co
-0001b1f0: 6e73 7428 702c 2064 696d 2c20 6c65 6e28  nst(p, dim, len(
-0001b200: 7365 6c66 2e73 6861 7065 2929 0a20 2020  self.shape)).   
-0001b210: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0001b220: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-0001b230: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-0001b240: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-0001b250: 6e6f 726d 2869 6e70 7574 5f6d 732c 206f  norm(input_ms, o
-0001b260: 7264 3d70 2c20 6469 6d3d 6469 6d2c 206b  rd=p, dim=dim, k
-0001b270: 6565 7064 696d 3d6b 6565 7064 696d 290a  eepdim=keepdim).
-0001b280: 2020 2020 2020 2020 6966 2064 7479 7065          if dtype
-0001b290: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
-0001b2a0: 7470 7574 203d 206f 7574 7075 742e 6173  tput = output.as
-0001b2b0: 7479 7065 2864 7479 7065 290a 2020 2020  type(dtype).    
-0001b2c0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-0001b2d0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-0001b2e0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-0001b2f0: 6566 2078 6c6f 6779 2873 656c 662c 206f  ef xlogy(self, o
-0001b300: 7468 6572 293a 0a20 2020 2020 2020 2069  ther):.        i
-0001b310: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0001b320: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0001b330: 290a 2020 2020 2020 2020 6f74 6865 7220  ).        other 
-0001b340: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-0001b350: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
-0001b360: 2020 2023 2054 4f44 4f3a 2054 6f20 7375     # TODO: To su
-0001b370: 7070 6f72 7420 6d6f 7265 2064 6174 6174  pport more datat
-0001b380: 7970 6520 6f6e 2041 7363 656e 640a 2020  ype on Ascend.  
-0001b390: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-0001b3a0: 732e 6f70 732e 786c 6f67 7928 696e 7075  s.ops.xlogy(inpu
-0001b3b0: 745f 6d73 2c20 6f74 6865 7229 0a20 2020  t_ms, other).   
-0001b3c0: 2020 2020 2069 6620 6973 5f75 6e64 6572       if is_under
-0001b3d0: 5f67 7075 5f63 6f6e 7465 7874 2829 206f  _gpu_context() o
-0001b3e0: 7220 6973 5f75 6e64 6572 5f61 7363 656e  r is_under_ascen
-0001b3f0: 645f 636f 6e74 6578 7428 293a 0a20 2020  d_context():.   
-0001b400: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
-0001b410: 7374 616e 6365 2869 6e70 7574 5f6d 732c  stance(input_ms,
-0001b420: 206d 732e 5465 6e73 6f72 2920 616e 6420   ms.Tensor) and 
-0001b430: 6973 696e 7374 616e 6365 286f 7468 6572  isinstance(other
-0001b440: 2c20 6d73 2e54 656e 736f 7229 3a0a 2020  , ms.Tensor):.  
-0001b450: 2020 2020 2020 2020 2020 2020 2020 6d61                ma
-0001b460: 736b 203d 206d 732e 6f70 732e 6973 6e61  sk = ms.ops.isna
-0001b470: 6e28 6f74 6865 7229 0a20 2020 2020 2020  n(other).       
-0001b480: 2020 2020 2020 2020 206f 7574 7075 7420           output 
-0001b490: 3d20 6d73 2e6f 7073 2e77 6865 7265 286d  = ms.ops.where(m
-0001b4a0: 6173 6b2c 206d 732e 5465 6e73 6f72 2866  ask, ms.Tensor(f
-0001b4b0: 6c6f 6174 2827 6e61 6e27 2929 2e61 7374  loat('nan')).ast
-0001b4c0: 7970 6528 6f75 7470 7574 2e64 7479 7065  ype(output.dtype
-0001b4d0: 292c 206f 7574 7075 7429 0a20 2020 2020  ), output).     
-0001b4e0: 2020 2020 2020 2065 6c69 6620 6e6f 7420         elif not 
-0001b4f0: 6973 696e 7374 616e 6365 2869 6e70 7574  isinstance(input
-0001b500: 5f6d 732c 206d 732e 5465 6e73 6f72 293a  _ms, ms.Tensor):
-0001b510: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b520: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-0001b530: 2e77 6865 7265 2828 6f74 6865 7220 3c20  .where((other < 
-0001b540: 3029 2c20 6d73 2e54 656e 736f 7228 666c  0), ms.Tensor(fl
-0001b550: 6f61 7428 276e 616e 2729 292e 6173 7479  oat('nan')).asty
-0001b560: 7065 286f 7574 7075 742e 6474 7970 6529  pe(output.dtype)
-0001b570: 2c20 6f75 7470 7574 290a 2020 2020 2020  , output).      
-0001b580: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0001b590: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0001b5a0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-0001b5b0: 2078 6c6f 6779 5f28 7365 6c66 2c20 6f74   xlogy_(self, ot
-0001b5c0: 6865 7229 3a0a 2020 2020 2020 2020 6f75  her):.        ou
-0001b5d0: 7470 7574 203d 2073 656c 662e 786c 6f67  tput = self.xlog
-0001b5e0: 7928 6f74 6865 7229 0a20 2020 2020 2020  y(other).       
-0001b5f0: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
-0001b600: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
-0001b610: 656c 662c 206f 7574 7075 742c 2022 786c  elf, output, "xl
-0001b620: 6f67 795f 222c 2022 786c 6f67 7922 290a  ogy_", "xlogy").
-0001b630: 0a20 2020 2064 6566 2076 7370 6c69 7428  .    def vsplit(
-0001b640: 7365 6c66 2c20 696e 6469 6365 735f 6f72  self, indices_or
-0001b650: 5f73 6563 7469 6f6e 7329 3a0a 2020 2020  _sections):.    
-0001b660: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-0001b670: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0001b680: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-0001b690: 7574 7075 7420 3d20 6d73 2e6f 7073 2e76  utput = ms.ops.v
-0001b6a0: 7370 6c69 7428 696e 7075 745f 6d73 2c20  split(input_ms, 
-0001b6b0: 696e 6469 6365 735f 6f72 5f73 6563 7469  indices_or_secti
-0001b6c0: 6f6e 7329 0a20 2020 2020 2020 2072 6574  ons).        ret
-0001b6d0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-0001b6e0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-0001b6f0: 7429 0a0a 2020 2020 6465 6620 7664 6f74  t)..    def vdot
-0001b700: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-0001b710: 2020 2020 2020 2069 6620 6e6f 7420 6973         if not is
-0001b720: 696e 7374 616e 6365 286f 7468 6572 2c20  instance(other, 
-0001b730: 5465 6e73 6f72 293a 0a20 2020 2020 2020  Tensor):.       
-0001b740: 2020 2020 2072 6169 7365 2054 7970 6545       raise TypeE
-0001b750: 7272 6f72 2866 2246 6f72 2054 656e 736f  rror(f"For Tenso
-0001b760: 722e 7664 6f74 2c20 6f74 6865 7220 6d75  r.vdot, other mu
-0001b770: 7374 2062 6520 7465 6e73 6f72 2c20 6275  st be tensor, bu
-0001b780: 7420 676f 7420 7b74 7970 6528 6f74 6865  t got {type(othe
-0001b790: 7229 7d22 290a 2020 2020 2020 2020 6966  r)}").        if
-0001b7a0: 2073 656c 662e 6474 7970 6520 213d 206f   self.dtype != o
-0001b7b0: 7468 6572 2e64 7479 7065 3a0a 2020 2020  ther.dtype:.    
-0001b7c0: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
-0001b7d0: 6e74 696d 6545 7272 6f72 2866 2246 6f72  ntimeError(f"For
-0001b7e0: 2054 656e 736f 722e 7664 6f74 2c20 6578   Tensor.vdot, ex
-0001b7f0: 7065 6374 6564 2062 6f74 6820 7665 6374  pected both vect
-0001b800: 6f72 7320 746f 2068 6176 6520 7361 6d65  ors to have same
-0001b810: 2064 7479 7065 2c20 6275 7420 666f 756e   dtype, but foun
-0001b820: 6420 7b73 656c 662e 6474 7970 657d 220a  d {self.dtype}".
-0001b830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b840: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0001b850: 2220 616e 6420 7b6f 7468 6572 2e64 7479  " and {other.dty
-0001b860: 7065 7d22 290a 2020 2020 2020 2020 6966  pe}").        if
-0001b870: 2073 656c 662e 6e64 696d 2021 3d20 3120   self.ndim != 1 
-0001b880: 6f72 206f 7468 6572 2e6e 6469 6d20 213d  or other.ndim !=
-0001b890: 2031 3a0a 2020 2020 2020 2020 2020 2020   1:.            
-0001b8a0: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-0001b8b0: 6f72 2866 2246 6f72 2054 656e 736f 722e  or(f"For Tensor.
-0001b8c0: 7664 6f74 2c20 3144 2074 656e 736f 7273  vdot, 1D tensors
-0001b8d0: 2065 7870 6563 7465 642c 2062 7574 2067   expected, but g
-0001b8e0: 6f74 207b 7365 6c66 2e6e 6469 6d7d 4420  ot {self.ndim}D 
-0001b8f0: 616e 6420 7b6f 7468 6572 2e6e 6469 6d7d  and {other.ndim}
-0001b900: 4420 7465 6e73 6f72 7322 290a 2020 2020  D tensors").    
-0001b910: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-0001b920: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0001b930: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-0001b940: 7468 6572 203d 2063 6173 745f 746f 5f6d  ther = cast_to_m
-0001b950: 735f 7465 6e73 6f72 286f 7468 6572 290a  s_tensor(other).
-0001b960: 2020 2020 2020 2020 6966 2069 6e70 7574          if input
-0001b970: 5f6d 732e 6973 5f63 6f6d 706c 6578 2829  _ms.is_complex()
-0001b980: 3a0a 2020 2020 2020 2020 2020 2020 696e  :.            in
-0001b990: 7075 745f 6d73 203d 206d 732e 6f70 732e  put_ms = ms.ops.
-0001b9a0: 636f 6e6a 2869 6e70 7574 5f6d 7329 0a20  conj(input_ms). 
-0001b9b0: 2020 2020 2020 2069 6620 2869 735f 756e         if (is_un
-0001b9c0: 6465 725f 6770 755f 636f 6e74 6578 7428  der_gpu_context(
-0001b9d0: 2920 616e 6420 2869 6e70 7574 5f6d 732e  ) and (input_ms.
-0001b9e0: 6474 7970 6520 696e 2061 6c6c 5f69 6e74  dtype in all_int
-0001b9f0: 5f74 7970 6529 2920 6f72 205c 0a20 2020  _type)) or \.   
-0001ba00: 2020 2020 2020 2020 2028 6973 5f75 6e64           (is_und
-0001ba10: 6572 5f61 7363 656e 645f 636f 6e74 6578  er_ascend_contex
-0001ba20: 7428 2920 616e 6420 2869 6e70 7574 5f6d  t() and (input_m
-0001ba30: 732e 6474 7970 6520 696e 2028 6d73 2e66  s.dtype in (ms.f
-0001ba40: 6c6f 6174 3634 2c29 202b 2061 6c6c 5f69  loat64,) + all_i
-0001ba50: 6e74 5f74 7970 6529 293a 0a20 2020 2020  nt_type)):.     
-0001ba60: 2020 2020 2020 2077 6172 6e69 6e67 2822         warning("
-0001ba70: 466f 7220 7664 6f74 2c20 696e 7075 745f  For vdot, input_
-0001ba80: 6d73 2077 6974 6820 696e 7436 3420 7479  ms with int64 ty
-0001ba90: 7065 2068 6173 2072 6973 6b20 6f66 2062  pe has risk of b
-0001baa0: 6569 6e67 2074 7275 6e63 6174 6564 2e22  eing truncated."
-0001bab0: 290a 2020 2020 2020 2020 2020 2020 696e  ).            in
-0001bac0: 7075 745f 6474 7970 6520 3d20 696e 7075  put_dtype = inpu
-0001bad0: 745f 6d73 2e64 7479 7065 0a20 2020 2020  t_ms.dtype.     
-0001bae0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0001baf0: 3d20 696e 7075 745f 6d73 2e61 7374 7970  = input_ms.astyp
-0001bb00: 6528 6d73 2e66 6c6f 6174 3332 290a 2020  e(ms.float32).  
-0001bb10: 2020 2020 2020 2020 2020 6f74 6865 7220            other 
-0001bb20: 3d20 6f74 6865 722e 6173 7479 7065 286d  = other.astype(m
-0001bb30: 732e 666c 6f61 7433 3229 0a20 2020 2020  s.float32).     
-0001bb40: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001bb50: 6d73 2e6f 7073 2e69 6e6e 6572 2869 6e70  ms.ops.inner(inp
-0001bb60: 7574 5f6d 732c 206f 7468 6572 292e 6173  ut_ms, other).as
-0001bb70: 7479 7065 2869 6e70 7574 5f64 7479 7065  type(input_dtype
-0001bb80: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-0001bb90: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-0001bba0: 7574 203d 206d 732e 6f70 732e 696e 6e65  ut = ms.ops.inne
-0001bbb0: 7228 696e 7075 745f 6d73 2c20 6f74 6865  r(input_ms, othe
-0001bbc0: 7229 0a20 2020 2020 2020 2072 6574 7572  r).        retur
-0001bbd0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-0001bbe0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-0001bbf0: 0a0a 2020 2020 6465 6620 7768 6572 6528  ..    def where(
-0001bc00: 7365 6c66 2c20 636f 6e64 6974 696f 6e2c  self, condition,
-0001bc10: 2079 293a 0a20 2020 2020 2020 2078 203d   y):.        x =
-0001bc20: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0001bc30: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-0001bc40: 2079 203d 2063 6173 745f 746f 5f6d 735f   y = cast_to_ms_
-0001bc50: 7465 6e73 6f72 2879 290a 2020 2020 2020  tensor(y).      
-0001bc60: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-0001bc70: 732e 7768 6572 6528 636f 6e64 6974 696f  s.where(conditio
-0001bc80: 6e2c 2078 2c20 7929 0a20 2020 2020 2020  n, x, y).       
-0001bc90: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0001bca0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-0001bcb0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-0001bcc0: 7472 7565 5f64 6976 6964 6528 7365 6c66  true_divide(self
-0001bcd0: 2c20 6469 7669 736f 7229 3a0a 2020 2020  , divisor):.    
-0001bce0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-0001bcf0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0001bd00: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-0001bd10: 7468 6572 203d 2063 6173 745f 746f 5f6d  ther = cast_to_m
-0001bd20: 735f 7465 6e73 6f72 2864 6976 6973 6f72  s_tensor(divisor
-0001bd30: 290a 2020 2020 2020 2020 6966 206e 6f74  ).        if not
-0001bd40: 2069 6e70 7574 5f6d 732e 6973 5f66 6c6f   input_ms.is_flo
-0001bd50: 6174 696e 675f 706f 696e 7428 293a 0a20  ating_point():. 
-0001bd60: 2020 2020 2020 2020 2020 2069 6620 6973             if is
-0001bd70: 696e 7374 616e 6365 286f 7468 6572 2c20  instance(other, 
-0001bd80: 6d73 2e54 656e 736f 7229 3a0a 2020 2020  ms.Tensor):.    
-0001bd90: 2020 2020 2020 2020 2020 2020 6966 206e              if n
-0001bda0: 6f74 206f 7468 6572 2e69 735f 666c 6f61  ot other.is_floa
-0001bdb0: 7469 6e67 5f70 6f69 6e74 2829 3a0a 2020  ting_point():.  
-0001bdc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bdd0: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
-0001bde0: 7574 5f6d 732e 6173 7479 7065 286d 732e  ut_ms.astype(ms.
-0001bdf0: 666c 6f61 7433 3229 0a0a 2020 2020 2020  float32)..      
-0001be00: 2020 2020 2020 656c 6966 206e 6f74 2069        elif not i
-0001be10: 7369 6e73 7461 6e63 6528 6f74 6865 722c  sinstance(other,
-0001be20: 2066 6c6f 6174 293a 0a20 2020 2020 2020   float):.       
-0001be30: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
-0001be40: 7320 3d20 696e 7075 745f 6d73 2e61 7374  s = input_ms.ast
-0001be50: 7970 6528 6d73 2e66 6c6f 6174 3332 290a  ype(ms.float32).
-0001be60: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-0001be70: 3d20 6d73 2e6f 7073 2e74 7275 655f 6469  = ms.ops.true_di
-0001be80: 7669 6465 2869 6e70 7574 5f6d 732c 206f  vide(input_ms, o
-0001be90: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
-0001bea0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-0001beb0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-0001bec0: 7574 290a 0a20 2020 2064 6566 2074 7275  ut)..    def tru
-0001bed0: 655f 6469 7669 6465 5f28 7365 6c66 2c20  e_divide_(self, 
-0001bee0: 6469 7669 736f 7229 3a0a 2020 2020 2020  divisor):.      
-0001bef0: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
-0001bf00: 7472 7565 5f64 6976 6964 6528 6469 7669  true_divide(divi
-0001bf10: 736f 7229 0a20 2020 2020 2020 2072 6574  sor).        ret
-0001bf20: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-0001bf30: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-0001bf40: 206f 7574 7075 742c 2022 7472 7565 5f64   output, "true_d
-0001bf50: 6976 6964 655f 222c 2022 7472 7565 5f64  ivide_", "true_d
-0001bf60: 6976 6964 6522 290a 0a20 2020 2064 6566  ivide")..    def
-0001bf70: 2074 7269 7528 7365 6c66 2c20 6469 6167   triu(self, diag
-0001bf80: 6f6e 616c 3d30 293a 0a20 2020 2020 2020  onal=0):.       
-0001bf90: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-0001bfa0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-0001bfb0: 6c66 290a 2020 2020 2020 2020 2320 544f  lf).        # TO
-0001bfc0: 444f 3a20 546f 2075 7365 206d 732e 6f70  DO: To use ms.op
-0001bfd0: 732e 7472 6975 2061 6674 6572 2069 7420  s.triu after it 
-0001bfe0: 7375 7070 6f72 7465 6420 6f6e 2041 7363  supported on Asc
-0001bff0: 656e 640a 2020 2020 2020 2020 6f75 7470  end.        outp
-0001c000: 7574 203d 206d 732e 6e75 6d70 792e 7472  ut = ms.numpy.tr
-0001c010: 6975 2869 6e70 7574 5f6d 732c 2064 6961  iu(input_ms, dia
-0001c020: 676f 6e61 6c29 0a20 2020 2020 2020 2072  gonal).        r
-0001c030: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0001c040: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-0001c050: 7075 7429 0a0a 2020 2020 6465 6620 7472  put)..    def tr
-0001c060: 6975 5f28 7365 6c66 2c20 6469 6167 6f6e  iu_(self, diagon
-0001c070: 616c 3d30 293a 0a20 2020 2020 2020 206f  al=0):.        o
-0001c080: 7574 7075 7420 3d20 7365 6c66 2e74 7269  utput = self.tri
-0001c090: 7528 6469 6167 6f6e 616c 290a 2020 2020  u(diagonal).    
-0001c0a0: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
-0001c0b0: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
-0001c0c0: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
-0001c0d0: 2274 7269 755f 222c 2022 7472 6975 2229  "triu_", "triu")
-0001c0e0: 0a0a 2020 2020 6465 6620 7472 696c 2873  ..    def tril(s
-0001c0f0: 656c 662c 2064 6961 676f 6e61 6c3d 3029  elf, diagonal=0)
-0001c100: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-0001c110: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0001c120: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-0001c130: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-0001c140: 2e6f 7073 2e74 7269 6c28 696e 7075 745f  .ops.tril(input_
-0001c150: 6d73 2c20 6469 6167 6f6e 616c 290a 2020  ms, diagonal).  
-0001c160: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-0001c170: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-0001c180: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-0001c190: 2064 6566 2074 7269 6c5f 2873 656c 662c   def tril_(self,
-0001c1a0: 2064 6961 676f 6e61 6c3d 3029 3a0a 2020   diagonal=0):.  
-0001c1b0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-0001c1c0: 656c 662e 7472 696c 2864 6961 676f 6e61  elf.tril(diagona
-0001c1d0: 6c29 0a20 2020 2020 2020 2072 6574 7572  l).        retur
-0001c1e0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-0001c1f0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-0001c200: 7574 7075 742c 2022 7472 696c 5f22 2c20  utput, "tril_", 
-0001c210: 2274 7269 6c22 290a 0a20 2020 2064 6566  "tril")..    def
-0001c220: 206e 616e 6d65 616e 2873 656c 662c 2064   nanmean(self, d
-0001c230: 696d 3d4e 6f6e 652c 206b 6565 7064 696d  im=None, keepdim
-0001c240: 3d46 616c 7365 2c20 2a2c 2064 7479 7065  =False, *, dtype
-0001c250: 3d4e 6f6e 6529 3a0a 2020 2020 2020 2020  =None):.        
-0001c260: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-0001c270: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-0001c280: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
-0001c290: 7420 3d20 6d73 2e6f 7073 2e6e 616e 6d65  t = ms.ops.nanme
-0001c2a0: 616e 2869 6e70 7574 5f6d 732c 2064 696d  an(input_ms, dim
-0001c2b0: 2c20 6b65 6570 6469 6d2c 2064 7479 7065  , keepdim, dtype
-0001c2c0: 3d64 7479 7065 290a 2020 2020 2020 2020  =dtype).        
-0001c2d0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0001c2e0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-0001c2f0: 7470 7574 290a 0a20 2020 2064 6566 206e  tput)..    def n
-0001c300: 616e 7375 6d28 7365 6c66 2c20 6469 6d3d  ansum(self, dim=
-0001c310: 4e6f 6e65 2c20 6b65 6570 6469 6d3d 4661  None, keepdim=Fa
-0001c320: 6c73 652c 2064 7479 7065 3d4e 6f6e 6529  lse, dtype=None)
-0001c330: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-0001c340: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0001c350: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-0001c360: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-0001c370: 2e6f 7073 2e6e 616e 7375 6d28 696e 7075  .ops.nansum(inpu
-0001c380: 745f 6d73 2c20 6469 6d2c 206b 6565 7064  t_ms, dim, keepd
-0001c390: 696d 2c20 6474 7970 653d 6474 7970 6529  im, dtype=dtype)
-0001c3a0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001c3b0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-0001c3c0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-0001c3d0: 2020 2020 6465 6620 6865 6176 6973 6964      def heavisid
-0001c3e0: 6528 7365 6c66 2c20 7661 6c75 6573 293a  e(self, values):
-0001c3f0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0001c400: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0001c410: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0001c420: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-0001c430: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-0001c440: 7228 696e 7075 745f 6d73 2e68 6561 7669  r(input_ms.heavi
-0001c450: 7369 6465 2876 616c 7565 7329 290a 0a20  side(values)).. 
-0001c460: 2020 2064 6566 2066 6c69 7075 6428 7365     def flipud(se
-0001c470: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
-0001c480: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0001c490: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0001c4a0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-0001c4b0: 206d 732e 6f70 732e 666c 6970 7564 2869   ms.ops.flipud(i
-0001c4c0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-0001c4d0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0001c4e0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-0001c4f0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-0001c500: 7469 6c65 2873 656c 662c 202a 7265 7073  tile(self, *reps
-0001c510: 293a 0a20 2020 2020 2020 2023 2054 4f44  ):.        # TOD
-0001c520: 4f3a 206d 732e 6f70 732e 7469 6c65 2074  O: ms.ops.tile t
-0001c530: 6f20 7375 7070 6f72 7420 7468 6520 6c65  o support the le
-0001c540: 6e20 6f66 2060 6d75 6c74 6970 6c65 7360  n of `multiples`
-0001c550: 2074 6f20 6265 206c 6573 7320 7468 616e   to be less than
-0001c560: 2069 6e70 7574 2e6e 6469 6d2e 0a20 2020   input.ndim..   
-0001c570: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
-0001c580: 6365 2872 6570 735b 305d 2c20 2874 7570  ce(reps[0], (tup
-0001c590: 6c65 2c20 6c69 7374 2929 3a0a 2020 2020  le, list)):.    
-0001c5a0: 2020 2020 2020 2020 7265 7073 203d 2074          reps = t
-0001c5b0: 7570 6c65 2872 6570 735b 305d 290a 2020  uple(reps[0]).  
-0001c5c0: 2020 2020 2020 6e65 775f 7265 7073 203d        new_reps =
-0001c5d0: 2028 312c 2920 2a20 2873 656c 662e 6e64   (1,) * (self.nd
-0001c5e0: 696d 202d 206c 656e 2872 6570 7329 2920  im - len(reps)) 
-0001c5f0: 2b20 7265 7073 0a20 2020 2020 2020 2072  + reps.        r
-0001c600: 6570 7320 3d20 6e65 775f 7265 7073 0a0a  eps = new_reps..
-0001c610: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-0001c620: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-0001c630: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-0001c640: 2020 2069 6620 6973 5f75 6e64 6572 5f67     if is_under_g
-0001c650: 7075 5f63 6f6e 7465 7874 2061 6e64 2069  pu_context and i
-0001c660: 6e70 7574 5f6d 732e 6474 7970 6520 3d3d  nput_ms.dtype ==
-0001c670: 206d 732e 7569 6e74 383a 0a20 2020 2020   ms.uint8:.     
-0001c680: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0001c690: 3d20 696e 7075 745f 6d73 2e61 7374 7970  = input_ms.astyp
-0001c6a0: 6528 6d73 2e66 6c6f 6174 3332 290a 2020  e(ms.float32).  
-0001c6b0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-0001c6c0: 203d 206d 732e 6f70 732e 7469 6c65 2869   = ms.ops.tile(i
-0001c6d0: 6e70 7574 5f6d 732c 2072 6570 7329 2e61  nput_ms, reps).a
-0001c6e0: 7374 7970 6528 6d73 2e75 696e 7438 290a  stype(ms.uint8).
-0001c6f0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-0001c700: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-0001c710: 203d 206d 732e 6f70 732e 7469 6c65 2869   = ms.ops.tile(i
-0001c720: 6e70 7574 5f6d 732c 2072 6570 7329 0a20  nput_ms, reps). 
-0001c730: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-0001c740: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-0001c750: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-0001c760: 2020 6465 6620 756e 6971 7565 5f63 6f6e    def unique_con
-0001c770: 7365 6375 7469 7665 2873 656c 662c 2072  secutive(self, r
-0001c780: 6574 7572 6e5f 696e 7665 7273 653d 4661  eturn_inverse=Fa
-0001c790: 6c73 652c 2072 6574 7572 6e5f 636f 756e  lse, return_coun
-0001c7a0: 7473 3d46 616c 7365 2c20 6469 6d3d 4e6f  ts=False, dim=No
-0001c7b0: 6e65 293a 0a20 2020 2020 2020 2069 6e70  ne):.        inp
-0001c7c0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0001c7d0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0001c7e0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-0001c7f0: 206d 732e 6f70 732e 756e 6971 7565 5f63   ms.ops.unique_c
-0001c800: 6f6e 7365 6375 7469 7665 2869 6e70 7574  onsecutive(input
-0001c810: 5f6d 732c 2072 6574 7572 6e5f 6964 783d  _ms, return_idx=
-0001c820: 7265 7475 726e 5f69 6e76 6572 7365 2c20  return_inverse, 
-0001c830: 7265 7475 726e 5f63 6f75 6e74 733d 7265  return_counts=re
-0001c840: 7475 726e 5f63 6f75 6e74 732c 2061 7869  turn_counts, axi
-0001c850: 733d 6469 6d29 0a20 2020 2020 2020 2072  s=dim).        r
-0001c860: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0001c870: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-0001c880: 7075 7429 0a0a 2020 2020 6465 6620 7461  put)..    def ta
-0001c890: 6e68 2873 656c 6629 3a0a 2020 2020 2020  nh(self):.      
-0001c8a0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
-0001c8b0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-0001c8c0: 656c 6629 0a20 2020 2020 2020 2069 6e70  elf).        inp
-0001c8d0: 7574 5f64 7479 7065 203d 2069 6e70 7574  ut_dtype = input
-0001c8e0: 5f6d 732e 6474 7970 650a 2020 2020 2020  _ms.dtype.      
-0001c8f0: 2020 6966 2069 6e70 7574 5f64 7479 7065    if input_dtype
-0001c900: 206e 6f74 2069 6e20 616c 6c5f 666c 6f61   not in all_floa
-0001c910: 745f 616e 645f 636f 6d70 6c65 785f 7479  t_and_complex_ty
-0001c920: 7065 3a0a 2020 2020 2020 2020 2020 2020  pe:.            
-0001c930: 696e 7075 745f 6d73 203d 2069 6e70 7574  input_ms = input
-0001c940: 5f6d 732e 6173 7479 7065 286d 732e 666c  _ms.astype(ms.fl
-0001c950: 6f61 7433 3229 0a20 2020 2020 2020 206f  oat32).        o
-0001c960: 7574 7075 7420 3d20 6d73 2e6f 7073 2e74  utput = ms.ops.t
-0001c970: 616e 6828 696e 7075 745f 6d73 290a 2020  anh(input_ms).  
-0001c980: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-0001c990: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-0001c9a0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-0001c9b0: 2064 6566 2074 616e 685f 2873 656c 6629   def tanh_(self)
-0001c9c0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-0001c9d0: 203d 2073 656c 662e 7461 6e68 2829 0a20   = self.tanh(). 
-0001c9e0: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-0001c9f0: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-0001ca00: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-0001ca10: 742c 2022 7461 6e68 5f22 2c20 2274 616e  t, "tanh_", "tan
-0001ca20: 6822 290a 0a20 2020 2064 6566 2074 616e  h")..    def tan
-0001ca30: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-0001ca40: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-0001ca50: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-0001ca60: 6629 0a20 2020 2020 2020 2069 6620 6e6f  f).        if no
-0001ca70: 7420 696e 7075 745f 6d73 2e69 735f 666c  t input_ms.is_fl
-0001ca80: 6f61 7469 6e67 5f70 6f69 6e74 2829 3a0a  oating_point():.
-0001ca90: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
-0001caa0: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
-0001cab0: 6173 7479 7065 286d 732e 666c 6f61 7433  astype(ms.float3
-0001cac0: 3229 0a20 2020 2020 2020 206f 7574 7075  2).        outpu
-0001cad0: 7420 3d20 6d73 2e6f 7073 2e74 616e 2869  t = ms.ops.tan(i
-0001cae0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-0001caf0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0001cb00: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-0001cb10: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-0001cb20: 7461 6e5f 2873 656c 6629 3a0a 2020 2020  tan_(self):.    
-0001cb30: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-0001cb40: 662e 7461 6e28 290a 2020 2020 2020 2020  f.tan().        
-0001cb50: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-0001cb60: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-0001cb70: 6c66 2c20 6f75 7470 7574 2c20 2274 616e  lf, output, "tan
-0001cb80: 5f22 2c20 2274 616e 2229 0a0a 2020 2020  _", "tan")..    
-0001cb90: 6465 6620 7465 6e73 6f72 5f73 706c 6974  def tensor_split
-0001cba0: 2873 656c 662c 2069 6e64 6963 6573 5f6f  (self, indices_o
-0001cbb0: 725f 7365 6374 696f 6e73 2c20 6469 6d3d  r_sections, dim=
-0001cbc0: 3029 3a0a 2020 2020 2020 2020 696e 7075  0):.        inpu
-0001cbd0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-0001cbe0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-0001cbf0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001cc00: 6d73 2e6f 7073 2e74 656e 736f 725f 7370  ms.ops.tensor_sp
-0001cc10: 6c69 7428 696e 7075 745f 6d73 2c20 696e  lit(input_ms, in
-0001cc20: 6469 6365 735f 6f72 5f73 6563 7469 6f6e  dices_or_section
-0001cc30: 732c 2061 7869 733d 6469 6d29 0a20 2020  s, axis=dim).   
-0001cc40: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0001cc50: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0001cc60: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0001cc70: 6465 6620 7461 6b65 2873 656c 662c 2069  def take(self, i
-0001cc80: 6e64 6578 293a 0a20 2020 2020 2020 2069  ndex):.        i
-0001cc90: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0001cca0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0001ccb0: 290a 2020 2020 2020 2020 696e 6465 7820  ).        index 
-0001ccc0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-0001ccd0: 736f 7228 696e 6465 7829 0a20 2020 2020  sor(index).     
-0001cce0: 2020 206f 7574 7075 7420 3d20 696e 7075     output = inpu
-0001ccf0: 745f 6d73 2e74 616b 6528 696e 6465 7829  t_ms.take(index)
-0001cd00: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001cd10: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-0001cd20: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-0001cd30: 2020 2020 6465 6620 7461 6b65 5f61 6c6f      def take_alo
-0001cd40: 6e67 5f64 696d 2873 656c 662c 2069 6e64  ng_dim(self, ind
-0001cd50: 6963 6573 2c20 6469 6d3d 4e6f 6e65 293a  ices, dim=None):
-0001cd60: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0001cd70: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0001cd80: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0001cd90: 2020 2020 696e 6469 6365 7320 3d20 6361      indices = ca
-0001cda0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-0001cdb0: 696e 6469 6365 7329 0a0a 2020 2020 2020  indices)..      
-0001cdc0: 2020 6966 206e 6f74 2064 696d 3a0a 2020    if not dim:.  
-0001cdd0: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-0001cde0: 6d73 203d 2069 6e70 7574 5f6d 732e 7265  ms = input_ms.re
-0001cdf0: 7368 6170 6528 2d31 290a 2020 2020 2020  shape(-1).      
-0001ce00: 2020 2020 2020 6469 6d20 3d20 300a 0a20        dim = 0.. 
-0001ce10: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001ce20: 6d73 2e6f 7073 2e67 6174 6865 725f 6428  ms.ops.gather_d(
-0001ce30: 696e 7075 745f 6d73 2c20 6469 6d2c 2069  input_ms, dim, i
-0001ce40: 6e64 6963 6573 290a 2020 2020 2020 2020  ndices).        
-0001ce50: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0001ce60: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-0001ce70: 7470 7574 290a 0a20 2020 2064 6566 2073  tput)..    def s
-0001ce80: 696e 6328 7365 6c66 293a 0a20 2020 2020  inc(self):.     
-0001ce90: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-0001cea0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-0001ceb0: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
-0001cec0: 7470 7574 203d 206d 732e 6f70 732e 7369  tput = ms.ops.si
-0001ced0: 6e63 2869 6e70 7574 5f6d 7329 0a20 2020  nc(input_ms).   
-0001cee0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0001cef0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0001cf00: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0001cf10: 6465 6620 7369 6e63 5f28 7365 6c66 293a  def sinc_(self):
-0001cf20: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-0001cf30: 3d20 7365 6c66 2e73 696e 6328 290a 2020  = self.sinc().  
-0001cf40: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-0001cf50: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-0001cf60: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-0001cf70: 2c20 2273 696e 635f 222c 2022 7369 6e63  , "sinc_", "sinc
-0001cf80: 2229 0a0a 2020 2020 6465 6620 7369 6e68  ")..    def sinh
-0001cf90: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-0001cfa0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-0001cfb0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-0001cfc0: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
-0001cfd0: 7420 3d20 6d73 2e6f 7073 2e73 696e 6828  t = ms.ops.sinh(
-0001cfe0: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
-0001cff0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0001d000: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0001d010: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-0001d020: 2073 696e 685f 2873 656c 6629 3a0a 2020   sinh_(self):.  
-0001d030: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-0001d040: 656c 662e 7369 6e68 2829 0a20 2020 2020  elf.sinh().     
-0001d050: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-0001d060: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-0001d070: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-0001d080: 7369 6e68 5f22 2c20 2273 696e 6822 290a  sinh_", "sinh").
-0001d090: 0a0a 2020 2020 6465 6620 6861 7264 7368  ..    def hardsh
-0001d0a0: 7269 6e6b 2873 656c 662c 206c 616d 6264  rink(self, lambd
-0001d0b0: 3d30 2e35 293a 0a20 2020 2020 2020 2023  =0.5):.        #
-0001d0c0: 2073 7570 706f 7274 206f 6e6c 7920 666c   support only fl
-0001d0d0: 6f61 7431 3620 616e 6420 666c 6f61 7433  oat16 and float3
-0001d0e0: 320a 2020 2020 2020 2020 696e 7075 745f  2.        input_
-0001d0f0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0001d100: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-0001d110: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-0001d120: 2e6f 7073 2e68 6172 6473 6872 696e 6b28  .ops.hardshrink(
-0001d130: 696e 7075 745f 6d73 2c20 6c61 6d62 6429  input_ms, lambd)
-0001d140: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001d150: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-0001d160: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-0001d170: 2020 2020 6465 6620 6873 706c 6974 2873      def hsplit(s
-0001d180: 656c 662c 2073 706c 6974 5f73 697a 655f  elf, split_size_
-0001d190: 6f72 5f73 6563 7469 6f6e 7329 3a0a 2020  or_sections):.  
-0001d1a0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-0001d1b0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0001d1c0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-0001d1d0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-0001d1e0: 2e68 7370 6c69 7428 696e 7075 745f 6d73  .hsplit(input_ms
-0001d1f0: 2c20 7370 6c69 745f 7369 7a65 5f6f 725f  , split_size_or_
-0001d200: 7365 6374 696f 6e73 290a 2020 2020 2020  sections).      
-0001d210: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0001d220: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0001d230: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-0001d240: 2068 7970 6f74 2873 656c 662c 206f 7468   hypot(self, oth
-0001d250: 6572 293a 0a20 2020 2020 2020 2069 6e70  er):.        inp
-0001d260: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
-0001d270: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
-0001d280: 2020 2020 2020 2020 6f74 6865 725f 6d73          other_ms
-0001d290: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-0001d2a0: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
+000151e0: 2079 203d 2063 6173 745f 746f 5f6d 735f   y = cast_to_ms_
+000151f0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+00015200: 2020 2020 2020 2354 4f44 4f3a 204e 414e        #TODO: NAN
+00015210: 2069 7320 6469 6666 6572 656e 740a 2020   is different.  
+00015220: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00015230: 732e 6f70 732e 6d69 6e69 6d75 6d28 782c  s.ops.minimum(x,
+00015240: 2079 290a 2020 2020 2020 2020 7265 7475   y).        retu
+00015250: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00015260: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+00015270: 290a 0a20 2020 2064 6566 2066 6d61 7828  )..    def fmax(
+00015280: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
+00015290: 2020 2020 2020 6966 2069 735f 756e 6465        if is_unde
+000152a0: 725f 6173 6365 6e64 5f63 6f6e 7465 7874  r_ascend_context
+000152b0: 2829 206f 7220 6973 5f75 6e64 6572 5f67  () or is_under_g
+000152c0: 7075 5f63 6f6e 7465 7874 2829 3a0a 2020  pu_context():.  
+000152d0: 2020 2020 2020 2020 2020 666d 6178 5f6f            fmax_o
+000152e0: 7020 3d20 6e75 6d70 795f 6365 6c6c 2e4e  p = numpy_cell.N
+000152f0: 756d 7079 466d 6178 2827 666d 6178 2729  umpyFmax('fmax')
+00015300: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00015310: 7075 7420 3d20 666d 6178 5f6f 7028 7365  put = fmax_op(se
+00015320: 6c66 2c20 6f74 6865 7229 0a20 2020 2020  lf, other).     
+00015330: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00015340: 2020 2020 2078 203d 2063 6173 745f 746f       x = cast_to
+00015350: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+00015360: 0a20 2020 2020 2020 2020 2020 2079 203d  .            y =
+00015370: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00015380: 6f72 286f 7468 6572 290a 2020 2020 2020  or(other).      
+00015390: 2020 2020 2020 2320 544f 444f 3a20 6d73        # TODO: ms
+000153a0: 2e6f 7073 2e66 6d61 7820 6f6e 6c79 2073  .ops.fmax only s
+000153b0: 7570 706f 7274 2043 5055 206e 6f77 0a20  upport CPU now. 
+000153c0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+000153d0: 7420 3d20 6d73 2e6f 7073 2e66 6d61 7828  t = ms.ops.fmax(
+000153e0: 782c 2079 290a 2020 2020 2020 2020 7265  x, y).        re
+000153f0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00015400: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00015410: 7574 290a 0a20 2020 2064 6566 2066 6d69  ut)..    def fmi
+00015420: 6e28 7365 6c66 2c20 6f74 6865 7229 3a0a  n(self, other):.
+00015430: 2020 2020 2020 2020 666d 696e 5f6f 7020          fmin_op 
+00015440: 3d20 6e75 6d70 795f 6365 6c6c 2e4e 756d  = numpy_cell.Num
+00015450: 7079 466d 696e 2827 666d 696e 2729 0a20  pyFmin('fmin'). 
+00015460: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00015470: 666d 696e 5f6f 7028 7365 6c66 2c20 6f74  fmin_op(self, ot
+00015480: 6865 7229 0a20 2020 2020 2020 2072 6574  her).        ret
+00015490: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+000154a0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+000154b0: 7429 0a0a 2020 2020 6465 6620 6d75 6c74  t)..    def mult
+000154c0: 6970 6c79 2873 656c 662c 2076 616c 7565  iply(self, value
+000154d0: 293a 0a20 2020 2020 2020 2078 203d 2063  ):.        x = c
+000154e0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+000154f0: 2873 656c 6629 0a20 2020 2020 2020 2079  (self).        y
+00015500: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00015510: 6e73 6f72 2876 616c 7565 290a 2020 2020  nsor(value).    
+00015520: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00015530: 6f70 732e 6d75 6c28 782c 2079 290a 2020  ops.mul(x, y).  
+00015540: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00015550: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00015560: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00015570: 2064 6566 206d 756c 7469 706c 795f 2873   def multiply_(s
+00015580: 656c 662c 2076 616c 7565 293a 0a20 2020  elf, value):.   
+00015590: 2020 2020 206f 7574 7075 7420 3d20 7365       output = se
+000155a0: 6c66 2e6d 756c 7469 706c 7928 7661 6c75  lf.multiply(valu
+000155b0: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
+000155c0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+000155d0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+000155e0: 7574 7075 742c 2022 6d75 6c74 6970 6c79  utput, "multiply
+000155f0: 5f22 2c20 226d 756c 7469 706c 7922 290a  _", "multiply").
+00015600: 0a20 2020 2064 6566 206e 6567 2873 656c  .    def neg(sel
+00015610: 6629 3a0a 2020 2020 2020 2020 7820 3d20  f):.        x = 
+00015620: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00015630: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00015640: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+00015650: 6e65 6728 7829 0a20 2020 2020 2020 2072  neg(x).        r
+00015660: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00015670: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00015680: 7075 7429 0a0a 2020 2020 6465 6620 6e65  put)..    def ne
+00015690: 675f 2873 656c 6629 3a0a 2020 2020 2020  g_(self):.      
+000156a0: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
+000156b0: 6e65 6728 290a 2020 2020 2020 2020 7265  neg().        re
+000156c0: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+000156d0: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+000156e0: 2c20 6f75 7470 7574 2c20 226e 6567 5f22  , output, "neg_"
+000156f0: 2c20 226e 6567 2229 0a0a 2020 2020 6465  , "neg")..    de
+00015700: 6620 7261 7665 6c28 7365 6c66 293a 0a20  f ravel(self):. 
+00015710: 2020 2020 2020 2078 203d 2063 6173 745f         x = cast_
+00015720: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00015730: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
+00015740: 7420 3d20 782e 7261 7665 6c28 290a 2020  t = x.ravel().  
+00015750: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00015760: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00015770: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00015780: 2064 6566 2073 656c 6563 7428 7365 6c66   def select(self
+00015790: 2c20 6469 6d2c 2069 6e64 6578 293a 0a20  , dim, index):. 
+000157a0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+000157b0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+000157c0: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+000157d0: 2020 5f69 6e70 7574 5f69 6e64 6963 6573    _input_indices
+000157e0: 203d 206d 732e 5465 6e73 6f72 2869 6e64   = ms.Tensor(ind
+000157f0: 6578 290a 2020 2020 2020 2020 6f75 7470  ex).        outp
+00015800: 7574 203d 206d 732e 6f70 732e 6761 7468  ut = ms.ops.gath
+00015810: 6572 2869 6e70 7574 5f6d 732c 205f 696e  er(input_ms, _in
+00015820: 7075 745f 696e 6469 6365 732c 2064 696d  put_indices, dim
+00015830: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+00015840: 5f73 6861 7065 203d 205f 6765 745f 7365  _shape = _get_se
+00015850: 6c65 6374 5f6f 7574 5f73 6861 7065 2869  lect_out_shape(i
+00015860: 6e70 7574 5f6d 732e 7368 6170 652c 2064  nput_ms.shape, d
+00015870: 696d 290a 2020 2020 2020 2020 6f75 7470  im).        outp
+00015880: 7574 203d 206f 7574 7075 742e 7265 7368  ut = output.resh
+00015890: 6170 6528 6f75 7470 7574 5f73 6861 7065  ape(output_shape
+000158a0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000158b0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+000158c0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+000158d0: 0a20 2020 2064 6566 2073 7175 6172 6528  .    def square(
+000158e0: 7365 6c66 293a 0a20 2020 2020 2020 2078  self):.        x
+000158f0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00015900: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00015910: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+00015920: 7073 2e73 7175 6172 6528 7829 0a20 2020  ps.square(x).   
+00015930: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00015940: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00015950: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00015960: 6465 6620 7371 7561 7265 5f28 7365 6c66  def square_(self
+00015970: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+00015980: 7420 3d20 7365 6c66 2e73 7175 6172 6528  t = self.square(
+00015990: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000159a0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+000159b0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+000159c0: 7470 7574 2c20 2273 7175 6172 655f 222c  tput, "square_",
+000159d0: 2022 7371 7561 7265 2229 0a0a 2020 2020   "square")..    
+000159e0: 6465 6620 6272 6f61 6463 6173 745f 746f  def broadcast_to
+000159f0: 2873 656c 662c 2073 6861 7065 293a 0a20  (self, shape):. 
+00015a00: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+00015a10: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00015a20: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+00015a30: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
+00015a40: 7368 6170 652c 206c 6973 7429 3a0a 2020  shape, list):.  
+00015a50: 2020 2020 2020 2020 2020 7368 6170 6520            shape 
+00015a60: 3d20 7475 706c 6528 7368 6170 6529 0a20  = tuple(shape). 
+00015a70: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00015a80: 6d73 2e6f 7073 2e62 726f 6164 6361 7374  ms.ops.broadcast
+00015a90: 5f74 6f28 696e 7075 745f 6d73 2c20 7368  _to(input_ms, sh
+00015aa0: 6170 6529 0a20 2020 2020 2020 2072 6574  ape).        ret
+00015ab0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+00015ac0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+00015ad0: 7429 0a0a 2020 2020 6465 6620 6469 7669  t)..    def divi
+00015ae0: 6465 2873 656c 662c 2076 616c 7565 2c20  de(self, value, 
+00015af0: 2a2c 2072 6f75 6e64 696e 675f 6d6f 6465  *, rounding_mode
+00015b00: 3d4e 6f6e 6529 203a 0a20 2020 2020 2020  =None) :.       
+00015b10: 206f 7574 7075 7420 3d20 7365 6c66 2e64   output = self.d
+00015b20: 6976 2876 616c 7565 2c20 726f 756e 6469  iv(value, roundi
+00015b30: 6e67 5f6d 6f64 653d 726f 756e 6469 6e67  ng_mode=rounding
+00015b40: 5f6d 6f64 6529 0a20 2020 2020 2020 2072  _mode).        r
+00015b50: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00015b60: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00015b70: 7075 7429 0a0a 2020 2020 6465 6620 6469  put)..    def di
+00015b80: 7669 6465 5f28 7365 6c66 2c20 7661 6c75  vide_(self, valu
+00015b90: 652c 202a 2c20 726f 756e 6469 6e67 5f6d  e, *, rounding_m
+00015ba0: 6f64 653d 4e6f 6e65 2920 3a0a 2020 2020  ode=None) :.    
+00015bb0: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+00015bc0: 662e 6469 7628 7661 6c75 652c 2072 6f75  f.div(value, rou
+00015bd0: 6e64 696e 675f 6d6f 6465 3d72 6f75 6e64  nding_mode=round
+00015be0: 696e 675f 6d6f 6465 290a 2020 2020 2020  ing_mode).      
+00015bf0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+00015c00: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+00015c10: 7365 6c66 2c20 6f75 7470 7574 2c20 2264  self, output, "d
+00015c20: 6976 6964 655f 222c 2022 6469 7669 6465  ivide_", "divide
+00015c30: 2229 0a0a 2020 2020 6465 6620 756e 6971  ")..    def uniq
+00015c40: 7565 2873 656c 662c 2073 6f72 7465 643d  ue(self, sorted=
+00015c50: 5472 7565 2c20 7265 7475 726e 5f69 6e76  True, return_inv
+00015c60: 6572 7365 3d46 616c 7365 2c20 7265 7475  erse=False, retu
+00015c70: 726e 5f63 6f75 6e74 733d 4661 6c73 652c  rn_counts=False,
+00015c80: 2064 696d 3d4e 6f6e 6529 3a0a 2020 2020   dim=None):.    
+00015c90: 2020 2020 756e 7375 7070 6f72 7465 645f      unsupported_
+00015ca0: 6174 7472 2864 696d 290a 2020 2020 2020  attr(dim).      
+00015cb0: 2020 756e 7375 7070 6f72 7465 645f 6174    unsupported_at
+00015cc0: 7472 2872 6574 7572 6e5f 636f 756e 7473  tr(return_counts
+00015cd0: 290a 2020 2020 2020 2020 696e 7075 745f  ).        input_
+00015ce0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00015cf0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+00015d00: 2020 2020 2064 6174 615f 7479 7065 203d       data_type =
+00015d10: 2069 6e70 7574 5f6d 732e 6474 7970 650a   input_ms.dtype.
+00015d20: 2020 2020 2020 2020 6966 2073 6f72 7465          if sorte
+00015d30: 6420 616e 6420 7265 7475 726e 5f69 6e76  d and return_inv
+00015d40: 6572 7365 3a0a 2020 2020 2020 2020 2020  erse:.          
+00015d50: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00015d60: 6f72 2822 446f 6e27 7420 7375 7070 6f72  or("Don't suppor
+00015d70: 7420 736f 7274 6564 3d54 7275 6520 616e  t sorted=True an
+00015d80: 6420 7265 7475 726e 5f69 6e76 6572 7365  d return_inverse
+00015d90: 3d54 7275 652e 2229 0a0a 2020 2020 2020  =True.")..      
+00015da0: 2020 7265 732c 2069 6478 203d 206d 732e    res, idx = ms.
+00015db0: 6f70 732e 756e 6971 7565 2869 6e70 7574  ops.unique(input
+00015dc0: 5f6d 7329 0a20 2020 2020 2020 2069 6620  _ms).        if 
+00015dd0: 736f 7274 6564 3a0a 2020 2020 2020 2020  sorted:.        
+00015de0: 2020 2020 7265 7320 3d20 6d73 2e6f 7073      res = ms.ops
+00015df0: 2e63 6173 7428 7265 732c 206d 732e 666c  .cast(res, ms.fl
+00015e00: 6f61 7433 3229 0a20 2020 2020 2020 2020  oat32).         
+00015e10: 2020 2072 6573 2c20 5f20 3d20 6d73 2e6f     res, _ = ms.o
+00015e20: 7073 2e73 6f72 7428 7265 7329 0a20 2020  ps.sort(res).   
+00015e30: 2020 2020 2020 2020 2072 6573 203d 206d           res = m
+00015e40: 732e 6f70 732e 6361 7374 2872 6573 2c20  s.ops.cast(res, 
+00015e50: 6461 7461 5f74 7970 6529 0a20 2020 2020  data_type).     
+00015e60: 2020 2069 6620 7265 7475 726e 5f69 6e76     if return_inv
+00015e70: 6572 7365 3a0a 2020 2020 2020 2020 2020  erse:.          
+00015e80: 2020 7265 7320 3d20 6361 7374 5f74 6f5f    res = cast_to_
+00015e90: 6164 6170 7465 725f 7465 6e73 6f72 2872  adapter_tensor(r
+00015ea0: 6573 290a 2020 2020 2020 2020 2020 2020  es).            
+00015eb0: 6964 7820 3d20 6361 7374 5f74 6f5f 6164  idx = cast_to_ad
+00015ec0: 6170 7465 725f 7465 6e73 6f72 2869 6478  apter_tensor(idx
+00015ed0: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
+00015ee0: 7475 726e 2028 7265 732c 2069 6478 290a  turn (res, idx).
+00015ef0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00015f00: 2020 2020 2020 2020 2020 7265 7320 3d20            res = 
+00015f10: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00015f20: 7465 6e73 6f72 2872 6573 290a 2020 2020  tensor(res).    
+00015f30: 2020 2020 2020 2020 7265 7475 726e 2072          return r
+00015f40: 6573 0a0a 2020 2020 6465 6620 6d6d 2873  es..    def mm(s
+00015f50: 656c 662c 206d 6174 3229 3a0a 2020 2020  elf, mat2):.    
+00015f60: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+00015f70: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00015f80: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
+00015f90: 6e70 7574 3220 3d20 6361 7374 5f74 6f5f  nput2 = cast_to_
+00015fa0: 6d73 5f74 656e 736f 7228 6d61 7432 290a  ms_tensor(mat2).
+00015fb0: 2020 2020 2020 2020 696e 7075 745f 7479          input_ty
+00015fc0: 7065 203d 2069 6e70 7574 5f6d 732e 6474  pe = input_ms.dt
+00015fd0: 7970 650a 2020 2020 2020 2020 6966 2069  ype.        if i
+00015fe0: 6e70 7574 5f74 7970 6520 696e 2061 6c6c  nput_type in all
+00015ff0: 5f69 6e74 5f74 7970 6520 616e 6420 6973  _int_type and is
+00016000: 5f75 6e64 6572 5f67 7075 5f63 6f6e 7465  _under_gpu_conte
+00016010: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
+00016020: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
+00016030: 7574 5f6d 732e 6173 7479 7065 286d 7374  ut_ms.astype(mst
+00016040: 7970 652e 666c 6f61 7433 3229 0a20 2020  ype.float32).   
+00016050: 2020 2020 2020 2020 2069 6e70 7574 3220           input2 
+00016060: 3d20 696e 7075 7432 2e61 7374 7970 6528  = input2.astype(
+00016070: 6d73 7479 7065 2e66 6c6f 6174 3332 290a  mstype.float32).
+00016080: 2020 2020 2020 2020 2020 2020 2320 544f              # TO
+00016090: 444f 3a20 7265 7061 6c63 6520 7769 7468  DO: repalce with
+000160a0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+000160b0: 2e6d 6174 6d75 6c28 696e 7075 745f 6d73  .matmul(input_ms
+000160c0: 2c20 696e 7075 7432 290a 2020 2020 2020  , input2).      
+000160d0: 2020 2020 2020 6f75 7470 7574 203d 2063        output = c
+000160e0: 7573 746f 6d5f 6d61 746d 756c 2869 6e70  ustom_matmul(inp
+000160f0: 7574 5f6d 732c 2069 6e70 7574 3229 0a20  ut_ms, input2). 
+00016100: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+00016110: 7420 3d20 6d73 2e6f 7073 2e63 6173 7428  t = ms.ops.cast(
+00016120: 6f75 7470 7574 2c20 696e 7075 745f 7479  output, input_ty
+00016130: 7065 290a 2020 2020 2020 2020 656c 7365  pe).        else
+00016140: 3a0a 2020 2020 2020 2020 2020 2020 2320  :.            # 
+00016150: 544f 444f 3a20 7265 7061 6c63 6520 7769  TODO: repalce wi
+00016160: 7468 206f 7574 7075 7420 3d20 6d73 2e6f  th output = ms.o
+00016170: 7073 2e6d 6174 6d75 6c28 696e 7075 745f  ps.matmul(input_
+00016180: 6d73 2c20 696e 7075 7432 290a 2020 2020  ms, input2).    
+00016190: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000161a0: 2063 7573 746f 6d5f 6d61 746d 756c 2869   custom_matmul(i
+000161b0: 6e70 7574 5f6d 732c 2069 6e70 7574 3229  nput_ms, input2)
+000161c0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000161d0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+000161e0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+000161f0: 2020 2020 6465 6620 6c6f 6773 756d 6578      def logsumex
+00016200: 7028 7365 6c66 2c20 6469 6d2c 206b 6565  p(self, dim, kee
+00016210: 7064 696d 3d46 616c 7365 293a 0a20 2020  pdim=False):.   
+00016220: 2020 2020 206d 735f 696e 7075 7420 3d20       ms_input = 
+00016230: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00016240: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00016250: 6966 206d 735f 696e 7075 742e 6474 7970  if ms_input.dtyp
+00016260: 6520 213d 206d 7374 7970 652e 666c 6f61  e != mstype.floa
+00016270: 7433 323a 0a20 2020 2020 2020 2020 2020  t32:.           
+00016280: 206d 735f 696e 7075 7420 3d20 6d73 5f69   ms_input = ms_i
+00016290: 6e70 7574 2e61 7374 7970 6528 6d73 7479  nput.astype(msty
+000162a0: 7065 2e66 6c6f 6174 3332 290a 2020 2020  pe.float32).    
+000162b0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+000162c0: 6f70 732e 6c6f 6773 756d 6578 7028 6d73  ops.logsumexp(ms
+000162d0: 5f69 6e70 7574 2c20 6469 6d2c 206b 6565  _input, dim, kee
+000162e0: 7064 696d 290a 2020 2020 2020 2020 7265  pdim).        re
+000162f0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00016300: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00016310: 7574 290a 0a20 2020 2064 6566 2061 6464  ut)..    def add
+00016320: 6d76 2873 656c 662c 206d 6174 2c20 7665  mv(self, mat, ve
+00016330: 632c 202a 2c20 6265 7461 3d31 2c20 616c  c, *, beta=1, al
+00016340: 7068 613d 3129 3a0a 2020 2020 2020 2020  pha=1):.        
+00016350: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+00016360: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00016370: 6629 0a20 2020 2020 2020 206d 6174 203d  f).        mat =
+00016380: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00016390: 6f72 286d 6174 290a 2020 2020 2020 2020  or(mat).        
+000163a0: 7665 6320 3d20 6361 7374 5f74 6f5f 6d73  vec = cast_to_ms
+000163b0: 5f74 656e 736f 7228 7665 6329 0a20 2020  _tensor(vec).   
+000163c0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+000163d0: 2e6f 7073 2e61 6464 6d76 2869 6e70 7574  .ops.addmv(input
+000163e0: 5f6d 732c 206d 6174 2c20 7665 632c 2062  _ms, mat, vec, b
+000163f0: 6574 613d 6265 7461 2c20 616c 7068 613d  eta=beta, alpha=
+00016400: 616c 7068 6129 0a20 2020 2020 2020 2072  alpha).        r
+00016410: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00016420: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00016430: 7075 7429 0a0a 2020 2020 6465 6620 6164  put)..    def ad
+00016440: 646d 765f 2873 656c 662c 206d 6174 2c20  dmv_(self, mat, 
+00016450: 7665 632c 202a 2c20 6265 7461 3d31 2c20  vec, *, beta=1, 
+00016460: 616c 7068 613d 3129 3a0a 2020 2020 2020  alpha=1):.      
+00016470: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
+00016480: 6164 646d 7628 6d61 742c 2076 6563 2c20  addmv(mat, vec, 
+00016490: 6265 7461 3d62 6574 612c 2061 6c70 6861  beta=beta, alpha
+000164a0: 3d61 6c70 6861 290a 2020 2020 2020 2020  =alpha).        
+000164b0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
+000164c0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
+000164d0: 6c66 2c20 6f75 7470 7574 2c20 2261 6464  lf, output, "add
+000164e0: 6d76 5f22 2c20 2261 6464 6d76 2229 0a0a  mv_", "addmv")..
+000164f0: 2020 2020 6465 6620 646f 7428 7365 6c66      def dot(self
+00016500: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+00016510: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+00016520: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+00016530: 656c 6629 0a20 2020 2020 2020 206f 7468  elf).        oth
+00016540: 6572 203d 2063 6173 745f 746f 5f6d 735f  er = cast_to_ms_
+00016550: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+00016560: 2020 2020 2020 2354 4f44 4f3a 206d 732e        #TODO: ms.
+00016570: 6f70 732e 7465 6e73 6f72 5f64 6f74 206f  ops.tensor_dot o
+00016580: 6e6c 7920 7375 7070 6f72 7473 2066 6c6f  nly supports flo
+00016590: 6174 3136 2f66 6c6f 6174 3332 0a20 2020  at16/float32.   
+000165a0: 2020 2020 2069 6e70 7574 5f64 7479 7065       input_dtype
+000165b0: 203d 2069 6e70 7574 5f6d 732e 6474 7970   = input_ms.dtyp
+000165c0: 650a 2020 2020 2020 2020 6966 2069 6e70  e.        if inp
+000165d0: 7574 5f64 7479 7065 2069 6e20 286d 7374  ut_dtype in (mst
+000165e0: 7970 652e 666c 6f61 7433 322c 206d 7374  ype.float32, mst
+000165f0: 7970 652e 666c 6f61 7431 3629 3a0a 2020  ype.float16):.  
+00016600: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00016610: 203d 206d 732e 6f70 732e 7465 6e73 6f72   = ms.ops.tensor
+00016620: 5f64 6f74 2869 6e70 7574 5f6d 732c 206f  _dot(input_ms, o
+00016630: 7468 6572 2c20 3129 0a20 2020 2020 2020  ther, 1).       
+00016640: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00016650: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
+00016660: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
+00016670: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
+00016680: 2020 2020 2020 6f74 6865 7220 3d20 6f74        other = ot
+00016690: 6865 722e 6173 7479 7065 286d 732e 666c  her.astype(ms.fl
+000166a0: 6f61 7433 3229 0a20 2020 2020 2020 2020  oat32).         
+000166b0: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+000166c0: 7073 2e74 656e 736f 725f 646f 7428 696e  ps.tensor_dot(in
+000166d0: 7075 745f 6d73 2c20 6f74 6865 722c 2031  put_ms, other, 1
+000166e0: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
+000166f0: 7470 7574 203d 206f 7574 7075 742e 6173  tput = output.as
+00016700: 7479 7065 2869 6e70 7574 5f64 7479 7065  type(input_dtype
+00016710: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00016720: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00016730: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+00016740: 0a20 2020 2064 6566 2069 6e76 6572 7365  .    def inverse
+00016750: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00016760: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+00016770: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00016780: 6629 0a20 2020 2020 2020 2069 6620 7365  f).        if se
+00016790: 6c66 2e64 7479 7065 2069 6e20 6d69 6e64  lf.dtype in mind
+000167a0: 746f 7263 685f 6474 7970 652e 616c 6c5f  torch_dtype.all_
+000167b0: 696e 745f 7479 7065 3a0a 2020 2020 2020  int_type:.      
+000167c0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+000167d0: 2069 6e70 7574 5f6d 732e 6173 7479 7065   input_ms.astype
+000167e0: 286d 7374 7970 652e 666c 6f61 7433 3229  (mstype.float32)
+000167f0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+00016800: 3d20 6d73 2e6f 7073 2e69 6e76 6572 7365  = ms.ops.inverse
+00016810: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
+00016820: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00016830: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00016840: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00016850: 6620 6173 696e 2873 656c 6629 3a0a 2020  f asin(self):.  
+00016860: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00016870: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00016880: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00016890: 2069 6620 7365 6c66 2e64 7479 7065 2069   if self.dtype i
+000168a0: 6e20 6d69 6e64 746f 7263 685f 6474 7970  n mindtorch_dtyp
+000168b0: 652e 616c 6c5f 696e 745f 7479 7065 3a0a  e.all_int_type:.
+000168c0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+000168d0: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
+000168e0: 6173 7479 7065 286d 7374 7970 652e 666c  astype(mstype.fl
+000168f0: 6f61 7433 3229 0a20 2020 2020 2020 206f  oat32).        o
+00016900: 7574 7075 7420 3d20 6d73 2e6f 7073 2e61  utput = ms.ops.a
+00016910: 7369 6e28 696e 7075 745f 6d73 290a 2020  sin(input_ms).  
+00016920: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00016930: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00016940: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00016950: 2064 6566 2061 7369 6e5f 2873 656c 6629   def asin_(self)
+00016960: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
+00016970: 203d 2073 656c 662e 6173 696e 2829 0a20   = self.asin(). 
+00016980: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
+00016990: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
+000169a0: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
+000169b0: 742c 2022 6173 696e 5f22 2c20 2261 7369  t, "asin_", "asi
+000169c0: 6e22 290a 0a20 2020 2064 6566 2061 7461  n")..    def ata
+000169d0: 6e28 7365 6c66 293a 0a20 2020 2020 2020  n(self):.       
+000169e0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+000169f0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+00016a00: 6c66 290a 2020 2020 2020 2020 6966 2069  lf).        if i
+00016a10: 6e70 7574 5f6d 732e 6474 7970 6520 696e  nput_ms.dtype in
+00016a20: 2061 6c6c 5f69 6e74 5f74 7970 653a 0a20   all_int_type:. 
+00016a30: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00016a40: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
+00016a50: 7374 7970 6528 6d73 7479 7065 2e66 6c6f  stype(mstype.flo
+00016a60: 6174 3332 290a 2020 2020 2020 2020 6f75  at32).        ou
+00016a70: 7470 7574 203d 206d 732e 6f70 732e 6174  tput = ms.ops.at
+00016a80: 616e 2869 6e70 7574 5f6d 7329 0a20 2020  an(input_ms).   
+00016a90: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00016aa0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00016ab0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00016ac0: 6465 6620 6174 616e 5f28 7365 6c66 293a  def atan_(self):
+00016ad0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+00016ae0: 3d20 7365 6c66 2e61 7461 6e28 290a 2020  = self.atan().  
+00016af0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+00016b00: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+00016b10: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+00016b20: 2c20 2261 7461 6e5f 222c 2022 6174 616e  , "atan_", "atan
+00016b30: 2229 0a0a 2020 2020 6465 6620 6174 616e  ")..    def atan
+00016b40: 3228 7365 6c66 2c20 6f74 6865 7229 3a0a  2(self, other):.
+00016b50: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00016b60: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00016b70: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00016b80: 2020 206f 7468 6572 203d 2063 6173 745f     other = cast_
+00016b90: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
+00016ba0: 6572 290a 2020 2020 2020 2020 6966 2069  er).        if i
+00016bb0: 6e70 7574 5f6d 732e 6474 7970 6520 696e  nput_ms.dtype in
+00016bc0: 2061 6c6c 5f69 6e74 5f74 7970 653a 0a20   all_int_type:. 
+00016bd0: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00016be0: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
+00016bf0: 7374 7970 6528 6d73 7479 7065 2e66 6c6f  stype(mstype.flo
+00016c00: 6174 3332 290a 2020 2020 2020 2020 2020  at32).          
+00016c10: 2020 6f74 6865 7220 3d20 6f74 6865 722e    other = other.
+00016c20: 6173 7479 7065 286d 7374 7970 652e 666c  astype(mstype.fl
+00016c30: 6f61 7433 3229 0a20 2020 2020 2020 206f  oat32).        o
+00016c40: 7574 7075 7420 3d20 6d73 2e6f 7073 2e61  utput = ms.ops.a
+00016c50: 7461 6e32 2869 6e70 7574 5f6d 732c 206f  tan2(input_ms, o
+00016c60: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
+00016c70: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00016c80: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00016c90: 7574 290a 0a20 2020 2064 6566 2061 7461  ut)..    def ata
+00016ca0: 6e32 5f28 7365 6c66 2c20 6f74 6865 7229  n2_(self, other)
+00016cb0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
+00016cc0: 203d 2073 656c 662e 6174 616e 3228 6f74   = self.atan2(ot
+00016cd0: 6865 7229 0a20 2020 2020 2020 2072 6574  her).        ret
+00016ce0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+00016cf0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+00016d00: 206f 7574 7075 742c 2022 6174 616e 325f   output, "atan2_
+00016d10: 222c 2022 6174 616e 3222 290a 0a0a 2020  ", "atan2")...  
+00016d20: 2020 6465 6620 636f 756e 745f 6e6f 6e7a    def count_nonz
+00016d30: 6572 6f28 7365 6c66 2c20 6469 6d3d 4e6f  ero(self, dim=No
+00016d40: 6e65 293a 0a20 2020 2020 2020 2069 6e70  ne):.        inp
+00016d50: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+00016d60: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00016d70: 2020 2020 2020 2020 6966 2064 696d 2069          if dim i
+00016d80: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+00016d90: 2020 2020 6469 6d20 3d20 2829 0a20 2020      dim = ().   
+00016da0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+00016db0: 2e6f 7073 2e63 6f75 6e74 5f6e 6f6e 7a65  .ops.count_nonze
+00016dc0: 726f 2869 6e70 7574 5f6d 732c 2064 696d  ro(input_ms, dim
+00016dd0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00016de0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00016df0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+00016e00: 0a20 2020 2064 6566 2073 6361 7474 6572  .    def scatter
+00016e10: 2873 656c 662c 2064 696d 2c20 696e 6465  (self, dim, inde
+00016e20: 782c 2073 7263 2c20 7265 6475 6365 3d4e  x, src, reduce=N
+00016e30: 6f6e 6529 3a0a 2020 2020 2020 2020 6966  one):.        if
+00016e40: 206e 6f74 2072 6564 7563 653a 0a20 2020   not reduce:.   
+00016e50: 2020 2020 2020 2020 2072 6564 7563 6520           reduce 
+00016e60: 3d20 276e 6f6e 6527 0a20 2020 2020 2020  = 'none'.       
+00016e70: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00016e80: 2020 2023 2054 4f44 4f3a 2074 6f20 7375     # TODO: to su
+00016e90: 7070 6f72 7465 6420 276d 756c 7469 706c  pported 'multipl
+00016ea0: 7927 0a20 2020 2020 2020 2020 2020 2069  y'.            i
+00016eb0: 6620 7265 6475 6365 206e 6f74 2069 6e20  f reduce not in 
+00016ec0: 2827 6e6f 6e65 272c 2027 6164 6427 293a  ('none', 'add'):
+00016ed0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00016ee0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00016ef0: 7228 2246 6f72 2074 656e 736f 722e 7363  r("For tensor.sc
+00016f00: 6174 7465 7220 6f72 2073 6361 7474 6572  atter or scatter
+00016f10: 5f2c 2060 7265 6475 6365 6020 6f6e 6c79  _, `reduce` only
+00016f20: 2073 7570 706f 7274 2027 6e6f 6e65 272c   support 'none',
+00016f30: 2022 0a20 2020 2020 2020 2020 2020 2020   ".             
+00016f40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016f50: 2020 2020 6622 2761 6464 272c 2062 7574      f"'add', but
+00016f60: 2067 6f74 2027 7b72 6564 7563 657d 272e   got '{reduce}'.
+00016f70: 2229 0a0a 2020 2020 2020 2020 2020 2020  ")..            
+00016f80: 2320 544f 444f 3a20 6164 6420 6e6f 7420  # TODO: add not 
+00016f90: 7375 7070 6f72 7465 6420 6f6e 2041 7363  supported on Asc
+00016fa0: 656e 6420 7965 740a 2020 2020 2020 2020  end yet.        
+00016fb0: 2020 2020 6966 2072 6564 7563 6520 3d3d      if reduce ==
+00016fc0: 2027 6164 6427 2061 6e64 2069 735f 756e   'add' and is_un
+00016fd0: 6465 725f 6173 6365 6e64 5f63 6f6e 7465  der_ascend_conte
+00016fe0: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
+00016ff0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+00017000: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+00017010: 2246 6f72 2074 656e 736f 722e 7363 6174  "For tensor.scat
+00017020: 7465 7220 6f72 2073 6361 7474 6572 5f2c  ter or scatter_,
+00017030: 2060 7265 6475 6365 6020 3d3d 2027 6164   `reduce` == 'ad
+00017040: 6427 206e 6f74 2073 7570 706f 7274 6564  d' not supported
+00017050: 206f 6e20 4173 6365 6e64 2229 0a0a 2020   on Ascend")..  
+00017060: 2020 2020 2020 696e 7075 745f 6d73 2c20        input_ms, 
+00017070: 696e 6465 782c 2073 7263 203d 2063 6173  index, src = cas
+00017080: 745f 746f 5f6d 735f 7465 6e73 6f72 2828  t_to_ms_tensor((
+00017090: 7365 6c66 2c20 696e 6465 782c 2073 7263  self, index, src
+000170a0: 2929 0a0a 2020 2020 2020 2020 6966 2069  ))..        if i
+000170b0: 7369 6e73 7461 6e63 6528 7372 632c 206e  sinstance(src, n
+000170c0: 756d 6265 7273 2e4e 756d 6265 7229 3a0a  umbers.Number):.
+000170d0: 2020 2020 2020 2020 2020 2020 7372 6320              src 
+000170e0: 3d20 6d73 2e6f 7073 2e73 6361 6c61 725f  = ms.ops.scalar_
+000170f0: 746f 5f74 656e 736f 7228 7372 632c 2064  to_tensor(src, d
+00017100: 7479 7065 3d69 6e70 7574 5f6d 732e 6474  type=input_ms.dt
+00017110: 7970 6529 0a20 2020 2020 2020 2020 2020  ype).           
+00017120: 2073 7263 203d 206d 732e 6f70 732e 6272   src = ms.ops.br
+00017130: 6f61 6463 6173 745f 746f 2873 7263 2c20  oadcast_to(src, 
+00017140: 696e 6465 782e 7368 6170 6529 0a20 2020  index.shape).   
+00017150: 2020 2020 2065 6c69 6620 6973 696e 7374       elif isinst
+00017160: 616e 6365 2873 7263 2c20 6d73 2e54 656e  ance(src, ms.Ten
+00017170: 736f 7229 3a0a 2020 2020 2020 2020 2020  sor):.          
+00017180: 2020 7372 635f 7368 6170 6520 3d20 7372    src_shape = sr
+00017190: 632e 7368 6170 650a 2020 2020 2020 2020  c.shape.        
+000171a0: 2020 2020 696e 6465 785f 7368 6170 6520      index_shape 
+000171b0: 3d20 696e 6465 782e 7368 6170 650a 2020  = index.shape.  
+000171c0: 2020 2020 2020 2020 2020 6966 2073 7263            if src
+000171d0: 5f73 6861 7065 2021 3d20 696e 6465 785f  _shape != index_
+000171e0: 7368 6170 653a 0a20 2020 2020 2020 2020  shape:.         
+000171f0: 2020 2020 2020 2023 2054 4f44 4f0a 2020         # TODO.  
+00017200: 2020 2020 2020 2020 2020 2020 2020 7261                ra
+00017210: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
+00017220: 6564 4572 726f 7228 2246 6f72 2073 6361  edError("For sca
+00017230: 7474 6572 2c20 6e6f 7420 7375 7070 6f72  tter, not suppor
+00017240: 7420 7372 632e 7368 6170 6520 213d 2069  t src.shape != i
+00017250: 6e64 6578 2e73 6861 7065 2079 6574 2229  ndex.shape yet")
+00017260: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00017270: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00017280: 2054 7970 6545 7272 6f72 2866 2246 6f72   TypeError(f"For
+00017290: 2073 6361 7474 6572 2c20 6073 7263 6020   scatter, `src` 
+000172a0: 6d75 7374 2062 6520 6e75 6d62 6572 206f  must be number o
+000172b0: 7220 7465 6e73 6f72 2c20 6275 7420 676f  r tensor, but go
+000172c0: 7420 7b74 7970 6528 7372 6329 7d22 290a  t {type(src)}").
+000172d0: 0a20 2020 2020 2020 2069 6620 6973 5f75  .        if is_u
+000172e0: 6e64 6572 5f61 7363 656e 645f 636f 6e74  nder_ascend_cont
+000172f0: 6578 7428 293a 0a20 2020 2020 2020 2020  ext():.         
+00017300: 2020 2069 6e70 7574 5f64 7479 7065 203d     input_dtype =
+00017310: 2069 6e70 7574 5f6d 732e 6474 7970 650a   input_ms.dtype.
+00017320: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00017330: 745f 6d73 203d 205f 6173 6365 6e64 5f74  t_ms = _ascend_t
+00017340: 656e 736f 725f 6765 6e65 7261 6c5f 6361  ensor_general_ca
+00017350: 7374 2869 6e70 7574 5f6d 7329 0a20 2020  st(input_ms).   
+00017360: 2020 2020 2020 2020 2073 7263 203d 205f           src = _
+00017370: 6173 6365 6e64 5f74 656e 736f 725f 6765  ascend_tensor_ge
+00017380: 6e65 7261 6c5f 6361 7374 2873 7263 290a  neral_cast(src).
+00017390: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+000173a0: 7574 203d 206d 732e 6f70 732e 7465 6e73  ut = ms.ops.tens
+000173b0: 6f72 5f73 6361 7474 6572 5f65 6c65 6d65  or_scatter_eleme
+000173c0: 6e74 7328 696e 7075 745f 6d73 2c20 696e  nts(input_ms, in
+000173d0: 6465 782c 2073 7263 2c20 6469 6d2c 2072  dex, src, dim, r
+000173e0: 6564 7563 6529 0a20 2020 2020 2020 2020  educe).         
+000173f0: 2020 206f 7574 7075 7420 3d20 6f75 7470     output = outp
+00017400: 7574 2e61 7374 7970 6528 696e 7075 745f  ut.astype(input_
+00017410: 6474 7970 6529 0a20 2020 2020 2020 2065  dtype).        e
+00017420: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00017430: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00017440: 2e74 656e 736f 725f 7363 6174 7465 725f  .tensor_scatter_
+00017450: 656c 656d 656e 7473 2869 6e70 7574 5f6d  elements(input_m
+00017460: 732c 2069 6e64 6578 2c20 7372 632c 2064  s, index, src, d
+00017470: 696d 2c20 7265 6475 6365 290a 0a20 2020  im, reduce)..   
+00017480: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00017490: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+000174a0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+000174b0: 6465 6620 7363 6174 7465 725f 2873 656c  def scatter_(sel
+000174c0: 662c 2064 696d 2c20 696e 6465 782c 2073  f, dim, index, s
+000174d0: 7263 2c20 7265 6475 6365 3d4e 6f6e 6529  rc, reduce=None)
+000174e0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
+000174f0: 203d 2073 656c 662e 7363 6174 7465 7228   = self.scatter(
+00017500: 6469 6d2c 2069 6e64 6578 2c20 7372 632c  dim, index, src,
+00017510: 2072 6564 7563 6529 0a20 2020 2020 2020   reduce).       
+00017520: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+00017530: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+00017540: 656c 662c 206f 7574 7075 742c 2022 7363  elf, output, "sc
+00017550: 6174 7465 725f 222c 2022 7363 6174 7465  atter_", "scatte
+00017560: 7222 290a 0a20 2020 2064 6566 2061 636f  r")..    def aco
+00017570: 7368 2873 656c 6629 3a0a 2020 2020 2020  sh(self):.      
+00017580: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+00017590: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+000175a0: 656c 6629 0a20 2020 2020 2020 2069 6620  elf).        if 
+000175b0: 696e 7075 745f 6d73 2e64 7479 7065 2069  input_ms.dtype i
+000175c0: 6e20 616c 6c5f 696e 745f 7479 7065 3a0a  n all_int_type:.
+000175d0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+000175e0: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
+000175f0: 6173 7479 7065 286d 7374 7970 652e 666c  astype(mstype.fl
+00017600: 6f61 7433 3229 0a20 2020 2020 2020 206f  oat32).        o
+00017610: 7574 7075 7420 3d20 6d73 2e6f 7073 2e61  utput = ms.ops.a
+00017620: 636f 7368 2869 6e70 7574 5f6d 7329 0a20  cosh(input_ms). 
+00017630: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00017640: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00017650: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+00017660: 2020 6465 6620 6163 6f73 685f 2873 656c    def acosh_(sel
+00017670: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
+00017680: 7574 203d 2073 656c 662e 6163 6f73 6828  ut = self.acosh(
+00017690: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000176a0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+000176b0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+000176c0: 7470 7574 2c20 2261 636f 7368 5f22 2c20  tput, "acosh_", 
+000176d0: 2261 636f 7368 2229 0a0a 2020 2020 6465  "acosh")..    de
+000176e0: 6620 6e65 775f 6f6e 6573 2873 656c 662c  f new_ones(self,
+000176f0: 202a 7369 7a65 2c20 6474 7970 653d 4e6f   *size, dtype=No
+00017700: 6e65 2c20 6465 7669 6365 3d4e 6f6e 652c  ne, device=None,
+00017710: 2072 6571 7569 7265 735f 6772 6164 3d46   requires_grad=F
+00017720: 616c 7365 2c20 6c61 796f 7574 3d4e 6f6e  alse, layout=Non
+00017730: 652c 2070 696e 5f6d 656d 6f72 793d 4661  e, pin_memory=Fa
+00017740: 6c73 6529 3a0a 2020 2020 2020 2020 756e  lse):.        un
+00017750: 7375 7070 6f72 7465 645f 6174 7472 2864  supported_attr(d
+00017760: 6576 6963 6529 0a20 2020 2020 2020 2075  evice).        u
+00017770: 6e73 7570 706f 7274 6564 5f61 7474 7228  nsupported_attr(
+00017780: 6c61 796f 7574 290a 2020 2020 2020 2020  layout).        
+00017790: 756e 7375 7070 6f72 7465 645f 6174 7472  unsupported_attr
+000177a0: 2870 696e 5f6d 656d 6f72 7929 0a0a 2020  (pin_memory)..  
+000177b0: 2020 2020 2020 6966 2064 7479 7065 2069        if dtype i
+000177c0: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+000177d0: 2020 2020 6474 7970 6520 3d20 7365 6c66      dtype = self
+000177e0: 2e64 7479 7065 0a0a 2020 2020 2020 2020  .dtype..        
+000177f0: 6966 2069 7369 6e73 7461 6e63 6528 7369  if isinstance(si
+00017800: 7a65 5b30 5d2c 2028 7475 706c 652c 206c  ze[0], (tuple, l
+00017810: 6973 7429 293a 0a20 2020 2020 2020 2020  ist)):.         
+00017820: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+00017830: 7073 2e6f 6e65 7328 2a73 697a 652c 2064  ps.ones(*size, d
+00017840: 7479 7065 3d64 7479 7065 290a 2020 2020  type=dtype).    
+00017850: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+00017860: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00017870: 732e 6f70 732e 6f6e 6573 2873 697a 652c  s.ops.ones(size,
+00017880: 2064 7479 7065 3d64 7479 7065 290a 2020   dtype=dtype).  
+00017890: 2020 2020 2020 6f75 7470 7574 2e72 6571        output.req
+000178a0: 7569 7265 735f 6772 6164 203d 2072 6571  uires_grad = req
+000178b0: 7569 7265 735f 6772 6164 0a20 2020 2020  uires_grad.     
+000178c0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+000178d0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+000178e0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+000178f0: 6620 6e65 775f 656d 7074 7928 7365 6c66  f new_empty(self
+00017900: 2c20 2a73 697a 652c 2064 7479 7065 3d4e  , *size, dtype=N
+00017910: 6f6e 652c 206c 6179 6f75 743d 4e6f 6e65  one, layout=None
+00017920: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+00017930: 2020 2020 6465 7669 6365 3d4e 6f6e 652c      device=None,
+00017940: 2072 6571 7569 7265 735f 6772 6164 3d46   requires_grad=F
+00017950: 616c 7365 2c20 7069 6e5f 6d65 6d6f 7279  alse, pin_memory
+00017960: 3d46 616c 7365 2c0a 2020 2020 2020 2020  =False,.        
+00017970: 2020 2020 2020 2020 2020 6d65 6d6f 7279            memory
+00017980: 5f66 6f72 6d61 743d 4e6f 6e65 293a 0a20  _format=None):. 
+00017990: 2020 2020 2020 2075 6e73 7570 706f 7274         unsupport
+000179a0: 6564 5f61 7474 7228 6c61 796f 7574 290a  ed_attr(layout).
+000179b0: 2020 2020 2020 2020 756e 7375 7070 6f72          unsuppor
+000179c0: 7465 645f 6174 7472 2864 6576 6963 6529  ted_attr(device)
+000179d0: 0a20 2020 2020 2020 2075 6e73 7570 706f  .        unsuppo
+000179e0: 7274 6564 5f61 7474 7228 7069 6e5f 6d65  rted_attr(pin_me
+000179f0: 6d6f 7279 290a 2020 2020 2020 2020 756e  mory).        un
+00017a00: 7375 7070 6f72 7465 645f 6174 7472 286d  supported_attr(m
+00017a10: 656d 6f72 795f 666f 726d 6174 290a 2020  emory_format).  
+00017a20: 2020 2020 2020 6966 2064 7479 7065 2069        if dtype i
+00017a30: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
+00017a40: 2020 2020 6474 7970 6520 3d20 7365 6c66      dtype = self
+00017a50: 2e64 7479 7065 0a0a 2020 2020 2020 2020  .dtype..        
+00017a60: 5f73 697a 6520 3d20 7369 7a65 0a20 2020  _size = size.   
+00017a70: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
+00017a80: 6365 2873 697a 655b 305d 2c20 2874 7570  ce(size[0], (tup
+00017a90: 6c65 2c20 6c69 7374 2929 3a0a 2020 2020  le, list)):.    
+00017aa0: 2020 2020 2020 2020 5f73 697a 6520 3d20          _size = 
+00017ab0: 7369 7a65 5b30 5d0a 2020 2020 2020 2020  size[0].        
+00017ac0: 6f75 7470 7574 203d 206d 732e 6e75 6d70  output = ms.nump
+00017ad0: 792e 656d 7074 7928 5f73 697a 652c 2064  y.empty(_size, d
+00017ae0: 7479 7065 290a 2020 2020 2020 2020 6f75  type).        ou
+00017af0: 7470 7574 2e72 6571 7569 7265 735f 6772  tput.requires_gr
+00017b00: 6164 203d 2072 6571 7569 7265 735f 6772  ad = requires_gr
+00017b10: 6164 0a20 2020 2020 2020 2072 6574 7572  ad.        retur
+00017b20: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00017b30: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00017b40: 0a0a 2020 2020 6465 6620 6164 6463 6d75  ..    def addcmu
+00017b50: 6c28 7365 6c66 2c20 7465 6e73 6f72 312c  l(self, tensor1,
+00017b60: 2074 656e 736f 7232 2c20 2a2c 2076 616c   tensor2, *, val
+00017b70: 7565 3d31 293a 0a20 2020 2020 2020 2023  ue=1):.        #
+00017b80: 546f 646f 3a20 7573 6520 6d73 2e6f 7073  Todo: use ms.ops
+00017b90: 2e61 6464 636d 756c 2061 6674 6572 2069  .addcmul after i
+00017ba0: 7420 6861 7320 6265 656e 2066 6978 6564  t has been fixed
+00017bb0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+00017bc0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00017bd0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+00017be0: 2020 2020 7465 6e73 6f72 3120 3d20 6361      tensor1 = ca
+00017bf0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00017c00: 7465 6e73 6f72 3129 0a20 2020 2020 2020  tensor1).       
+00017c10: 2074 656e 736f 7232 203d 2063 6173 745f   tensor2 = cast_
+00017c20: 746f 5f6d 735f 7465 6e73 6f72 2874 656e  to_ms_tensor(ten
+00017c30: 736f 7232 290a 2020 2020 2020 2020 6966  sor2).        if
+00017c40: 2069 735f 756e 6465 725f 6173 6365 6e64   is_under_ascend
+00017c50: 5f63 6f6e 7465 7874 2829 3a0a 2020 2020  _context():.    
+00017c60: 2020 2020 2020 2020 7661 6c75 6520 3d20          value = 
+00017c70: 6d73 2e54 656e 736f 7228 7661 6c75 6529  ms.Tensor(value)
+00017c80: 2e61 7374 7970 6528 696e 7075 745f 6d73  .astype(input_ms
+00017c90: 2e64 7479 7065 290a 2020 2020 2020 2020  .dtype).        
+00017ca0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+00017cb0: 6164 6463 6d75 6c28 696e 7075 745f 6d73  addcmul(input_ms
+00017cc0: 2c20 7465 6e73 6f72 312c 2074 656e 736f  , tensor1, tenso
+00017cd0: 7232 2c20 7661 6c75 6529 0a20 2020 2020  r2, value).     
+00017ce0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00017cf0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00017d00: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00017d10: 6620 6164 6463 6d75 6c5f 2873 656c 662c  f addcmul_(self,
+00017d20: 2074 656e 736f 7231 2c20 7465 6e73 6f72   tensor1, tensor
+00017d30: 322c 202a 2c20 7661 6c75 653d 3129 3a0a  2, *, value=1):.
+00017d40: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00017d50: 2073 656c 662e 6164 6463 6d75 6c28 7465   self.addcmul(te
+00017d60: 6e73 6f72 312c 2074 656e 736f 7232 2c20  nsor1, tensor2, 
+00017d70: 7661 6c75 653d 7661 6c75 6529 0a20 2020  value=value).   
+00017d80: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
+00017d90: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
+00017da0: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
+00017db0: 2022 6164 6463 6d75 6c5f 222c 2022 6164   "addcmul_", "ad
+00017dc0: 6463 6d75 6c22 290a 0a20 2020 2064 6566  dcmul")..    def
+00017dd0: 2061 7263 636f 7368 2873 656c 6629 3a0a   arccosh(self):.
+00017de0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00017df0: 656c 662e 6163 6f73 6828 290a 0a20 2020  elf.acosh()..   
+00017e00: 2064 6566 2061 7263 636f 7368 5f28 7365   def arccosh_(se
+00017e10: 6c66 293a 0a20 2020 2020 2020 206f 7574  lf):.        out
+00017e20: 7075 7420 3d20 7365 6c66 2e61 636f 7368  put = self.acosh
+00017e30: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
+00017e40: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+00017e50: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00017e60: 7574 7075 742c 2022 6172 6363 6f73 685f  utput, "arccosh_
+00017e70: 222c 2022 6172 6363 6f73 6822 290a 0a20  ", "arccosh").. 
+00017e80: 2020 2064 6566 2061 7263 7369 6e28 7365     def arcsin(se
+00017e90: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
+00017ea0: 7572 6e20 7365 6c66 2e61 7369 6e28 290a  urn self.asin().
+00017eb0: 0a20 2020 2064 6566 2061 7263 7369 6e5f  .    def arcsin_
+00017ec0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00017ed0: 6f75 7470 7574 203d 2073 656c 662e 6173  output = self.as
+00017ee0: 696e 2829 0a20 2020 2020 2020 2072 6574  in().        ret
+00017ef0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+00017f00: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+00017f10: 206f 7574 7075 742c 2022 6172 6373 696e   output, "arcsin
+00017f20: 5f22 2c20 2261 7263 7369 6e22 290a 0a20  _", "arcsin").. 
+00017f30: 2020 2064 6566 2061 7263 7461 6e28 7365     def arctan(se
+00017f40: 6c66 293a 0a20 2020 2020 2020 2072 6574  lf):.        ret
+00017f50: 7572 6e20 7365 6c66 2e61 7461 6e28 290a  urn self.atan().
+00017f60: 0a20 2020 2064 6566 2061 7263 7461 6e5f  .    def arctan_
+00017f70: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00017f80: 6f75 7470 7574 203d 2073 656c 662e 6174  output = self.at
+00017f90: 616e 2829 0a20 2020 2020 2020 2072 6574  an().        ret
+00017fa0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+00017fb0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+00017fc0: 206f 7574 7075 742c 2022 6172 6374 616e   output, "arctan
+00017fd0: 5f22 2c20 2261 7263 7461 6e22 290a 0a20  _", "arctan").. 
+00017fe0: 2020 2064 6566 2061 7263 7461 6e32 2873     def arctan2(s
+00017ff0: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
+00018000: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00018010: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00018020: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00018030: 6f74 6865 7220 3d20 6361 7374 5f74 6f5f  other = cast_to_
+00018040: 6d73 5f74 656e 736f 7228 6f74 6865 7229  ms_tensor(other)
+00018050: 0a20 2020 2020 2020 2069 6620 696e 7075  .        if inpu
+00018060: 745f 6d73 2e64 7479 7065 2069 6e20 616c  t_ms.dtype in al
+00018070: 6c5f 696e 745f 7479 7065 3a0a 2020 2020  l_int_type:.    
+00018080: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00018090: 203d 2069 6e70 7574 5f6d 732e 6173 7479   = input_ms.asty
+000180a0: 7065 286d 7374 7970 652e 666c 6f61 7433  pe(mstype.float3
+000180b0: 3229 0a20 2020 2020 2020 2069 6620 6f74  2).        if ot
+000180c0: 6865 722e 6474 7970 6520 696e 2061 6c6c  her.dtype in all
+000180d0: 5f69 6e74 5f74 7970 653a 0a20 2020 2020  _int_type:.     
+000180e0: 2020 2020 2020 206f 7468 6572 203d 206f         other = o
+000180f0: 7468 6572 2e61 7374 7970 6528 6d73 7479  ther.astype(msty
+00018100: 7065 2e66 6c6f 6174 3332 290a 2020 2020  pe.float32).    
+00018110: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00018120: 6f70 732e 6174 616e 3228 696e 7075 745f  ops.atan2(input_
+00018130: 6d73 2c20 6f74 6865 7229 0a20 2020 2020  ms, other).     
+00018140: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00018150: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00018160: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00018170: 6620 6172 6374 616e 325f 2873 656c 662c  f arctan2_(self,
+00018180: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
+00018190: 206f 7574 7075 7420 3d20 7365 6c66 2e61   output = self.a
+000181a0: 7263 7461 6e32 286f 7468 6572 290a 2020  rctan2(other).  
+000181b0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+000181c0: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+000181d0: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+000181e0: 2c20 2261 7263 7461 6e32 5f22 2c20 2261  , "arctan2_", "a
+000181f0: 7263 7461 6e32 2229 0a0a 2020 2020 6465  rctan2")..    de
+00018200: 6620 6269 7477 6973 655f 6e6f 7428 7365  f bitwise_not(se
+00018210: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
+00018220: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+00018230: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00018240: 2020 2020 2020 2020 7479 7065 203d 2069          type = i
+00018250: 6e70 7574 5f6d 732e 6474 7970 650a 2020  nput_ms.dtype.  
+00018260: 2020 2020 2020 6966 2073 7472 2874 7970        if str(typ
+00018270: 6529 2021 3d20 2742 6f6f 6c27 3a0a 2020  e) != 'Bool':.  
+00018280: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00018290: 203d 2030 202d 2069 6e70 7574 5f6d 7320   = 0 - input_ms 
+000182a0: 2d20 310a 2020 2020 2020 2020 656c 7365  - 1.        else
+000182b0: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
+000182c0: 7470 7574 203d 2031 202d 2069 6e70 7574  tput = 1 - input
+000182d0: 5f6d 730a 2020 2020 2020 2020 2020 2020  _ms.            
+000182e0: 6f75 7470 7574 203d 206f 7574 7075 742e  output = output.
+000182f0: 6173 7479 7065 286d 732e 626f 6f6c 5f29  astype(ms.bool_)
+00018300: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00018310: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00018320: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+00018330: 2020 2020 6465 6620 6269 7477 6973 655f      def bitwise_
+00018340: 6e6f 745f 2873 656c 6629 3a0a 2020 2020  not_(self):.    
+00018350: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+00018360: 662e 6269 7477 6973 655f 6e6f 7428 7365  f.bitwise_not(se
+00018370: 6c66 290a 2020 2020 2020 2020 7265 7475  lf).        retu
+00018380: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+00018390: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+000183a0: 6f75 7470 7574 2c20 2262 6974 7769 7365  output, "bitwise
+000183b0: 5f6e 6f74 5f22 2c20 2262 6974 7769 7365  _not_", "bitwise
+000183c0: 5f6e 6f74 2229 0a0a 2020 2020 6465 6620  _not")..    def 
+000183d0: 6269 7477 6973 655f 616e 6428 7365 6c66  bitwise_and(self
+000183e0: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+000183f0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+00018400: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+00018410: 656c 6629 0a20 2020 2020 2020 206f 7468  elf).        oth
+00018420: 6572 203d 2063 6173 745f 746f 5f6d 735f  er = cast_to_ms_
+00018430: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+00018440: 2020 2020 2020 2354 4f44 4f3a 2063 7572        #TODO: cur
+00018450: 7265 6e74 6c79 2062 6974 7769 7365 206f  rently bitwise o
+00018460: 7065 7261 7469 6f6e 7320 6f6e 2041 7363  perations on Asc
+00018470: 656e 6420 6e6f 7420 7375 7070 6f72 7420  end not support 
+00018480: 626f 6f6c 2074 7970 650a 2020 2020 2020  bool type.      
+00018490: 2020 6966 2069 735f 756e 6465 725f 6173    if is_under_as
+000184a0: 6365 6e64 5f63 6f6e 7465 7874 2829 3a0a  cend_context():.
+000184b0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+000184c0: 745f 6d73 2c20 6f74 6865 722c 206f 7574  t_ms, other, out
+000184d0: 7075 745f 6474 7970 6520 3d20 6269 7477  put_dtype = bitw
+000184e0: 6973 655f 6164 6170 7465 7228 696e 7075  ise_adapter(inpu
+000184f0: 745f 6d73 2c20 6f74 6865 7229 0a20 2020  t_ms, other).   
+00018500: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00018510: 3d20 6d73 2e6f 7073 2e62 6974 7769 7365  = ms.ops.bitwise
+00018520: 5f61 6e64 2869 6e70 7574 5f6d 732c 206f  _and(input_ms, o
+00018530: 7468 6572 290a 2020 2020 2020 2020 2020  ther).          
+00018540: 2020 6f75 7470 7574 203d 206f 7574 7075    output = outpu
+00018550: 742e 6173 7479 7065 286f 7574 7075 745f  t.astype(output_
+00018560: 6474 7970 6529 0a20 2020 2020 2020 2065  dtype).        e
+00018570: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00018580: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00018590: 2e62 6974 7769 7365 5f61 6e64 2869 6e70  .bitwise_and(inp
+000185a0: 7574 5f6d 732c 206f 7468 6572 290a 2020  ut_ms, other).  
+000185b0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+000185c0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+000185d0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+000185e0: 2064 6566 2062 6974 7769 7365 5f61 6e64   def bitwise_and
+000185f0: 5f28 7365 6c66 2c20 6f74 6865 7229 3a0a  _(self, other):.
+00018600: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00018610: 2073 656c 662e 6269 7477 6973 655f 616e   self.bitwise_an
+00018620: 6428 6f74 6865 7229 0a20 2020 2020 2020  d(other).       
+00018630: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+00018640: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+00018650: 656c 662c 206f 7574 7075 742c 2022 6269  elf, output, "bi
+00018660: 7477 6973 655f 616e 645f 222c 2022 6269  twise_and_", "bi
+00018670: 7477 6973 655f 616e 6422 290a 0a20 2020  twise_and")..   
+00018680: 2064 6566 2062 6974 7769 7365 5f6f 7228   def bitwise_or(
+00018690: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
+000186a0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+000186b0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+000186c0: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+000186d0: 206f 7468 6572 203d 2063 6173 745f 746f   other = cast_to
+000186e0: 5f6d 735f 7465 6e73 6f72 286f 7468 6572  _ms_tensor(other
+000186f0: 290a 2020 2020 2020 2020 2354 4f44 4f3a  ).        #TODO:
+00018700: 2063 7572 7265 6e74 6c79 2062 6974 7769   currently bitwi
+00018710: 7365 206f 7065 7261 7469 6f6e 7320 6f6e  se operations on
+00018720: 2041 7363 656e 6420 6e6f 7420 7375 7070   Ascend not supp
+00018730: 6f72 7420 626f 6f6c 2074 7970 650a 2020  ort bool type.  
+00018740: 2020 2020 2020 6966 2069 735f 756e 6465        if is_unde
+00018750: 725f 6173 6365 6e64 5f63 6f6e 7465 7874  r_ascend_context
+00018760: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
+00018770: 696e 7075 745f 6d73 2c20 6f74 6865 722c  input_ms, other,
+00018780: 206f 7574 7075 745f 6474 7970 6520 3d20   output_dtype = 
+00018790: 6269 7477 6973 655f 6164 6170 7465 7228  bitwise_adapter(
+000187a0: 696e 7075 745f 6d73 2c20 6f74 6865 7229  input_ms, other)
+000187b0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+000187c0: 7075 7420 3d20 6d73 2e6f 7073 2e62 6974  put = ms.ops.bit
+000187d0: 7769 7365 5f6f 7228 696e 7075 745f 6d73  wise_or(input_ms
+000187e0: 2c20 6f74 6865 7229 0a20 2020 2020 2020  , other).       
+000187f0: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
+00018800: 7470 7574 2e61 7374 7970 6528 6f75 7470  tput.astype(outp
+00018810: 7574 5f64 7479 7065 290a 2020 2020 2020  ut_dtype).      
+00018820: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00018830: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00018840: 6f70 732e 6269 7477 6973 655f 6f72 2869  ops.bitwise_or(i
+00018850: 6e70 7574 5f6d 732c 206f 7468 6572 290a  nput_ms, other).
+00018860: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00018870: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+00018880: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+00018890: 2020 2064 6566 2062 6974 7769 7365 5f6f     def bitwise_o
+000188a0: 725f 2873 656c 662c 206f 7468 6572 293a  r_(self, other):
+000188b0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+000188c0: 3d20 7365 6c66 2e62 6974 7769 7365 5f6f  = self.bitwise_o
+000188d0: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
+000188e0: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+000188f0: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+00018900: 656c 662c 206f 7574 7075 742c 2022 6269  elf, output, "bi
+00018910: 7477 6973 655f 6f72 5f22 2c20 2262 6974  twise_or_", "bit
+00018920: 7769 7365 5f6f 7222 290a 0a20 2020 2064  wise_or")..    d
+00018930: 6566 2062 6974 7769 7365 5f78 6f72 2873  ef bitwise_xor(s
+00018940: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
+00018950: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00018960: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00018970: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00018980: 6f74 6865 7220 3d20 6361 7374 5f74 6f5f  other = cast_to_
+00018990: 6d73 5f74 656e 736f 7228 6f74 6865 7229  ms_tensor(other)
+000189a0: 0a20 2020 2020 2020 2023 544f 444f 3a20  .        #TODO: 
+000189b0: 6375 7272 656e 746c 7920 6269 7477 6973  currently bitwis
+000189c0: 6520 6f70 6572 6174 696f 6e73 206f 6e20  e operations on 
+000189d0: 4173 6365 6e64 206e 6f74 2073 7570 706f  Ascend not suppo
+000189e0: 7274 2062 6f6f 6c20 7479 7065 0a20 2020  rt bool type.   
+000189f0: 2020 2020 2069 6620 6973 5f75 6e64 6572       if is_under
+00018a00: 5f61 7363 656e 645f 636f 6e74 6578 7428  _ascend_context(
+00018a10: 293a 0a20 2020 2020 2020 2020 2020 2069  ):.            i
+00018a20: 6e70 7574 5f6d 732c 206f 7468 6572 2c20  nput_ms, other, 
+00018a30: 6f75 7470 7574 5f64 7479 7065 203d 2062  output_dtype = b
+00018a40: 6974 7769 7365 5f61 6461 7074 6572 2869  itwise_adapter(i
+00018a50: 6e70 7574 5f6d 732c 206f 7468 6572 290a  nput_ms, other).
+00018a60: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+00018a70: 7574 203d 206d 732e 6f70 732e 6269 7477  ut = ms.ops.bitw
+00018a80: 6973 655f 786f 7228 696e 7075 745f 6d73  ise_xor(input_ms
+00018a90: 2c20 6f74 6865 7229 0a20 2020 2020 2020  , other).       
+00018aa0: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
+00018ab0: 7470 7574 2e61 7374 7970 6528 6f75 7470  tput.astype(outp
+00018ac0: 7574 5f64 7479 7065 290a 2020 2020 2020  ut_dtype).      
+00018ad0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00018ae0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00018af0: 6f70 732e 6269 7477 6973 655f 786f 7228  ops.bitwise_xor(
+00018b00: 696e 7075 745f 6d73 2c20 6f74 6865 7229  input_ms, other)
+00018b10: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00018b20: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00018b30: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+00018b40: 2020 2020 6465 6620 6269 7477 6973 655f      def bitwise_
+00018b50: 786f 725f 2873 656c 662c 206f 7468 6572  xor_(self, other
+00018b60: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+00018b70: 7420 3d20 7365 6c66 2e62 6974 7769 7365  t = self.bitwise
+00018b80: 5f78 6f72 286f 7468 6572 290a 2020 2020  _xor(other).    
+00018b90: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+00018ba0: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+00018bb0: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+00018bc0: 2262 6974 7769 7365 5f78 6f72 5f22 2c20  "bitwise_xor_", 
+00018bd0: 2262 6974 7769 7365 5f78 6f72 2229 0a0a  "bitwise_xor")..
+00018be0: 2020 2020 6465 6620 6164 6462 6d6d 2873      def addbmm(s
+00018bf0: 656c 662c 2062 6174 6368 312c 2062 6174  elf, batch1, bat
+00018c00: 6368 322c 202a 2c20 6265 7461 3d31 2c20  ch2, *, beta=1, 
+00018c10: 616c 7068 613d 3129 3a0a 2020 2020 2020  alpha=1):.      
+00018c20: 2020 5f69 6e70 7574 2c20 5f62 6174 6368    _input, _batch
+00018c30: 312c 205f 6261 7463 6832 203d 2063 6173  1, _batch2 = cas
+00018c40: 745f 746f 5f6d 735f 7465 6e73 6f72 2828  t_to_ms_tensor((
+00018c50: 7365 6c66 2c20 6261 7463 6831 2c20 6261  self, batch1, ba
+00018c60: 7463 6832 2929 0a20 2020 2020 2020 206f  tch2)).        o
+00018c70: 7574 7075 7420 3d20 6d73 2e6f 7073 2e61  utput = ms.ops.a
+00018c80: 6464 626d 6d28 5f69 6e70 7574 2c20 5f62  ddbmm(_input, _b
+00018c90: 6174 6368 312c 205f 6261 7463 6832 2c20  atch1, _batch2, 
+00018ca0: 6265 7461 3d62 6574 612c 2061 6c70 6861  beta=beta, alpha
+00018cb0: 3d61 6c70 6861 290a 2020 2020 2020 2020  =alpha).        
+00018cc0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00018cd0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00018ce0: 7470 7574 290a 0a20 2020 2064 6566 2061  tput)..    def a
+00018cf0: 6464 626d 6d5f 2873 656c 662c 2062 6174  ddbmm_(self, bat
+00018d00: 6368 312c 2062 6174 6368 322c 202a 2c20  ch1, batch2, *, 
+00018d10: 6265 7461 3d31 2c20 616c 7068 613d 3129  beta=1, alpha=1)
+00018d20: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
+00018d30: 203d 2073 656c 662e 6164 6462 6d6d 2862   = self.addbmm(b
+00018d40: 6174 6368 312c 2062 6174 6368 322c 2062  atch1, batch2, b
+00018d50: 6574 613d 6265 7461 2c20 616c 7068 613d  eta=beta, alpha=
+00018d60: 616c 7068 6129 0a20 2020 2020 2020 2072  alpha).        r
+00018d70: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
+00018d80: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
+00018d90: 662c 206f 7574 7075 742c 2022 6164 6462  f, output, "addb
+00018da0: 6d6d 5f22 2c20 2261 6464 626d 6d22 290a  mm_", "addbmm").
+00018db0: 0a20 2020 2064 6566 2061 6464 6d6d 2873  .    def addmm(s
+00018dc0: 656c 662c 206d 6174 312c 206d 6174 322c  elf, mat1, mat2,
+00018dd0: 202a 2c20 6265 7461 3d31 2c20 616c 7068   *, beta=1, alph
+00018de0: 613d 3129 3a0a 2020 2020 2020 2020 5f69  a=1):.        _i
+00018df0: 6e70 7574 2c20 5f6d 6174 312c 205f 6d61  nput, _mat1, _ma
+00018e00: 7432 203d 2063 6173 745f 746f 5f6d 735f  t2 = cast_to_ms_
+00018e10: 7465 6e73 6f72 2828 7365 6c66 2c20 6d61  tensor((self, ma
+00018e20: 7431 2c20 6d61 7432 2929 0a20 2020 2020  t1, mat2)).     
+00018e30: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+00018e40: 7073 2e61 6464 6d6d 285f 696e 7075 742c  ps.addmm(_input,
+00018e50: 205f 6d61 7431 2c20 5f6d 6174 322c 2062   _mat1, _mat2, b
+00018e60: 6574 613d 6265 7461 2c20 616c 7068 613d  eta=beta, alpha=
+00018e70: 616c 7068 6129 0a20 2020 2020 2020 2072  alpha).        r
+00018e80: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00018e90: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00018ea0: 7075 7429 0a0a 2020 2020 6465 6620 6164  put)..    def ad
+00018eb0: 646d 6d5f 2873 656c 662c 206d 6174 312c  dmm_(self, mat1,
+00018ec0: 206d 6174 322c 202a 2c20 6265 7461 3d31   mat2, *, beta=1
+00018ed0: 2c20 616c 7068 613d 3129 3a0a 2020 2020  , alpha=1):.    
+00018ee0: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+00018ef0: 662e 6164 646d 6d28 6d61 7431 2c20 6d61  f.addmm(mat1, ma
+00018f00: 7432 2c20 6265 7461 3d62 6574 612c 2061  t2, beta=beta, a
+00018f10: 6c70 6861 3d61 6c70 6861 290a 2020 2020  lpha=alpha).    
+00018f20: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+00018f30: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+00018f40: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+00018f50: 2261 6464 6d6d 5f22 2c20 2261 6464 6d6d  "addmm_", "addmm
+00018f60: 2229 0a0a 2020 2020 6465 6620 6164 6472  ")..    def addr
+00018f70: 2873 656c 662c 2076 6563 312c 2076 6563  (self, vec1, vec
+00018f80: 322c 202a 2c20 6265 7461 3d31 2c20 616c  2, *, beta=1, al
+00018f90: 7068 613d 3129 3a0a 2020 2020 2020 2020  pha=1):.        
+00018fa0: 5f69 6e70 7574 2c20 5f76 6563 312c 205f  _input, _vec1, _
+00018fb0: 7665 6332 203d 2063 6173 745f 746f 5f6d  vec2 = cast_to_m
+00018fc0: 735f 7465 6e73 6f72 2828 7365 6c66 2c20  s_tensor((self, 
+00018fd0: 7665 6331 2c20 7665 6332 2929 0a20 2020  vec1, vec2)).   
+00018fe0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+00018ff0: 2e6f 7073 2e61 6464 7228 5f69 6e70 7574  .ops.addr(_input
+00019000: 2c20 5f76 6563 312c 205f 7665 6332 2c20  , _vec1, _vec2, 
+00019010: 6265 7461 3d62 6574 612c 2061 6c70 6861  beta=beta, alpha
+00019020: 3d61 6c70 6861 290a 2020 2020 2020 2020  =alpha).        
+00019030: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00019040: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00019050: 7470 7574 290a 0a20 2020 2064 6566 2061  tput)..    def a
+00019060: 6464 725f 2873 656c 662c 2076 6563 312c  ddr_(self, vec1,
+00019070: 2076 6563 322c 202a 2c20 6265 7461 3d31   vec2, *, beta=1
+00019080: 2c20 616c 7068 613d 3129 3a0a 2020 2020  , alpha=1):.    
+00019090: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+000190a0: 662e 6164 6472 2876 6563 312c 2076 6563  f.addr(vec1, vec
+000190b0: 322c 2062 6574 613d 6265 7461 2c20 616c  2, beta=beta, al
+000190c0: 7068 613d 616c 7068 6129 0a20 2020 2020  pha=alpha).     
+000190d0: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
+000190e0: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
+000190f0: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
+00019100: 6164 6472 5f22 2c20 2261 6464 7222 290a  addr_", "addr").
+00019110: 0a20 2020 2064 6566 2061 6c6c 2873 656c  .    def all(sel
+00019120: 662c 2064 696d 3d28 292c 206b 6565 7064  f, dim=(), keepd
+00019130: 696d 3d46 616c 7365 293a 0a20 2020 2020  im=False):.     
+00019140: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+00019150: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00019160: 7365 6c66 290a 2020 2020 2020 2020 2320  self).        # 
+00019170: 7465 6e73 6f72 2e61 6c6c 206f 6e6c 7920  tensor.all only 
+00019180: 7375 7070 6f72 7420 626f 6f6c 2064 7479  support bool dty
+00019190: 7065 0a20 2020 2020 2020 206f 7574 7075  pe.        outpu
+000191a0: 7420 3d20 6d73 2e6f 7073 2e61 6c6c 2869  t = ms.ops.all(i
+000191b0: 6e70 7574 5f6d 732c 2061 7869 733d 6469  nput_ms, axis=di
+000191c0: 6d2c 206b 6565 705f 6469 6d73 3d6b 6565  m, keep_dims=kee
+000191d0: 7064 696d 290a 2020 2020 2020 2020 7265  pdim).        re
+000191e0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+000191f0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00019200: 7574 290a 0a20 2020 2064 6566 2069 7363  ut)..    def isc
+00019210: 6c6f 7365 2873 656c 662c 206f 7468 6572  lose(self, other
+00019220: 2c20 7274 6f6c 3d31 652d 3035 2c20 6174  , rtol=1e-05, at
+00019230: 6f6c 3d31 652d 3038 2c20 6571 7561 6c5f  ol=1e-08, equal_
+00019240: 6e61 6e3d 4661 6c73 6529 3a0a 2020 2020  nan=False):.    
+00019250: 2020 2020 5f69 6e70 7574 2c20 5f6f 7468      _input, _oth
+00019260: 6572 203d 2063 6173 745f 746f 5f6d 735f  er = cast_to_ms_
+00019270: 7465 6e73 6f72 2828 7365 6c66 2c20 6f74  tensor((self, ot
+00019280: 6865 7229 290a 2020 2020 2020 2020 6f75  her)).        ou
+00019290: 7470 7574 203d 206d 732e 6f70 732e 6973  tput = ms.ops.is
+000192a0: 636c 6f73 6528 5f69 6e70 7574 2c20 5f6f  close(_input, _o
+000192b0: 7468 6572 2c20 7274 6f6c 3d72 746f 6c2c  ther, rtol=rtol,
+000192c0: 2061 746f 6c3d 6174 6f6c 2c20 6571 7561   atol=atol, equa
+000192d0: 6c5f 6e61 6e3d 6571 7561 6c5f 6e61 6e29  l_nan=equal_nan)
+000192e0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000192f0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00019300: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+00019310: 2020 2020 6465 6620 616c 6c63 6c6f 7365      def allclose
+00019320: 2873 656c 662c 206f 7468 6572 2c20 7274  (self, other, rt
+00019330: 6f6c 3d31 652d 3035 2c20 6174 6f6c 3d31  ol=1e-05, atol=1
+00019340: 652d 3038 2c20 6571 7561 6c5f 6e61 6e3d  e-08, equal_nan=
+00019350: 4661 6c73 6529 3a0a 2020 2020 2020 2020  False):.        
+00019360: 6f75 7470 7574 203d 2073 656c 662e 6973  output = self.is
+00019370: 636c 6f73 6528 6f74 6865 722c 2072 746f  close(other, rto
+00019380: 6c3d 7274 6f6c 2c20 6174 6f6c 3d61 746f  l=rtol, atol=ato
+00019390: 6c2c 2065 7175 616c 5f6e 616e 3d65 7175  l, equal_nan=equ
+000193a0: 616c 5f6e 616e 290a 2020 2020 2020 2020  al_nan).        
+000193b0: 6f75 7470 7574 203d 206f 7574 7075 742e  output = output.
+000193c0: 616c 6c28 290a 2020 2020 2020 2020 7265  all().        re
+000193d0: 7475 726e 206f 7574 7075 742e 6974 656d  turn output.item
+000193e0: 2829 0a0a 2020 2020 6465 6620 6368 6f6c  ()..    def chol
+000193f0: 6573 6b79 2873 656c 662c 2075 7070 6572  esky(self, upper
+00019400: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
+00019410: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+00019420: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+00019430: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
+00019440: 7574 203d 2069 6e70 7574 5f6d 732e 6368  ut = input_ms.ch
+00019450: 6f6c 6573 6b79 2875 7070 6572 290a 2020  olesky(upper).  
+00019460: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00019470: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00019480: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00019490: 2064 6566 2063 686f 6c65 736b 795f 696e   def cholesky_in
+000194a0: 7665 7273 6528 7365 6c66 2c20 7570 7065  verse(self, uppe
+000194b0: 723d 4661 6c73 6529 3a0a 2020 2020 2020  r=False):.      
+000194c0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+000194d0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+000194e0: 656c 6629 0a20 2020 2020 2020 2023 2054  elf).        # T
+000194f0: 4f44 4f3a 206d 732e 7465 6e73 6f72 2e63  ODO: ms.tensor.c
+00019500: 686f 6c65 736b 795f 696e 7665 7273 6520  holesky_inverse 
+00019510: 6e6f 7420 7375 7070 6f72 7420 4750 552e  not support GPU.
+00019520: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+00019530: 3d20 696e 7075 745f 6d73 2e63 686f 6c65  = input_ms.chole
+00019540: 736b 795f 696e 7665 7273 6528 7570 7065  sky_inverse(uppe
+00019550: 7229 0a20 2020 2020 2020 2072 6574 7572  r).        retur
+00019560: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00019570: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00019580: 0a0a 2020 2020 6465 6620 6368 6f6c 6573  ..    def choles
+00019590: 6b79 5f73 6f6c 7665 2873 656c 662c 2069  ky_solve(self, i
+000195a0: 6e70 7574 322c 2075 7070 6572 3d46 616c  nput2, upper=Fal
+000195b0: 7365 293a 0a20 2020 2020 2020 2069 6e70  se):.        inp
+000195c0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+000195d0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+000195e0: 2020 2020 2020 2020 696e 7075 7432 203d          input2 =
+000195f0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00019600: 6f72 2869 6e70 7574 3229 0a20 2020 2020  or(input2).     
+00019610: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+00019620: 7073 2e63 686f 6c65 736b 795f 736f 6c76  ps.cholesky_solv
+00019630: 6528 696e 7075 745f 6d73 2c20 696e 7075  e(input_ms, inpu
+00019640: 7432 2c20 7570 7065 7229 0a20 2020 2020  t2, upper).     
+00019650: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+00019660: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00019670: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00019680: 6620 6e65 6c65 6d65 6e74 2873 656c 6629  f nelement(self)
+00019690: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+000196a0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+000196b0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+000196c0: 2020 2020 206f 7574 7075 7420 3d20 696e       output = in
+000196d0: 7075 745f 6d73 2e6e 656c 656d 656e 7428  put_ms.nelement(
+000196e0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000196f0: 206f 7574 7075 740a 0a20 2020 2064 6566   output..    def
+00019700: 2061 6d69 6e6d 6178 2873 656c 662c 202a   aminmax(self, *
+00019710: 2c20 6469 6d3d 4e6f 6e65 2c20 6b65 6570  , dim=None, keep
+00019720: 6469 6d3d 4661 6c73 6529 3a0a 2020 2020  dim=False):.    
+00019730: 2020 2020 5f69 6e70 7574 203d 2063 6173      _input = cas
+00019740: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+00019750: 656c 6629 0a20 2020 2020 2020 205f 6d69  elf).        _mi
+00019760: 6e20 3d20 5f69 6e70 7574 2e6d 696e 2861  n = _input.min(a
+00019770: 7869 733d 6469 6d2c 206b 6565 7064 696d  xis=dim, keepdim
+00019780: 733d 6b65 6570 6469 6d29 0a20 2020 2020  s=keepdim).     
+00019790: 2020 205f 6d61 7820 3d20 5f69 6e70 7574     _max = _input
+000197a0: 2e6d 6178 2861 7869 733d 6469 6d2c 206b  .max(axis=dim, k
+000197b0: 6565 7064 696d 733d 6b65 6570 6469 6d29  eepdims=keepdim)
+000197c0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000197d0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+000197e0: 7465 6e73 6f72 2828 5f6d 696e 2c20 5f6d  tensor((_min, _m
+000197f0: 6178 2929 0a0a 2020 2020 6465 6620 616e  ax))..    def an
+00019800: 7928 7365 6c66 2c20 6469 6d3d 2829 2c20  y(self, dim=(), 
+00019810: 6b65 6570 6469 6d3d 4661 6c73 6529 3a0a  keepdim=False):.
+00019820: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00019830: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00019840: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00019850: 2020 2069 6620 696e 7075 745f 6d73 2e64     if input_ms.d
+00019860: 7479 7065 2021 3d20 6d73 2e62 6f6f 6c5f  type != ms.bool_
+00019870: 3a0a 2020 2020 2020 2020 2020 2020 696e  :.            in
+00019880: 7075 745f 6d73 203d 2069 6e70 7574 5f6d  put_ms = input_m
+00019890: 732e 6173 7479 7065 286d 732e 626f 6f6c  s.astype(ms.bool
+000198a0: 5f29 0a20 2020 2020 2020 206f 7574 7075  _).        outpu
+000198b0: 7420 3d20 696e 7075 745f 6d73 2e61 6e79  t = input_ms.any
+000198c0: 2861 7869 733d 6469 6d2c 206b 6565 705f  (axis=dim, keep_
+000198d0: 6469 6d73 3d6b 6565 7064 696d 290a 2020  dims=keepdim).  
+000198e0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+000198f0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00019900: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00019910: 2064 6566 2062 696e 636f 756e 7428 7365   def bincount(se
+00019920: 6c66 2c20 7765 6967 6874 733d 4e6f 6e65  lf, weights=None
+00019930: 2c20 6d69 6e6c 656e 6774 683d 3029 3a0a  , minlength=0):.
+00019940: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00019950: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00019960: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00019970: 2020 2074 7970 6520 3d20 2769 6e74 3634     type = 'int64
+00019980: 270a 2020 2020 2020 2020 6966 2069 6e70  '.        if inp
+00019990: 7574 5f6d 732e 6474 7970 6520 3d3d 206d  ut_ms.dtype == m
+000199a0: 732e 7569 6e74 383a 0a20 2020 2020 2020  s.uint8:.       
+000199b0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+000199c0: 696e 7075 745f 6d73 2e61 7374 7970 6528  input_ms.astype(
+000199d0: 6d73 2e69 6e74 3136 290a 2020 2020 2020  ms.int16).      
+000199e0: 2020 6966 2077 6569 6768 7473 2069 7320    if weights is 
+000199f0: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00019a00: 2020 2020 2020 7765 6967 6874 7320 3d20        weights = 
+00019a10: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00019a20: 7228 7765 6967 6874 7329 0a20 2020 2020  r(weights).     
+00019a30: 2020 2020 2020 2074 7970 6520 3d20 7765         type = we
+00019a40: 6967 6874 732e 6474 7970 650a 2020 2020  ights.dtype.    
+00019a50: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00019a60: 6f70 732e 6269 6e63 6f75 6e74 2869 6e70  ops.bincount(inp
+00019a70: 7574 5f6d 732c 2077 6569 6768 7473 2c20  ut_ms, weights, 
+00019a80: 6d69 6e6c 656e 6774 6829 2e61 7374 7970  minlength).astyp
+00019a90: 6528 7479 7065 290a 2020 2020 2020 2020  e(type).        
+00019aa0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00019ab0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00019ac0: 7470 7574 290a 0a20 2020 2064 6566 2062  tput)..    def b
+00019ad0: 6974 7769 7365 5f6c 6566 745f 7368 6966  itwise_left_shif
+00019ae0: 7428 7365 6c66 2c20 6f74 6865 7229 3a0a  t(self, other):.
+00019af0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00019b00: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00019b10: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00019b20: 2020 206f 7468 6572 203d 2063 6173 745f     other = cast_
+00019b30: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
+00019b40: 6572 290a 2020 2020 2020 2020 6f75 7470  er).        outp
+00019b50: 7574 203d 206d 732e 6f70 732e 6269 7477  ut = ms.ops.bitw
+00019b60: 6973 655f 6c65 6674 5f73 6869 6674 2869  ise_left_shift(i
+00019b70: 6e70 7574 5f6d 732c 206f 7468 6572 290a  nput_ms, other).
+00019b80: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00019b90: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+00019ba0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+00019bb0: 2020 2064 6566 2062 6974 7769 7365 5f6c     def bitwise_l
+00019bc0: 6566 745f 7368 6966 745f 2873 656c 662c  eft_shift_(self,
+00019bd0: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
+00019be0: 206f 7574 7075 7420 3d20 7365 6c66 2e62   output = self.b
+00019bf0: 6974 7769 7365 5f6c 6566 745f 7368 6966  itwise_left_shif
+00019c00: 7428 6f74 6865 7229 0a20 2020 2020 2020  t(other).       
+00019c10: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+00019c20: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+00019c30: 656c 662c 206f 7574 7075 742c 2022 6269  elf, output, "bi
+00019c40: 7477 6973 655f 6c65 6674 5f73 6869 6674  twise_left_shift
+00019c50: 5f22 2c20 2262 6974 7769 7365 5f6c 6566  _", "bitwise_lef
+00019c60: 745f 7368 6966 7422 290a 0a20 2020 2064  t_shift")..    d
+00019c70: 6566 2062 6974 7769 7365 5f72 6967 6874  ef bitwise_right
+00019c80: 5f73 6869 6674 2873 656c 662c 206f 7468  _shift(self, oth
+00019c90: 6572 293a 0a20 2020 2020 2020 2069 6e70  er):.        inp
+00019ca0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+00019cb0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00019cc0: 2020 2020 2020 2020 6f74 6865 7220 3d20          other = 
+00019cd0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00019ce0: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
+00019cf0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00019d00: 2e62 6974 7769 7365 5f72 6967 6874 5f73  .bitwise_right_s
+00019d10: 6869 6674 2869 6e70 7574 5f6d 732c 206f  hift(input_ms, o
+00019d20: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
+00019d30: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00019d40: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00019d50: 7574 290a 0a20 2020 2064 6566 2062 6974  ut)..    def bit
+00019d60: 7769 7365 5f72 6967 6874 5f73 6869 6674  wise_right_shift
+00019d70: 5f28 7365 6c66 2c20 6f74 6865 7229 3a0a  _(self, other):.
+00019d80: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00019d90: 2073 656c 662e 6269 7477 6973 655f 7269   self.bitwise_ri
+00019da0: 6768 745f 7368 6966 7428 6f74 6865 7229  ght_shift(other)
+00019db0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00019dc0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+00019dd0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+00019de0: 7075 742c 2022 6269 7477 6973 655f 7269  put, "bitwise_ri
+00019df0: 6768 745f 7368 6966 745f 222c 2022 6269  ght_shift_", "bi
+00019e00: 7477 6973 655f 7269 6768 745f 7368 6966  twise_right_shif
+00019e10: 7422 290a 0a20 2020 2064 6566 2063 6c69  t")..    def cli
+00019e20: 7028 7365 6c66 2c20 6d69 6e3d 4e6f 6e65  p(self, min=None
+00019e30: 2c20 6d61 783d 4e6f 6e65 293a 0a20 2020  , max=None):.   
+00019e40: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00019e50: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00019e60: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00019e70: 6f75 7470 7574 203d 2069 6e70 7574 5f6d  output = input_m
+00019e80: 732e 636c 6970 286d 696e 2c20 6d61 7829  s.clip(min, max)
+00019e90: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00019ea0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00019eb0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+00019ec0: 2020 2020 6465 6620 636c 6970 5f28 7365      def clip_(se
+00019ed0: 6c66 2c20 6d69 6e3d 4e6f 6e65 2c20 6d61  lf, min=None, ma
+00019ee0: 783d 4e6f 6e65 293a 0a20 2020 2020 2020  x=None):.       
+00019ef0: 206f 7574 7075 7420 3d20 7365 6c66 2e63   output = self.c
+00019f00: 6c69 7028 6d69 6e3d 6d69 6e2c 206d 6178  lip(min=min, max
+00019f10: 3d6d 6178 290a 2020 2020 2020 2020 7265  =max).        re
+00019f20: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+00019f30: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+00019f40: 2c20 6f75 7470 7574 2c20 2263 6c69 705f  , output, "clip_
+00019f50: 222c 2022 636c 6970 2229 0a0a 2020 2020  ", "clip")..    
+00019f60: 6465 6620 636f 7079 7369 676e 2873 656c  def copysign(sel
+00019f70: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
+00019f80: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+00019f90: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00019fa0: 7365 6c66 290a 2020 2020 2020 2020 696e  self).        in
+00019fb0: 7075 745f 7479 7065 203d 2069 6e70 7574  put_type = input
+00019fc0: 5f6d 732e 6474 7970 650a 2020 2020 2020  _ms.dtype.      
+00019fd0: 2020 6973 5f6e 756d 203d 2054 7275 650a    is_num = True.
+00019fe0: 2020 2020 2020 2020 2320 666f 7220 6772          # for gr
+00019ff0: 6170 680a 2020 2020 2020 2020 6f74 6865  aph.        othe
+0001a000: 725f 7479 7065 203d 204e 6f6e 650a 2020  r_type = None.  
+0001a010: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+0001a020: 6e63 6528 6f74 6865 722c 2054 656e 736f  nce(other, Tenso
+0001a030: 7229 3a0a 2020 2020 2020 2020 2020 2020  r):.            
+0001a040: 6973 5f6e 756d 203d 2046 616c 7365 0a20  is_num = False. 
+0001a050: 2020 2020 2020 2020 2020 206f 7468 6572             other
+0001a060: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0001a070: 6e73 6f72 286f 7468 6572 290a 2020 2020  nsor(other).    
+0001a080: 2020 2020 2020 2020 6f74 6865 725f 7479          other_ty
+0001a090: 7065 203d 206f 7468 6572 2e64 7479 7065  pe = other.dtype
+0001a0a0: 0a20 2020 2020 2020 2020 2020 2023 544f  .            #TO
+0001a0b0: 444f 3a20 6375 7272 656e 746c 7920 7468  DO: currently th
+0001a0c0: 6520 7072 696d 5b54 696c 655d 2068 6173  e prim[Tile] has
+0001a0d0: 2070 726f 626c 656d 2062 726f 6164 6361   problem broadca
+0001a0e0: 7374 696e 670a 2020 2020 2020 2020 2020  sting.          
+0001a0f0: 2020 6966 2069 6e70 7574 5f6d 732e 6e64    if input_ms.nd
+0001a100: 696d 203c 206f 7468 6572 2e6e 6469 6d3a  im < other.ndim:
+0001a110: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001a120: 2069 6e70 7574 5f6d 7320 3d20 6d73 2e6f   input_ms = ms.o
+0001a130: 7073 2e62 726f 6164 6361 7374 5f74 6f28  ps.broadcast_to(
+0001a140: 696e 7075 745f 6d73 2c20 6f74 6865 722e  input_ms, other.
+0001a150: 7368 6170 6529 0a20 2020 2020 2020 2020  shape).         
+0001a160: 2020 2069 6620 6f74 6865 722e 6e64 696d     if other.ndim
+0001a170: 203c 2069 6e70 7574 5f6d 732e 6e64 696d   < input_ms.ndim
+0001a180: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+0001a190: 2020 6f74 6865 7220 3d20 6d73 2e6f 7073    other = ms.ops
+0001a1a0: 2e62 726f 6164 6361 7374 5f74 6f28 6f74  .broadcast_to(ot
+0001a1b0: 6865 722c 2069 6e70 7574 5f6d 732e 7368  her, input_ms.sh
+0001a1c0: 6170 6529 0a20 2020 2020 2020 206f 7574  ape).        out
+0001a1d0: 7075 7420 3d20 6d73 2e6f 7073 2e63 6f70  put = ms.ops.cop
+0001a1e0: 7973 6967 6e28 696e 7075 745f 6d73 2c20  ysign(input_ms, 
+0001a1f0: 6f74 6865 7229 0a20 2020 2020 2020 2069  other).        i
+0001a200: 6620 2749 6e74 2720 696e 2073 7472 2869  f 'Int' in str(i
+0001a210: 6e70 7574 5f74 7970 6529 3a0a 2020 2020  nput_type):.    
+0001a220: 2020 2020 2020 2020 6966 2069 735f 6e75          if is_nu
+0001a230: 6d20 6f72 2027 496e 7427 2069 6e20 7374  m or 'Int' in st
+0001a240: 7228 6f74 6865 725f 7479 7065 293a 0a20  r(other_type):. 
+0001a250: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+0001a260: 7574 7075 7420 3d20 6f75 7470 7574 2e61  utput = output.a
+0001a270: 7374 7970 6528 6d73 2e66 6c6f 6174 3332  stype(ms.float32
+0001a280: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
+0001a290: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
+0001a2a0: 2020 2020 6f75 7470 7574 203d 206f 7574      output = out
+0001a2b0: 7075 742e 6173 7479 7065 286f 7468 6572  put.astype(other
+0001a2c0: 5f74 7970 6529 0a20 2020 2020 2020 2065  _type).        e
+0001a2d0: 6c69 6620 6973 5f6e 756d 206f 7220 2749  lif is_num or 'I
+0001a2e0: 6e74 2720 696e 2073 7472 286f 7468 6572  nt' in str(other
+0001a2f0: 5f74 7970 6529 3a0a 2020 2020 2020 2020  _type):.        
+0001a300: 2020 2020 6f75 7470 7574 203d 206f 7574      output = out
+0001a310: 7075 742e 6173 7479 7065 2869 6e70 7574  put.astype(input
+0001a320: 5f74 7970 6529 0a20 2020 2020 2020 2065  _type).        e
+0001a330: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0001a340: 2074 7970 6531 203d 2069 6e70 7574 5f74   type1 = input_t
+0001a350: 7970 6520 6966 2069 6e70 7574 5f6d 732e  ype if input_ms.
+0001a360: 6974 656d 7369 7a65 203e 206f 7468 6572  itemsize > other
+0001a370: 2e69 7465 6d73 697a 6520 656c 7365 206f  .itemsize else o
+0001a380: 7468 6572 5f74 7970 650a 2020 2020 2020  ther_type.      
+0001a390: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
+0001a3a0: 7574 7075 742e 6173 7479 7065 2874 7970  utput.astype(typ
+0001a3b0: 6531 290a 2020 2020 2020 2020 7265 7475  e1).        retu
+0001a3c0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0001a3d0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0001a3e0: 290a 0a20 2020 2064 6566 2063 6f70 7973  )..    def copys
+0001a3f0: 6967 6e5f 2873 656c 662c 206f 7468 6572  ign_(self, other
+0001a400: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+0001a410: 7420 3d20 7365 6c66 2e63 6f70 7973 6967  t = self.copysig
+0001a420: 6e28 6f74 6865 7229 0a20 2020 2020 2020  n(other).       
+0001a430: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+0001a440: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+0001a450: 656c 662c 206f 7574 7075 742c 2022 636f  elf, output, "co
+0001a460: 7079 7369 676e 5f22 2c20 2263 6f70 7973  pysign_", "copys
+0001a470: 6967 6e22 290a 0a20 2020 2064 6566 2063  ign")..    def c
+0001a480: 6f73 2873 656c 6629 3a0a 2020 2020 2020  os(self):.      
+0001a490: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+0001a4a0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+0001a4b0: 656c 6629 0a20 2020 2020 2020 206f 7574  elf).        out
+0001a4c0: 7075 7420 3d20 6d73 2e6f 7073 2e63 6f73  put = ms.ops.cos
+0001a4d0: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
+0001a4e0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0001a4f0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0001a500: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0001a510: 6620 636f 735f 2873 656c 6629 3a0a 2020  f cos_(self):.  
+0001a520: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
+0001a530: 656c 662e 636f 7328 290a 2020 2020 2020  elf.cos().      
+0001a540: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+0001a550: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+0001a560: 7365 6c66 2c20 6f75 7470 7574 2c20 2263  self, output, "c
+0001a570: 6f73 5f22 2c20 2263 6f73 2229 0a0a 2020  os_", "cos")..  
+0001a580: 2020 6465 6620 636f 7368 2873 656c 6629    def cosh(self)
+0001a590: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+0001a5a0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0001a5b0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+0001a5c0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+0001a5d0: 2e6f 7073 2e63 6f73 6828 696e 7075 745f  .ops.cosh(input_
+0001a5e0: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
+0001a5f0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0001a600: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0001a610: 290a 0a20 2020 2064 6566 2063 6f73 685f  )..    def cosh_
+0001a620: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+0001a630: 6f75 7470 7574 203d 2073 656c 662e 636f  output = self.co
+0001a640: 7368 2829 0a20 2020 2020 2020 2072 6574  sh().        ret
+0001a650: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+0001a660: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+0001a670: 206f 7574 7075 742c 2022 636f 7368 5f22   output, "cosh_"
+0001a680: 2c20 2263 6f73 6822 290a 0a20 2020 2064  , "cosh")..    d
+0001a690: 6566 2063 756d 6d61 7828 7365 6c66 2c20  ef cummax(self, 
+0001a6a0: 6469 6d29 3a0a 2020 2020 2020 2020 696e  dim):.        in
+0001a6b0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+0001a6c0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+0001a6d0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001a6e0: 3d20 6d73 2e6f 7073 2e63 756d 6d61 7828  = ms.ops.cummax(
+0001a6f0: 696e 7075 745f 6d73 2c20 6178 6973 3d64  input_ms, axis=d
+0001a700: 696d 290a 2020 2020 2020 2020 7265 7475  im).        retu
+0001a710: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0001a720: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0001a730: 290a 0a20 2020 2064 6566 2063 756d 6d69  )..    def cummi
+0001a740: 6e28 7365 6c66 2c20 6469 6d29 3a0a 2020  n(self, dim):.  
+0001a750: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0001a760: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0001a770: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0001a780: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+0001a790: 2e63 756d 6d69 6e28 696e 7075 745f 6d73  .cummin(input_ms
+0001a7a0: 2c20 6469 6d29 0a20 2020 2020 2020 2023  , dim).        #
+0001a7b0: 2074 6865 206f 7574 7075 7420 6474 7970   the output dtyp
+0001a7c0: 6520 696e 206d 732e 6f70 732e 6375 6d6d  e in ms.ops.cumm
+0001a7d0: 696e 2069 7320 6469 6666 6572 656e 7420  in is different 
+0001a7e0: 7769 7468 206d 732e 6f70 732e 6375 6d6d  with ms.ops.cumm
+0001a7f0: 6178 0a20 2020 2020 2020 206f 7574 7075  ax.        outpu
+0001a800: 745b 315d 203d 206f 7574 7075 745b 315d  t[1] = output[1]
+0001a810: 2e61 7374 7970 6528 6d73 2e63 6f6d 6d6f  .astype(ms.commo
+0001a820: 6e2e 6474 7970 652e 696e 7436 3429 0a20  n.dtype.int64). 
+0001a830: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+0001a840: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+0001a850: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+0001a860: 2020 6465 6620 6375 6d70 726f 6428 7365    def cumprod(se
+0001a870: 6c66 2c20 6469 6d2c 202a 2c20 6474 7970  lf, dim, *, dtyp
+0001a880: 653d 4e6f 6e65 293a 0a20 2020 2020 2020  e=None):.       
+0001a890: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0001a8a0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0001a8b0: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
+0001a8c0: 7574 203d 206d 732e 6f70 732e 6375 6d70  ut = ms.ops.cump
+0001a8d0: 726f 6428 696e 7075 745f 6d73 2c20 6469  rod(input_ms, di
+0001a8e0: 6d2c 2064 7479 7065 3d64 7479 7065 290a  m, dtype=dtype).
+0001a8f0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+0001a900: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+0001a910: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+0001a920: 2020 2064 6566 2063 756d 7072 6f64 5f28     def cumprod_(
+0001a930: 7365 6c66 2c20 6469 6d2c 202a 2c20 6474  self, dim, *, dt
+0001a940: 7970 653d 4e6f 6e65 293a 0a20 2020 2020  ype=None):.     
+0001a950: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
+0001a960: 2e63 756d 7072 6f64 2864 696d 2c20 6474  .cumprod(dim, dt
+0001a970: 7970 653d 6474 7970 6529 0a20 2020 2020  ype=dtype).     
+0001a980: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
+0001a990: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
+0001a9a0: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
+0001a9b0: 6375 6d70 726f 645f 222c 2022 6375 6d70  cumprod_", "cump
+0001a9c0: 726f 6422 290a 0a20 2020 2064 6566 2064  rod")..    def d
+0001a9d0: 6567 3272 6164 2873 656c 6629 3a0a 2020  eg2rad(self):.  
+0001a9e0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0001a9f0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0001aa00: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0001aa10: 2069 6620 696e 7075 745f 6d73 2e64 7479   if input_ms.dty
+0001aa20: 7065 206e 6f74 2069 6e20 286d 732e 666c  pe not in (ms.fl
+0001aa30: 6f61 7431 362c 206d 732e 666c 6f61 7433  oat16, ms.float3
+0001aa40: 322c 206d 732e 666c 6f61 7436 3429 3a0a  2, ms.float64):.
+0001aa50: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+0001aa60: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
+0001aa70: 6173 7479 7065 286d 732e 666c 6f61 7433  astype(ms.float3
+0001aa80: 3229 0a20 2020 2020 2020 206f 7574 7075  2).        outpu
+0001aa90: 7420 3d20 6d73 2e6f 7073 2e64 6567 3272  t = ms.ops.deg2r
+0001aaa0: 6164 2869 6e70 7574 5f6d 7329 0a20 2020  ad(input_ms).   
+0001aab0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+0001aac0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+0001aad0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+0001aae0: 6465 6620 6469 6167 2873 656c 662c 2064  def diag(self, d
+0001aaf0: 6961 676f 6e61 6c3d 3029 3a0a 2020 2020  iagonal=0):.    
+0001ab00: 2020 2020 2320 544f 444f 0a20 2020 2020      # TODO.     
+0001ab10: 2020 2023 204d 6179 2062 6520 7573 6520     # May be use 
+0001ab20: 6d69 6e64 7370 6f72 652e 6f70 732e 6469  mindspore.ops.di
+0001ab30: 6167 2069 6e73 7465 6164 2e20 4e6f 7761  ag instead. Nowa
+0001ab40: 6461 7973 2c20 7468 6973 206f 7065 7261  days, this opera
+0001ab50: 746f 7220 646f 206e 6f74 2073 7570 706f  tor do not suppo
+0001ab60: 7274 2043 5055 2e0a 2020 2020 2020 2020  rt CPU..        
+0001ab70: 2320 6d73 2e6e 756d 7079 2e64 6961 6720  # ms.numpy.diag 
+0001ab80: 6861 7320 6275 6720 6f6e 2061 7363 656e  has bug on ascen
+0001ab90: 642c 2075 7365 206d 732e 6f70 732e 6469  d, use ms.ops.di
+0001aba0: 6167 2066 6f72 2064 6961 676f 6e61 6c3d  ag for diagonal=
+0001abb0: 4e6f 6e65 2061 6e64 2031 4420 696e 7075  None and 1D inpu
+0001abc0: 740a 2020 2020 2020 2020 696e 7075 745f  t.        input_
+0001abd0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0001abe0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+0001abf0: 2020 2020 2069 6620 6973 5f75 6e64 6572       if is_under
+0001ac00: 5f61 7363 656e 645f 636f 6e74 6578 7428  _ascend_context(
+0001ac10: 2920 616e 6420 696e 7075 745f 6d73 2e6e  ) and input_ms.n
+0001ac20: 6469 6d20 3d3d 2031 2061 6e64 2064 6961  dim == 1 and dia
+0001ac30: 676f 6e61 6c20 3d3d 2030 3a0a 2020 2020  gonal == 0:.    
+0001ac40: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0001ac50: 206d 732e 6f70 732e 6469 6167 2869 6e70   ms.ops.diag(inp
+0001ac60: 7574 5f6d 7329 0a20 2020 2020 2020 2065  ut_ms).        e
+0001ac70: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+0001ac80: 206f 7574 7075 7420 3d20 206d 732e 6e75   output =  ms.nu
+0001ac90: 6d70 792e 6469 6167 2869 6e70 7574 5f6d  mpy.diag(input_m
+0001aca0: 732c 2064 6961 676f 6e61 6c29 0a20 2020  s, diagonal).   
+0001acb0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+0001acc0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+0001acd0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+0001ace0: 6465 6620 6469 6167 666c 6174 2873 656c  def diagflat(sel
+0001acf0: 662c 206f 6666 7365 743d 3029 3a0a 2020  f, offset=0):.  
+0001ad00: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0001ad10: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0001ad20: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0001ad30: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+0001ad40: 2e64 6961 6766 6c61 7428 696e 7075 745f  .diagflat(input_
+0001ad50: 6d73 2c20 6f66 6673 6574 290a 2020 2020  ms, offset).    
+0001ad60: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+0001ad70: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+0001ad80: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+0001ad90: 6566 2064 6961 676f 6e61 6c28 7365 6c66  ef diagonal(self
+0001ada0: 2c20 6f66 6673 6574 3d30 2c20 6469 6d31  , offset=0, dim1
+0001adb0: 3d30 2c20 6469 6d32 3d31 293a 0a20 2020  =0, dim2=1):.   
+0001adc0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0001add0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0001ade0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+0001adf0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+0001ae00: 6469 6167 6f6e 616c 2869 6e70 7574 5f6d  diagonal(input_m
+0001ae10: 732c 206f 6666 7365 742c 2064 696d 312c  s, offset, dim1,
+0001ae20: 2064 696d 3229 0a20 2020 2020 2020 2072   dim2).        r
+0001ae30: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+0001ae40: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+0001ae50: 7075 7429 0a0a 2020 2020 6465 6620 6973  put)..    def is
+0001ae60: 5f63 6f6d 706c 6578 2873 656c 6629 3a0a  _complex(self):.
+0001ae70: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+0001ae80: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0001ae90: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+0001aea0: 2020 2072 6574 7572 6e20 696e 7075 745f     return input_
+0001aeb0: 6d73 2e69 735f 636f 6d70 6c65 7828 290a  ms.is_complex().
+0001aec0: 0a20 2020 2064 6566 2069 7369 6e66 2873  .    def isinf(s
+0001aed0: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
+0001aee0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+0001aef0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+0001af00: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001af10: 3d20 6d73 2e6f 7073 2e69 7369 6e66 2869  = ms.ops.isinf(i
+0001af20: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
+0001af30: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0001af40: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0001af50: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0001af60: 6973 6e65 6769 6e66 2873 656c 6629 3a0a  isneginf(self):.
+0001af70: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+0001af80: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0001af90: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+0001afa0: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+0001afb0: 7073 2e69 736e 6567 696e 6628 696e 7075  ps.isneginf(inpu
+0001afc0: 745f 6d73 290a 2020 2020 2020 2020 7265  t_ms).        re
+0001afd0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0001afe0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+0001aff0: 7574 290a 0a20 2020 2064 6566 2069 7370  ut)..    def isp
+0001b000: 6f73 696e 6628 7365 6c66 293a 0a20 2020  osinf(self):.   
+0001b010: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0001b020: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0001b030: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+0001b040: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+0001b050: 6973 706f 7369 6e66 2869 6e70 7574 5f6d  isposinf(input_m
+0001b060: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+0001b070: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0001b080: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0001b090: 0a0a 2020 2020 6465 6620 6973 7265 616c  ..    def isreal
+0001b0a0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+0001b0b0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+0001b0c0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+0001b0d0: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
+0001b0e0: 7420 3d20 6d73 2e6f 7073 2e69 7372 6561  t = ms.ops.isrea
+0001b0f0: 6c28 696e 7075 745f 6d73 290a 2020 2020  l(input_ms).    
+0001b100: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+0001b110: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+0001b120: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+0001b130: 6566 2076 6172 2873 656c 662c 2064 696d  ef var(self, dim
+0001b140: 3d4e 6f6e 652c 2075 6e62 6961 7365 643d  =None, unbiased=
+0001b150: 5472 7565 2c20 6b65 6570 6469 6d3d 4661  True, keepdim=Fa
+0001b160: 6c73 6529 3a0a 2020 2020 2020 2020 2332  lse):.        #2
+0001b170: 2e30 2020 5465 6e73 6f72 2e76 6172 2864  .0  Tensor.var(d
+0001b180: 696d 3d4e 6f6e 652c 202a 2c20 636f 7272  im=None, *, corr
+0001b190: 6563 7469 6f6e 3d31 2c20 6b65 6570 6469  ection=1, keepdi
+0001b1a0: 6d3d 4661 6c73 6529 0a20 2020 2020 2020  m=False).       
+0001b1b0: 2023 312e 3132 2054 656e 736f 722e 7661   #1.12 Tensor.va
+0001b1c0: 7228 6469 6d2c 2075 6e62 6961 7365 643d  r(dim, unbiased=
+0001b1d0: 5472 7565 2c20 6b65 6570 6469 6d3d 4661  True, keepdim=Fa
+0001b1e0: 6c73 6529 0a20 2020 2020 2020 2023 312e  lse).        #1.
+0001b1f0: 3132 2054 656e 736f 722e 7661 7228 756e  12 Tensor.var(un
+0001b200: 6269 6173 6564 3d54 7275 6529 0a20 2020  biased=True).   
+0001b210: 2020 2020 2069 6620 6469 6d20 6973 206e       if dim is n
+0001b220: 6f74 204e 6f6e 6520 616e 6420 6973 696e  ot None and isin
+0001b230: 7374 616e 6365 2864 696d 2c20 626f 6f6c  stance(dim, bool
+0001b240: 293a 0a20 2020 2020 2020 2020 2020 2072  ):.            r
+0001b250: 6169 7365 2054 7970 6545 7272 6f72 2822  aise TypeError("
+0001b260: 7661 7228 2920 7265 6365 6976 6564 2061  var() received a
+0001b270: 6e20 696e 7661 6c69 6420 636f 6d62 696e  n invalid combin
+0001b280: 6174 696f 6e20 6f66 2061 7267 756d 656e  ation of argumen
+0001b290: 7473 3a20 676f 7420 2864 696d 3d62 6f6f  ts: got (dim=boo
+0001b2a0: 6c29 2c22 202b 0a20 2020 2020 2020 2020  l)," +.         
+0001b2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b2c0: 2020 2022 6275 7420 6578 7065 6374 6564     "but expected
+0001b2d0: 206f 6e65 206f 663a 2028 7475 706c 6520   one of: (tuple 
+0001b2e0: 6f66 2069 6e74 7320 6469 6d2c 2062 6f6f  of ints dim, boo
+0001b2f0: 6c20 756e 6269 6173 6564 2c20 626f 6f6c  l unbiased, bool
+0001b300: 206b 6565 7064 696d 2922 290a 2020 2020   keepdim)").    
+0001b310: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+0001b320: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0001b330: 2873 656c 6629 0a20 2020 2020 2020 2023  (self).        #
+0001b340: 6d73 2e6f 7073 2e76 6172 2075 6e73 7570  ms.ops.var unsup
+0001b350: 706f 7274 2064 646f 663d 302f 3120 6f6e  port ddof=0/1 on
+0001b360: 2047 5055 0a20 2020 2020 2020 2064 646f   GPU.        ddo
+0001b370: 6620 3d20 3120 6966 2075 6e62 6961 7365  f = 1 if unbiase
+0001b380: 6420 6973 2054 7275 6520 656c 7365 2030  d is True else 0
+0001b390: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001b3a0: 3d20 696e 7075 745f 6d73 2e76 6172 2861  = input_ms.var(a
+0001b3b0: 7869 733d 6469 6d2c 2064 646f 663d 6464  xis=dim, ddof=dd
+0001b3c0: 6f66 2c20 6b65 6570 6469 6d73 3d6b 6565  of, keepdims=kee
+0001b3d0: 7064 696d 290a 2020 2020 2020 2020 7265  pdim).        re
+0001b3e0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0001b3f0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+0001b400: 7574 290a 0a20 2020 2064 6566 2064 6966  ut)..    def dif
+0001b410: 6628 7365 6c66 2c20 6e3d 312c 2064 696d  f(self, n=1, dim
+0001b420: 3d2d 312c 2070 7265 7065 6e64 3d4e 6f6e  =-1, prepend=Non
+0001b430: 652c 2061 7070 656e 643d 4e6f 6e65 293a  e, append=None):
+0001b440: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+0001b450: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+0001b460: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+0001b470: 2020 2020 2354 4f44 4f3a 206d 732e 6f70      #TODO: ms.op
+0001b480: 732e 6469 6666 206f 6e6c 7920 7375 7070  s.diff only supp
+0001b490: 6f72 7420 6e3d 310a 2020 2020 2020 2020  ort n=1.        
+0001b4a0: 6966 206e 203d 3d20 313a 0a20 2020 2020  if n == 1:.     
+0001b4b0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0001b4c0: 6d73 2e6f 7073 2e64 6966 6628 696e 7075  ms.ops.diff(inpu
+0001b4d0: 745f 6d73 2c20 6e2c 2064 696d 2c20 7072  t_ms, n, dim, pr
+0001b4e0: 6570 656e 642c 2061 7070 656e 6429 0a20  epend, append). 
+0001b4f0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0001b500: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+0001b510: 3d20 6d73 2e6e 756d 7079 2e64 6966 6628  = ms.numpy.diff(
+0001b520: 696e 7075 745f 6d73 2c20 6e2c 2064 696d  input_ms, n, dim
+0001b530: 2c20 7072 6570 656e 642c 2061 7070 656e  , prepend, appen
+0001b540: 6429 0a20 2020 2020 2020 2072 6574 7572  d).        retur
+0001b550: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0001b560: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0001b570: 0a0a 2020 2020 6465 6620 6469 6761 6d6d  ..    def digamm
+0001b580: 6128 7365 6c66 293a 0a20 2020 2020 2020  a(self):.       
+0001b590: 2023 2054 4f44 4f3a 2057 6865 6e20 696e   # TODO: When in
+0001b5a0: 7075 7420 6474 7970 6520 6973 2066 6c6f  put dtype is flo
+0001b5b0: 6174 3634 2c20 7265 7375 6c74 206d 6179  at64, result may
+0001b5c0: 2062 6520 696e 6163 6375 7261 7465 0a20   be inaccurate. 
+0001b5d0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+0001b5e0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0001b5f0: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+0001b600: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+0001b610: 732e 6469 6761 6d6d 6128 696e 7075 745f  s.digamma(input_
+0001b620: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
+0001b630: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0001b640: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0001b650: 290a 0a20 2020 2064 6566 2064 6967 616d  )..    def digam
+0001b660: 6d61 5f28 7365 6c66 293a 0a20 2020 2020  ma_(self):.     
+0001b670: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
+0001b680: 2e64 6967 616d 6d61 2829 0a20 2020 2020  .digamma().     
+0001b690: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
+0001b6a0: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
+0001b6b0: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
+0001b6c0: 6469 6761 6d6d 615f 222c 2022 6469 6761  digamma_", "diga
+0001b6d0: 6d6d 6122 290a 0a20 2020 2023 544f 444f  mma")..    #TODO
+0001b6e0: 3a20 6569 6720 6375 7272 656e 746c 7920  : eig currently 
+0001b6f0: 6e6f 7420 7375 7070 6f72 7420 6f6e 2047  not support on G
+0001b700: 5055 0a20 2020 2064 6566 2065 6967 2873  PU.    def eig(s
+0001b710: 656c 6629 3a0a 2020 2020 2020 2020 6966  elf):.        if
+0001b720: 2069 735f 756e 6465 725f 6770 755f 636f   is_under_gpu_co
+0001b730: 6e74 6578 7428 293a 0a20 2020 2020 2020  ntext():.       
+0001b740: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
+0001b750: 706c 656d 656e 7465 6445 7272 6f72 2822  plementedError("
+0001b760: 666f 7220 6164 6170 7465 722c 2065 6967  for adapter, eig
+0001b770: 206e 6f74 2073 7570 706f 7274 6564 206f   not supported o
+0001b780: 6e20 4750 5522 290a 2020 2020 2020 2020  n GPU").        
+0001b790: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+0001b7a0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+0001b7b0: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
+0001b7c0: 7420 3d20 6d73 2e6f 7073 2e65 6967 2869  t = ms.ops.eig(i
+0001b7d0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
+0001b7e0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0001b7f0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0001b800: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0001b810: 6469 7374 2873 656c 662c 206f 7468 6572  dist(self, other
+0001b820: 2c20 703d 3229 3a0a 2020 2020 2020 2020  , p=2):.        
+0001b830: 5f69 6e70 7574 203d 2063 6173 745f 746f  _input = cast_to
+0001b840: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+0001b850: 0a20 2020 2020 2020 205f 6f74 6865 7220  .        _other 
+0001b860: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0001b870: 736f 7228 6f74 6865 7229 0a0a 2020 2020  sor(other)..    
+0001b880: 2020 2020 5f69 6e70 7574 5f64 7479 7065      _input_dtype
+0001b890: 203d 205f 696e 7075 742e 6474 7970 650a   = _input.dtype.
+0001b8a0: 2020 2020 2020 2020 5f6f 7468 6572 5f64          _other_d
+0001b8b0: 7479 7065 203d 205f 6f74 6865 722e 6474  type = _other.dt
+0001b8c0: 7970 650a 2020 2020 2020 2020 6966 205f  ype.        if _
+0001b8d0: 696e 7075 745f 6474 7970 6520 696e 2028  input_dtype in (
+0001b8e0: 6d73 2e66 6c6f 6174 3136 2c20 6d73 2e66  ms.float16, ms.f
+0001b8f0: 6c6f 6174 3332 2920 616e 6420 5f6f 7468  loat32) and _oth
+0001b900: 6572 5f64 7479 7065 2021 3d20 6d73 2e66  er_dtype != ms.f
+0001b910: 6c6f 6174 3634 3a0a 2020 2020 2020 2020  loat64:.        
+0001b920: 2020 2020 6966 205f 6f74 6865 725f 6474      if _other_dt
+0001b930: 7970 6520 3d3d 206d 732e 666c 6f61 7433  ype == ms.float3
+0001b940: 323a 0a20 2020 2020 2020 2020 2020 2020  2:.             
+0001b950: 2020 205f 696e 7075 7420 3d20 5f69 6e70     _input = _inp
+0001b960: 7574 2e61 7374 7970 6528 5f6f 7468 6572  ut.astype(_other
+0001b970: 5f64 7479 7065 290a 2020 2020 2020 2020  _dtype).        
+0001b980: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
+0001b990: 2020 2020 2020 2020 2020 5f6f 7468 6572            _other
+0001b9a0: 203d 205f 6f74 6865 722e 6173 7479 7065   = _other.astype
+0001b9b0: 285f 696e 7075 745f 6474 7970 6529 0a20  (_input_dtype). 
+0001b9c0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+0001b9d0: 7420 3d20 6d73 2e6f 7073 2e64 6973 7428  t = ms.ops.dist(
+0001b9e0: 5f69 6e70 7574 2c20 5f6f 7468 6572 2c20  _input, _other, 
+0001b9f0: 703d 7029 0a20 2020 2020 2020 2065 6c69  p=p).        eli
+0001ba00: 6620 5f69 6e70 7574 5f64 7479 7065 203d  f _input_dtype =
+0001ba10: 3d20 6d73 2e66 6c6f 6174 3634 206f 7220  = ms.float64 or 
+0001ba20: 5f6f 7468 6572 5f64 7479 7065 203d 3d20  _other_dtype == 
+0001ba30: 6d73 2e66 6c6f 6174 3634 3a0a 2020 2020  ms.float64:.    
+0001ba40: 2020 2020 2020 2020 5f69 6e70 7574 203d          _input =
+0001ba50: 205f 696e 7075 742e 6173 7479 7065 286d   _input.astype(m
+0001ba60: 732e 666c 6f61 7433 3229 0a20 2020 2020  s.float32).     
+0001ba70: 2020 2020 2020 205f 6f74 6865 7220 3d20         _other = 
+0001ba80: 5f6f 7468 6572 2e61 7374 7970 6528 6d73  _other.astype(ms
+0001ba90: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
+0001baa0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+0001bab0: 732e 6f70 732e 6469 7374 285f 696e 7075  s.ops.dist(_inpu
+0001bac0: 742c 205f 6f74 6865 722c 2070 3d70 290a  t, _other, p=p).
+0001bad0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+0001bae0: 7574 203d 206f 7574 7075 742e 6173 7479  ut = output.asty
+0001baf0: 7065 286d 732e 666c 6f61 7436 3429 0a20  pe(ms.float64). 
+0001bb00: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+0001bb10: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
+0001bb20: 616c 7565 4572 726f 7228 6622 466f 7220  alueError(f"For 
+0001bb30: 746f 7263 682e 6469 7374 2c20 696e 7075  torch.dist, inpu
+0001bb40: 7420 7368 6f75 6c64 2062 6520 666c 6f61  t should be floa
+0001bb50: 7469 6e67 2054 656e 736f 722c 2062 7574  ting Tensor, but
+0001bb60: 2067 6f74 207b 5f69 6e70 7574 5f64 7479   got {_input_dty
+0001bb70: 7065 7d2e 2229 0a0a 2020 2020 2020 2020  pe}.")..        
+0001bb80: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+0001bb90: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+0001bba0: 7470 7574 290a 0a20 2020 2064 6566 2064  tput)..    def d
+0001bbb0: 7370 6c69 7428 7365 6c66 2c20 696e 6469  split(self, indi
+0001bbc0: 6365 735f 6f72 5f73 6563 7469 6f6e 7329  ces_or_sections)
+0001bbd0: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+0001bbe0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0001bbf0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+0001bc00: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+0001bc10: 2e6f 7073 2e64 7370 6c69 7428 696e 7075  .ops.dsplit(inpu
+0001bc20: 745f 6d73 2c20 696e 6469 6365 735f 6f72  t_ms, indices_or
+0001bc30: 5f73 6563 7469 6f6e 7329 0a20 2020 2020  _sections).     
+0001bc40: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0001bc50: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0001bc60: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0001bc70: 6620 6572 6628 7365 6c66 293a 0a20 2020  f erf(self):.   
+0001bc80: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0001bc90: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0001bca0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+0001bcb0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+0001bcc0: 6572 6628 696e 7075 745f 6d73 290a 2020  erf(input_ms).  
+0001bcd0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+0001bce0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0001bcf0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+0001bd00: 2064 6566 2065 7266 5f28 7365 6c66 293a   def erf_(self):
+0001bd10: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001bd20: 3d20 7365 6c66 2e65 7266 2829 0a20 2020  = self.erf().   
+0001bd30: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
+0001bd40: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
+0001bd50: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
+0001bd60: 2022 6572 665f 222c 2022 6572 6622 290a   "erf_", "erf").
+0001bd70: 0a20 2020 2064 6566 2065 7266 6328 7365  .    def erfc(se
+0001bd80: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
+0001bd90: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+0001bda0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+0001bdb0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0001bdc0: 206d 732e 6f70 732e 6572 6663 2869 6e70   ms.ops.erfc(inp
+0001bdd0: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
+0001bde0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+0001bdf0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+0001be00: 7075 7429 0a0a 2020 2020 6465 6620 6572  put)..    def er
+0001be10: 6663 5f28 7365 6c66 293a 0a20 2020 2020  fc_(self):.     
+0001be20: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
+0001be30: 2e65 7266 6328 290a 2020 2020 2020 2020  .erfc().        
+0001be40: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
+0001be50: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
+0001be60: 6c66 2c20 6f75 7470 7574 2c20 2265 7266  lf, output, "erf
+0001be70: 635f 222c 2022 6572 6663 2229 0a0a 2020  c_", "erfc")..  
+0001be80: 2020 6465 6620 6578 706d 3128 7365 6c66    def expm1(self
+0001be90: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0001bea0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0001beb0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0001bec0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+0001bed0: 732e 6f70 732e 6578 706d 3128 696e 7075  s.ops.expm1(inpu
+0001bee0: 745f 6d73 290a 2020 2020 2020 2020 7265  t_ms).        re
+0001bef0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0001bf00: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+0001bf10: 7574 290a 0a20 2020 2064 6566 2065 7870  ut)..    def exp
+0001bf20: 6d31 5f28 7365 6c66 293a 0a20 2020 2020  m1_(self):.     
+0001bf30: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
+0001bf40: 2e65 7870 6d31 2829 0a20 2020 2020 2020  .expm1().       
+0001bf50: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+0001bf60: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+0001bf70: 656c 662c 206f 7574 7075 742c 2022 6578  elf, output, "ex
+0001bf80: 706d 315f 222c 2022 6578 706d 3122 290a  pm1_", "expm1").
+0001bf90: 0a20 2020 2064 6566 2074 7275 6e63 2873  .    def trunc(s
+0001bfa0: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
+0001bfb0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+0001bfc0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+0001bfd0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001bfe0: 3d20 6d73 2e6f 7073 2e74 7275 6e63 2869  = ms.ops.trunc(i
+0001bff0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
+0001c000: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0001c010: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0001c020: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0001c030: 7472 756e 635f 2873 656c 6629 3a0a 2020  trunc_(self):.  
+0001c040: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
+0001c050: 656c 662e 7472 756e 6328 290a 2020 2020  elf.trunc().    
+0001c060: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+0001c070: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+0001c080: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+0001c090: 2274 7275 6e63 5f22 2c20 2274 7275 6e63  "trunc_", "trunc
+0001c0a0: 2229 0a0a 2020 2020 6465 6620 6669 7828  ")..    def fix(
+0001c0b0: 7365 6c66 293a 0a20 2020 2020 2020 2072  self):.        r
+0001c0c0: 6574 7572 6e20 7365 6c66 2e74 7275 6e63  eturn self.trunc
+0001c0d0: 2829 0a0a 2020 2020 6465 6620 6669 785f  ()..    def fix_
+0001c0e0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+0001c0f0: 6f75 7470 7574 203d 2073 656c 662e 6669  output = self.fi
+0001c100: 7828 290a 2020 2020 2020 2020 7265 7475  x().        retu
+0001c110: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+0001c120: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+0001c130: 6f75 7470 7574 2c20 2266 6978 5f22 2c20  output, "fix_", 
+0001c140: 2266 6978 2229 0a0a 2020 2020 6465 6620  "fix")..    def 
+0001c150: 666c 6970 6c72 2873 656c 6629 3a0a 2020  fliplr(self):.  
+0001c160: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0001c170: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0001c180: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0001c190: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+0001c1a0: 2e66 6c69 706c 7228 696e 7075 745f 6d73  .fliplr(input_ms
+0001c1b0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0001c1c0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0001c1d0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+0001c1e0: 0a20 2020 2064 6566 2066 6c6f 6174 5f70  .    def float_p
+0001c1f0: 6f77 6572 2873 656c 662c 2065 7870 6f6e  ower(self, expon
+0001c200: 656e 7429 3a0a 2020 2020 2020 2020 2320  ent):.        # 
+0001c210: 544f 444f 3a20 6e6f 7420 7375 7070 6f72  TODO: not suppor
+0001c220: 7420 636f 6d70 6c65 7820 696e 7075 7420  t complex input 
+0001c230: 616e 6420 6578 706f 6e65 6e74 206e 6f77  and exponent now
+0001c240: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+0001c250: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+0001c260: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+0001c270: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+0001c280: 6f70 732e 666c 6f61 745f 706f 7765 7228  ops.float_power(
+0001c290: 696e 7075 745f 6d73 2c20 6578 706f 6e65  input_ms, expone
+0001c2a0: 6e74 290a 2020 2020 2020 2020 7265 7475  nt).        retu
+0001c2b0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0001c2c0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0001c2d0: 290a 0a20 2020 2064 6566 2066 6c6f 6174  )..    def float
+0001c2e0: 5f70 6f77 6572 5f28 7365 6c66 2c20 6578  _power_(self, ex
+0001c2f0: 706f 6e65 6e74 293a 0a20 2020 2020 2020  ponent):.       
+0001c300: 206f 7574 7075 7420 3d20 7365 6c66 2e66   output = self.f
+0001c310: 6c6f 6174 5f70 6f77 6572 2865 7870 6f6e  loat_power(expon
+0001c320: 656e 7429 0a20 2020 2020 2020 2072 6574  ent).        ret
+0001c330: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+0001c340: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+0001c350: 206f 7574 7075 742c 2022 666c 6f61 745f   output, "float_
+0001c360: 706f 7765 725f 222c 2022 666c 6f61 745f  power_", "float_
+0001c370: 706f 7765 7222 290a 0a20 2020 2064 6566  power")..    def
+0001c380: 206e 6172 726f 7728 7365 6c66 2c20 6469   narrow(self, di
+0001c390: 6d65 6e73 696f 6e2c 2073 7461 7274 2c20  mension, start, 
+0001c3a0: 6c65 6e67 7468 293a 0a20 2020 2020 2020  length):.       
+0001c3b0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0001c3c0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0001c3d0: 6c66 290a 0a20 2020 2020 2020 2064 6566  lf)..        def
+0001c3e0: 205f 6765 745f 7465 6e73 6f72 5f64 6174   _get_tensor_dat
+0001c3f0: 6128 7829 3a0a 2020 2020 2020 2020 2020  a(x):.          
+0001c400: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
+0001c410: 782c 2054 656e 736f 7229 3a0a 2020 2020  x, Tensor):.    
+0001c420: 2020 2020 2020 2020 2020 2020 6966 2078              if x
+0001c430: 2e6e 6469 6d20 213d 2030 3a0a 2020 2020  .ndim != 0:.    
+0001c440: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001c450: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+0001c460: 2822 6974 206d 7573 7420 6265 2061 6e20  ("it must be an 
+0001c470: 302d 6469 6d20 696e 7465 6772 616c 2054  0-dim integral T
+0001c480: 656e 736f 722e 2229 0a20 2020 2020 2020  ensor.").       
+0001c490: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0001c4a0: 696e 7428 7829 0a20 2020 2020 2020 2020  int(x).         
+0001c4b0: 2020 2072 6574 7572 6e20 780a 0a20 2020     return x..   
+0001c4c0: 2020 2020 2064 696d 656e 7369 6f6e 203d       dimension =
+0001c4d0: 205f 6765 745f 7465 6e73 6f72 5f64 6174   _get_tensor_dat
+0001c4e0: 6128 6469 6d65 6e73 696f 6e29 0a20 2020  a(dimension).   
+0001c4f0: 2020 2020 2073 7461 7274 203d 205f 6765       start = _ge
+0001c500: 745f 7465 6e73 6f72 5f64 6174 6128 7374  t_tensor_data(st
+0001c510: 6172 7429 0a20 2020 2020 2020 206c 656e  art).        len
+0001c520: 6774 6820 3d20 5f67 6574 5f74 656e 736f  gth = _get_tenso
+0001c530: 725f 6461 7461 286c 656e 6774 6829 0a20  r_data(length). 
+0001c540: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0001c550: 6d73 2e6f 7073 2e6e 6172 726f 7728 696e  ms.ops.narrow(in
+0001c560: 7075 745f 6d73 2c20 6469 6d65 6e73 696f  put_ms, dimensio
+0001c570: 6e2c 2073 7461 7274 2c20 6c65 6e67 7468  n, start, length
+0001c580: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0001c590: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0001c5a0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+0001c5b0: 0a20 2020 2064 6566 206e 6172 726f 775f  .    def narrow_
+0001c5c0: 636f 7079 2873 656c 662c 2064 696d 656e  copy(self, dimen
+0001c5d0: 7369 6f6e 2c20 7374 6172 742c 206c 656e  sion, start, len
+0001c5e0: 6774 6829 3a0a 2020 2020 2020 2020 696e  gth):.        in
+0001c5f0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+0001c600: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+0001c610: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001c620: 3d20 6d73 2e6f 7073 2e6e 6172 726f 7728  = ms.ops.narrow(
+0001c630: 696e 7075 745f 6d73 2c20 6469 6d65 6e73  input_ms, dimens
+0001c640: 696f 6e2c 2073 7461 7274 2c20 6c65 6e67  ion, start, leng
+0001c650: 7468 290a 2020 2020 2020 2020 2320 544f  th).        # TO
+0001c660: 444f 3a20 6e6f 206d 732e 6f70 732e 6e61  DO: no ms.ops.na
+0001c670: 7272 6f77 5f63 6f70 7920 6170 692c 206d  rrow_copy api, m
+0001c680: 732e 6f70 732e 6e61 7272 6f77 2069 7320  s.ops.narrow is 
+0001c690: 6120 7669 6577 2061 7069 206f 6e20 6d73  a view api on ms
+0001c6a0: 322e 330a 2020 2020 2020 2020 6f75 7470  2.3.        outp
+0001c6b0: 7574 203d 206f 7574 7075 742e 636f 7079  ut = output.copy
+0001c6c0: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
+0001c6d0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0001c6e0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0001c6f0: 0a0a 2020 2020 6465 6620 6e6f 726d 2873  ..    def norm(s
+0001c700: 656c 662c 2070 3d27 6672 6f27 2c20 6469  elf, p='fro', di
+0001c710: 6d3d 4e6f 6e65 2c20 6b65 6570 6469 6d3d  m=None, keepdim=
+0001c720: 4661 6c73 652c 2064 7479 7065 3d4e 6f6e  False, dtype=Non
+0001c730: 6529 3a0a 2020 2020 2020 2020 2320 544f  e):.        # TO
+0001c740: 444f 3a20 6d73 2e6f 7073 2e6e 6f72 6d20  DO: ms.ops.norm 
+0001c750: 6265 6e63 686d 6172 6b69 6e67 2074 6f72  benchmarking tor
+0001c760: 6368 2e6c 696e 616c 672e 6e6f 726d 2e20  ch.linalg.norm. 
+0001c770: 736f 6d65 206d 6174 7269 782d 6e6f 726d  some matrix-norm
+0001c780: 2072 6573 756c 7420 6e6f 7420 7269 6768   result not righ
+0001c790: 742e 0a20 2020 2020 2020 2023 2060 7060  t..        # `p`
+0001c7a0: 2063 616e 206e 6f74 2073 7570 706f 7274   can not support
+0001c7b0: 2076 616c 7565 2062 6573 6964 6520 5b27   value beside ['
+0001c7c0: 6672 6f27 2c20 276e 7563 272c 2069 6e66  fro', 'nuc', inf
+0001c7d0: 2c20 2d69 6e66 2c20 302c 2031 2c20 2d31  , -inf, 0, 1, -1
+0001c7e0: 2c20 322c 202d 325d 0a20 2020 2020 2020  , 2, -2].       
+0001c7f0: 2077 6172 6e69 6e67 2822 6074 6f72 6368   warning("`torch
+0001c800: 2e6e 6f72 6d60 206f 7220 6074 656e 736f  .norm` or `tenso
+0001c810: 722e 6e6f 726d 6020 6973 2064 6570 7265  r.norm` is depre
+0001c820: 6361 7465 642c 2070 6c65 6173 6520 7573  cated, please us
+0001c830: 6520 606c 696e 616c 672e 7665 6374 6f72  e `linalg.vector
+0001c840: 5f6e 6f72 6d28 2960 2022 0a20 2020 2020  _norm()` ".     
+0001c850: 2020 2020 2020 2020 2020 2022 6f72 2060             "or `
+0001c860: 6c69 6e61 6c67 2e6d 6174 7269 785f 6e6f  linalg.matrix_no
+0001c870: 726d 2829 6020 696e 7374 6561 642e 2229  rm()` instead.")
+0001c880: 0a20 2020 2020 2020 2070 203d 205f 6e6f  .        p = _no
+0001c890: 726d 5f67 6574 5f63 6f6e 7374 2870 2c20  rm_get_const(p, 
+0001c8a0: 6469 6d2c 206c 656e 2873 656c 662e 7368  dim, len(self.sh
+0001c8b0: 6170 6529 290a 2020 2020 2020 2020 696e  ape)).        in
+0001c8c0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+0001c8d0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+0001c8e0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001c8f0: 3d20 6d73 2e6f 7073 2e6e 6f72 6d28 696e  = ms.ops.norm(in
+0001c900: 7075 745f 6d73 2c20 6f72 643d 702c 2064  put_ms, ord=p, d
+0001c910: 696d 3d64 696d 2c20 6b65 6570 6469 6d3d  im=dim, keepdim=
+0001c920: 6b65 6570 6469 6d29 0a20 2020 2020 2020  keepdim).       
+0001c930: 2069 6620 6474 7970 653a 0a20 2020 2020   if dtype:.     
+0001c940: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0001c950: 6f75 7470 7574 2e61 7374 7970 6528 6474  output.astype(dt
+0001c960: 7970 6529 0a20 2020 2020 2020 2072 6574  ype).        ret
+0001c970: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+0001c980: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+0001c990: 7429 0a0a 2020 2020 6465 6620 786c 6f67  t)..    def xlog
+0001c9a0: 7928 7365 6c66 2c20 6f74 6865 7229 3a0a  y(self, other):.
+0001c9b0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+0001c9c0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0001c9d0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+0001c9e0: 2020 206f 7468 6572 203d 2063 6173 745f     other = cast_
+0001c9f0: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
+0001ca00: 6572 290a 2020 2020 2020 2020 2320 544f  er).        # TO
+0001ca10: 444f 3a20 546f 2073 7570 706f 7274 206d  DO: To support m
+0001ca20: 6f72 6520 6461 7461 7479 7065 206f 6e20  ore datatype on 
+0001ca30: 4173 6365 6e64 0a20 2020 2020 2020 206f  Ascend.        o
+0001ca40: 7574 7075 7420 3d20 6d73 2e6f 7073 2e78  utput = ms.ops.x
+0001ca50: 6c6f 6779 2869 6e70 7574 5f6d 732c 206f  logy(input_ms, o
+0001ca60: 7468 6572 290a 2020 2020 2020 2020 6966  ther).        if
+0001ca70: 2069 735f 756e 6465 725f 6770 755f 636f   is_under_gpu_co
+0001ca80: 6e74 6578 7428 2920 6f72 2069 735f 756e  ntext() or is_un
+0001ca90: 6465 725f 6173 6365 6e64 5f63 6f6e 7465  der_ascend_conte
+0001caa0: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
+0001cab0: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
+0001cac0: 696e 7075 745f 6d73 2c20 6d73 2e54 656e  input_ms, ms.Ten
+0001cad0: 736f 7229 2061 6e64 2069 7369 6e73 7461  sor) and isinsta
+0001cae0: 6e63 6528 6f74 6865 722c 206d 732e 5465  nce(other, ms.Te
+0001caf0: 6e73 6f72 293a 0a20 2020 2020 2020 2020  nsor):.         
+0001cb00: 2020 2020 2020 206d 6173 6b20 3d20 6d73         mask = ms
+0001cb10: 2e6f 7073 2e69 736e 616e 286f 7468 6572  .ops.isnan(other
+0001cb20: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+0001cb30: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+0001cb40: 732e 7768 6572 6528 6d61 736b 2c20 6d73  s.where(mask, ms
+0001cb50: 2e54 656e 736f 7228 666c 6f61 7428 276e  .Tensor(float('n
+0001cb60: 616e 2729 292e 6173 7479 7065 286f 7574  an')).astype(out
+0001cb70: 7075 742e 6474 7970 6529 2c20 6f75 7470  put.dtype), outp
+0001cb80: 7574 290a 2020 2020 2020 2020 2020 2020  ut).            
+0001cb90: 656c 6966 206e 6f74 2069 7369 6e73 7461  elif not isinsta
+0001cba0: 6e63 6528 696e 7075 745f 6d73 2c20 6d73  nce(input_ms, ms
+0001cbb0: 2e54 656e 736f 7229 3a0a 2020 2020 2020  .Tensor):.      
+0001cbc0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+0001cbd0: 203d 206d 732e 6f70 732e 7768 6572 6528   = ms.ops.where(
+0001cbe0: 286f 7468 6572 203c 2030 292c 206d 732e  (other < 0), ms.
+0001cbf0: 5465 6e73 6f72 2866 6c6f 6174 2827 6e61  Tensor(float('na
+0001cc00: 6e27 2929 2e61 7374 7970 6528 6f75 7470  n')).astype(outp
+0001cc10: 7574 2e64 7479 7065 292c 206f 7574 7075  ut.dtype), outpu
+0001cc20: 7429 0a20 2020 2020 2020 2072 6574 7572  t).        retur
+0001cc30: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0001cc40: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0001cc50: 0a0a 2020 2020 6465 6620 786c 6f67 795f  ..    def xlogy_
+0001cc60: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
+0001cc70: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0001cc80: 7365 6c66 2e78 6c6f 6779 286f 7468 6572  self.xlogy(other
+0001cc90: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0001cca0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+0001ccb0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+0001ccc0: 7470 7574 2c20 2278 6c6f 6779 5f22 2c20  tput, "xlogy_", 
+0001ccd0: 2278 6c6f 6779 2229 0a0a 2020 2020 6465  "xlogy")..    de
+0001cce0: 6620 7673 706c 6974 2873 656c 662c 2069  f vsplit(self, i
+0001ccf0: 6e64 6963 6573 5f6f 725f 7365 6374 696f  ndices_or_sectio
+0001cd00: 6e73 293a 0a20 2020 2020 2020 2069 6e70  ns):.        inp
+0001cd10: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+0001cd20: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+0001cd30: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0001cd40: 206d 732e 6f70 732e 7673 706c 6974 2869   ms.ops.vsplit(i
+0001cd50: 6e70 7574 5f6d 732c 2069 6e64 6963 6573  nput_ms, indices
+0001cd60: 5f6f 725f 7365 6374 696f 6e73 290a 2020  _or_sections).  
+0001cd70: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+0001cd80: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0001cd90: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+0001cda0: 2064 6566 2076 646f 7428 7365 6c66 2c20   def vdot(self, 
+0001cdb0: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
+0001cdc0: 6966 206e 6f74 2069 7369 6e73 7461 6e63  if not isinstanc
+0001cdd0: 6528 6f74 6865 722c 2054 656e 736f 7229  e(other, Tensor)
+0001cde0: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+0001cdf0: 6973 6520 5479 7065 4572 726f 7228 6622  ise TypeError(f"
+0001ce00: 466f 7220 5465 6e73 6f72 2e76 646f 742c  For Tensor.vdot,
+0001ce10: 206f 7468 6572 206d 7573 7420 6265 2074   other must be t
+0001ce20: 656e 736f 722c 2062 7574 2067 6f74 207b  ensor, but got {
+0001ce30: 7479 7065 286f 7468 6572 297d 2229 0a20  type(other)}"). 
+0001ce40: 2020 2020 2020 2069 6620 7365 6c66 2e64         if self.d
+0001ce50: 7479 7065 2021 3d20 6f74 6865 722e 6474  type != other.dt
+0001ce60: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
+0001ce70: 2072 6169 7365 2052 756e 7469 6d65 4572   raise RuntimeEr
+0001ce80: 726f 7228 6622 466f 7220 5465 6e73 6f72  ror(f"For Tensor
+0001ce90: 2e76 646f 742c 2065 7870 6563 7465 6420  .vdot, expected 
+0001cea0: 626f 7468 2076 6563 746f 7273 2074 6f20  both vectors to 
+0001ceb0: 6861 7665 2073 616d 6520 6474 7970 652c  have same dtype,
+0001cec0: 2062 7574 2066 6f75 6e64 207b 7365 6c66   but found {self
+0001ced0: 2e64 7479 7065 7d22 0a20 2020 2020 2020  .dtype}".       
+0001cee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cef0: 2020 2020 2020 2020 6622 2061 6e64 207b          f" and {
+0001cf00: 6f74 6865 722e 6474 7970 657d 2229 0a20  other.dtype}"). 
+0001cf10: 2020 2020 2020 2069 6620 7365 6c66 2e6e         if self.n
+0001cf20: 6469 6d20 213d 2031 206f 7220 6f74 6865  dim != 1 or othe
+0001cf30: 722e 6e64 696d 2021 3d20 313a 0a20 2020  r.ndim != 1:.   
+0001cf40: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
+0001cf50: 756e 7469 6d65 4572 726f 7228 6622 466f  untimeError(f"Fo
+0001cf60: 7220 5465 6e73 6f72 2e76 646f 742c 2031  r Tensor.vdot, 1
+0001cf70: 4420 7465 6e73 6f72 7320 6578 7065 6374  D tensors expect
+0001cf80: 6564 2c20 6275 7420 676f 7420 7b73 656c  ed, but got {sel
+0001cf90: 662e 6e64 696d 7d44 2061 6e64 207b 6f74  f.ndim}D and {ot
+0001cfa0: 6865 722e 6e64 696d 7d44 2074 656e 736f  her.ndim}D tenso
+0001cfb0: 7273 2229 0a20 2020 2020 2020 2069 6e70  rs").        inp
+0001cfc0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+0001cfd0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+0001cfe0: 2020 2020 2020 2020 6f74 6865 7220 3d20          other = 
+0001cff0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0001d000: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
+0001d010: 2069 6620 696e 7075 745f 6d73 2e69 735f   if input_ms.is_
+0001d020: 636f 6d70 6c65 7828 293a 0a20 2020 2020  complex():.     
+0001d030: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+0001d040: 3d20 6d73 2e6f 7073 2e63 6f6e 6a28 696e  = ms.ops.conj(in
+0001d050: 7075 745f 6d73 290a 2020 2020 2020 2020  put_ms).        
+0001d060: 6966 2028 6973 5f75 6e64 6572 5f67 7075  if (is_under_gpu
+0001d070: 5f63 6f6e 7465 7874 2829 2061 6e64 2028  _context() and (
+0001d080: 696e 7075 745f 6d73 2e64 7479 7065 2069  input_ms.dtype i
+0001d090: 6e20 616c 6c5f 696e 745f 7479 7065 2929  n all_int_type))
+0001d0a0: 206f 7220 5c0a 2020 2020 2020 2020 2020   or \.          
+0001d0b0: 2020 2869 735f 756e 6465 725f 6173 6365    (is_under_asce
+0001d0c0: 6e64 5f63 6f6e 7465 7874 2829 2061 6e64  nd_context() and
+0001d0d0: 2028 696e 7075 745f 6d73 2e64 7479 7065   (input_ms.dtype
+0001d0e0: 2069 6e20 286d 732e 666c 6f61 7436 342c   in (ms.float64,
+0001d0f0: 2920 2b20 616c 6c5f 696e 745f 7479 7065  ) + all_int_type
+0001d100: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
+0001d110: 696e 7075 745f 6474 7970 6520 3d20 696e  input_dtype = in
+0001d120: 7075 745f 6d73 2e64 7479 7065 0a20 2020  put_ms.dtype.   
+0001d130: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
+0001d140: 7320 3d20 696e 7075 745f 6d73 2e61 7374  s = input_ms.ast
+0001d150: 7970 6528 6d73 2e66 6c6f 6174 3332 290a  ype(ms.float32).
+0001d160: 2020 2020 2020 2020 2020 2020 6f74 6865              othe
+0001d170: 7220 3d20 6f74 6865 722e 6173 7479 7065  r = other.astype
+0001d180: 286d 732e 666c 6f61 7433 3229 0a20 2020  (ms.float32).   
+0001d190: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+0001d1a0: 3d20 6d73 2e6f 7073 2e69 6e6e 6572 2869  = ms.ops.inner(i
+0001d1b0: 6e70 7574 5f6d 732c 206f 7468 6572 292e  nput_ms, other).
+0001d1c0: 6173 7479 7065 2869 6e70 7574 5f64 7479  astype(input_dty
+0001d1d0: 7065 290a 2020 2020 2020 2020 656c 7365  pe).        else
+0001d1e0: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
+0001d1f0: 7470 7574 203d 206d 732e 6f70 732e 696e  tput = ms.ops.in
+0001d200: 6e65 7228 696e 7075 745f 6d73 2c20 6f74  ner(input_ms, ot
+0001d210: 6865 7229 0a20 2020 2020 2020 2072 6574  her).        ret
+0001d220: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+0001d230: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+0001d240: 7429 0a0a 2020 2020 6465 6620 7768 6572  t)..    def wher
+0001d250: 6528 7365 6c66 2c20 636f 6e64 6974 696f  e(self, conditio
+0001d260: 6e2c 2079 293a 0a20 2020 2020 2020 2078  n, y):.        x
+0001d270: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0001d280: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+0001d290: 2020 2079 203d 2063 6173 745f 746f 5f6d     y = cast_to_m
+0001d2a0: 735f 7465 6e73 6f72 2879 290a 2020 2020  s_tensor(y).    
 0001d2b0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-0001d2c0: 6f70 732e 6879 706f 7428 696e 7075 745f  ops.hypot(input_
-0001d2d0: 6d73 2c20 6f74 6865 725f 6d73 290a 2020  ms, other_ms).  
-0001d2e0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-0001d2f0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-0001d300: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-0001d310: 2064 6566 2068 7970 6f74 5f28 7365 6c66   def hypot_(self
-0001d320: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-0001d330: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
-0001d340: 6879 706f 7428 6f74 6865 7229 0a20 2020  hypot(other).   
-0001d350: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
-0001d360: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
-0001d370: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
-0001d380: 2022 6879 706f 745f 222c 2022 6879 706f   "hypot_", "hypo
-0001d390: 7422 290a 0a20 2020 2064 6566 206c 6f67  t")..    def log
-0001d3a0: 3130 2873 656c 6629 3a0a 2020 2020 2020  10(self):.      
-0001d3b0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
-0001d3c0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-0001d3d0: 656c 6629 0a20 2020 2020 2020 206f 7574  elf).        out
-0001d3e0: 7075 7420 3d20 6d73 2e6f 7073 2e6c 6f67  put = ms.ops.log
-0001d3f0: 3130 2869 6e70 7574 5f6d 7329 0a20 2020  10(input_ms).   
-0001d400: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0001d410: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0001d420: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0001d430: 6465 6620 6c6f 6731 305f 2873 656c 6629  def log10_(self)
-0001d440: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-0001d450: 203d 2073 656c 662e 6c6f 6731 3028 290a   = self.log10().
-0001d460: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-0001d470: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-0001d480: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-0001d490: 7574 2c20 226c 6f67 3130 5f22 2c20 226c  ut, "log10_", "l
-0001d4a0: 6f67 3130 2229 0a0a 2020 2020 6465 6620  og10")..    def 
-0001d4b0: 6c6f 6731 7028 7365 6c66 293a 0a20 2020  log1p(self):.   
-0001d4c0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0001d4d0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-0001d4e0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-0001d4f0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-0001d500: 6c6f 6731 7028 696e 7075 745f 6d73 290a  log1p(input_ms).
-0001d510: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-0001d520: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-0001d530: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
-0001d540: 2020 2064 6566 206c 6f67 3170 5f28 7365     def log1p_(se
-0001d550: 6c66 293a 0a20 2020 2020 2020 206f 7574  lf):.        out
-0001d560: 7075 7420 3d20 7365 6c66 2e6c 6f67 3170  put = self.log1p
-0001d570: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
-0001d580: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-0001d590: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-0001d5a0: 7574 7075 742c 2022 6c6f 6731 705f 222c  utput, "log1p_",
-0001d5b0: 2022 6c6f 6731 7022 290a 0a20 2020 2064   "log1p")..    d
-0001d5c0: 6566 206c 6f67 6164 6465 7870 2873 656c  ef logaddexp(sel
-0001d5d0: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
+0001d2c0: 6f70 732e 7768 6572 6528 636f 6e64 6974  ops.where(condit
+0001d2d0: 696f 6e2c 2078 2c20 7929 0a20 2020 2020  ion, x, y).     
+0001d2e0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0001d2f0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0001d300: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0001d310: 6620 7472 7565 5f64 6976 6964 6528 7365  f true_divide(se
+0001d320: 6c66 2c20 6469 7669 736f 7229 3a0a 2020  lf, divisor):.  
+0001d330: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0001d340: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0001d350: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0001d360: 206f 7468 6572 203d 2063 6173 745f 746f   other = cast_to
+0001d370: 5f6d 735f 7465 6e73 6f72 2864 6976 6973  _ms_tensor(divis
+0001d380: 6f72 290a 2020 2020 2020 2020 6966 206e  or).        if n
+0001d390: 6f74 2069 6e70 7574 5f6d 732e 6973 5f66  ot input_ms.is_f
+0001d3a0: 6c6f 6174 696e 675f 706f 696e 7428 293a  loating_point():
+0001d3b0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+0001d3c0: 6973 696e 7374 616e 6365 286f 7468 6572  isinstance(other
+0001d3d0: 2c20 6d73 2e54 656e 736f 7229 3a0a 2020  , ms.Tensor):.  
+0001d3e0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0001d3f0: 206e 6f74 206f 7468 6572 2e69 735f 666c   not other.is_fl
+0001d400: 6f61 7469 6e67 5f70 6f69 6e74 2829 3a0a  oating_point():.
+0001d410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d420: 2020 2020 696e 7075 745f 6d73 203d 2069      input_ms = i
+0001d430: 6e70 7574 5f6d 732e 6173 7479 7065 286d  nput_ms.astype(m
+0001d440: 732e 666c 6f61 7433 3229 0a0a 2020 2020  s.float32)..    
+0001d450: 2020 2020 2020 2020 656c 6966 206e 6f74          elif not
+0001d460: 2069 7369 6e73 7461 6e63 6528 6f74 6865   isinstance(othe
+0001d470: 722c 2066 6c6f 6174 293a 0a20 2020 2020  r, float):.     
+0001d480: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+0001d490: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
+0001d4a0: 7374 7970 6528 6d73 2e66 6c6f 6174 3332  stype(ms.float32
+0001d4b0: 290a 0a20 2020 2020 2020 206f 7574 7075  )..        outpu
+0001d4c0: 7420 3d20 6d73 2e6f 7073 2e74 7275 655f  t = ms.ops.true_
+0001d4d0: 6469 7669 6465 2869 6e70 7574 5f6d 732c  divide(input_ms,
+0001d4e0: 206f 7468 6572 290a 2020 2020 2020 2020   other).        
+0001d4f0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+0001d500: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+0001d510: 7470 7574 290a 0a20 2020 2064 6566 2074  tput)..    def t
+0001d520: 7275 655f 6469 7669 6465 5f28 7365 6c66  rue_divide_(self
+0001d530: 2c20 6469 7669 736f 7229 3a0a 2020 2020  , divisor):.    
+0001d540: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+0001d550: 662e 7472 7565 5f64 6976 6964 6528 6469  f.true_divide(di
+0001d560: 7669 736f 7229 0a20 2020 2020 2020 2072  visor).        r
+0001d570: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
+0001d580: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
+0001d590: 662c 206f 7574 7075 742c 2022 7472 7565  f, output, "true
+0001d5a0: 5f64 6976 6964 655f 222c 2022 7472 7565  _divide_", "true
+0001d5b0: 5f64 6976 6964 6522 290a 0a20 2020 2064  _divide")..    d
+0001d5c0: 6566 2074 7269 7528 7365 6c66 2c20 6469  ef triu(self, di
+0001d5d0: 6167 6f6e 616c 3d30 293a 0a20 2020 2020  agonal=0):.     
 0001d5e0: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
 0001d5f0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-0001d600: 7365 6c66 290a 2020 2020 2020 2020 6f74  self).        ot
-0001d610: 6865 725f 6d73 203d 2063 6173 745f 746f  her_ms = cast_to
-0001d620: 5f6d 735f 7465 6e73 6f72 286f 7468 6572  _ms_tensor(other
-0001d630: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-0001d640: 203d 206d 732e 6f70 732e 6c6f 6761 6464   = ms.ops.logadd
-0001d650: 6578 7028 696e 7075 745f 6d73 2c20 6f74  exp(input_ms, ot
-0001d660: 6865 725f 6d73 290a 2020 2020 2020 2020  her_ms).        
-0001d670: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-0001d680: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-0001d690: 7470 7574 290a 0a20 2020 2064 6566 206c  tput)..    def l
-0001d6a0: 6f67 6465 7428 7365 6c66 293a 0a20 2020  ogdet(self):.   
-0001d6b0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0001d6c0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-0001d6d0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-0001d6e0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-0001d6f0: 6c6f 6764 6574 2869 6e70 7574 5f6d 7329  logdet(input_ms)
-0001d700: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001d710: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-0001d720: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-0001d730: 2020 2020 6465 6620 6c6f 6769 6361 6c5f      def logical_
-0001d740: 6e6f 7428 7365 6c66 293a 0a20 2020 2020  not(self):.     
-0001d750: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-0001d760: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-0001d770: 7365 6c66 292e 6173 7479 7065 286d 732e  self).astype(ms.
-0001d780: 626f 6f6c 5f29 0a20 2020 2020 2020 206f  bool_).        o
-0001d790: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6c  utput = ms.ops.l
-0001d7a0: 6f67 6963 616c 5f6e 6f74 2869 6e70 7574  ogical_not(input
-0001d7b0: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
-0001d7c0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-0001d7d0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-0001d7e0: 7429 0a0a 2020 2020 6465 6620 6c6f 6769  t)..    def logi
-0001d7f0: 6361 6c5f 6e6f 745f 2873 656c 6629 3a0a  cal_not_(self):.
+0001d600: 7365 6c66 290a 2020 2020 2020 2020 2320  self).        # 
+0001d610: 544f 444f 3a20 546f 2075 7365 206d 732e  TODO: To use ms.
+0001d620: 6f70 732e 7472 6975 2061 6674 6572 2069  ops.triu after i
+0001d630: 7420 7375 7070 6f72 7465 6420 6f6e 2041  t supported on A
+0001d640: 7363 656e 640a 2020 2020 2020 2020 6f75  scend.        ou
+0001d650: 7470 7574 203d 206d 732e 6e75 6d70 792e  tput = ms.numpy.
+0001d660: 7472 6975 2869 6e70 7574 5f6d 732c 2064  triu(input_ms, d
+0001d670: 6961 676f 6e61 6c29 0a20 2020 2020 2020  iagonal).       
+0001d680: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0001d690: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0001d6a0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0001d6b0: 7472 6975 5f28 7365 6c66 2c20 6469 6167  triu_(self, diag
+0001d6c0: 6f6e 616c 3d30 293a 0a20 2020 2020 2020  onal=0):.       
+0001d6d0: 206f 7574 7075 7420 3d20 7365 6c66 2e74   output = self.t
+0001d6e0: 7269 7528 6469 6167 6f6e 616c 290a 2020  riu(diagonal).  
+0001d6f0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+0001d700: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+0001d710: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+0001d720: 2c20 2274 7269 755f 222c 2022 7472 6975  , "triu_", "triu
+0001d730: 2229 0a0a 2020 2020 6465 6620 7472 696c  ")..    def tril
+0001d740: 2873 656c 662c 2064 6961 676f 6e61 6c3d  (self, diagonal=
+0001d750: 3029 3a0a 2020 2020 2020 2020 696e 7075  0):.        inpu
+0001d760: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+0001d770: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+0001d780: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0001d790: 6d73 2e6f 7073 2e74 7269 6c28 696e 7075  ms.ops.tril(inpu
+0001d7a0: 745f 6d73 2c20 6469 6167 6f6e 616c 290a  t_ms, diagonal).
+0001d7b0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+0001d7c0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+0001d7d0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+0001d7e0: 2020 2064 6566 2074 7269 6c5f 2873 656c     def tril_(sel
+0001d7f0: 662c 2064 6961 676f 6e61 6c3d 3029 3a0a  f, diagonal=0):.
 0001d800: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-0001d810: 2073 656c 662e 6c6f 6769 6361 6c5f 6e6f   self.logical_no
-0001d820: 7428 292e 6173 7479 7065 2873 656c 662e  t().astype(self.
-0001d830: 6474 7970 6529 0a20 2020 2020 2020 2072  dtype).        r
-0001d840: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
-0001d850: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
-0001d860: 662c 206f 7574 7075 742c 2022 6c6f 6769  f, output, "logi
-0001d870: 6361 6c5f 6e6f 745f 222c 2022 6c6f 6769  cal_not_", "logi
-0001d880: 6361 6c5f 6e6f 7422 290a 0a20 2020 2064  cal_not")..    d
-0001d890: 6566 206c 6f67 6963 616c 5f6f 7228 7365  ef logical_or(se
-0001d8a0: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
-0001d8b0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-0001d8c0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0001d8d0: 2873 656c 6629 2e61 7374 7970 6528 6d73  (self).astype(ms
-0001d8e0: 2e62 6f6f 6c5f 290a 2020 2020 2020 2020  .bool_).        
-0001d8f0: 6966 2069 7369 6e73 7461 6e63 6528 6f74  if isinstance(ot
-0001d900: 6865 722c 2054 656e 736f 7229 3a0a 2020  her, Tensor):.  
-0001d910: 2020 2020 2020 2020 2020 6f74 6865 725f            other_
-0001d920: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0001d930: 7465 6e73 6f72 286f 7468 6572 292e 6173  tensor(other).as
-0001d940: 7479 7065 286d 732e 626f 6f6c 5f29 0a20  type(ms.bool_). 
-0001d950: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001d960: 6d73 2e6f 7073 2e6c 6f67 6963 616c 5f6f  ms.ops.logical_o
-0001d970: 7228 696e 7075 745f 6d73 2c20 6f74 6865  r(input_ms, othe
-0001d980: 725f 6d73 290a 2020 2020 2020 2020 7265  r_ms).        re
-0001d990: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-0001d9a0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-0001d9b0: 7574 290a 0a20 2020 2064 6566 206c 6f67  ut)..    def log
-0001d9c0: 6963 616c 5f6f 725f 2873 656c 662c 206f  ical_or_(self, o
-0001d9d0: 7468 6572 293a 0a20 2020 2020 2020 206f  ther):.        o
-0001d9e0: 7574 7075 7420 3d20 7365 6c66 2e6c 6f67  utput = self.log
-0001d9f0: 6963 616c 5f6f 7228 6f74 6865 7229 2e61  ical_or(other).a
-0001da00: 7374 7970 6528 7365 6c66 2e64 7479 7065  stype(self.dtype
-0001da10: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0001da20: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
-0001da30: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
-0001da40: 7470 7574 2c20 226c 6f67 6963 616c 5f6f  tput, "logical_o
-0001da50: 725f 222c 2022 6c6f 6769 6361 6c5f 6f72  r_", "logical_or
-0001da60: 2229 0a0a 2020 2020 6465 6620 6c6f 6769  ")..    def logi
-0001da70: 6361 6c5f 786f 7228 7365 6c66 2c20 6f74  cal_xor(self, ot
-0001da80: 6865 7229 3a0a 2020 2020 2020 2020 6966  her):.        if
-0001da90: 2069 7369 6e73 7461 6e63 6528 7365 6c66   isinstance(self
-0001daa0: 2c20 5465 6e73 6f72 293a 0a20 2020 2020  , Tensor):.     
-0001dab0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-0001dac0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-0001dad0: 736f 7228 7365 6c66 292e 6173 7479 7065  sor(self).astype
-0001dae0: 286d 732e 626f 6f6c 5f29 0a20 2020 2020  (ms.bool_).     
-0001daf0: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
-0001db00: 286f 7468 6572 2c20 5465 6e73 6f72 293a  (other, Tensor):
-0001db10: 0a20 2020 2020 2020 2020 2020 206f 7468  .            oth
-0001db20: 6572 203d 2063 6173 745f 746f 5f6d 735f  er = cast_to_ms_
-0001db30: 7465 6e73 6f72 286f 7468 6572 292e 6173  tensor(other).as
-0001db40: 7479 7065 286d 732e 626f 6f6c 5f29 0a0a  type(ms.bool_)..
-0001db50: 2020 2020 2020 2020 2320 544f 444f 3a20          # TODO: 
-0001db60: 6d73 2e6f 7073 2e6c 6f67 6963 616c 5f78  ms.ops.logical_x
-0001db70: 6f72 2074 6f20 7375 7070 6f72 7465 6420  or to supported 
-0001db80: 4750 550a 2020 2020 2020 2020 6966 2069  GPU.        if i
-0001db90: 735f 756e 6465 725f 6770 755f 636f 6e74  s_under_gpu_cont
-0001dba0: 6578 7428 293a 0a20 2020 2020 2020 2020  ext():.         
-0001dbb0: 2020 206f 7574 7075 7420 3d20 6d73 2e6e     output = ms.n
-0001dbc0: 756d 7079 2e6c 6f67 6963 616c 5f78 6f72  umpy.logical_xor
-0001dbd0: 2869 6e70 7574 5f6d 732c 206f 7468 6572  (input_ms, other
-0001dbe0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-0001dbf0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-0001dc00: 7574 203d 206d 732e 6f70 732e 6c6f 6769  ut = ms.ops.logi
-0001dc10: 6361 6c5f 786f 7228 696e 7075 745f 6d73  cal_xor(input_ms
-0001dc20: 2c20 6f74 6865 7229 0a20 2020 2020 2020  , other).       
-0001dc30: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0001dc40: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-0001dc50: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-0001dc60: 6c6f 6769 6361 6c5f 786f 725f 2873 656c  logical_xor_(sel
-0001dc70: 662c 206f 7468 6572 293a 0a20 2020 2020  f, other):.     
-0001dc80: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-0001dc90: 2e6c 6f67 6963 616c 5f78 6f72 286f 7468  .logical_xor(oth
-0001dca0: 6572 292e 6173 7479 7065 2873 656c 662e  er).astype(self.
-0001dcb0: 6474 7970 6529 0a20 2020 2020 2020 2072  dtype).        r
-0001dcc0: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
-0001dcd0: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
-0001dce0: 662c 206f 7574 7075 742c 2022 6c6f 6769  f, output, "logi
-0001dcf0: 6361 6c5f 786f 725f 222c 2022 6c6f 6769  cal_xor_", "logi
-0001dd00: 6361 6c5f 786f 7222 290a 0a20 2020 2064  cal_xor")..    d
-0001dd10: 6566 2061 646a 6f69 6e74 2873 656c 6629  ef adjoint(self)
-0001dd20: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-0001dd30: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0001dd40: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-0001dd50: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-0001dd60: 2e6f 7073 2e61 646a 6f69 6e74 2869 6e70  .ops.adjoint(inp
-0001dd70: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
-0001dd80: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0001dd90: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-0001dda0: 7075 7429 0a0a 2020 2020 6465 6620 6c65  put)..    def le
-0001ddb0: 7270 2873 656c 662c 2065 6e64 2c20 7765  rp(self, end, we
-0001ddc0: 6967 6874 293a 0a20 2020 2020 2020 2069  ight):.        i
-0001ddd0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0001dde0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0001ddf0: 290a 2020 2020 2020 2020 656e 645f 6d73  ).        end_ms
-0001de00: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-0001de10: 6e73 6f72 2865 6e64 290a 2020 2020 2020  nsor(end).      
-0001de20: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-0001de30: 7765 6967 6874 2c20 5465 6e73 6f72 293a  weight, Tensor):
-0001de40: 0a20 2020 2020 2020 2020 2020 2077 6569  .            wei
-0001de50: 6768 7420 3d20 6361 7374 5f74 6f5f 6d73  ght = cast_to_ms
-0001de60: 5f74 656e 736f 7228 7765 6967 6874 290a  _tensor(weight).
-0001de70: 2020 2020 2020 2020 656c 6966 206e 6f74          elif not
-0001de80: 2069 7369 6e73 7461 6e63 6528 7765 6967   isinstance(weig
-0001de90: 6874 2c20 666c 6f61 7429 3a0a 2020 2020  ht, float):.    
-0001dea0: 2020 2020 2020 2020 7765 6967 6874 203d          weight =
-0001deb0: 2066 6c6f 6174 2877 6569 6768 7429 0a20   float(weight). 
-0001dec0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001ded0: 6d73 2e6f 7073 2e6c 6572 7028 696e 7075  ms.ops.lerp(inpu
-0001dee0: 745f 6d73 2c20 656e 645f 6d73 2c20 7765  t_ms, end_ms, we
-0001def0: 6967 6874 290a 2020 2020 2020 2020 7265  ight).        re
-0001df00: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-0001df10: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-0001df20: 7574 290a 0a20 2020 2064 6566 206c 6572  ut)..    def ler
-0001df30: 705f 2873 656c 662c 2065 6e64 2c20 7765  p_(self, end, we
-0001df40: 6967 6874 293a 0a20 2020 2020 2020 206f  ight):.        o
-0001df50: 7574 7075 7420 3d20 7365 6c66 2e6c 6572  utput = self.ler
-0001df60: 7028 656e 642c 2077 6569 6768 7429 0a20  p(end, weight). 
-0001df70: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-0001df80: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-0001df90: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-0001dfa0: 742c 2022 6c65 7270 5f22 2c20 226c 6572  t, "lerp_", "ler
-0001dfb0: 7022 290a 0a20 2020 2064 6566 206c 7528  p")..    def lu(
-0001dfc0: 7365 6c66 2c20 2a2c 2070 6976 6f74 3d54  self, *, pivot=T
-0001dfd0: 7275 652c 2067 6574 5f69 6e66 6f73 3d46  rue, get_infos=F
-0001dfe0: 616c 7365 293a 0a20 2020 2020 2020 2069  alse):.        i
-0001dff0: 6620 6765 745f 696e 666f 733a 0a20 2020  f get_infos:.   
-0001e000: 2020 2020 2020 2020 206f 7574 7075 7431           output1
-0001e010: 2c20 696e 666f 203d 205f 6c75 5f66 6163  , info = _lu_fac
-0001e020: 746f 725f 6578 2873 656c 662c 2070 6976  tor_ex(self, piv
-0001e030: 6f74 3d70 6976 6f74 290a 2020 2020 2020  ot=pivot).      
-0001e040: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
-0001e050: 7574 7075 7431 202b 2028 696e 666f 2c29  utput1 + (info,)
-0001e060: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-0001e070: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-0001e080: 7420 3d20 5f6c 755f 6661 6374 6f72 2873  t = _lu_factor(s
-0001e090: 656c 662c 2070 6976 6f74 3d70 6976 6f74  elf, pivot=pivot
-0001e0a0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0001e0b0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-0001e0c0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-0001e0d0: 0a20 2020 2064 6566 206c 755f 736f 6c76  .    def lu_solv
-0001e0e0: 6528 7365 6c66 2c20 4c55 5f64 6174 612c  e(self, LU_data,
-0001e0f0: 204c 555f 7069 766f 7473 293a 0a20 2020   LU_pivots):.   
-0001e100: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0001e110: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-0001e120: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-0001e130: 4c55 5f64 6174 6120 3d20 6361 7374 5f74  LU_data = cast_t
-0001e140: 6f5f 6d73 5f74 656e 736f 7228 4c55 5f64  o_ms_tensor(LU_d
-0001e150: 6174 6129 0a20 2020 2020 2020 204c 555f  ata).        LU_
-0001e160: 7069 766f 7473 203d 2063 6173 745f 746f  pivots = cast_to
-0001e170: 5f6d 735f 7465 6e73 6f72 284c 555f 7069  _ms_tensor(LU_pi
-0001e180: 766f 7473 290a 2020 2020 2020 2020 6f75  vots).        ou
-0001e190: 7470 7574 203d 206d 732e 6f70 732e 6c75  tput = ms.ops.lu
-0001e1a0: 5f73 6f6c 7665 2869 6e70 7574 5f6d 732c  _solve(input_ms,
-0001e1b0: 204c 555f 6461 7461 2c20 4c55 5f70 6976   LU_data, LU_piv
-0001e1c0: 6f74 7329 0a20 2020 2020 2020 2072 6574  ots).        ret
-0001e1d0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-0001e1e0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-0001e1f0: 7429 0a0a 2020 2020 6465 6620 6d61 736b  t)..    def mask
-0001e200: 6564 5f73 656c 6563 7428 7365 6c66 2c20  ed_select(self, 
-0001e210: 6d61 736b 293a 0a20 2020 2020 2020 206d  mask):.        m
-0001e220: 6173 6b5f 6d73 203d 2063 6173 745f 746f  ask_ms = cast_to
-0001e230: 5f6d 735f 7465 6e73 6f72 286d 6173 6b29  _ms_tensor(mask)
-0001e240: 0a20 2020 2020 2020 206d 6173 6b5f 6474  .        mask_dt
-0001e250: 7970 6520 3d20 6d61 736b 2e64 7479 7065  ype = mask.dtype
-0001e260: 0a20 2020 2020 2020 2069 6620 6d61 736b  .        if mask
-0001e270: 5f64 7479 7065 206e 6f74 2069 6e20 286d  _dtype not in (m
-0001e280: 732e 626f 6f6c 5f2c 206d 732e 7569 6e74  s.bool_, ms.uint
-0001e290: 3829 3a0a 2020 2020 2020 2020 2020 2020  8):.            
-0001e2a0: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-0001e2b0: 6f72 2822 6d61 736b 6564 5f73 656c 6563  or("masked_selec
-0001e2c0: 743a 2065 7870 6563 7465 6420 426f 6f6c  t: expected Bool
-0001e2d0: 5465 6e73 6f72 206f 7220 4279 7465 5465  Tensor or ByteTe
-0001e2e0: 6e73 6f72 2066 6f72 206d 6173 6b22 290a  nsor for mask").
-0001e2f0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-0001e300: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-0001e310: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-0001e320: 2020 2069 6620 6d61 736b 5f64 7479 7065     if mask_dtype
-0001e330: 203d 3d20 6d73 2e75 696e 7438 3a0a 2020   == ms.uint8:.  
-0001e340: 2020 2020 2020 2020 2020 7761 726e 696e            warnin
-0001e350: 6728 226d 6173 6b65 645f 7365 6c65 6374  g("masked_select
-0001e360: 2072 6563 6569 7665 6420 6120 6d61 736b   received a mask
-0001e370: 2077 6974 6820 6474 7970 6520 746f 7263   with dtype torc
-0001e380: 682e 7569 6e74 382c 2074 6869 7320 6265  h.uint8, this be
-0001e390: 6861 7669 6f72 2069 7320 6e6f 7720 6465  havior is now de
-0001e3a0: 7072 6563 6174 6564 2c20 2220 5c0a 2020  precated, " \.  
-0001e3b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e3c0: 2020 2270 6c65 6173 6520 7573 6520 6120    "please use a 
-0001e3d0: 6d61 736b 2077 6974 6820 6474 7970 6520  mask with dtype 
-0001e3e0: 746f 7263 682e 626f 6f6c 2069 6e73 7465  torch.bool inste
-0001e3f0: 6164 2229 0a20 2020 2020 2020 2020 2020  ad").           
-0001e400: 206d 6173 6b5f 6d73 203d 206d 6173 6b5f   mask_ms = mask_
-0001e410: 6d73 2e61 7374 7970 6528 6d73 2e62 6f6f  ms.astype(ms.boo
-0001e420: 6c5f 290a 2020 2020 2020 2020 6f75 7470  l_).        outp
-0001e430: 7574 203d 206d 732e 6f70 732e 6d61 736b  ut = ms.ops.mask
-0001e440: 6564 5f73 656c 6563 7428 696e 7075 745f  ed_select(input_
-0001e450: 6d73 2c20 6d61 736b 5f6d 7329 0a20 2020  ms, mask_ms).   
-0001e460: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0001e470: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0001e480: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0001e490: 6465 6620 616e 676c 6528 7365 6c66 293a  def angle(self):
-0001e4a0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0001e4b0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0001e4c0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0001e4d0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-0001e4e0: 6f70 732e 616e 676c 6528 696e 7075 745f  ops.angle(input_
-0001e4f0: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-0001e500: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-0001e510: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-0001e520: 290a 0a20 2020 2064 6566 2065 6c65 6d65  )..    def eleme
-0001e530: 6e74 5f73 697a 6528 7365 6c66 293a 0a20  nt_size(self):. 
-0001e540: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-0001e550: 6c66 2e6e 756d 7079 2829 2e69 7465 6d73  lf.numpy().items
-0001e560: 697a 650a 0a20 2020 2064 6566 2061 7267  ize..    def arg
-0001e570: 7768 6572 6528 7365 6c66 293a 0a20 2020  where(self):.   
-0001e580: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-0001e590: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-0001e5a0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-0001e5b0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-0001e5c0: 6172 6777 6865 7265 2869 6e70 7574 5f6d  argwhere(input_m
-0001e5d0: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
-0001e5e0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-0001e5f0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-0001e600: 0a0a 2020 2020 6465 6620 6361 7563 6879  ..    def cauchy
-0001e610: 5f28 7365 6c66 2c20 6d65 6469 616e 3d30  _(self, median=0
-0001e620: 2c20 7369 676d 613d 312c 202a 2c20 6765  , sigma=1, *, ge
-0001e630: 6e65 7261 746f 723d 4e6f 6e65 293a 0a20  nerator=None):. 
-0001e640: 2020 2020 2020 2069 6620 6765 6e65 7261         if genera
-0001e650: 746f 723a 0a20 2020 2020 2020 2020 2020  tor:.           
-0001e660: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
-0001e670: 656e 7465 6445 7272 6f72 2822 466f 7220  entedError("For 
-0001e680: 7465 6e73 6f72 2e63 6175 6368 792c 2067  tensor.cauchy, g
-0001e690: 656e 6572 6174 6f72 2068 6173 206e 6f74  enerator has not
-0001e6a0: 2062 6565 6e20 7375 7070 6f72 7465 642e   been supported.
-0001e6b0: 2229 0a0a 2020 2020 2020 2020 696e 7075  ")..        inpu
-0001e6c0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-0001e6d0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-0001e6e0: 2020 2020 2020 205f 7368 6170 6520 3d20         _shape = 
-0001e6f0: 696e 7075 745f 6d73 2e73 6861 7065 0a20  input_ms.shape. 
-0001e700: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001e710: 5f67 6574 5f63 6163 6865 5f70 7269 6d28  _get_cache_prim(
-0001e720: 6d73 2e6f 7073 2e43 6175 6368 7929 286c  ms.ops.Cauchy)(l
-0001e730: 6973 7428 5f73 6861 7065 292c 2073 6967  ist(_shape), sig
-0001e740: 6d61 3d66 6c6f 6174 2873 6967 6d61 292c  ma=float(sigma),
-0001e750: 206d 6564 6961 6e3d 666c 6f61 7428 6d65   median=float(me
-0001e760: 6469 616e 2929 2829 0a0a 2020 2020 2020  dian))()..      
-0001e770: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
-0001e780: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
-0001e790: 7365 6c66 2c20 6f75 7470 7574 2c20 2263  self, output, "c
-0001e7a0: 6175 6368 795f 222c 2022 6361 7563 6879  auchy_", "cauchy
-0001e7b0: 2229 0a0a 2020 2020 6465 6620 636f 6e6a  ")..    def conj
-0001e7c0: 5f70 6879 7369 6361 6c28 7365 6c66 293a  _physical(self):
-0001e7d0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-0001e7e0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0001e7f0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-0001e800: 2020 2020 6966 206d 732e 6f70 732e 6973      if ms.ops.is
-0001e810: 5f63 6f6d 706c 6578 2869 6e70 7574 5f6d  _complex(input_m
-0001e820: 7329 3a0a 2020 2020 2020 2020 2020 2020  s):.            
-0001e830: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-0001e840: 636f 6e6a 2869 6e70 7574 5f6d 7329 0a20  conj(input_ms). 
-0001e850: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0001e860: 2020 2020 2020 2020 206f 7574 7075 7420           output 
-0001e870: 3d20 696e 7075 745f 6d73 0a20 2020 2020  = input_ms.     
-0001e880: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-0001e890: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-0001e8a0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
-0001e8b0: 6620 636f 6e6a 5f70 6879 7369 6361 6c5f  f conj_physical_
-0001e8c0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
-0001e8d0: 6f75 7470 7574 203d 2073 656c 662e 636f  output = self.co
-0001e8e0: 6e6a 5f70 6879 7369 6361 6c28 290a 2020  nj_physical().  
-0001e8f0: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-0001e900: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-0001e910: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-0001e920: 2c20 2263 6f6e 6a5f 7068 7973 6963 616c  , "conj_physical
-0001e930: 5f22 2c20 2263 6f6e 6a5f 7068 7973 6963  _", "conj_physic
-0001e940: 616c 2229 0a0a 2020 2020 6465 6620 706f  al")..    def po
-0001e950: 7369 7469 7665 2873 656c 6629 3a0a 2020  sitive(self):.  
-0001e960: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-0001e970: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0001e980: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-0001e990: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-0001e9a0: 2e70 6f73 6974 6976 6528 696e 7075 745f  .positive(input_
-0001e9b0: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-0001e9c0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-0001e9d0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-0001e9e0: 290a 0a20 2020 2064 6566 206f 7574 6572  )..    def outer
-0001e9f0: 2873 656c 662c 2076 6563 3229 3a0a 2020  (self, vec2):.  
-0001ea00: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-0001ea10: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0001ea20: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-0001ea30: 2076 6563 3220 3d20 6361 7374 5f74 6f5f   vec2 = cast_to_
-0001ea40: 6d73 5f74 656e 736f 7228 7665 6332 290a  ms_tensor(vec2).
-0001ea50: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-0001ea60: 206d 732e 6f70 732e 6f75 7465 7228 696e   ms.ops.outer(in
-0001ea70: 7075 745f 6d73 2c20 7665 6332 290a 2020  put_ms, vec2).  
-0001ea80: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-0001ea90: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-0001eaa0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-0001eab0: 2064 6566 2073 676e 2873 656c 6629 3a0a   def sgn(self):.
-0001eac0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-0001ead0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-0001eae0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-0001eaf0: 2020 2069 6620 2742 6f6f 6c27 2069 6e20     if 'Bool' in 
-0001eb00: 7374 7228 696e 7075 745f 6d73 2e64 7479  str(input_ms.dty
-0001eb10: 7065 2920 6f72 2027 496e 7427 2069 6e20  pe) or 'Int' in 
-0001eb20: 7374 7228 696e 7075 745f 6d73 2e64 7479  str(input_ms.dty
-0001eb30: 7065 293a 0a20 2020 2020 2020 2020 2020  pe):.           
-0001eb40: 2074 7970 6520 3d20 696e 7075 745f 6d73   type = input_ms
-0001eb50: 2e64 7479 7065 0a20 2020 2020 2020 2020  .dtype.         
-0001eb60: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
-0001eb70: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
-0001eb80: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
-0001eb90: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-0001eba0: 732e 6f70 732e 7367 6e28 696e 7075 745f  s.ops.sgn(input_
-0001ebb0: 6d73 292e 6173 7479 7065 2874 7970 6529  ms).astype(type)
-0001ebc0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-0001ebd0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-0001ebe0: 7420 3d20 6d73 2e6f 7073 2e73 676e 2869  t = ms.ops.sgn(i
-0001ebf0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-0001ec00: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-0001ec10: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-0001ec20: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-0001ec30: 7367 6e5f 2873 656c 6629 3a0a 2020 2020  sgn_(self):.    
-0001ec40: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-0001ec50: 662e 7367 6e28 290a 2020 2020 2020 2020  f.sgn().        
-0001ec60: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-0001ec70: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-0001ec80: 6c66 2c20 6f75 7470 7574 2c20 2273 676e  lf, output, "sgn
-0001ec90: 5f22 2c20 2273 676e 2229 0a0a 2020 2020  _", "sgn")..    
-0001eca0: 6465 6620 6c6f 6769 6361 6c5f 616e 6428  def logical_and(
-0001ecb0: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
-0001ecc0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-0001ecd0: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-0001ece0: 6f72 2873 656c 6629 2e61 7374 7970 6528  or(self).astype(
-0001ecf0: 6d73 2e62 6f6f 6c5f 290a 2020 2020 2020  ms.bool_).      
-0001ed00: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-0001ed10: 6f74 6865 722c 2054 656e 736f 7229 3a0a  other, Tensor):.
-0001ed20: 2020 2020 2020 2020 2020 2020 6f74 6865              othe
-0001ed30: 7220 3d20 6361 7374 5f74 6f5f 6d73 5f74  r = cast_to_ms_t
-0001ed40: 656e 736f 7228 6f74 6865 7229 2e61 7374  ensor(other).ast
-0001ed50: 7970 6528 6d73 7479 7065 2e62 6f6f 6c5f  ype(mstype.bool_
-0001ed60: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-0001ed70: 203d 206d 732e 6f70 732e 6c6f 6769 6361   = ms.ops.logica
-0001ed80: 6c5f 616e 6428 696e 7075 745f 6d73 2c20  l_and(input_ms, 
-0001ed90: 6f74 6865 7229 0a20 2020 2020 2020 2072  other).        r
-0001eda0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
-0001edb0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
-0001edc0: 7075 7429 0a0a 2020 2020 6465 6620 6c6f  put)..    def lo
-0001edd0: 6769 6361 6c5f 616e 645f 2873 656c 662c  gical_and_(self,
-0001ede0: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
-0001edf0: 206f 7574 7075 7420 3d20 7365 6c66 2e6c   output = self.l
-0001ee00: 6f67 6963 616c 5f61 6e64 286f 7468 6572  ogical_and(other
-0001ee10: 292e 6173 7479 7065 2873 656c 662e 6474  ).astype(self.dt
-0001ee20: 7970 6529 0a20 2020 2020 2020 2072 6574  ype).        ret
-0001ee30: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-0001ee40: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-0001ee50: 206f 7574 7075 742c 2022 6c6f 6769 6361   output, "logica
-0001ee60: 6c5f 616e 645f 222c 2022 6c6f 6769 6361  l_and_", "logica
-0001ee70: 6c5f 616e 6422 290a 0a20 2020 2064 6566  l_and")..    def
-0001ee80: 2069 6761 6d6d 6128 7365 6c66 2c20 6f74   igamma(self, ot
-0001ee90: 6865 7229 3a0a 2020 2020 2020 2020 696e  her):.        in
-0001eea0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-0001eeb0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-0001eec0: 0a20 2020 2020 2020 206f 7468 6572 5f6d  .        other_m
-0001eed0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0001eee0: 656e 736f 7228 6f74 6865 7229 0a20 2020  ensor(other).   
-0001eef0: 2020 2020 2023 2054 4f44 4f3a 2061 6674       # TODO: aft
-0001ef00: 6572 206d 732e 6f70 732e 6967 616d 6d61  er ms.ops.igamma
-0001ef10: 2073 7570 706f 7274 2066 6c6f 6174 3136   support float16
-0001ef20: 2c20 6465 6c65 7465 2063 6f64 6520 6265  , delete code be
-0001ef30: 6c6f 770a 2020 2020 2020 2020 696e 7075  low.        inpu
-0001ef40: 745f 6d73 2c20 6f74 6865 725f 6d73 2c20  t_ms, other_ms, 
-0001ef50: 666c 6167 203d 205f 6761 6d6d 615f 7479  flag = _gamma_ty
-0001ef60: 7065 2869 6e70 7574 5f6d 732c 206f 7468  pe(input_ms, oth
-0001ef70: 6572 5f6d 7329 0a20 2020 2020 2020 206f  er_ms).        o
-0001ef80: 7574 7075 7420 3d20 6d73 2e6f 7073 2e69  utput = ms.ops.i
-0001ef90: 6761 6d6d 6128 696e 7075 745f 6d73 2c20  gamma(input_ms, 
-0001efa0: 6f74 6865 725f 6d73 290a 2020 2020 2020  other_ms).      
-0001efb0: 2020 6966 2066 6c61 673a 0a20 2020 2020    if flag:.     
-0001efc0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-0001efd0: 6f75 7470 7574 2e61 7374 7970 6528 6d73  output.astype(ms
-0001efe0: 2e66 6c6f 6174 3136 290a 2020 2020 2020  .float16).      
-0001eff0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-0001f000: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0001f010: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-0001f020: 2069 6761 6d6d 6163 2873 656c 662c 206f   igammac(self, o
-0001f030: 7468 6572 293a 0a20 2020 2020 2020 2069  ther):.        i
-0001f040: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0001f050: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0001f060: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
-0001f070: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-0001f080: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
-0001f090: 2020 2020 2020 2320 544f 444f 3a20 6166        # TODO: af
-0001f0a0: 7465 7220 6d73 2e6f 7073 2e69 6761 6d6d  ter ms.ops.igamm
-0001f0b0: 6163 2073 7570 706f 7274 2066 6c6f 6174  ac support float
-0001f0c0: 3136 2c20 6465 6c65 7465 2063 6f64 6520  16, delete code 
-0001f0d0: 6265 6c6f 770a 2020 2020 2020 2020 696e  below.        in
-0001f0e0: 7075 745f 6d73 2c20 6f74 6865 725f 6d73  put_ms, other_ms
-0001f0f0: 2c20 666c 6167 203d 205f 6761 6d6d 615f  , flag = _gamma_
-0001f100: 7479 7065 2869 6e70 7574 5f6d 732c 206f  type(input_ms, o
-0001f110: 7468 6572 5f6d 7329 0a20 2020 2020 2020  ther_ms).       
-0001f120: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-0001f130: 2e69 6761 6d6d 6163 2869 6e70 7574 5f6d  .igammac(input_m
-0001f140: 732c 206f 7468 6572 5f6d 7329 0a20 2020  s, other_ms).   
-0001f150: 2020 2020 2069 6620 666c 6167 3a0a 2020       if flag:.  
-0001f160: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-0001f170: 203d 206f 7574 7075 742e 6173 7479 7065   = output.astype
-0001f180: 286d 732e 666c 6f61 7431 3629 0a20 2020  (ms.float16).   
-0001f190: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0001f1a0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0001f1b0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0001f1c0: 6465 6620 6c63 6d28 7365 6c66 2c20 6f74  def lcm(self, ot
-0001f1d0: 6865 7229 3a0a 2020 2020 2020 2020 696e  her):.        in
-0001f1e0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-0001f1f0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-0001f200: 0a20 2020 2020 2020 206f 7468 6572 5f6d  .        other_m
-0001f210: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-0001f220: 656e 736f 7228 6f74 6865 7229 0a20 2020  ensor(other).   
-0001f230: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-0001f240: 2e6f 7073 2e6c 636d 2869 6e70 7574 5f6d  .ops.lcm(input_m
-0001f250: 732c 206f 7468 6572 5f6d 7329 0a20 2020  s, other_ms).   
-0001f260: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-0001f270: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-0001f280: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-0001f290: 6465 6620 6c63 6d5f 2873 656c 662c 206f  def lcm_(self, o
-0001f2a0: 7468 6572 293a 0a20 2020 2020 2020 206f  ther):.        o
-0001f2b0: 7574 7075 7420 3d20 7365 6c66 2e6c 636d  utput = self.lcm
-0001f2c0: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
-0001f2d0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-0001f2e0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-0001f2f0: 6c66 2c20 6f75 7470 7574 2c20 226c 636d  lf, output, "lcm
-0001f300: 5f22 2c20 226c 636d 2229 0a0a 2020 2020  _", "lcm")..    
-0001f310: 6465 6620 696e 6e65 7228 7365 6c66 2c20  def inner(self, 
-0001f320: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
-0001f330: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-0001f340: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-0001f350: 6629 0a20 2020 2020 2020 206f 7468 6572  f).        other
-0001f360: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-0001f370: 5f74 656e 736f 7228 6f74 6865 7229 0a20  _tensor(other). 
-0001f380: 2020 2020 2020 2069 6620 6973 5f75 6e64         if is_und
-0001f390: 6572 5f67 7075 5f63 6f6e 7465 7874 2829  er_gpu_context()
-0001f3a0: 2061 6e64 2069 6e70 7574 5f6d 732e 6474   and input_ms.dt
-0001f3b0: 7970 6520 696e 2061 6c6c 5f69 6e74 5f74  ype in all_int_t
-0001f3c0: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
-0001f3d0: 2069 6e70 7574 5f74 7970 6520 3d20 696e   input_type = in
-0001f3e0: 7075 745f 6d73 2e64 7479 7065 0a20 2020  put_ms.dtype.   
-0001f3f0: 2020 2020 2020 2020 206f 7468 6572 5f74           other_t
-0001f400: 7970 6520 3d20 6f74 6865 725f 6d73 2e64  ype = other_ms.d
-0001f410: 7479 7065 0a20 2020 2020 2020 2020 2020  type.           
-0001f420: 2069 6e70 7574 5f6d 7320 3d20 696e 7075   input_ms = inpu
-0001f430: 745f 6d73 2e61 7374 7970 6528 6d73 7479  t_ms.astype(msty
-0001f440: 7065 2e66 6c6f 6174 3332 290a 2020 2020  pe.float32).    
-0001f450: 2020 2020 2020 2020 6f74 6865 725f 6d73          other_ms
-0001f460: 203d 206f 7468 6572 5f6d 732e 6173 7479   = other_ms.asty
-0001f470: 7065 286d 7374 7970 652e 666c 6f61 7433  pe(mstype.float3
-0001f480: 3229 0a20 2020 2020 2020 2020 2020 206f  2).            o
-0001f490: 7574 7075 7420 3d20 6d73 2e6f 7073 2e69  utput = ms.ops.i
-0001f4a0: 6e6e 6572 2869 6e70 7574 5f6d 732c 206f  nner(input_ms, o
-0001f4b0: 7468 6572 5f6d 7329 0a20 2020 2020 2020  ther_ms).       
-0001f4c0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-0001f4d0: 2e6f 7073 2e63 6173 7428 6f75 7470 7574  .ops.cast(output
-0001f4e0: 2c20 7072 6f6d 6f74 655f 7479 7065 5f6c  , promote_type_l
-0001f4f0: 6f6f 6b75 7028 696e 7075 745f 7479 7065  ookup(input_type
-0001f500: 2c20 6f74 6865 725f 7479 7065 2929 0a20  , other_type)). 
-0001f510: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
-0001f520: 2020 2020 2020 2020 206f 7574 7075 7420           output 
-0001f530: 3d20 6d73 2e6f 7073 2e69 6e6e 6572 2869  = ms.ops.inner(i
-0001f540: 6e70 7574 5f6d 732c 206f 7468 6572 5f6d  nput_ms, other_m
-0001f550: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
-0001f560: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-0001f570: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-0001f580: 0a0a 2020 2020 6465 6620 726f 6c6c 2873  ..    def roll(s
-0001f590: 656c 662c 2073 6869 6674 732c 2064 696d  elf, shifts, dim
-0001f5a0: 733d 4e6f 6e65 293a 0a20 2020 2020 2020  s=None):.       
-0001f5b0: 2069 6e70 7574 5f6d 7320 203d 2063 6173   input_ms  = cas
-0001f5c0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-0001f5d0: 656c 6629 0a20 2020 2020 2020 2023 2054  elf).        # T
-0001f5e0: 4f44 4f3a 2073 7570 706f 7274 2072 6f6c  ODO: support rol
-0001f5f0: 6c20 6f6e 2043 5055 2061 6e64 2041 7363  l on CPU and Asc
-0001f600: 656e 6420 706c 6174 666f 726d 2e20 4375  end platform. Cu
-0001f610: 7272 656e 746c 7920 7573 6520 6e75 6d70  rrently use nump
-0001f620: 7920 6675 6e63 0a20 2020 2020 2020 2023  y func.        #
-0001f630: 2054 4f44 4f3a 206f 6e20 4173 6365 6e64   TODO: on Ascend
-0001f640: 2c20 6d73 2e6f 7073 2e72 6f6c 6c20 6361  , ms.ops.roll ca
-0001f650: 6e20 6f6e 6c79 2061 6363 6570 7420 7368  n only accept sh
-0001f660: 6966 7473 2077 6974 6820 7369 6e67 6c65  ifts with single
-0001f670: 206e 756d 6265 722e 0a20 2020 2020 2020   number..       
-0001f680: 2069 6620 6e6f 7420 6973 5f75 6e64 6572   if not is_under
-0001f690: 5f67 7075 5f63 6f6e 7465 7874 2829 3a0a  _gpu_context():.
-0001f6a0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-0001f6b0: 7574 203d 206d 732e 6e75 6d70 792e 726f  ut = ms.numpy.ro
-0001f6c0: 6c6c 2869 6e70 7574 5f6d 732c 2073 6869  ll(input_ms, shi
-0001f6d0: 6674 732c 2064 696d 7329 0a20 2020 2020  fts, dims).     
-0001f6e0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-0001f6f0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-0001f700: 2e6f 7073 2e72 6f6c 6c28 696e 7075 745f  .ops.roll(input_
-0001f710: 6d73 2c20 7368 6966 7473 2c20 6469 6d73  ms, shifts, dims
-0001f720: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-0001f730: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-0001f740: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-0001f750: 0a20 2020 2064 6566 2075 6e66 6f6c 6428  .    def unfold(
-0001f760: 7365 6c66 2c20 6469 6d65 6e73 696f 6e2c  self, dimension,
-0001f770: 2073 697a 652c 2073 7465 7029 3a0a 2020   size, step):.  
-0001f780: 2020 2020 2020 2320 544f 444f 3a20 6d69        # TODO: mi
-0001f790: 6e64 7370 6f72 6520 646f 206e 6f74 2068  ndspore do not h
-0001f7a0: 6176 6520 7265 6c61 7465 6420 696e 7465  ave related inte
-0001f7b0: 7266 6163 652c 206d 732e 6f70 732e 756e  rface, ms.ops.un
-0001f7c0: 666f 6c64 2069 7320 6e6f 7420 7468 6520  fold is not the 
-0001f7d0: 7361 6d65 2061 7320 7468 6973 2069 6e74  same as this int
-0001f7e0: 6572 6661 6365 0a20 2020 2020 2020 2069  erface.        i
-0001f7f0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-0001f800: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-0001f810: 290a 2020 2020 2020 2020 5f69 6e64 6963  ).        _indic
-0001f820: 6573 2c20 5f64 696d 656e 7369 6f6e 203d  es, _dimension =
-0001f830: 205f 6765 745f 756e 666f 6c64 5f69 6e64   _get_unfold_ind
-0001f840: 6963 6573 2869 6e70 7574 5f6d 732e 7368  ices(input_ms.sh
-0001f850: 6170 652c 2064 696d 656e 7369 6f6e 2c20  ape, dimension, 
-0001f860: 7369 7a65 2c20 7374 6570 290a 2020 2020  size, step).    
-0001f870: 2020 2020 696e 6469 6365 7320 3d20 6d73      indices = ms
-0001f880: 2e54 656e 736f 7228 5f69 6e64 6963 6573  .Tensor(_indices
-0001f890: 292e 6173 7479 7065 286d 732e 696e 7433  ).astype(ms.int3
-0001f8a0: 3229 0a20 2020 2020 2020 206f 7574 7075  2).        outpu
-0001f8b0: 7420 3d20 6d73 2e6f 7073 2e67 6174 6865  t = ms.ops.gathe
-0001f8c0: 7228 696e 7075 745f 6d73 2c20 696e 6469  r(input_ms, indi
-0001f8d0: 6365 732c 2061 7869 733d 5f64 696d 656e  ces, axis=_dimen
-0001f8e0: 7369 6f6e 290a 2020 2020 2020 2020 6f75  sion).        ou
-0001f8f0: 7470 7574 203d 206d 732e 6f70 732e 6d6f  tput = ms.ops.mo
-0001f900: 7665 6178 6973 286f 7574 7075 742c 205f  veaxis(output, _
-0001f910: 6469 6d65 6e73 696f 6e20 2b20 312c 202d  dimension + 1, -
-0001f920: 3129 0a20 2020 2020 2020 2072 6574 7572  1).        retur
-0001f930: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-0001f940: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-0001f950: 0a0a 2020 2020 6465 6620 736c 6f67 6465  ..    def slogde
-0001f960: 7428 7365 6c66 293a 0a20 2020 2020 2020  t(self):.       
-0001f970: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-0001f980: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-0001f990: 6c66 290a 2020 2020 2020 2020 7369 676e  lf).        sign
-0001f9a0: 2c20 6f75 7470 7574 203d 206d 732e 6f70  , output = ms.op
-0001f9b0: 732e 736c 6f67 6465 7428 696e 7075 745f  s.slogdet(input_
-0001f9c0: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-0001f9d0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-0001f9e0: 6572 5f74 656e 736f 7228 2873 6967 6e2c  er_tensor((sign,
-0001f9f0: 206f 7574 7075 7429 290a 0a20 2020 2064   output))..    d
-0001fa00: 6566 2073 6c69 6365 5f73 6361 7474 6572  ef slice_scatter
-0001fa10: 2873 656c 662c 2073 7263 2c20 6469 6d3d  (self, src, dim=
-0001fa20: 302c 2073 7461 7274 3d4e 6f6e 652c 2065  0, start=None, e
-0001fa30: 6e64 3d4e 6f6e 652c 2073 7465 703d 3129  nd=None, step=1)
-0001fa40: 3a0a 2020 2020 2020 2020 2320 544f 444f  :.        # TODO
-0001fa50: 3a20 6d73 2e6f 7073 2e73 6c69 6365 5f73  : ms.ops.slice_s
-0001fa60: 6361 7474 6572 206e 6f74 2073 7570 706f  catter not suppo
-0001fa70: 7274 0a20 2020 2020 2020 2078 203d 2063  rt.        x = c
-0001fa80: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-0001fa90: 2873 656c 6629 0a20 2020 2020 2020 2073  (self).        s
-0001faa0: 7263 203d 2063 6173 745f 746f 5f6d 735f  rc = cast_to_ms_
-0001fab0: 7465 6e73 6f72 2873 7263 290a 2020 2020  tensor(src).    
-0001fac0: 2020 2020 785f 7368 6170 6520 3d20 782e      x_shape = x.
-0001fad0: 7368 6170 650a 2020 2020 2020 2020 785f  shape.        x_
-0001fae0: 7261 6e6b 2c20 696e 6465 782c 2064 696d  rank, index, dim
-0001faf0: 203d 205f 6765 745f 736c 6963 655f 7363   = _get_slice_sc
-0001fb00: 6174 7465 725f 636f 6e73 7428 785f 7368  atter_const(x_sh
-0001fb10: 6170 652c 2064 696d 2c20 7374 6172 742c  ape, dim, start,
-0001fb20: 2065 6e64 2c20 7374 6570 290a 0a20 2020   end, step)..   
-0001fb30: 2020 2020 2073 7263 5f73 6861 7065 203d       src_shape =
-0001fb40: 2073 7263 2e73 6861 7065 0a20 2020 2020   src.shape.     
-0001fb50: 2020 2069 6e64 6578 5f74 656e 736f 7220     index_tensor 
-0001fb60: 3d20 6d73 2e54 656e 736f 7228 696e 6465  = ms.Tensor(inde
-0001fb70: 7829 0a20 2020 2020 2020 2066 6f72 205f  x).        for _
-0001fb80: 2069 6e20 7261 6e67 6528 6469 6d29 3a0a   in range(dim):.
-0001fb90: 2020 2020 2020 2020 2020 2020 7372 6320              src 
-0001fba0: 3d20 7372 632e 6578 7061 6e64 5f64 696d  = src.expand_dim
-0001fbb0: 7328 3029 0a20 2020 2020 2020 2020 2020  s(0).           
-0001fbc0: 2069 6e64 6578 5f74 656e 736f 7220 3d20   index_tensor = 
-0001fbd0: 696e 6465 785f 7465 6e73 6f72 2e65 7870  index_tensor.exp
-0001fbe0: 616e 645f 6469 6d73 2830 290a 0a20 2020  and_dims(0)..   
-0001fbf0: 2020 2020 2069 6620 6469 6d20 3d3d 2078       if dim == x
-0001fc00: 5f72 616e 6b20 2d20 313a 0a20 2020 2020  _rank - 1:.     
-0001fc10: 2020 2020 2020 2073 7263 203d 2073 7263         src = src
-0001fc20: 2e62 726f 6164 6361 7374 5f74 6f28 782e  .broadcast_to(x.
-0001fc30: 7368 6170 655b 303a 6469 6d5d 202b 2073  shape[0:dim] + s
-0001fc40: 7263 5f73 6861 7065 290a 2020 2020 2020  rc_shape).      
-0001fc50: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-0001fc60: 2020 2020 666f 7220 5f20 696e 2072 616e      for _ in ran
-0001fc70: 6765 286c 656e 2873 7263 5f73 6861 7065  ge(len(src_shape
-0001fc80: 2929 3a0a 2020 2020 2020 2020 2020 2020  )):.            
-0001fc90: 2020 2020 696e 6465 785f 7465 6e73 6f72      index_tensor
-0001fca0: 203d 2069 6e64 6578 5f74 656e 736f 722e   = index_tensor.
-0001fcb0: 6578 7061 6e64 5f64 696d 7328 2d31 290a  expand_dims(-1).
-0001fcc0: 2020 2020 2020 2020 2020 2020 7372 6320              src 
-0001fcd0: 3d20 7372 632e 6272 6f61 6463 6173 745f  = src.broadcast_
-0001fce0: 746f 2878 2e73 6861 7065 5b30 3a64 696d  to(x.shape[0:dim
-0001fcf0: 5d20 2b20 286c 656e 2869 6e64 6578 292c  ] + (len(index),
-0001fd00: 292b 2073 7263 5f73 6861 7065 290a 0a20  )+ src_shape).. 
-0001fd10: 2020 2020 2020 2069 6e64 6578 5f74 656e         index_ten
-0001fd20: 736f 7220 3d20 696e 6465 785f 7465 6e73  sor = index_tens
-0001fd30: 6f72 2e62 726f 6164 6361 7374 5f74 6f28  or.broadcast_to(
-0001fd40: 7372 632e 7368 6170 6529 0a20 2020 2020  src.shape).     
-0001fd50: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
-0001fd60: 7073 2e74 656e 736f 725f 7363 6174 7465  ps.tensor_scatte
-0001fd70: 725f 656c 656d 656e 7473 2878 2c20 6178  r_elements(x, ax
-0001fd80: 6973 3d64 696d 2c20 696e 6469 6365 733d  is=dim, indices=
-0001fd90: 696e 6465 785f 7465 6e73 6f72 2c20 7570  index_tensor, up
-0001fda0: 6461 7465 733d 7372 6329 0a20 2020 2020  dates=src).     
-0001fdb0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-0001fdc0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-0001fdd0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
-0001fde0: 6620 7365 6c65 6374 5f73 6361 7474 6572  f select_scatter
-0001fdf0: 2873 656c 662c 2073 7263 2c20 6469 6d2c  (self, src, dim,
-0001fe00: 2069 6e64 6578 293a 0a20 2020 2020 2020   index):.       
-0001fe10: 2072 6574 7572 6e20 7365 6c66 2e73 6c69   return self.sli
-0001fe20: 6365 5f73 6361 7474 6572 2873 7263 2c20  ce_scatter(src, 
-0001fe30: 6469 6d2c 2073 7461 7274 3d69 6e64 6578  dim, start=index
-0001fe40: 2c20 656e 643d 696e 6465 7820 2b20 3129  , end=index + 1)
-0001fe50: 0a0a 2020 2020 6465 6620 6967 616d 6d61  ..    def igamma
-0001fe60: 5f28 7365 6c66 2c20 6f74 6865 7229 3a0a  _(self, other):.
-0001fe70: 2020 2020 2020 2020 666c 6167 3332 203d          flag32 =
-0001fe80: 2046 616c 7365 0a20 2020 2020 2020 2066   False.        f
-0001fe90: 6c61 6731 3620 3d20 4661 6c73 650a 2020  lag16 = False.  
-0001fea0: 2020 2020 2020 6966 2073 656c 662e 6474        if self.dt
-0001feb0: 7970 6520 3d3d 206d 732e 666c 6f61 7433  ype == ms.float3
-0001fec0: 323a 0a20 2020 2020 2020 2020 2020 2066  2:.            f
-0001fed0: 6c61 6733 3220 3d20 5472 7565 0a20 2020  lag32 = True.   
-0001fee0: 2020 2020 2069 6620 7365 6c66 2e64 7479       if self.dty
-0001fef0: 7065 203d 3d20 6d73 2e66 6c6f 6174 3136  pe == ms.float16
-0001ff00: 3a0a 2020 2020 2020 2020 2020 2020 666c  :.            fl
-0001ff10: 6167 3136 203d 2054 7275 650a 2020 2020  ag16 = True.    
-0001ff20: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-0001ff30: 662e 6967 616d 6d61 286f 7468 6572 290a  f.igamma(other).
-0001ff40: 2020 2020 2020 2020 6966 2066 6c61 6733          if flag3
-0001ff50: 323a 0a20 2020 2020 2020 2020 2020 206f  2:.            o
-0001ff60: 7574 7075 7420 3d20 6f75 7470 7574 2e61  utput = output.a
-0001ff70: 7374 7970 6528 6d73 2e66 6c6f 6174 3332  stype(ms.float32
-0001ff80: 290a 2020 2020 2020 2020 6966 2066 6c61  ).        if fla
-0001ff90: 6731 363a 0a20 2020 2020 2020 2020 2020  g16:.           
-0001ffa0: 206f 7574 7075 7420 3d20 6f75 7470 7574   output = output
-0001ffb0: 2e61 7374 7970 6528 6d73 2e66 6c6f 6174  .astype(ms.float
-0001ffc0: 3136 290a 2020 2020 2020 2020 7265 7475  16).        retu
-0001ffd0: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
-0001ffe0: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
-0001fff0: 6f75 7470 7574 2c20 2269 6761 6d6d 615f  output, "igamma_
-00020000: 222c 2022 6967 616d 6d61 2229 0a0a 2020  ", "igamma")..  
-00020010: 2020 6465 6620 6967 616d 6d61 635f 2873    def igammac_(s
-00020020: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
-00020030: 2020 2020 2066 6c61 6733 3220 3d20 4661       flag32 = Fa
-00020040: 6c73 650a 2020 2020 2020 2020 666c 6167  lse.        flag
-00020050: 3136 203d 2046 616c 7365 0a20 2020 2020  16 = False.     
-00020060: 2020 2069 6620 7365 6c66 2e64 7479 7065     if self.dtype
-00020070: 203d 3d20 6d73 2e66 6c6f 6174 3332 3a0a   == ms.float32:.
-00020080: 2020 2020 2020 2020 2020 2020 666c 6167              flag
-00020090: 3332 203d 2054 7275 650a 2020 2020 2020  32 = True.      
-000200a0: 2020 6966 2073 656c 662e 6474 7970 6520    if self.dtype 
-000200b0: 3d3d 206d 732e 666c 6f61 7431 363a 0a20  == ms.float16:. 
-000200c0: 2020 2020 2020 2020 2020 2066 6c61 6731             flag1
-000200d0: 3620 3d20 5472 7565 0a20 2020 2020 2020  6 = True.       
-000200e0: 206f 7574 7075 7420 3d20 7365 6c66 2e69   output = self.i
-000200f0: 6761 6d6d 6163 286f 7468 6572 290a 2020  gammac(other).  
-00020100: 2020 2020 2020 6966 2066 6c61 6733 323a        if flag32:
-00020110: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00020120: 7075 7420 3d20 6f75 7470 7574 2e61 7374  put = output.ast
-00020130: 7970 6528 6d73 2e66 6c6f 6174 3332 290a  ype(ms.float32).
-00020140: 2020 2020 2020 2020 6966 2066 6c61 6731          if flag1
-00020150: 363a 0a20 2020 2020 2020 2020 2020 206f  6:.            o
-00020160: 7574 7075 7420 3d20 6f75 7470 7574 2e61  utput = output.a
-00020170: 7374 7970 6528 6d73 2e66 6c6f 6174 3136  stype(ms.float16
-00020180: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00020190: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
-000201a0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
-000201b0: 7470 7574 2c20 2269 6761 6d6d 6163 5f22  tput, "igammac_"
-000201c0: 2c20 2269 6761 6d6d 6163 2229 0a0a 2020  , "igammac")..  
-000201d0: 2020 6465 6620 6c67 616d 6d61 2873 656c    def lgamma(sel
-000201e0: 6629 3a0a 2020 2020 2020 2020 2320 544f  f):.        # TO
-000201f0: 444f 3a20 6d73 2e6f 7073 2e6c 6761 6d6d  DO: ms.ops.lgamm
-00020200: 6120 746f 2073 7570 706f 7274 2061 7363  a to support asc
-00020210: 656e 640a 2020 2020 2020 2020 696e 7075  end.        inpu
-00020220: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00020230: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00020240: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00020250: 6d73 2e6f 7073 2e6c 6761 6d6d 6128 696e  ms.ops.lgamma(in
-00020260: 7075 745f 6d73 290a 2020 2020 2020 2020  put_ms).        
-00020270: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00020280: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00020290: 7470 7574 290a 0a20 2020 2064 6566 206c  tput)..    def l
-000202a0: 6761 6d6d 615f 2873 656c 6629 3a0a 2020  gamma_(self):.  
-000202b0: 2020 2020 2020 2320 544f 444f 3a20 6d73        # TODO: ms
-000202c0: 2e6f 7073 2e6c 6761 6d6d 6120 746f 2073  .ops.lgamma to s
-000202d0: 7570 706f 7274 2061 7363 656e 640a 2020  upport ascend.  
-000202e0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
-000202f0: 656c 662e 6c67 616d 6d61 2829 0a20 2020  elf.lgamma().   
-00020300: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
-00020310: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
-00020320: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
-00020330: 2022 6c67 616d 6d61 5f22 2c20 226c 6761   "lgamma_", "lga
-00020340: 6d6d 6122 290a 0a20 2020 2064 6566 206d  mma")..    def m
-00020350: 756c 7469 6e6f 6d69 616c 2873 656c 662c  ultinomial(self,
-00020360: 206e 756d 5f73 616d 706c 652c 2072 6570   num_sample, rep
-00020370: 6c61 6365 6d65 6e74 3d46 616c 7365 2c20  lacement=False, 
-00020380: 7365 6564 3d4e 6f6e 6529 3a0a 2020 2020  seed=None):.    
-00020390: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-000203a0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-000203b0: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
-000203c0: 6620 7265 706c 6163 656d 656e 7420 616e  f replacement an
-000203d0: 6420 696e 7075 745f 6d73 2e6e 6469 6d20  d input_ms.ndim 
-000203e0: 3d3d 2031 3a0a 2020 2020 2020 2020 2020  == 1:.          
-000203f0: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
-00020400: 7574 5f6d 732e 756e 7371 7565 657a 6528  ut_ms.unsqueeze(
-00020410: 3029 0a20 2020 2020 2020 2020 2020 206f  0).            o
-00020420: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6d  utput = ms.ops.m
-00020430: 756c 7469 6e6f 6d69 616c 2869 6e70 7574  ultinomial(input
-00020440: 5f6d 732c 206e 756d 5f73 616d 706c 652c  _ms, num_sample,
-00020450: 2072 6570 6c61 6365 6d65 6e74 2c20 7365   replacement, se
-00020460: 6564 290a 2020 2020 2020 2020 2020 2020  ed).            
-00020470: 6f75 7470 7574 203d 206f 7574 7075 742e  output = output.
-00020480: 7371 7565 657a 6528 3029 0a20 2020 2020  squeeze(0).     
-00020490: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-000204a0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-000204b0: 2e6f 7073 2e6d 756c 7469 6e6f 6d69 616c  .ops.multinomial
-000204c0: 2869 6e70 7574 5f6d 732c 206e 756d 5f73  (input_ms, num_s
-000204d0: 616d 706c 652c 2072 6570 6c61 6365 6d65  ample, replaceme
-000204e0: 6e74 2c20 7365 6564 290a 2020 2020 2020  nt, seed).      
-000204f0: 2020 6f75 7470 7574 203d 206f 7574 7075    output = outpu
-00020500: 742e 6173 7479 7065 286d 732e 696e 7436  t.astype(ms.int6
-00020510: 3429 0a20 2020 2020 2020 2072 6574 7572  4).        retur
-00020520: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00020530: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-00020540: 0a0a 2020 2020 6465 6620 636f 7628 7365  ..    def cov(se
-00020550: 6c66 2c20 2a2c 2063 6f72 7265 6374 696f  lf, *, correctio
-00020560: 6e3d 312c 2066 7765 6967 6874 733d 4e6f  n=1, fweights=No
-00020570: 6e65 2c20 6177 6569 6768 7473 3d4e 6f6e  ne, aweights=Non
-00020580: 6529 3a0a 2020 2020 2020 2020 2320 544f  e):.        # TO
-00020590: 444f 3a20 6d73 2e6f 7073 2e63 6f76 2074  DO: ms.ops.cov t
-000205a0: 6f20 7375 7070 6f72 7420 666c 6f61 7436  o support float6
-000205b0: 3420 616e 6420 636f 6d70 6c65 7820 696e  4 and complex in
-000205c0: 7075 740a 2020 2020 2020 2020 696e 7075  put.        inpu
-000205d0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-000205e0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-000205f0: 2020 2020 2020 2069 6620 6677 6569 6768         if fweigh
-00020600: 7473 2069 7320 6e6f 7420 4e6f 6e65 3a0a  ts is not None:.
-00020610: 2020 2020 2020 2020 2020 2020 6677 6569              fwei
-00020620: 6768 7473 203d 2063 6173 745f 746f 5f6d  ghts = cast_to_m
-00020630: 735f 7465 6e73 6f72 2866 7765 6967 6874  s_tensor(fweight
-00020640: 7329 0a20 2020 2020 2020 2069 6620 6177  s).        if aw
-00020650: 6569 6768 7473 2069 7320 6e6f 7420 4e6f  eights is not No
-00020660: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00020670: 6177 6569 6768 7473 203d 2063 6173 745f  aweights = cast_
-00020680: 746f 5f6d 735f 7465 6e73 6f72 2861 7765  to_ms_tensor(awe
-00020690: 6967 6874 7329 0a20 2020 2020 2020 206f  ights).        o
-000206a0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e63  utput = ms.ops.c
-000206b0: 6f76 2869 6e70 7574 5f6d 732c 2063 6f72  ov(input_ms, cor
-000206c0: 7265 6374 696f 6e3d 636f 7272 6563 7469  rection=correcti
-000206d0: 6f6e 2c20 6677 6569 6768 7473 3d66 7765  on, fweights=fwe
-000206e0: 6967 6874 732c 2061 7765 6967 6874 733d  ights, aweights=
-000206f0: 6177 6569 6768 7473 290a 2020 2020 2020  aweights).      
-00020700: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00020710: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00020720: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00020730: 2072 6f74 3930 2873 656c 662c 206b 2c20   rot90(self, k, 
-00020740: 6469 6d73 293a 0a20 2020 2020 2020 2069  dims):.        i
-00020750: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-00020760: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00020770: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-00020780: 203d 206d 732e 6f70 732e 726f 7439 3028   = ms.ops.rot90(
-00020790: 696e 7075 745f 6d73 2c20 6b2c 2064 696d  input_ms, k, dim
-000207a0: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
-000207b0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-000207c0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-000207d0: 0a0a 2020 2020 6465 6620 6d65 6469 616e  ..    def median
-000207e0: 2873 656c 662c 2064 696d 3d4e 6f6e 652c  (self, dim=None,
-000207f0: 206b 6565 7064 696d 3d46 616c 7365 293a   keepdim=False):
-00020800: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-00020810: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00020820: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00020830: 2020 2020 6966 2064 696d 2069 7320 4e6f      if dim is No
-00020840: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
-00020850: 2320 6d73 2e6f 7073 2e6d 6564 6961 6e20  # ms.ops.median 
-00020860: 6361 6e20 6e6f 7420 636f 6d70 7574 6520  can not compute 
-00020870: 7468 6520 6d65 6469 616e 2076 616c 7565  the median value
-00020880: 2061 6c6f 6e67 2061 6c6c 2064 696d 656e   along all dimen
-00020890: 7469 6f6e 730a 2020 2020 2020 2020 2020  tions.          
-000208a0: 2020 2320 6f6e 6c79 206d 732e 6f70 732e    # only ms.ops.
-000208b0: 4d65 6469 616e 2867 6c6f 6261 6c5f 6d65  Median(global_me
-000208c0: 6469 616e 3d54 7275 6529 2063 616e 2064  dian=True) can d
-000208d0: 6f20 7468 6174 2e0a 2020 2020 2020 2020  o that..        
-000208e0: 2020 2020 2320 736f 2063 616e 206e 6f74      # so can not
-000208f0: 2072 6570 6c61 6365 206d 732e 6f70 732e   replace ms.ops.
-00020900: 4d65 6469 616e 2074 6f20 6d73 2e6f 7073  Median to ms.ops
-00020910: 2e6d 6564 6961 6e0a 2020 2020 2020 2020  .median.        
-00020920: 2020 2020 6f75 7470 7574 2c20 5f20 3d20      output, _ = 
-00020930: 5f67 6574 5f63 6163 6865 5f70 7269 6d28  _get_cache_prim(
-00020940: 6d73 2e6f 7073 2e4d 6564 6961 6e29 2854  ms.ops.Median)(T
-00020950: 7275 6529 2869 6e70 7574 5f6d 7329 0a20  rue)(input_ms). 
-00020960: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00020970: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00020980: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
-00020990: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-000209a0: 2020 2020 2020 2020 2020 2023 2054 4f44             # TOD
-000209b0: 4f3a 204f 6e20 4750 552c 206d 732e 6f70  O: On GPU, ms.op
-000209c0: 732e 6d65 6469 616e 2074 6865 2072 6574  s.median the ret
-000209d0: 7572 6e20 696e 6469 6365 7320 6d61 7920  urn indices may 
-000209e0: 6265 2077 726f 6e67 2e0a 2020 2020 2020  be wrong..      
-000209f0: 2020 2020 2020 7661 6c75 652c 2069 6e64        value, ind
-00020a00: 6963 6573 203d 206d 732e 6f70 732e 6d65  ices = ms.ops.me
-00020a10: 6469 616e 2869 6e70 7574 5f6d 732c 2064  dian(input_ms, d
-00020a20: 696d 2c20 6b65 6570 6469 6d29 0a20 2020  im, keepdim).   
-00020a30: 2020 2020 2020 2020 2069 6620 7079 6e61           if pyna
-00020a40: 7469 7665 5f6d 6f64 655f 636f 6e64 6974  tive_mode_condit
-00020a50: 696f 6e28 293a 0a20 2020 2020 2020 2020  ion():.         
-00020a60: 2020 2020 2020 2070 6f69 6e74 203d 2073         point = s
-00020a70: 6574 5f6e 616d 655f 7475 706c 6528 276d  et_name_tuple('m
-00020a80: 6564 6961 6e27 290a 2020 2020 2020 2020  edian').        
-00020a90: 2020 2020 2020 2020 726c 7420 3d20 706f          rlt = po
-00020aa0: 696e 7428 6361 7374 5f74 6f5f 6164 6170  int(cast_to_adap
-00020ab0: 7465 725f 7465 6e73 6f72 2876 616c 7565  ter_tensor(value
-00020ac0: 292c 2063 6173 745f 746f 5f61 6461 7074  ), cast_to_adapt
-00020ad0: 6572 5f74 656e 736f 7228 696e 6469 6365  er_tensor(indice
-00020ae0: 7329 290a 2020 2020 2020 2020 2020 2020  s)).            
-00020af0: 2020 2020 7265 7475 726e 2072 6c74 0a20      return rlt. 
-00020b00: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00020b10: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-00020b20: 725f 7465 6e73 6f72 2876 616c 7565 292c  r_tensor(value),
-00020b30: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00020b40: 5f74 656e 736f 7228 696e 6469 6365 7329  _tensor(indices)
-00020b50: 0a0a 2020 2020 6465 6620 6672 6163 2873  ..    def frac(s
-00020b60: 656c 6629 3a0a 2020 2020 2020 2020 696e  elf):.        in
-00020b70: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-00020b80: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00020b90: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00020ba0: 3d20 6d73 2e6f 7073 2e66 7261 6328 696e  = ms.ops.frac(in
-00020bb0: 7075 745f 6d73 290a 2020 2020 2020 2020  put_ms).        
-00020bc0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00020bd0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00020be0: 7470 7574 290a 0a20 2020 2064 6566 2066  tput)..    def f
-00020bf0: 7261 635f 2873 656c 6629 3a0a 2020 2020  rac_(self):.    
-00020c00: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-00020c10: 662e 6672 6163 2829 0a20 2020 2020 2020  f.frac().       
-00020c20: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
-00020c30: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
-00020c40: 656c 662c 206f 7574 7075 742c 2022 6672  elf, output, "fr
-00020c50: 6163 5f22 2c20 2266 7261 6322 290a 0a20  ac_", "frac").. 
-00020c60: 2020 2064 6566 2067 6364 2873 656c 662c     def gcd(self,
-00020c70: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
-00020c80: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00020c90: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00020ca0: 6c66 290a 2020 2020 2020 2020 6f74 6865  lf).        othe
-00020cb0: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
-00020cc0: 735f 7465 6e73 6f72 286f 7468 6572 290a  s_tensor(other).
-00020cd0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00020ce0: 206d 732e 6f70 732e 6763 6428 696e 7075   ms.ops.gcd(inpu
-00020cf0: 745f 6d73 2c20 6f74 6865 725f 6d73 290a  t_ms, other_ms).
-00020d00: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-00020d10: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-00020d20: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
-00020d30: 2020 2064 6566 2067 6364 5f28 7365 6c66     def gcd_(self
-00020d40: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
-00020d50: 2020 6f75 7470 7574 203d 2073 656c 662e    output = self.
-00020d60: 6763 6428 6f74 6865 7229 0a20 2020 2020  gcd(other).     
-00020d70: 2020 2072 6574 7572 6e20 5f74 656e 736f     return _tenso
-00020d80: 725f 696e 706c 6163 655f 6173 7369 676e  r_inplace_assign
-00020d90: 2873 656c 662c 206f 7574 7075 742c 2022  (self, output, "
-00020da0: 6763 645f 222c 2022 6763 6422 290a 0a20  gcd_", "gcd").. 
-00020db0: 2020 2040 7072 6f70 6572 7479 0a20 2020     @property.   
-00020dc0: 2064 6566 2069 6d61 6728 7365 6c66 293a   def imag(self):
-00020dd0: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
-00020de0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00020df0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
-00020e00: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00020e10: 6f70 732e 696d 6167 2869 6e70 7574 5f6d  ops.imag(input_m
-00020e20: 7329 0a20 2020 2020 2020 206f 7574 7075  s).        outpu
-00020e30: 7420 3d20 6361 7374 5f74 6f5f 6164 6170  t = cast_to_adap
-00020e40: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-00020e50: 7429 0a20 2020 2020 2020 206f 7574 7075  t).        outpu
-00020e60: 742e 6e65 675f 6269 7420 3d20 5472 7565  t.neg_bit = True
-00020e70: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00020e80: 6f75 7470 7574 0a0a 2020 2020 6465 6620  output..    def 
-00020e90: 6c64 6578 7028 7365 6c66 2c20 6f74 6865  ldexp(self, othe
-00020ea0: 7229 3a0a 2020 2020 2020 2020 696e 7075  r):.        inpu
-00020eb0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00020ec0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00020ed0: 2020 2020 2020 206f 7468 6572 5f6d 7320         other_ms 
-00020ee0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00020ef0: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
-00020f00: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
-00020f10: 7073 2e6c 6465 7870 2869 6e70 7574 5f6d  ps.ldexp(input_m
-00020f20: 732c 206f 7468 6572 5f6d 7329 0a20 2020  s, other_ms).   
-00020f30: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-00020f40: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00020f50: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-00020f60: 6465 6620 6c64 6578 705f 2873 656c 662c  def ldexp_(self,
-00020f70: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
-00020f80: 206f 7574 7075 7420 3d20 7365 6c66 2e6c   output = self.l
-00020f90: 6465 7870 286f 7468 6572 290a 2020 2020  dexp(other).    
-00020fa0: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
-00020fb0: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
-00020fc0: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
-00020fd0: 226c 6465 7870 5f22 2c20 226c 6465 7870  "ldexp_", "ldexp
-00020fe0: 2229 0a0a 2020 2020 6465 6620 6372 6f73  ")..    def cros
-00020ff0: 7328 7365 6c66 2c20 6f74 6865 722c 2064  s(self, other, d
-00021000: 696d 3d4e 6f6e 6529 3a0a 2020 2020 2020  im=None):.      
-00021010: 2020 2354 4f44 4f3a 2077 6865 6e20 6469    #TODO: when di
-00021020: 6d3d 4e6f 6e65 2c20 6f70 732e 6469 6d20  m=None, ops.dim 
-00021030: 6f6e 2041 7363 656e 6420 6861 7320 6275  on Ascend has bu
-00021040: 6720 746f 2062 6520 6669 782e 0a20 2020  g to be fix..   
-00021050: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00021060: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00021070: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00021080: 6f74 6865 7220 3d20 6361 7374 5f74 6f5f  other = cast_to_
-00021090: 6d73 5f74 656e 736f 7228 6f74 6865 7229  ms_tensor(other)
-000210a0: 0a20 2020 2020 2020 2023 2054 4f44 4f3a  .        # TODO:
-000210b0: 2061 6674 6572 206d 732e 6f70 732e 6372   after ms.ops.cr
-000210c0: 6f73 7320 7375 7070 6f72 7420 4750 552c  oss support GPU,
-000210d0: 2072 656d 6f76 6520 636f 6465 2062 656c   remove code bel
-000210e0: 6f77 0a20 2020 2020 2020 2069 6620 6973  ow.        if is
-000210f0: 5f75 6e64 6572 5f67 7075 5f63 6f6e 7465  _under_gpu_conte
-00021100: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
-00021110: 2020 6966 2064 696d 2069 7320 4e6f 6e65    if dim is None
-00021120: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
-00021130: 2020 6469 6d20 3d20 2d36 3535 3330 0a20    dim = -65530. 
-00021140: 2020 2020 2020 2020 2020 205f 6f70 203d             _op =
-00021150: 205f 6765 745f 6361 6368 655f 7072 696d   _get_cache_prim
-00021160: 286d 732e 6f70 732e 4372 6f73 7329 2864  (ms.ops.Cross)(d
-00021170: 696d 3d64 696d 290a 2020 2020 2020 2020  im=dim).        
-00021180: 2020 2020 5f6f 702e 7365 745f 6465 7669      _op.set_devi
-00021190: 6365 2822 4350 5522 290a 2020 2020 2020  ce("CPU").      
-000211a0: 2020 2020 2020 6f75 7470 7574 203d 205f        output = _
-000211b0: 6f70 2869 6e70 7574 5f6d 732c 206f 7468  op(input_ms, oth
-000211c0: 6572 290a 2020 2020 2020 2020 656c 7365  er).        else
-000211d0: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
-000211e0: 7470 7574 203d 206d 732e 6f70 732e 6372  tput = ms.ops.cr
-000211f0: 6f73 7328 696e 7075 745f 6d73 2c20 6f74  oss(input_ms, ot
-00021200: 6865 722c 2064 696d 290a 2020 2020 2020  her, dim).      
-00021210: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00021220: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00021230: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00021240: 2066 696c 6c5f 6469 6167 6f6e 616c 5f28   fill_diagonal_(
-00021250: 7365 6c66 2c20 6669 6c6c 5f76 616c 7565  self, fill_value
-00021260: 2c20 7772 6170 3d46 616c 7365 293a 0a20  , wrap=False):. 
-00021270: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00021280: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00021290: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-000212a0: 2020 2320 6d73 2e6f 7073 2e46 696c 6c44    # ms.ops.FillD
-000212b0: 6961 676f 6e61 6c20 6e65 6564 2060 6669  iagonal need `fi
-000212c0: 6c6c 5f76 616c 7565 6020 746f 2062 6520  ll_value` to be 
-000212d0: 666c 6f61 7420 7479 7065 0a20 2020 2020  float type.     
-000212e0: 2020 205f 6f70 203d 205f 6765 745f 6361     _op = _get_ca
-000212f0: 6368 655f 7072 696d 286d 732e 6f70 732e  che_prim(ms.ops.
-00021300: 4669 6c6c 4469 6167 6f6e 616c 2928 666c  FillDiagonal)(fl
-00021310: 6f61 7428 6669 6c6c 5f76 616c 7565 292c  oat(fill_value),
-00021320: 2077 7261 7029 0a20 2020 2020 2020 2023   wrap).        #
-00021330: 206d 732e 6f70 732e 4669 6c6c 4469 6167   ms.ops.FillDiag
-00021340: 6f6e 616c 2069 7320 6e6f 7420 6120 696e  onal is not a in
-00021350: 2d70 6c61 6365 206f 700a 2020 2020 2020  -place op.      
-00021360: 2020 6f75 7470 7574 203d 205f 6f70 2869    output = _op(i
-00021370: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-00021380: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
-00021390: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
-000213a0: 656c 662c 206f 7574 7075 742c 2022 6669  elf, output, "fi
-000213b0: 6c6c 5f64 6961 676f 6e61 6c5f 222c 2022  ll_diagonal_", "
-000213c0: 6669 6c6c 5f64 6961 676f 6e61 6c22 290a  fill_diagonal").
-000213d0: 0a20 2020 2064 6566 206d 7628 7365 6c66  .    def mv(self
-000213e0: 2c20 7665 6329 3a0a 2020 2020 2020 2020  , vec):.        
-000213f0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00021400: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00021410: 6629 0a20 2020 2020 2020 2076 6563 5f6d  f).        vec_m
-00021420: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
-00021430: 656e 736f 7228 7665 6329 0a20 2020 2020  ensor(vec).     
-00021440: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
-00021450: 7073 2e6d 7628 696e 7075 745f 6d73 2c20  ps.mv(input_ms, 
-00021460: 7665 635f 6d73 290a 2020 2020 2020 2020  vec_ms).        
-00021470: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00021480: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00021490: 7470 7574 290a 0a20 2020 2064 6566 2068  tput)..    def h
-000214a0: 6973 7463 2873 656c 662c 2062 696e 733d  istc(self, bins=
-000214b0: 3130 302c 206d 696e 3d30 2c20 6d61 783d  100, min=0, max=
-000214c0: 3029 3a0a 2020 2020 2020 2020 696e 7075  0):.        inpu
-000214d0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-000214e0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-000214f0: 2020 2020 2020 2069 6e70 7574 5f64 7479         input_dty
-00021500: 7065 203d 2069 6e70 7574 5f6d 732e 6474  pe = input_ms.dt
-00021510: 7970 650a 2020 2020 2020 2020 2354 4f44  ype.        #TOD
-00021520: 4f3a 2063 7572 7265 6e74 6c79 206e 6f74  O: currently not
-00021530: 2073 7570 706f 7274 2068 6973 7463 206f   support histc o
-00021540: 6e20 4750 550a 2020 2020 2020 2020 6966  n GPU.        if
-00021550: 2069 735f 756e 6465 725f 6770 755f 636f   is_under_gpu_co
-00021560: 6e74 6578 7428 293a 0a20 2020 2020 2020  ntext():.       
-00021570: 2020 2020 2069 6620 6d61 7820 3d3d 206d       if max == m
-00021580: 696e 3a0a 2020 2020 2020 2020 2020 2020  in:.            
-00021590: 2020 2020 6d61 782c 205f 203d 206d 732e      max, _ = ms.
-000215a0: 6f70 732e 6d61 7828 696e 7075 745f 6d73  ops.max(input_ms
-000215b0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
-000215c0: 2020 6d69 6e2c 205f 203d 206d 732e 6f70    min, _ = ms.op
-000215d0: 732e 6d69 6e28 696e 7075 745f 6d73 290a  s.min(input_ms).
-000215e0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-000215f0: 7574 2c20 5f20 3d20 6d73 2e6e 756d 7079  ut, _ = ms.numpy
-00021600: 2e68 6973 746f 6772 616d 2869 6e70 7574  .histogram(input
-00021610: 5f6d 732c 2062 696e 732c 2028 6d69 6e2c  _ms, bins, (min,
-00021620: 206d 6178 2929 0a20 2020 2020 2020 2065   max)).        e
-00021630: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
-00021640: 2069 6620 696e 7075 745f 6474 7970 6520   if input_dtype 
-00021650: 6e6f 7420 696e 2028 6d73 2e66 6c6f 6174  not in (ms.float
-00021660: 3136 2c20 6d73 2e66 6c6f 6174 3332 2c20  16, ms.float32, 
-00021670: 6d73 2e69 6e74 3332 293a 0a20 2020 2020  ms.int32):.     
-00021680: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00021690: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
-000216a0: 7374 7970 6528 6d73 2e66 6c6f 6174 3332  stype(ms.float32
-000216b0: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
-000216c0: 7470 7574 203d 206d 732e 6f70 732e 6869  tput = ms.ops.hi
-000216d0: 7374 6328 696e 7075 745f 6d73 2c20 6269  stc(input_ms, bi
-000216e0: 6e73 2c20 6d69 6e2c 206d 6178 290a 2020  ns, min, max).  
-000216f0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00021700: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00021710: 736f 7228 6f75 7470 7574 2e61 7374 7970  sor(output.astyp
-00021720: 6528 696e 7075 745f 6474 7970 6529 290a  e(input_dtype)).
-00021730: 0a20 2020 2064 6566 2068 6973 746f 6772  .    def histogr
-00021740: 616d 2873 656c 662c 2062 696e 732c 202a  am(self, bins, *
-00021750: 2c20 7261 6e67 653d 4e6f 6e65 2c20 7765  , range=None, we
-00021760: 6967 6874 3d4e 6f6e 652c 2064 656e 7369  ight=None, densi
-00021770: 7479 3d46 616c 7365 293a 0a20 2020 2020  ty=False):.     
-00021780: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
-00021790: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-000217a0: 7365 6c66 290a 2020 2020 2020 2020 5f62  self).        _b
-000217b0: 696e 7320 3d20 6361 7374 5f74 6f5f 6d73  ins = cast_to_ms
-000217c0: 5f74 656e 736f 7228 6269 6e73 290a 2020  _tensor(bins).  
-000217d0: 2020 2020 2020 6966 2077 6569 6768 7420        if weight 
-000217e0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-000217f0: 2020 2020 2020 2020 2077 6569 6768 7420           weight 
-00021800: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00021810: 736f 7228 7765 6967 6874 290a 2020 2020  sor(weight).    
-00021820: 2020 2020 2320 544f 444f 3a20 6d73 2e6f      # TODO: ms.o
-00021830: 7073 2e68 6973 746f 6772 616d 2069 7320  ps.histogram is 
-00021840: 6e6f 7420 7375 7070 6f72 7420 6e6f 772e  not support now.
-00021850: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-00021860: 3d20 6d73 2e6e 756d 7079 2e68 6973 746f  = ms.numpy.histo
-00021870: 6772 616d 2869 6e70 7574 5f6d 732c 205f  gram(input_ms, _
-00021880: 6269 6e73 2c20 7261 6e67 652c 2077 6569  bins, range, wei
-00021890: 6768 742c 2064 656e 7369 7479 290a 2020  ght, density).  
-000218a0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-000218b0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-000218c0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-000218d0: 2064 6566 2067 6571 7266 2873 656c 6629   def geqrf(self)
-000218e0: 3a0a 2020 2020 2020 2020 2320 544f 444f  :.        # TODO
-000218f0: 3a20 4f6e 2041 7363 656e 642c 206d 732e  : On Ascend, ms.
-00021900: 6f70 732e 6765 7172 6620 646f 206e 6f74  ops.geqrf do not
-00021910: 2073 7570 706f 7274 2069 6e70 7574 2e6e   support input.n
-00021920: 6469 6d20 3e20 322e 0a20 2020 2020 2020  dim > 2..       
-00021930: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00021940: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00021950: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
-00021960: 7574 203d 206d 732e 6f70 732e 6765 7172  ut = ms.ops.geqr
-00021970: 6628 696e 7075 745f 6d73 290a 2020 2020  f(input_ms).    
-00021980: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00021990: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-000219a0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-000219b0: 6566 206c 6f67 6164 6465 7870 3228 7365  ef logaddexp2(se
-000219c0: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
-000219d0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-000219e0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-000219f0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-00021a00: 7468 6572 203d 2063 6173 745f 746f 5f6d  ther = cast_to_m
-00021a10: 735f 7465 6e73 6f72 286f 7468 6572 290a  s_tensor(other).
-00021a20: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00021a30: 206d 732e 6f70 732e 6c6f 6761 6464 6578   ms.ops.logaddex
-00021a40: 7032 2869 6e70 7574 5f6d 732c 206f 7468  p2(input_ms, oth
-00021a50: 6572 290a 2020 2020 2020 2020 7265 7475  er).        retu
-00021a60: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00021a70: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00021a80: 290a 0a20 2020 2064 6566 2066 6c6f 6f72  )..    def floor
-00021a90: 5f64 6976 6964 6528 7365 6c66 2c20 7661  _divide(self, va
-00021aa0: 6c75 6529 3a0a 2020 2020 2020 2020 2320  lue):.        # 
-00021ab0: 6d73 2e6f 7073 2e66 6c6f 6f72 5f64 6976  ms.ops.floor_div
-00021ac0: 6964 6520 646f 6573 6e27 7420 726f 756e  ide doesn't roun
-00021ad0: 6420 7468 6520 7175 6f74 6965 6e74 2074  d the quotient t
-00021ae0: 6f77 6172 6473 2030 0a20 2020 2020 2020  owards 0.       
-00021af0: 2023 2073 616d 6520 6265 6861 7669 6f72   # same behavior
-00021b00: 2061 7320 746f 7263 6820 7665 7273 696f   as torch versio
-00021b10: 6e20 6c6f 7765 7220 7468 616e 2031 2e31  n lower than 1.1
-00021b20: 330a 2020 2020 2020 2020 696e 7075 745f  3.        input_
-00021b30: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00021b40: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-00021b50: 2020 2020 2076 616c 7565 203d 2063 6173       value = cas
-00021b60: 745f 746f 5f6d 735f 7465 6e73 6f72 2876  t_to_ms_tensor(v
-00021b70: 616c 7565 290a 2020 2020 2020 2020 6f75  alue).        ou
-00021b80: 7470 7574 203d 206d 732e 6f70 732e 6469  tput = ms.ops.di
-00021b90: 7628 696e 7075 745f 6d73 2c20 7661 6c75  v(input_ms, valu
-00021ba0: 652c 2072 6f75 6e64 696e 675f 6d6f 6465  e, rounding_mode
-00021bb0: 3d27 7472 756e 6327 290a 2020 2020 2020  ='trunc').      
-00021bc0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00021bd0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00021be0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00021bf0: 2066 6c6f 6f72 5f64 6976 6964 655f 2873   floor_divide_(s
-00021c00: 656c 662c 2076 616c 7565 293a 0a20 2020  elf, value):.   
-00021c10: 2020 2020 206f 7574 7075 7420 3d20 7365       output = se
-00021c20: 6c66 2e66 6c6f 6f72 5f64 6976 6964 6528  lf.floor_divide(
-00021c30: 7661 6c75 6529 0a20 2020 2020 2020 2072  value).        r
-00021c40: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
-00021c50: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
-00021c60: 662c 206f 7574 7075 742c 2022 666c 6f6f  f, output, "floo
-00021c70: 725f 6469 7669 6465 5f22 2c20 2266 6c6f  r_divide_", "flo
-00021c80: 6f72 5f64 6976 6964 6522 290a 0a20 2020  or_divide")..   
-00021c90: 2064 6566 2072 656e 6f72 6d28 7365 6c66   def renorm(self
-00021ca0: 2c20 702c 2064 696d 2c20 6d61 786e 6f72  , p, dim, maxnor
-00021cb0: 6d29 3a0a 2020 2020 2020 2020 696e 7075  m):.        inpu
-00021cc0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00021cd0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00021ce0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00021cf0: 6d73 2e6f 7073 2e72 656e 6f72 6d28 696e  ms.ops.renorm(in
-00021d00: 7075 745f 6d73 2c20 696e 7428 7029 2c20  put_ms, int(p), 
-00021d10: 6469 6d2c 2066 6c6f 6174 286d 6178 6e6f  dim, float(maxno
-00021d20: 726d 2929 0a20 2020 2020 2020 2072 6574  rm)).        ret
-00021d30: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-00021d40: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-00021d50: 7429 0a0a 2020 2020 6465 6620 7265 6e6f  t)..    def reno
-00021d60: 726d 5f28 7365 6c66 2c20 702c 2064 696d  rm_(self, p, dim
-00021d70: 2c20 6d61 786e 6f72 6d29 3a0a 2020 2020  , maxnorm):.    
-00021d80: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
-00021d90: 662e 7265 6e6f 726d 2870 2c20 6469 6d2c  f.renorm(p, dim,
-00021da0: 206d 6178 6e6f 726d 290a 2020 2020 2020   maxnorm).      
-00021db0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
-00021dc0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
-00021dd0: 7365 6c66 2c20 6f75 7470 7574 2c20 2272  self, output, "r
-00021de0: 656e 6f72 6d5f 222c 2022 7265 6e6f 726d  enorm_", "renorm
-00021df0: 2229 0a0a 2020 2020 6465 6620 6d76 6c67  ")..    def mvlg
-00021e00: 616d 6d61 2873 656c 662c 2070 293a 0a20  amma(self, p):. 
-00021e10: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00021e20: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00021e30: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00021e40: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-00021e50: 732e 6d76 6c67 616d 6d61 2869 6e70 7574  s.mvlgamma(input
-00021e60: 5f6d 732c 2070 290a 2020 2020 2020 2020  _ms, p).        
-00021e70: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00021e80: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00021e90: 7470 7574 290a 0a20 2020 2064 6566 206d  tput)..    def m
-00021ea0: 766c 6761 6d6d 615f 2873 656c 662c 2070  vlgamma_(self, p
-00021eb0: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
-00021ec0: 7420 3d20 7365 6c66 2e6d 766c 6761 6d6d  t = self.mvlgamm
-00021ed0: 6128 7029 0a20 2020 2020 2020 2072 6574  a(p).        ret
-00021ee0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-00021ef0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-00021f00: 206f 7574 7075 742c 2022 6d76 6c67 616d   output, "mvlgam
-00021f10: 6d61 5f22 2c20 226d 766c 6761 6d6d 6122  ma_", "mvlgamma"
-00021f20: 290a 0a20 2020 2064 6566 206f 7267 7172  )..    def orgqr
-00021f30: 2873 656c 662c 2069 6e70 7574 3229 3a0a  (self, input2):.
-00021f40: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00021f50: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00021f60: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00021f70: 2020 2069 6e70 7574 3220 3d20 6361 7374     input2 = cast
-00021f80: 5f74 6f5f 6d73 5f74 656e 736f 7228 696e  _to_ms_tensor(in
-00021f90: 7075 7432 290a 2020 2020 2020 2020 6f75  put2).        ou
-00021fa0: 7470 7574 203d 206d 732e 6f70 732e 6f72  tput = ms.ops.or
-00021fb0: 6771 7228 696e 7075 745f 6d73 2c20 696e  gqr(input_ms, in
-00021fc0: 7075 7432 290a 2020 2020 2020 2020 7265  put2).        re
-00021fd0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00021fe0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-00021ff0: 7574 290a 0a20 2020 2064 6566 2071 7228  ut)..    def qr(
-00022000: 7365 6c66 2c20 736f 6d65 3d54 7275 6529  self, some=True)
-00022010: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
-00022020: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00022030: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
-00022040: 2020 2020 2069 6620 736f 6d65 3a0a 2020       if some:.  
-00022050: 2020 2020 2020 2020 2020 6d6f 6465 203d            mode =
-00022060: 2022 7265 6475 6365 6422 0a20 2020 2020   "reduced".     
-00022070: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
-00022080: 2020 2020 206d 6f64 6520 3d20 2263 6f6d       mode = "com
-00022090: 706c 6574 6522 0a20 2020 2020 2020 206f  plete".        o
-000220a0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e71  utput = ms.ops.q
-000220b0: 7228 696e 7075 745f 6d73 2c20 6d6f 6465  r(input_ms, mode
-000220c0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-000220d0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-000220e0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-000220f0: 0a20 2020 2064 6566 2069 3028 7365 6c66  .    def i0(self
-00022100: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
-00022110: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00022120: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00022130: 2020 2020 2020 2320 544f 444f efbc 9a6d        # TODO...m
-00022140: 732e 6f70 732e 6265 7373 656c 5f69 3020  s.ops.bessel_i0 
-00022150: 746f 2073 7570 706f 7274 206f 6e20 4173  to support on As
-00022160: 6365 6e64 0a20 2020 2020 2020 2069 6620  cend.        if 
-00022170: 6973 5f75 6e64 6572 5f61 7363 656e 645f  is_under_ascend_
-00022180: 636f 6e74 6578 7428 293a 0a20 2020 2020  context():.     
-00022190: 2020 2020 2020 2069 305f 6f70 203d 206e         i0_op = n
-000221a0: 756d 7079 5f63 656c 6c2e 4e75 6d70 7949  umpy_cell.NumpyI
-000221b0: 3028 2769 3027 290a 2020 2020 2020 2020  0('i0').        
-000221c0: 2020 2020 6f75 7470 7574 203d 2069 305f      output = i0_
-000221d0: 6f70 2869 6e70 7574 5f6d 7329 0a20 2020  op(input_ms).   
-000221e0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-000221f0: 2020 2020 2020 2069 6620 696e 7075 745f         if input_
-00022200: 6d73 2e64 7479 7065 2069 6e20 6d73 6461  ms.dtype in msda
-00022210: 7074 6572 5f64 7479 7065 2e61 6c6c 5f69  pter_dtype.all_i
-00022220: 6e74 5f74 7970 653a 0a20 2020 2020 2020  nt_type:.       
-00022230: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
-00022240: 7320 3d20 696e 7075 745f 6d73 2e61 7374  s = input_ms.ast
-00022250: 7970 6528 6d73 2e66 6c6f 6174 3332 290a  ype(ms.float32).
-00022260: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00022270: 7574 203d 206d 732e 6f70 732e 6265 7373  ut = ms.ops.bess
-00022280: 656c 5f69 3028 696e 7075 745f 6d73 290a  el_i0(input_ms).
-00022290: 2020 2020 2020 2020 7265 7475 726e 2063          return c
-000222a0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
-000222b0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
-000222c0: 2020 2064 6566 2069 305f 2873 656c 6629     def i0_(self)
-000222d0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-000222e0: 203d 2073 656c 662e 6930 2829 0a20 2020   = self.i0().   
-000222f0: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
-00022300: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
-00022310: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
-00022320: 2022 6930 5f22 2c20 2269 3022 290a 0a20   "i0_", "i0").. 
-00022330: 2020 2064 6566 206e 6578 7461 6674 6572     def nextafter
-00022340: 2873 656c 662c 206f 7468 6572 293a 0a20  (self, other):. 
-00022350: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00022360: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00022370: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00022380: 2020 6f74 6865 7220 3d20 6361 7374 5f74    other = cast_t
-00022390: 6f5f 6d73 5f74 656e 736f 7228 6f74 6865  o_ms_tensor(othe
-000223a0: 7229 0a20 2020 2020 2020 206f 7574 7075  r).        outpu
-000223b0: 7420 3d20 6d73 2e6f 7073 2e6e 6578 7461  t = ms.ops.nexta
-000223c0: 6674 6572 2869 6e70 7574 5f6d 732c 206f  fter(input_ms, o
-000223d0: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
-000223e0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-000223f0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-00022400: 7574 290a 0a20 2020 2064 6566 206e 6578  ut)..    def nex
-00022410: 7461 6674 6572 5f28 7365 6c66 2c20 6f74  tafter_(self, ot
-00022420: 6865 7229 3a0a 2020 2020 2020 2020 6f75  her):.        ou
-00022430: 7470 7574 203d 2073 656c 662e 6e65 7874  tput = self.next
-00022440: 6166 7465 7228 6f74 6865 7229 0a20 2020  after(other).   
-00022450: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
-00022460: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
-00022470: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
-00022480: 2022 6e65 7874 6166 7465 725f 222c 2022   "nextafter_", "
-00022490: 6e65 7874 6166 7465 7222 290a 0a20 2020  nextafter")..   
-000224a0: 2064 6566 206c 6f67 6974 2873 656c 662c   def logit(self,
-000224b0: 2065 7073 3d4e 6f6e 6529 3a0a 2020 2020   eps=None):.    
-000224c0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
-000224d0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
-000224e0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
-000224f0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6c  utput = ms.ops.l
-00022500: 6f67 6974 2869 6e70 7574 5f6d 732c 2065  ogit(input_ms, e
-00022510: 7073 290a 2020 2020 2020 2020 7265 7475  ps).        retu
-00022520: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00022530: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00022540: 290a 0a20 2020 2064 6566 206c 6f67 6974  )..    def logit
-00022550: 5f28 7365 6c66 2c20 6570 733d 4e6f 6e65  _(self, eps=None
-00022560: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
-00022570: 7420 3d20 7365 6c66 2e6c 6f67 6974 2865  t = self.logit(e
-00022580: 7073 3d65 7073 290a 2020 2020 2020 2020  ps=eps).        
-00022590: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-000225a0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-000225b0: 6c66 2c20 6f75 7470 7574 2c20 226c 6f67  lf, output, "log
-000225c0: 6974 5f22 2c20 226c 6f67 6974 2229 0a0a  it_", "logit")..
-000225d0: 2020 2020 6465 6620 6d61 7472 6978 5f70      def matrix_p
-000225e0: 6f77 6572 2873 656c 662c 206e 293a 0a20  ower(self, n):. 
-000225f0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00022600: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00022610: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00022620: 2020 696e 7075 745f 7479 7065 203d 2069    input_type = i
-00022630: 6e70 7574 5f6d 732e 6474 7970 650a 2020  nput_ms.dtype.  
-00022640: 2020 2020 2020 6966 2069 6e70 7574 5f74        if input_t
-00022650: 7970 6520 6e6f 7420 696e 2028 6d73 2e66  ype not in (ms.f
-00022660: 6c6f 6174 3332 2c20 6d73 2e66 6c6f 6174  loat32, ms.float
-00022670: 3136 293a 0a20 2020 2020 2020 2020 2020  16):.           
-00022680: 2069 6e70 7574 5f6d 7320 3d20 696e 7075   input_ms = inpu
-00022690: 745f 6d73 2e61 7374 7970 6528 6d73 2e66  t_ms.astype(ms.f
-000226a0: 6c6f 6174 3332 290a 2020 2020 2020 2020  loat32).        
-000226b0: 6966 206e 6f74 2069 735f 756e 6465 725f  if not is_under_
-000226c0: 6770 755f 636f 6e74 6578 7428 293a 0a20  gpu_context():. 
-000226d0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
-000226e0: 7420 3d20 6d73 2e6f 7073 2e6d 6174 7269  t = ms.ops.matri
-000226f0: 785f 706f 7765 7228 696e 7075 745f 6d73  x_power(input_ms
-00022700: 2c20 6e29 0a20 2020 2020 2020 2065 6c73  , n).        els
-00022710: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
-00022720: 544f 444f 3a20 7573 6564 206f 7073 2066  TODO: used ops f
-00022730: 756e 6320 6f6e 2047 5055 0a20 2020 2020  unc on GPU.     
-00022740: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00022750: 6d73 2e6e 756d 7079 2e6d 6174 7269 785f  ms.numpy.matrix_
-00022760: 706f 7765 7228 696e 7075 745f 6d73 2c20  power(input_ms, 
-00022770: 6e29 0a20 2020 2020 2020 2069 6620 696e  n).        if in
-00022780: 7075 745f 7479 7065 206e 6f74 2069 6e20  put_type not in 
-00022790: 286d 732e 666c 6f61 7433 322c 206d 732e  (ms.float32, ms.
-000227a0: 666c 6f61 7431 3629 3a0a 2020 2020 2020  float16):.      
-000227b0: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
-000227c0: 7574 7075 742e 6173 7479 7065 2869 6e70  utput.astype(inp
-000227d0: 7574 5f74 7970 6529 0a20 2020 2020 2020  ut_type).       
-000227e0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-000227f0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00022800: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-00022810: 696e 6465 785f 6164 6428 7365 6c66 2c20  index_add(self, 
-00022820: 6469 6d2c 2069 6e64 6578 2c20 736f 7572  dim, index, sour
-00022830: 6365 2c20 2a2c 2061 6c70 6861 3d31 293a  ce, *, alpha=1):
-00022840: 0a20 2020 2020 2020 2023 2054 4f44 4f3a  .        # TODO:
-00022850: 2074 6f20 7375 7070 6f72 7420 696e 7075   to support inpu
-00022860: 7420 6f66 206d 6f72 6520 7468 616e 2032  t of more than 2
-00022870: 2d44 2026 2064 696d 203e 3d20 312c 2074  -D & dim >= 1, t
-00022880: 6f20 7375 7070 6f72 7420 4752 4150 4820  o support GRAPH 
-00022890: 6d6f 6465 0a20 2020 2020 2020 2069 6620  mode.        if 
-000228a0: 7365 6c66 2e64 7479 7065 2021 3d20 736f  self.dtype != so
-000228b0: 7572 6365 2e64 7479 7065 3a0a 2020 2020  urce.dtype:.    
-000228c0: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
-000228d0: 6e74 696d 6545 7272 6f72 2866 2269 6e64  ntimeError(f"ind
-000228e0: 6578 5f61 6464 2829 3a20 7365 6c66 2028  ex_add(): self (
-000228f0: 7b73 656c 662e 6474 7970 657d 2920 616e  {self.dtype}) an
-00022900: 6420 736f 7572 6365 2028 7b73 6f75 7263  d source ({sourc
-00022910: 652e 6474 7970 657d 2920 220a 2020 2020  e.dtype}) ".    
-00022920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022930: 2020 2020 2020 2020 2020 2066 226d 7573             f"mus
-00022940: 7420 6861 7665 2074 6865 2073 616d 6520  t have the same 
-00022950: 7363 616c 6172 2074 7970 6522 290a 2020  scalar type").  
-00022960: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00022970: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
-00022980: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
-00022990: 2073 6f75 7263 6520 3d20 6361 7374 5f74   source = cast_t
-000229a0: 6f5f 6d73 5f74 656e 736f 7228 736f 7572  o_ms_tensor(sour
-000229b0: 6365 290a 2020 2020 2020 2020 696e 6465  ce).        inde
-000229c0: 7820 3d20 6361 7374 5f74 6f5f 6d73 5f74  x = cast_to_ms_t
-000229d0: 656e 736f 7228 696e 6465 7829 2e61 7374  ensor(index).ast
-000229e0: 7970 6528 6d73 7479 7065 2e69 6e74 3332  ype(mstype.int32
-000229f0: 290a 2020 2020 2020 2020 2320 6d73 2e54  ).        # ms.T
-00022a00: 656e 736f 722e 696e 6465 785f 6164 6420  ensor.index_add 
-00022a10: 6973 2061 6e20 696e 2d70 6c61 6365 206f  is an in-place o
-00022a20: 7065 7261 7469 6f6e 2c20 736f 2077 6520  peration, so we 
-00022a30: 6e65 6564 2074 6f20 6465 6570 636f 7079  need to deepcopy
-00022a40: 2069 6e70 7574 2066 6972 7374 0a20 2020   input first.   
-00022a50: 2020 2020 2069 6e70 7574 5f63 6f70 7920       input_copy 
-00022a60: 3d20 6d73 2e6f 7073 2e64 6565 7063 6f70  = ms.ops.deepcop
-00022a70: 7928 696e 7075 745f 6d73 290a 2020 2020  y(input_ms).    
-00022a80: 2020 2020 736f 7572 6365 203d 2073 6f75      source = sou
-00022a90: 7263 6520 2a20 616c 7068 610a 2020 2020  rce * alpha.    
-00022aa0: 2020 2020 6966 2069 6e70 7574 5f63 6f70      if input_cop
-00022ab0: 792e 6474 7970 6520 3d3d 206d 7374 7970  y.dtype == mstyp
-00022ac0: 652e 696e 7436 343a 0a20 2020 2020 2020  e.int64:.       
-00022ad0: 2020 2020 2023 206d 732e 6f70 732e 696e       # ms.ops.in
-00022ae0: 6465 785f 6164 6420 7461 6b65 7320 6f6e  dex_add takes on
-00022af0: 6c79 2050 6172 616d 6574 6572 2069 6e70  ly Parameter inp
-00022b00: 7574 2c20 736f 2077 6520 7573 6520 6d73  ut, so we use ms
-00022b10: 2e54 656e 736f 722e 696e 6465 785f 6164  .Tensor.index_ad
-00022b20: 6420 6865 7265 0a20 2020 2020 2020 2020  d here.         
-00022b30: 2020 206f 7574 7075 7420 3d20 696e 7075     output = inpu
-00022b40: 745f 636f 7079 2e69 6e74 2829 2e69 6e64  t_copy.int().ind
-00022b50: 6578 5f61 6464 2864 696d 2c20 696e 6465  ex_add(dim, inde
-00022b60: 782c 2073 6f75 7263 652e 696e 7428 2929  x, source.int())
-00022b70: 2e61 7374 7970 6528 6d73 7479 7065 2e69  .astype(mstype.i
-00022b80: 6e74 3634 290a 2020 2020 2020 2020 656c  nt64).        el
-00022b90: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00022ba0: 6f75 7470 7574 203d 2069 6e70 7574 5f63  output = input_c
-00022bb0: 6f70 792e 696e 6465 785f 6164 6428 6469  opy.index_add(di
-00022bc0: 6d2c 2069 6e64 6578 2c20 736f 7572 6365  m, index, source
-00022bd0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00022be0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-00022bf0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-00022c00: 0a0a 2020 2020 6465 6620 696e 6465 785f  ..    def index_
-00022c10: 6164 645f 2873 656c 662c 2064 696d 2c20  add_(self, dim, 
-00022c20: 696e 6465 782c 2073 6f75 7263 652c 202a  index, source, *
-00022c30: 2c20 616c 7068 613d 3129 3a0a 2020 2020  , alpha=1):.    
-00022c40: 2020 2020 2320 544f 444f 3a20 746f 2073      # TODO: to s
-00022c50: 7570 706f 7274 2069 6e70 7574 206f 6620  upport input of 
-00022c60: 6d6f 7265 2074 6861 6e20 322d 4420 2620  more than 2-D & 
-00022c70: 6469 6d20 3e3d 2031 2c20 746f 2073 7570  dim >= 1, to sup
-00022c80: 706f 7274 2047 5241 5048 206d 6f64 650a  port GRAPH mode.
-00022c90: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00022ca0: 2073 656c 662e 696e 6465 785f 6164 6428   self.index_add(
-00022cb0: 6469 6d2c 2069 6e64 6578 2c20 736f 7572  dim, index, sour
-00022cc0: 6365 2c20 616c 7068 613d 616c 7068 6129  ce, alpha=alpha)
-00022cd0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00022ce0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
-00022cf0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
-00022d00: 7075 742c 2022 696e 6465 785f 6164 645f  put, "index_add_
-00022d10: 222c 2022 696e 6465 785f 6164 6422 290a  ", "index_add").
-00022d20: 0a20 2020 2064 6566 2073 6361 7474 6572  .    def scatter
-00022d30: 5f61 6464 2873 656c 662c 2064 696d 2c20  _add(self, dim, 
-00022d40: 696e 6465 782c 2073 7263 293a 0a20 2020  index, src):.   
-00022d50: 2020 2020 2023 2054 4f44 4f3a 2073 7570       # TODO: sup
-00022d60: 706f 7274 2073 7263 2061 6e64 2069 6e64  port src and ind
-00022d70: 6578 206f 6620 6469 6666 6572 656e 7420  ex of different 
-00022d80: 7368 6170 650a 2020 2020 2020 2020 2320  shape.        # 
-00022d90: 6d73 2e6f 7073 2e73 6361 7474 6572 5f61  ms.ops.scatter_a
-00022da0: 6464 2068 6173 206d 6f72 6520 7265 7374  dd has more rest
-00022db0: 7269 6374 696f 6e73 206f 6e20 7468 6520  rictions on the 
-00022dc0: 7368 6170 6520 6f66 2069 6e70 7574 730a  shape of inputs.
-00022dd0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00022de0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00022df0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00022e00: 2020 2069 6e64 6578 203d 2063 6173 745f     index = cast_
-00022e10: 746f 5f6d 735f 7465 6e73 6f72 2869 6e64  to_ms_tensor(ind
-00022e20: 6578 290a 2020 2020 2020 2020 7372 6320  ex).        src 
-00022e30: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00022e40: 736f 7228 7372 6329 0a20 2020 2020 2020  sor(src).       
-00022e50: 2023 2054 4f44 4f3a 2061 7363 656e 6420   # TODO: ascend 
-00022e60: 646f 6573 206e 6f74 2073 7570 706f 7274  does not support
-00022e70: 2074 656e 736f 725f 7363 6174 7465 725f   tensor_scatter_
-00022e80: 656c 656d 656e 7473 0a20 2020 2020 2020  elements.       
-00022e90: 2069 6620 6973 5f75 6e64 6572 5f61 7363   if is_under_asc
-00022ea0: 656e 645f 636f 6e74 6578 7428 293a 0a20  end_context():. 
-00022eb0: 2020 2020 2020 2020 2020 2069 6620 6469             if di
-00022ec0: 6d20 3e20 303a 0a20 2020 2020 2020 2020  m > 0:.         
-00022ed0: 2020 2020 2020 206e 645f 6964 782c 206e         nd_idx, n
-00022ee0: 645f 696e 7075 742c 206e 645f 7372 6320  d_input, nd_src 
-00022ef0: 3d20 7365 6c66 2e5f 6765 745f 7363 6174  = self._get_scat
-00022f00: 7465 725f 6e64 696d 5f69 6e70 7574 2869  ter_ndim_input(i
-00022f10: 6e70 7574 5f6d 732c 2069 6e64 6578 2c20  nput_ms, index, 
-00022f20: 7372 632c 2064 696d 290a 2020 2020 2020  src, dim).      
-00022f30: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-00022f40: 203d 206d 732e 6f70 732e 7363 6174 7465   = ms.ops.scatte
-00022f50: 725f 6e64 5f61 6464 286e 645f 696e 7075  r_nd_add(nd_inpu
-00022f60: 742c 206e 645f 6964 782c 206e 645f 7372  t, nd_idx, nd_sr
-00022f70: 6329 2e73 7175 6565 7a65 282d 3129 0a20  c).squeeze(-1). 
-00022f80: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-00022f90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00022fa0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
-00022fb0: 2e73 6361 7474 6572 5f61 6464 2869 6e70  .scatter_add(inp
-00022fc0: 7574 5f6d 732c 2069 6e64 6578 2c20 7372  ut_ms, index, sr
-00022fd0: 6329 0a20 2020 2020 2020 2065 6c73 653a  c).        else:
-00022fe0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00022ff0: 7075 7420 3d20 6d73 2e6f 7073 2e74 656e  put = ms.ops.ten
-00023000: 736f 725f 7363 6174 7465 725f 656c 656d  sor_scatter_elem
-00023010: 656e 7473 2869 6e70 7574 5f6d 732c 2069  ents(input_ms, i
-00023020: 6e64 6578 2c20 7372 632c 2061 7869 733d  ndex, src, axis=
-00023030: 6469 6d2c 2072 6564 7563 7469 6f6e 3d22  dim, reduction="
-00023040: 6164 6422 290a 2020 2020 2020 2020 7265  add").        re
-00023050: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00023060: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
-00023070: 7574 290a 0a20 2020 2064 6566 2073 6361  ut)..    def sca
-00023080: 7474 6572 5f61 6464 5f28 7365 6c66 2c20  tter_add_(self, 
-00023090: 6469 6d2c 2069 6e64 6578 2c20 7372 6329  dim, index, src)
-000230a0: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
-000230b0: 203d 2073 656c 662e 7363 6174 7465 725f   = self.scatter_
-000230c0: 6164 6428 6469 6d2c 2069 6e64 6578 2c20  add(dim, index, 
-000230d0: 7372 6329 0a20 2020 2020 2020 2072 6574  src).        ret
-000230e0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-000230f0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-00023100: 206f 7574 7075 742c 2022 7363 6174 7465   output, "scatte
-00023110: 725f 6164 645f 222c 2022 7363 6174 7465  r_add_", "scatte
-00023120: 725f 6164 6422 290a 0a20 2020 2064 6566  r_add")..    def
-00023130: 2069 6e64 6578 5f63 6f70 7928 7365 6c66   index_copy(self
-00023140: 2c20 6469 6d2c 2069 6e64 6578 2c20 7465  , dim, index, te
-00023150: 6e73 6f72 3229 3a0a 2020 2020 2020 2020  nsor2):.        
-00023160: 2320 544f 444f 3a20 746f 2073 7570 706f  # TODO: to suppo
-00023170: 7274 2069 6e70 7574 206f 6620 6d6f 7265  rt input of more
-00023180: 2074 6861 6e20 322d 4420 2620 6469 6d20   than 2-D & dim 
-00023190: 3e3d 2031 2c20 746f 2073 7570 706f 7274  >= 1, to support
-000231a0: 2047 5241 5048 206d 6f64 650a 2020 2020   GRAPH mode.    
-000231b0: 2020 2020 2320 544f 444f 3a20 7265 706c      # TODO: repl
-000231c0: 6163 6520 7769 7468 206d 732e 6f70 732e  ace with ms.ops.
-000231d0: 696e 6465 785f 636f 7079 0a20 2020 2020  index_copy.     
-000231e0: 2020 2069 6620 7365 6c66 2e64 7479 7065     if self.dtype
-000231f0: 2021 3d20 7465 6e73 6f72 322e 6474 7970   != tensor2.dtyp
-00023200: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
-00023210: 6169 7365 2052 756e 7469 6d65 4572 726f  aise RuntimeErro
-00023220: 7228 6622 696e 6465 785f 6164 6428 293a  r(f"index_add():
-00023230: 2073 656c 6620 287b 7365 6c66 2e64 7479   self ({self.dty
-00023240: 7065 7d29 2061 6e64 2073 6f75 7263 6520  pe}) and source 
-00023250: 287b 7465 6e73 6f72 322e 6474 7970 657d  ({tensor2.dtype}
-00023260: 2920 220a 2020 2020 2020 2020 2020 2020  ) ".            
-00023270: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023280: 2020 2066 226d 7573 7420 6861 7665 2074     f"must have t
-00023290: 6865 2073 616d 6520 7363 616c 6172 2074  he same scalar t
-000232a0: 7970 6522 290a 2020 2020 2020 2020 696e  ype").        in
-000232b0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-000232c0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-000232d0: 0a20 2020 2020 2020 2073 6f75 7263 6520  .        source 
-000232e0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-000232f0: 736f 7228 7465 6e73 6f72 3229 0a20 2020  sor(tensor2).   
-00023300: 2020 2020 2069 6e64 6578 203d 2063 6173       index = cas
-00023310: 745f 746f 5f6d 735f 7465 6e73 6f72 2869  t_to_ms_tensor(i
-00023320: 6e64 6578 292e 6173 7479 7065 286d 7374  ndex).astype(mst
-00023330: 7970 652e 696e 7433 3229 0a0a 2020 2020  ype.int32)..    
-00023340: 2020 2020 6966 2073 656c 662e 6474 7970      if self.dtyp
-00023350: 6520 3d3d 206d 7374 7970 652e 696e 7436  e == mstype.int6
-00023360: 343a 0a20 2020 2020 2020 2020 2020 2069  4:.            i
-00023370: 6e70 7574 5f6d 7320 3d20 696e 7075 745f  nput_ms = input_
-00023380: 6d73 2e61 7374 7970 6528 6d73 7479 7065  ms.astype(mstype
-00023390: 2e69 6e74 3332 290a 2020 2020 2020 2020  .int32).        
-000233a0: 2020 2020 736f 7572 6365 203d 2073 6f75      source = sou
-000233b0: 7263 652e 6173 7479 7065 286d 7374 7970  rce.astype(mstyp
-000233c0: 652e 696e 7433 3229 0a20 2020 2020 2020  e.int32).       
-000233d0: 2073 656c 6563 7420 3d20 6d73 2e6f 7073   select = ms.ops
-000233e0: 2e69 6e64 6578 5f73 656c 6563 7428 696e  .index_select(in
-000233f0: 7075 745f 6d73 2c20 6469 6d2c 2069 6e64  put_ms, dim, ind
-00023400: 6578 290a 2020 2020 2020 2020 2320 6d73  ex).        # ms
-00023410: 2e54 656e 736f 722e 696e 6465 785f 6164  .Tensor.index_ad
-00023420: 6420 6973 2061 6e20 696e 2d70 6c61 6365  d is an in-place
-00023430: 206f 7065 7261 7469 6f6e 2c20 736f 2077   operation, so w
-00023440: 6520 6e65 6564 2074 6f20 6465 6570 636f  e need to deepco
-00023450: 7079 2069 6e70 7574 2066 6972 7374 0a20  py input first. 
-00023460: 2020 2020 2020 2069 6e70 7574 5f63 6f70         input_cop
-00023470: 7920 3d20 6d73 2e6f 7073 2e64 6565 7063  y = ms.ops.deepc
-00023480: 6f70 7928 696e 7075 745f 6d73 290a 2020  opy(input_ms).  
-00023490: 2020 2020 2020 2320 6d73 2e6f 7073 2e69        # ms.ops.i
-000234a0: 6e64 6578 5f61 6464 2073 7570 706f 7274  ndex_add support
-000234b0: 7320 6f6e 6c79 2050 6172 616d 6574 6572  s only Parameter
-000234c0: 2069 6e70 7574 2073 6f20 7765 2075 7365   input so we use
-000234d0: 206d 732e 5465 6e73 6f72 2e69 6e64 6578   ms.Tensor.index
-000234e0: 5f61 6464 2068 6572 650a 2020 2020 2020  _add here.      
-000234f0: 2020 6f75 7470 7574 3020 3d20 696e 7075    output0 = inpu
-00023500: 745f 636f 7079 2e69 6e64 6578 5f61 6464  t_copy.index_add
-00023510: 2864 696d 2c20 696e 6465 782c 2073 656c  (dim, index, sel
-00023520: 6563 742c 2061 6c70 6861 3d2d 3129 0a20  ect, alpha=-1). 
-00023530: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00023540: 6f75 7470 7574 302e 696e 6465 785f 6164  output0.index_ad
-00023550: 6428 6469 6d2c 2069 6e64 6578 2c20 736f  d(dim, index, so
-00023560: 7572 6365 290a 2020 2020 2020 2020 6966  urce).        if
-00023570: 2073 656c 662e 6474 7970 6520 3d3d 206d   self.dtype == m
-00023580: 7374 7970 652e 696e 7436 343a 0a20 2020  stype.int64:.   
-00023590: 2020 2020 2020 2020 206f 7574 7075 7420           output 
-000235a0: 3d20 6f75 7470 7574 2e61 7374 7970 6528  = output.astype(
-000235b0: 6d73 7479 7065 2e69 6e74 3634 290a 2020  mstype.int64).  
-000235c0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-000235d0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-000235e0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-000235f0: 2064 6566 2069 6e64 6578 5f63 6f70 795f   def index_copy_
-00023600: 2873 656c 662c 2064 696d 2c20 696e 6465  (self, dim, inde
-00023610: 782c 2074 656e 736f 7229 3a0a 2020 2020  x, tensor):.    
-00023620: 2020 2020 2320 544f 444f 3a20 746f 2073      # TODO: to s
-00023630: 7570 706f 7274 2069 6e70 7574 206f 6620  upport input of 
-00023640: 6d6f 7265 2074 6861 6e20 322d 4420 2620  more than 2-D & 
-00023650: 6469 6d20 3e3d 2031 2c20 746f 2073 7570  dim >= 1, to sup
-00023660: 706f 7274 2047 5241 5048 206d 6f64 650a  port GRAPH mode.
-00023670: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00023680: 2073 656c 662e 696e 6465 785f 636f 7079   self.index_copy
-00023690: 2864 696d 2c20 696e 6465 782c 2074 656e  (dim, index, ten
-000236a0: 736f 7229 0a20 2020 2020 2020 2072 6574  sor).        ret
-000236b0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
-000236c0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
-000236d0: 206f 7574 7075 742c 2022 696e 6465 785f   output, "index_
-000236e0: 636f 7079 5f22 2c20 2269 6e64 6578 5f63  copy_", "index_c
-000236f0: 6f70 7922 290a 0a20 2020 2064 6566 2064  opy")..    def d
-00023700: 6961 675f 656d 6265 6428 7365 6c66 2c20  iag_embed(self, 
-00023710: 6f66 6673 6574 3d30 2c20 6469 6d31 3d2d  offset=0, dim1=-
-00023720: 322c 2064 696d 323d 2d31 293a 0a20 2020  2, dim2=-1):.   
-00023730: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00023740: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00023750: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00023760: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-00023770: 6469 6167 5f65 6d62 6564 2869 6e70 7574  diag_embed(input
-00023780: 5f6d 732c 206f 6666 7365 743d 6f66 6673  _ms, offset=offs
-00023790: 6574 2c20 6469 6d31 3d64 696d 312c 2064  et, dim1=dim1, d
-000237a0: 696d 323d 6469 6d32 290a 2020 2020 2020  im2=dim2).      
-000237b0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-000237c0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-000237d0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-000237e0: 2069 735f 6e65 6728 7365 6c66 293a 0a20   is_neg(self):. 
-000237f0: 2020 2020 2020 2069 6620 6e6f 7420 6861         if not ha
-00023800: 7361 7474 7228 7365 6c66 2c20 226e 6567  sattr(self, "neg
-00023810: 5f62 6974 2229 3a0a 2020 2020 2020 2020  _bit"):.        
-00023820: 2020 2020 7265 7475 726e 2046 616c 7365      return False
-00023830: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00023840: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00023850: 6e20 7365 6c66 2e6e 6567 5f62 6974 0a0a  n self.neg_bit..
-00023860: 2020 2020 6465 6620 7265 736f 6c76 655f      def resolve_
-00023870: 6e65 6728 7365 6c66 293a 0a20 2020 2020  neg(self):.     
-00023880: 2020 206f 7574 7075 7420 3d20 6465 6570     output = deep
-00023890: 636f 7079 2873 656c 6629 0a20 2020 2020  copy(self).     
-000238a0: 2020 206f 7574 7075 742e 6e65 675f 6269     output.neg_bi
-000238b0: 7420 3d20 4661 6c73 650a 2020 2020 2020  t = False.      
-000238c0: 2020 7265 7475 726e 206f 7574 7075 740a    return output.
-000238d0: 0a20 2020 2023 544f 444f 3a20 7069 6e76  .    #TODO: pinv
-000238e0: 2063 7572 7265 6e74 6c79 206e 6f74 2073   currently not s
-000238f0: 7570 706f 7274 206f 6e20 4173 6365 6e64  upport on Ascend
-00023900: 0a20 2020 2064 6566 2070 696e 7665 7273  .    def pinvers
-00023910: 6528 7365 6c66 2c20 7263 6f6e 643d 3165  e(self, rcond=1e
-00023920: 2d31 3529 3a0a 2020 2020 2020 2020 6966  -15):.        if
-00023930: 2069 735f 756e 6465 725f 6173 6365 6e64   is_under_ascend
-00023940: 5f63 6f6e 7465 7874 2829 3a0a 2020 2020  _context():.    
-00023950: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
-00023960: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
-00023970: 7228 2270 696e 7665 7273 6520 6375 7272  r("pinverse curr
-00023980: 656e 746c 7920 6e6f 7420 7375 7070 6f72  ently not suppor
-00023990: 7465 6420 6f6e 2041 7363 656e 6422 290a  ted on Ascend").
-000239a0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-000239b0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-000239c0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-000239d0: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
-000239e0: 7073 2e70 696e 7628 696e 7075 745f 6d73  ps.pinv(input_ms
-000239f0: 2c20 7274 6f6c 3d72 636f 6e64 290a 2020  , rtol=rcond).  
-00023a00: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00023a10: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00023a20: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
-00023a30: 2023 544f 444f 3a20 6e65 6564 2074 6f20   #TODO: need to 
-00023a40: 7573 6520 6f70 7320 6675 6e63 0a20 2020  use ops func.   
-00023a50: 2064 6566 2073 796d 6569 6728 7365 6c66   def symeig(self
-00023a60: 2c20 6569 6765 6e76 6563 746f 7273 3d46  , eigenvectors=F
-00023a70: 616c 7365 2c20 7570 7065 723d 5472 7565  alse, upper=True
-00023a80: 293a 0a20 2020 2020 2020 2073 796d 6569  ):.        symei
-00023a90: 675f 6f70 203d 206e 756d 7079 5f63 656c  g_op = numpy_cel
-00023aa0: 6c2e 4e75 6d70 7945 6967 6828 2773 796d  l.NumpyEigh('sym
-00023ab0: 6569 6727 290a 2020 2020 2020 2020 6966  eig').        if
-00023ac0: 2065 6967 656e 7665 6374 6f72 733a 0a20   eigenvectors:. 
-00023ad0: 2020 2020 2020 2020 2020 2076 616c 7565             value
-00023ae0: 732c 2076 6563 746f 7273 203d 2073 796d  s, vectors = sym
-00023af0: 6569 675f 6f70 2873 656c 662c 206c 6f77  eig_op(self, low
-00023b00: 6572 3d6e 6f74 2075 7070 6572 2c20 6569  er=not upper, ei
-00023b10: 6776 616c 735f 6f6e 6c79 3d46 616c 7365  gvals_only=False
-00023b20: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-00023b30: 2020 2020 2020 2020 2020 2020 7661 6c75              valu
-00023b40: 6573 203d 2020 7379 6d65 6967 5f6f 7028  es =  symeig_op(
-00023b50: 7365 6c66 2c20 6c6f 7765 723d 6e6f 7420  self, lower=not 
-00023b60: 7570 7065 722c 2065 6967 7661 6c73 5f6f  upper, eigvals_o
-00023b70: 6e6c 793d 5472 7565 290a 2020 2020 2020  nly=True).      
-00023b80: 2020 2020 2020 7665 6374 6f72 7320 3d20        vectors = 
-00023b90: 6d73 2e54 656e 736f 7228 5b5d 290a 2020  ms.Tensor([]).  
-00023ba0: 2020 2020 2020 6f75 7470 7574 203d 2028        output = (
-00023bb0: 7661 6c75 6573 2c20 7665 6374 6f72 7329  values, vectors)
-00023bc0: 0a20 2020 2020 2020 2069 6620 7079 6e61  .        if pyna
-00023bd0: 7469 7665 5f6d 6f64 655f 636f 6e64 6974  tive_mode_condit
-00023be0: 696f 6e28 293a 0a20 2020 2020 2020 2020  ion():.         
-00023bf0: 2020 2073 796d 6569 675f 6e61 6d65 6474     symeig_namedt
-00023c00: 7570 6c65 203d 2073 6574 5f6d 756c 7469  uple = set_multi
-00023c10: 706c 655f 6e61 6d65 5f74 7570 6c65 2827  ple_name_tuple('
-00023c20: 7379 6d65 6967 272c 2027 6569 6765 6e76  symeig', 'eigenv
-00023c30: 616c 7565 732c 2065 6967 656e 7665 6374  alues, eigenvect
-00023c40: 6f72 7327 290a 2020 2020 2020 2020 2020  ors').          
-00023c50: 2020 6966 2076 616c 7565 732e 6474 7970    if values.dtyp
-00023c60: 6520 696e 2028 6d73 2e63 6f6d 706c 6578  e in (ms.complex
-00023c70: 3634 2c20 6d73 2e63 6f6d 706c 6578 3132  64, ms.complex12
-00023c80: 3829 3a0a 2020 2020 2020 2020 2020 2020  8):.            
-00023c90: 2020 2020 7661 6c75 6573 203d 2076 616c      values = val
-00023ca0: 7565 732e 7265 616c 2829 0a20 2020 2020  ues.real().     
-00023cb0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-00023cc0: 7379 6d65 6967 5f6e 616d 6564 7475 706c  symeig_namedtupl
-00023cd0: 6528 6361 7374 5f74 6f5f 6164 6170 7465  e(cast_to_adapte
-00023ce0: 725f 7465 6e73 6f72 2876 616c 7565 7329  r_tensor(values)
-00023cf0: 2c20 6361 7374 5f74 6f5f 6164 6170 7465  , cast_to_adapte
-00023d00: 725f 7465 6e73 6f72 2876 6563 746f 7273  r_tensor(vectors
-00023d10: 2929 0a20 2020 2020 2020 2020 2020 2072  )).            r
-00023d20: 6574 7572 6e20 6f75 7470 7574 0a20 2020  eturn output.   
-00023d30: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
-00023d40: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
-00023d50: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
-00023d60: 6465 6620 6e61 6e5f 746f 5f6e 756d 2873  def nan_to_num(s
-00023d70: 656c 662c 206e 616e 3d30 2e30 2c20 706f  elf, nan=0.0, po
-00023d80: 7369 6e66 3d4e 6f6e 652c 206e 6567 696e  sinf=None, negin
-00023d90: 663d 4e6f 6e65 293a 0a20 2020 2020 2020  f=None):.       
-00023da0: 2023 2054 4f44 4f3a 206d 732e 6f70 732e   # TODO: ms.ops.
-00023db0: 6e61 6e5f 746f 5f6e 756d 2074 6f20 7375  nan_to_num to su
-00023dc0: 7070 6f72 7420 666c 6f61 7436 3420 696e  pport float64 in
-00023dd0: 7075 740a 2020 2020 2020 2020 696e 7075  put.        inpu
-00023de0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00023df0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00023e00: 2020 2020 2020 2023 544f 444f 3a20 322e         #TODO: 2.
-00023e10: 3120 6e6f 7420 7375 7070 6f72 7420 6e65  1 not support ne
-00023e20: 6769 6e66 2f70 6f73 696e 6620 696e 7420  ginf/posinf int 
-00023e30: 696e 7075 740a 2020 2020 2020 2020 6966  input.        if
-00023e40: 206e 6567 696e 6620 6973 206e 6f74 204e   neginf is not N
-00023e50: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-00023e60: 206e 6567 696e 6620 3d20 666c 6f61 7428   neginf = float(
-00023e70: 6e65 6769 6e66 290a 2020 2020 2020 2020  neginf).        
-00023e80: 6966 2070 6f73 696e 6620 6973 206e 6f74  if posinf is not
-00023e90: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
-00023ea0: 2020 2070 6f73 696e 6620 3d20 666c 6f61     posinf = floa
-00023eb0: 7428 706f 7369 6e66 290a 2020 2020 2020  t(posinf).      
-00023ec0: 2020 696e 7075 745f 6474 7970 6520 3d20    input_dtype = 
-00023ed0: 696e 7075 745f 6d73 2e64 7479 7065 0a20  input_ms.dtype. 
-00023ee0: 2020 2020 2020 2069 6620 6973 5f75 6e64         if is_und
-00023ef0: 6572 5f67 7075 5f63 6f6e 7465 7874 2829  er_gpu_context()
-00023f00: 206f 7220 696e 7075 745f 6474 7970 6520   or input_dtype 
-00023f10: 3d3d 206d 7374 7970 652e 666c 6f61 7436  == mstype.float6
-00023f20: 343a 0a20 2020 2020 2020 2020 2020 206f  4:.            o
-00023f30: 7574 7075 7420 3d20 696e 7075 745f 6d73  utput = input_ms
-00023f40: 2e6d 6173 6b65 645f 6669 6c6c 2869 6e70  .masked_fill(inp
-00023f50: 7574 5f6d 732e 6973 6e61 6e28 292c 206e  ut_ms.isnan(), n
-00023f60: 616e 290a 2020 2020 2020 2020 2020 2020  an).            
-00023f70: 6966 2069 6e70 7574 5f6d 732e 6474 7970  if input_ms.dtyp
-00023f80: 6520 696e 2061 6c6c 5f69 6e74 5f74 7970  e in all_int_typ
-00023f90: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-00023fa0: 2020 2069 6e70 7574 5f64 7479 7065 203d     input_dtype =
-00023fb0: 2069 6e70 7574 5f6d 732e 6474 7970 650a   input_ms.dtype.
-00023fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00023fd0: 6966 2070 6f73 696e 6620 6973 204e 6f6e  if posinf is Non
-00023fe0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-00023ff0: 2020 2020 2020 2070 6f73 696e 6620 3d20         posinf = 
-00024000: 6969 6e66 6f28 696e 7075 745f 6d73 2e64  iinfo(input_ms.d
-00024010: 7479 7065 292e 6d61 780a 2020 2020 2020  type).max.      
-00024020: 2020 2020 2020 2020 2020 6966 206e 6567            if neg
-00024030: 696e 6620 6973 204e 6f6e 653a 0a20 2020  inf is None:.   
-00024040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024050: 206e 6567 696e 6620 3d20 6969 6e66 6f28   neginf = iinfo(
-00024060: 696e 7075 745f 6d73 2e64 7479 7065 292e  input_ms.dtype).
-00024070: 6d69 6e0a 2020 2020 2020 2020 2020 2020  min.            
-00024080: 2020 2020 6f75 7470 7574 203d 206f 7574      output = out
-00024090: 7075 742e 6173 7479 7065 286d 732e 666c  put.astype(ms.fl
-000240a0: 6f61 7433 3229 0a20 2020 2020 2020 2020  oat32).         
-000240b0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
-000240c0: 6f75 7470 7574 2e6d 6173 6b65 645f 6669  output.masked_fi
-000240d0: 6c6c 286f 7574 7075 742e 6973 6e65 6769  ll(output.isnegi
-000240e0: 6e66 2829 2c20 6e65 6769 6e66 290a 2020  nf(), neginf).  
-000240f0: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-00024100: 7470 7574 203d 206f 7574 7075 742e 6d61  tput = output.ma
-00024110: 736b 6564 5f66 696c 6c28 6f75 7470 7574  sked_fill(output
-00024120: 2e69 7370 6f73 696e 6628 292c 2070 6f73  .isposinf(), pos
-00024130: 696e 6629 2e61 7374 7970 6528 696e 7075  inf).astype(inpu
-00024140: 745f 6474 7970 6529 0a20 2020 2020 2020  t_dtype).       
-00024150: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
-00024160: 2020 2020 2020 2020 2020 2069 6620 706f             if po
-00024170: 7369 6e66 2069 7320 4e6f 6e65 3a0a 2020  sinf is None:.  
-00024180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00024190: 2020 706f 7369 6e66 203d 2066 696e 666f    posinf = finfo
-000241a0: 2869 6e70 7574 5f6d 732e 6474 7970 6529  (input_ms.dtype)
-000241b0: 2e6d 6178 0a20 2020 2020 2020 2020 2020  .max.           
-000241c0: 2020 2020 2069 6620 6e65 6769 6e66 2069       if neginf i
-000241d0: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-000241e0: 2020 2020 2020 2020 2020 2020 6e65 6769              negi
-000241f0: 6e66 203d 2066 696e 666f 2869 6e70 7574  nf = finfo(input
-00024200: 5f6d 732e 6474 7970 6529 2e6d 696e 0a20  _ms.dtype).min. 
-00024210: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00024220: 7574 7075 7420 3d20 6f75 7470 7574 2e6d  utput = output.m
-00024230: 6173 6b65 645f 6669 6c6c 286f 7574 7075  asked_fill(outpu
-00024240: 742e 6973 6e65 6769 6e66 2829 2c20 6e65  t.isneginf(), ne
-00024250: 6769 6e66 290a 2020 2020 2020 2020 2020  ginf).          
-00024260: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
-00024270: 7574 7075 742e 6d61 736b 6564 5f66 696c  utput.masked_fil
-00024280: 6c28 6f75 7470 7574 2e69 7370 6f73 696e  l(output.isposin
-00024290: 6628 292c 2070 6f73 696e 6629 0a20 2020  f(), posinf).   
-000242a0: 2020 2020 2065 6c69 6620 696e 7075 745f       elif input_
-000242b0: 6474 7970 6520 696e 2061 6c6c 5f69 6e74  dtype in all_int
-000242c0: 5f74 7970 653a 0a20 2020 2020 2020 2020  _type:.         
-000242d0: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
-000242e0: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
-000242f0: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
-00024300: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-00024310: 732e 6f70 732e 6e61 6e5f 746f 5f6e 756d  s.ops.nan_to_num
-00024320: 2869 6e70 7574 5f6d 732c 206e 616e 3d6e  (input_ms, nan=n
-00024330: 616e 2c20 706f 7369 6e66 3d70 6f73 696e  an, posinf=posin
-00024340: 662c 206e 6567 696e 663d 6e65 6769 6e66  f, neginf=neginf
-00024350: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
-00024360: 7470 7574 203d 206f 7574 7075 742e 6173  tput = output.as
-00024370: 7479 7065 2869 6e70 7574 5f64 7479 7065  type(input_dtype
-00024380: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-00024390: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-000243a0: 7574 203d 206d 732e 6f70 732e 6e61 6e5f  ut = ms.ops.nan_
-000243b0: 746f 5f6e 756d 2869 6e70 7574 5f6d 732c  to_num(input_ms,
-000243c0: 206e 616e 3d6e 616e 2c20 706f 7369 6e66   nan=nan, posinf
-000243d0: 3d70 6f73 696e 662c 206e 6567 696e 663d  =posinf, neginf=
-000243e0: 6e65 6769 6e66 290a 2020 2020 2020 2020  neginf).        
-000243f0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00024400: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00024410: 7470 7574 290a 0a20 2020 2064 6566 206e  tput)..    def n
-00024420: 616e 5f74 6f5f 6e75 6d5f 2873 656c 662c  an_to_num_(self,
-00024430: 206e 616e 3d30 2e30 2c20 706f 7369 6e66   nan=0.0, posinf
-00024440: 3d4e 6f6e 652c 206e 6567 696e 663d 4e6f  =None, neginf=No
-00024450: 6e65 293a 0a20 2020 2020 2020 2023 2054  ne):.        # T
-00024460: 4f44 4f3a 206d 732e 6f70 732e 6e61 6e5f  ODO: ms.ops.nan_
-00024470: 746f 5f6e 756d 2074 6f20 7375 7070 6f72  to_num to suppor
-00024480: 7420 666c 6f61 7436 3420 696e 7075 740a  t float64 input.
-00024490: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-000244a0: 2073 656c 662e 6e61 6e5f 746f 5f6e 756d   self.nan_to_num
-000244b0: 286e 616e 3d6e 616e 2c20 706f 7369 6e66  (nan=nan, posinf
-000244c0: 3d70 6f73 696e 662c 206e 6567 696e 663d  =posinf, neginf=
-000244d0: 6e65 6769 6e66 290a 2020 2020 2020 2020  neginf).        
-000244e0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
-000244f0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
-00024500: 6c66 2c20 6f75 7470 7574 2c20 226e 616e  lf, output, "nan
-00024510: 5f74 6f5f 6e75 6d5f 222c 2022 6e61 6e5f  _to_num_", "nan_
-00024520: 746f 5f6e 756d 2229 0a0a 2020 2020 6465  to_num")..    de
-00024530: 6620 7075 745f 2873 656c 662c 2069 6e64  f put_(self, ind
-00024540: 6578 2c20 736f 7572 6365 2c20 6163 6375  ex, source, accu
-00024550: 6d75 6c61 7465 3d46 616c 7365 293a 0a20  mulate=False):. 
-00024560: 2020 2020 2020 2023 2054 4f44 4f3a 2064         # TODO: d
-00024570: 6f65 7320 6e6f 7420 7375 7070 6f72 7420  oes not support 
-00024580: 4752 4150 4820 4d4f 4445 0a20 2020 2020  GRAPH MODE.     
-00024590: 2020 2023 2053 6361 7474 6572 5570 6461     # ScatterUpda
-000245a0: 7465 2074 616b 6573 206f 6e6c 7920 5061  te takes only Pa
-000245b0: 7261 6d65 7465 7220 6f62 6a65 6374 2061  rameter object a
-000245c0: 7320 696e 7075 740a 2020 2020 2020 2020  s input.        
-000245d0: 2320 6275 7420 5061 7261 6d65 7465 7220  # but Parameter 
-000245e0: 6f62 6a65 6374 2063 616e 2774 2062 6520  object can't be 
-000245f0: 6372 6561 7465 6420 696e 2063 6f6e 7374  created in const
-00024600: 7275 6374 2066 756e 6320 696e 2067 7261  ruct func in gra
-00024610: 7068 206d 6f64 650a 2020 2020 2020 2020  ph mode.        
-00024620: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00024630: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00024640: 6629 0a20 2020 2020 2020 2069 6e64 6578  f).        index
-00024650: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00024660: 6e73 6f72 2869 6e64 6578 290a 2020 2020  nsor(index).    
-00024670: 2020 2020 736f 7572 6365 203d 2063 6173      source = cas
-00024680: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-00024690: 6f75 7263 6529 0a20 2020 2020 2020 2069  ource).        i
-000246a0: 6e70 7574 5f73 6861 7065 203d 2073 656c  nput_shape = sel
-000246b0: 662e 7368 6170 650a 2020 2020 2020 2020  f.shape.        
-000246c0: 696e 7075 745f 7479 7065 203d 2073 656c  input_type = sel
-000246d0: 662e 6474 7970 650a 2020 2020 2020 2020  f.dtype.        
-000246e0: 696e 7075 745f 6d73 203d 2069 6e70 7574  input_ms = input
-000246f0: 5f6d 732e 666c 6174 7465 6e28 290a 2020  _ms.flatten().  
-00024700: 2020 2020 2020 696e 6465 7820 3d20 696e        index = in
-00024710: 6465 782e 666c 6174 7465 6e28 290a 2020  dex.flatten().  
-00024720: 2020 2020 2020 736f 7572 6365 203d 2073        source = s
-00024730: 6f75 7263 652e 666c 6174 7465 6e28 290a  ource.flatten().
-00024740: 0a20 2020 2020 2020 2069 6620 6973 5f75  .        if is_u
-00024750: 6e64 6572 5f61 7363 656e 645f 636f 6e74  nder_ascend_cont
-00024760: 6578 7428 2920 616e 6420 696e 7075 745f  ext() and input_
-00024770: 6d73 2e64 7479 7065 2069 6e20 6d73 6461  ms.dtype in msda
-00024780: 7074 6572 5f64 7479 7065 2e61 6c6c 5f69  pter_dtype.all_i
-00024790: 6e74 5f74 7970 653a 0a20 2020 2020 2020  nt_type:.       
-000247a0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-000247b0: 696e 7075 745f 6d73 2e61 7374 7970 6528  input_ms.astype(
-000247c0: 6d73 2e66 6c6f 6174 3332 290a 2020 2020  ms.float32).    
-000247d0: 2020 2020 2020 2020 736f 7572 6365 203d          source =
-000247e0: 2073 6f75 7263 652e 6173 7479 7065 286d   source.astype(m
-000247f0: 732e 666c 6f61 7433 3229 0a0a 2020 2020  s.float32)..    
-00024800: 2020 2020 2320 6265 6861 7669 6f72 2069      # behavior i
-00024810: 7320 756e 6465 6669 6e65 6420 7768 656e  s undefined when
-00024820: 2061 6363 756d 756c 6174 653d 4661 6c73   accumulate=Fals
-00024830: 6520 616e 6420 696e 6465 7820 636f 6e74  e and index cont
-00024840: 6169 6e20 6475 706c 6963 6174 6520 656c  ain duplicate el
-00024850: 656d 656e 7473 2c20 7361 6d65 2061 7320  ements, same as 
-00024860: 746f 7263 680a 2020 2020 2020 2020 6966  torch.        if
-00024870: 2061 6363 756d 756c 6174 6520 6973 2046   accumulate is F
-00024880: 616c 7365 3a0a 2020 2020 2020 2020 2020  alse:.          
-00024890: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-000248a0: 732e 7363 6174 7465 725f 7570 6461 7465  s.scatter_update
-000248b0: 2869 6e70 7574 5f6d 732c 2069 6e64 6578  (input_ms, index
-000248c0: 2c20 736f 7572 6365 292e 7265 7368 6170  , source).reshap
-000248d0: 6528 696e 7075 745f 7368 6170 6529 2e61  e(input_shape).a
-000248e0: 7374 7970 6528 696e 7075 745f 7479 7065  stype(input_type
-000248f0: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-00024900: 2020 2020 2020 2020 2020 2020 2320 496e              # In
-00024910: 6465 7841 6464 2073 7570 706f 7274 7320  dexAdd supports 
-00024920: 6f6e 6c79 2046 6c6f 6174 3136 2046 6c6f  only Float16 Flo
-00024930: 6174 3332 2046 6c6f 6174 3634 2049 6e74  at32 Float64 Int
-00024940: 3136 2049 6e74 3332 2049 6e74 3820 5549  16 Int32 Int8 UI
-00024950: 6e74 3820 696e 7075 7420 616e 6420 496e  nt8 input and In
-00024960: 7433 3220 696e 6465 780a 2020 2020 2020  t32 index.      
-00024970: 2020 2020 2020 696e 6465 7820 3d20 696e        index = in
-00024980: 6465 782e 6173 7479 7065 286d 7374 7970  dex.astype(mstyp
-00024990: 652e 696e 7433 3229 0a20 2020 2020 2020  e.int32).       
-000249a0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-000249b0: 2e6f 7073 2e69 6e64 6578 5f61 6464 2869  .ops.index_add(i
-000249c0: 6e70 7574 5f6d 732e 6173 7479 7065 286d  nput_ms.astype(m
-000249d0: 7374 7970 652e 666c 6f61 7433 3229 2c20  stype.float32), 
-000249e0: 696e 6465 782c 2073 6f75 7263 652c 2030  index, source, 0
-000249f0: 2920 5c0a 2020 2020 2020 2020 2020 2020  ) \.            
-00024a00: 2020 2020 2e72 6573 6861 7065 2869 6e70      .reshape(inp
-00024a10: 7574 5f73 6861 7065 292e 6173 7479 7065  ut_shape).astype
-00024a20: 2869 6e70 7574 5f74 7970 6529 0a20 2020  (input_type).   
-00024a30: 2020 2020 206f 7574 7075 7420 3d20 6361       output = ca
-00024a40: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00024a50: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-00024a60: 2020 2020 2020 7365 6c66 2e61 7373 6967        self.assig
-00024a70: 6e5f 7661 6c75 6528 6f75 7470 7574 290a  n_value(output).
-00024a80: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00024a90: 656c 660a 0a20 2020 2064 6566 2070 6f6c  elf..    def pol
-00024aa0: 7967 616d 6d61 2873 656c 662c 206e 293a  ygamma(self, n):
-00024ab0: 0a20 2020 2020 2020 206e 203d 206d 732e  .        n = ms.
-00024ac0: 5465 6e73 6f72 286e 290a 2020 2020 2020  Tensor(n).      
-00024ad0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
-00024ae0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-00024af0: 656c 6629 0a20 2020 2020 2020 206f 7574  elf).        out
-00024b00: 7075 7420 3d20 6d73 2e6f 7073 2e70 6f6c  put = ms.ops.pol
-00024b10: 7967 616d 6d61 286e 2c20 696e 7075 745f  ygamma(n, input_
-00024b20: 6d73 290a 2020 2020 2020 2020 7265 7475  ms).        retu
-00024b30: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00024b40: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00024b50: 290a 0a20 2020 2064 6566 2070 6f6c 7967  )..    def polyg
-00024b60: 616d 6d61 5f28 7365 6c66 2c20 6e29 3a0a  amma_(self, n):.
-00024b70: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00024b80: 2073 656c 662e 706f 6c79 6761 6d6d 6128   self.polygamma(
-00024b90: 6e29 0a20 2020 2020 2020 2072 6574 7572  n).        retur
-00024ba0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
-00024bb0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
-00024bc0: 7574 7075 742c 2022 706f 6c79 6761 6d6d  utput, "polygamm
-00024bd0: 615f 222c 2022 706f 6c79 6761 6d6d 6122  a_", "polygamma"
-00024be0: 290a 0a20 2020 2064 6566 2069 6e64 6578  )..    def index
-00024bf0: 5f70 7574 2873 656c 662c 2069 6e64 6963  _put(self, indic
-00024c00: 6573 2c20 7661 6c75 6573 2c20 6163 6375  es, values, accu
-00024c10: 6d75 6c61 7465 3d46 616c 7365 293a 0a20  mulate=False):. 
-00024c20: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00024c30: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00024c40: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00024c50: 2020 696e 6469 6365 7320 3d20 6361 7374    indices = cast
-00024c60: 5f74 6f5f 6d73 5f74 656e 736f 7228 696e  _to_ms_tensor(in
-00024c70: 6469 6365 7329 0a20 2020 2020 2020 2076  dices).        v
-00024c80: 616c 7565 7320 3d20 6361 7374 5f74 6f5f  alues = cast_to_
-00024c90: 6d73 5f74 656e 736f 7228 7661 6c75 6573  ms_tensor(values
-00024ca0: 290a 2020 2020 2020 2020 666f 7220 696e  ).        for in
-00024cb0: 6465 7820 696e 2069 6e64 6963 6573 3a0a  dex in indices:.
-00024cc0: 2020 2020 2020 2020 2020 2020 6966 2069              if i
-00024cd0: 6e64 6578 2e6e 756d 656c 2829 203d 3d20  ndex.numel() == 
-00024ce0: 303a 0a20 2020 2020 2020 2020 2020 2020  0:.             
-00024cf0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-00024d00: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-00024d10: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
-00024d20: 2020 2023 2054 4f44 4f3a 206d 732e 6f70     # TODO: ms.op
-00024d30: 732e 696e 6465 785f 7075 7420 646f 6573  s.index_put does
-00024d40: 206e 6f74 2073 7570 706f 7274 2076 616c   not support val
-00024d50: 7565 7320 696e 7075 7420 7769 7468 2072  ues input with r
-00024d60: 616e 6b3e 310a 2020 2020 2020 2020 6964  ank>1.        id
-00024d70: 7820 3d20 6d73 2e6f 7073 2e64 7374 6163  x = ms.ops.dstac
-00024d80: 6b28 696e 6469 6365 7329 5b30 5d0a 2020  k(indices)[0].  
-00024d90: 2020 2020 2020 6966 2061 6363 756d 756c        if accumul
-00024da0: 6174 6520 6973 2046 616c 7365 3a0a 2020  ate is False:.  
-00024db0: 2020 2020 2020 2020 2020 6f70 203d 206d            op = m
-00024dc0: 732e 6f70 732e 5363 6174 7465 724e 6455  s.ops.ScatterNdU
-00024dd0: 7064 6174 6528 290a 2020 2020 2020 2020  pdate().        
-00024de0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-00024df0: 2020 6f70 203d 206d 732e 6f70 732e 5363    op = ms.ops.Sc
-00024e00: 6174 7465 724e 6441 6464 2829 0a20 2020  atterNdAdd().   
-00024e10: 2020 2020 206f 7574 7075 7420 3d20 6f70       output = op
-00024e20: 2869 6e70 7574 5f6d 732c 2069 6478 2c20  (input_ms, idx, 
-00024e30: 7661 6c75 6573 290a 2020 2020 2020 2020  values).        
+0001d810: 2073 656c 662e 7472 696c 2864 6961 676f   self.tril(diago
+0001d820: 6e61 6c29 0a20 2020 2020 2020 2072 6574  nal).        ret
+0001d830: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+0001d840: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+0001d850: 206f 7574 7075 742c 2022 7472 696c 5f22   output, "tril_"
+0001d860: 2c20 2274 7269 6c22 290a 0a20 2020 2064  , "tril")..    d
+0001d870: 6566 206e 616e 6d65 616e 2873 656c 662c  ef nanmean(self,
+0001d880: 2064 696d 3d4e 6f6e 652c 206b 6565 7064   dim=None, keepd
+0001d890: 696d 3d46 616c 7365 2c20 2a2c 2064 7479  im=False, *, dty
+0001d8a0: 7065 3d4e 6f6e 6529 3a0a 2020 2020 2020  pe=None):.      
+0001d8b0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+0001d8c0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+0001d8d0: 656c 6629 0a20 2020 2020 2020 206f 7574  elf).        out
+0001d8e0: 7075 7420 3d20 6d73 2e6f 7073 2e6e 616e  put = ms.ops.nan
+0001d8f0: 6d65 616e 2869 6e70 7574 5f6d 732c 2064  mean(input_ms, d
+0001d900: 696d 2c20 6b65 6570 6469 6d2c 2064 7479  im, keepdim, dty
+0001d910: 7065 3d64 7479 7065 290a 2020 2020 2020  pe=dtype).      
+0001d920: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+0001d930: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+0001d940: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+0001d950: 206e 616e 7375 6d28 7365 6c66 2c20 6469   nansum(self, di
+0001d960: 6d3d 4e6f 6e65 2c20 6b65 6570 6469 6d3d  m=None, keepdim=
+0001d970: 4661 6c73 652c 2064 7479 7065 3d4e 6f6e  False, dtype=Non
+0001d980: 6529 3a0a 2020 2020 2020 2020 696e 7075  e):.        inpu
+0001d990: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+0001d9a0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+0001d9b0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0001d9c0: 6d73 2e6f 7073 2e6e 616e 7375 6d28 696e  ms.ops.nansum(in
+0001d9d0: 7075 745f 6d73 2c20 6469 6d2c 206b 6565  put_ms, dim, kee
+0001d9e0: 7064 696d 2c20 6474 7970 653d 6474 7970  pdim, dtype=dtyp
+0001d9f0: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
+0001da00: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0001da10: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0001da20: 0a0a 2020 2020 6465 6620 6865 6176 6973  ..    def heavis
+0001da30: 6964 6528 7365 6c66 2c20 7661 6c75 6573  ide(self, values
+0001da40: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0001da50: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0001da60: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0001da70: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+0001da80: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0001da90: 736f 7228 696e 7075 745f 6d73 2e68 6561  sor(input_ms.hea
+0001daa0: 7669 7369 6465 2876 616c 7565 7329 290a  viside(values)).
+0001dab0: 0a20 2020 2064 6566 2066 6c69 7075 6428  .    def flipud(
+0001dac0: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
+0001dad0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0001dae0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0001daf0: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+0001db00: 203d 206d 732e 6f70 732e 666c 6970 7564   = ms.ops.flipud
+0001db10: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
+0001db20: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0001db30: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0001db40: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0001db50: 6620 7469 6c65 2873 656c 662c 202a 7265  f tile(self, *re
+0001db60: 7073 293a 0a20 2020 2020 2020 2023 2054  ps):.        # T
+0001db70: 4f44 4f3a 206d 732e 6f70 732e 7469 6c65  ODO: ms.ops.tile
+0001db80: 2074 6f20 7375 7070 6f72 7420 7468 6520   to support the 
+0001db90: 6c65 6e20 6f66 2060 6d75 6c74 6970 6c65  len of `multiple
+0001dba0: 7360 2074 6f20 6265 206c 6573 7320 7468  s` to be less th
+0001dbb0: 616e 2069 6e70 7574 2e6e 6469 6d2e 0a20  an input.ndim.. 
+0001dbc0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+0001dbd0: 616e 6365 2872 6570 735b 305d 2c20 2874  ance(reps[0], (t
+0001dbe0: 7570 6c65 2c20 6c69 7374 2929 3a0a 2020  uple, list)):.  
+0001dbf0: 2020 2020 2020 2020 2020 7265 7073 203d            reps =
+0001dc00: 2074 7570 6c65 2872 6570 735b 305d 290a   tuple(reps[0]).
+0001dc10: 2020 2020 2020 2020 6e65 775f 7265 7073          new_reps
+0001dc20: 203d 2028 312c 2920 2a20 2873 656c 662e   = (1,) * (self.
+0001dc30: 6e64 696d 202d 206c 656e 2872 6570 7329  ndim - len(reps)
+0001dc40: 2920 2b20 7265 7073 0a20 2020 2020 2020  ) + reps.       
+0001dc50: 2072 6570 7320 3d20 6e65 775f 7265 7073   reps = new_reps
+0001dc60: 0a0a 2020 2020 2020 2020 696e 7075 745f  ..        input_
+0001dc70: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0001dc80: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+0001dc90: 2020 2020 2069 6620 6973 5f75 6e64 6572       if is_under
+0001dca0: 5f67 7075 5f63 6f6e 7465 7874 2061 6e64  _gpu_context and
+0001dcb0: 2069 6e70 7574 5f6d 732e 6474 7970 6520   input_ms.dtype 
+0001dcc0: 3d3d 206d 732e 7569 6e74 383a 0a20 2020  == ms.uint8:.   
+0001dcd0: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
+0001dce0: 7320 3d20 696e 7075 745f 6d73 2e61 7374  s = input_ms.ast
+0001dcf0: 7970 6528 6d73 2e66 6c6f 6174 3332 290a  ype(ms.float32).
+0001dd00: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+0001dd10: 7574 203d 206d 732e 6f70 732e 7469 6c65  ut = ms.ops.tile
+0001dd20: 2869 6e70 7574 5f6d 732c 2072 6570 7329  (input_ms, reps)
+0001dd30: 2e61 7374 7970 6528 6d73 2e75 696e 7438  .astype(ms.uint8
+0001dd40: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
+0001dd50: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+0001dd60: 7574 203d 206d 732e 6f70 732e 7469 6c65  ut = ms.ops.tile
+0001dd70: 2869 6e70 7574 5f6d 732c 2072 6570 7329  (input_ms, reps)
+0001dd80: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001dd90: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+0001dda0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+0001ddb0: 2020 2020 6465 6620 756e 6971 7565 5f63      def unique_c
+0001ddc0: 6f6e 7365 6375 7469 7665 2873 656c 662c  onsecutive(self,
+0001ddd0: 2072 6574 7572 6e5f 696e 7665 7273 653d   return_inverse=
+0001dde0: 4661 6c73 652c 2072 6574 7572 6e5f 636f  False, return_co
+0001ddf0: 756e 7473 3d46 616c 7365 2c20 6469 6d3d  unts=False, dim=
+0001de00: 4e6f 6e65 293a 0a20 2020 2020 2020 2069  None):.        i
+0001de10: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0001de20: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0001de30: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+0001de40: 203d 206d 732e 6f70 732e 756e 6971 7565   = ms.ops.unique
+0001de50: 5f63 6f6e 7365 6375 7469 7665 2869 6e70  _consecutive(inp
+0001de60: 7574 5f6d 732c 2072 6574 7572 6e5f 6964  ut_ms, return_id
+0001de70: 783d 7265 7475 726e 5f69 6e76 6572 7365  x=return_inverse
+0001de80: 2c20 7265 7475 726e 5f63 6f75 6e74 733d  , return_counts=
+0001de90: 7265 7475 726e 5f63 6f75 6e74 732c 2061  return_counts, a
+0001dea0: 7869 733d 6469 6d29 0a20 2020 2020 2020  xis=dim).       
+0001deb0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0001dec0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0001ded0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0001dee0: 7461 6e68 2873 656c 6629 3a0a 2020 2020  tanh(self):.    
+0001def0: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+0001df00: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0001df10: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
+0001df20: 6e70 7574 5f64 7479 7065 203d 2069 6e70  nput_dtype = inp
+0001df30: 7574 5f6d 732e 6474 7970 650a 2020 2020  ut_ms.dtype.    
+0001df40: 2020 2020 6966 2069 6e70 7574 5f64 7479      if input_dty
+0001df50: 7065 206e 6f74 2069 6e20 616c 6c5f 666c  pe not in all_fl
+0001df60: 6f61 745f 616e 645f 636f 6d70 6c65 785f  oat_and_complex_
+0001df70: 7479 7065 3a0a 2020 2020 2020 2020 2020  type:.          
+0001df80: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
+0001df90: 7574 5f6d 732e 6173 7479 7065 286d 732e  ut_ms.astype(ms.
+0001dfa0: 666c 6f61 7433 3229 0a20 2020 2020 2020  float32).       
+0001dfb0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+0001dfc0: 2e74 616e 6828 696e 7075 745f 6d73 290a  .tanh(input_ms).
+0001dfd0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+0001dfe0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+0001dff0: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+0001e000: 2020 2064 6566 2074 616e 685f 2873 656c     def tanh_(sel
+0001e010: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
+0001e020: 7574 203d 2073 656c 662e 7461 6e68 2829  ut = self.tanh()
+0001e030: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001e040: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+0001e050: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+0001e060: 7075 742c 2022 7461 6e68 5f22 2c20 2274  put, "tanh_", "t
+0001e070: 616e 6822 290a 0a20 2020 2064 6566 2074  anh")..    def t
+0001e080: 616e 2873 656c 6629 3a0a 2020 2020 2020  an(self):.      
+0001e090: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+0001e0a0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+0001e0b0: 656c 6629 0a20 2020 2020 2020 2069 6620  elf).        if 
+0001e0c0: 6e6f 7420 696e 7075 745f 6d73 2e69 735f  not input_ms.is_
+0001e0d0: 666c 6f61 7469 6e67 5f70 6f69 6e74 2829  floating_point()
+0001e0e0: 3a0a 2020 2020 2020 2020 2020 2020 696e  :.            in
+0001e0f0: 7075 745f 6d73 203d 2069 6e70 7574 5f6d  put_ms = input_m
+0001e100: 732e 6173 7479 7065 286d 732e 666c 6f61  s.astype(ms.floa
+0001e110: 7433 3229 0a20 2020 2020 2020 206f 7574  t32).        out
+0001e120: 7075 7420 3d20 6d73 2e6f 7073 2e74 616e  put = ms.ops.tan
+0001e130: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
+0001e140: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0001e150: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0001e160: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0001e170: 6620 7461 6e5f 2873 656c 6629 3a0a 2020  f tan_(self):.  
+0001e180: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
+0001e190: 656c 662e 7461 6e28 290a 2020 2020 2020  elf.tan().      
+0001e1a0: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+0001e1b0: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+0001e1c0: 7365 6c66 2c20 6f75 7470 7574 2c20 2274  self, output, "t
+0001e1d0: 616e 5f22 2c20 2274 616e 2229 0a0a 2020  an_", "tan")..  
+0001e1e0: 2020 6465 6620 7465 6e73 6f72 5f73 706c    def tensor_spl
+0001e1f0: 6974 2873 656c 662c 2069 6e64 6963 6573  it(self, indices
+0001e200: 5f6f 725f 7365 6374 696f 6e73 2c20 6469  _or_sections, di
+0001e210: 6d3d 3029 3a0a 2020 2020 2020 2020 696e  m=0):.        in
+0001e220: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+0001e230: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+0001e240: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001e250: 3d20 6d73 2e6f 7073 2e74 656e 736f 725f  = ms.ops.tensor_
+0001e260: 7370 6c69 7428 696e 7075 745f 6d73 2c20  split(input_ms, 
+0001e270: 696e 6469 6365 735f 6f72 5f73 6563 7469  indices_or_secti
+0001e280: 6f6e 732c 2061 7869 733d 6469 6d29 0a20  ons, axis=dim). 
+0001e290: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+0001e2a0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+0001e2b0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+0001e2c0: 2020 6465 6620 7461 6b65 2873 656c 662c    def take(self,
+0001e2d0: 2069 6e64 6578 293a 0a20 2020 2020 2020   index):.       
+0001e2e0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0001e2f0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0001e300: 6c66 290a 2020 2020 2020 2020 696e 6465  lf).        inde
+0001e310: 7820 3d20 6361 7374 5f74 6f5f 6d73 5f74  x = cast_to_ms_t
+0001e320: 656e 736f 7228 696e 6465 7829 0a20 2020  ensor(index).   
+0001e330: 2020 2020 206f 7574 7075 7420 3d20 696e       output = in
+0001e340: 7075 745f 6d73 2e74 616b 6528 696e 6465  put_ms.take(inde
+0001e350: 7829 0a20 2020 2020 2020 2072 6574 7572  x).        retur
+0001e360: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0001e370: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0001e380: 0a0a 2020 2020 6465 6620 7461 6b65 5f61  ..    def take_a
+0001e390: 6c6f 6e67 5f64 696d 2873 656c 662c 2069  long_dim(self, i
+0001e3a0: 6e64 6963 6573 2c20 6469 6d3d 4e6f 6e65  ndices, dim=None
+0001e3b0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0001e3c0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0001e3d0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0001e3e0: 2020 2020 2020 696e 6469 6365 7320 3d20        indices = 
+0001e3f0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0001e400: 7228 696e 6469 6365 7329 0a0a 2020 2020  r(indices)..    
+0001e410: 2020 2020 6966 206e 6f74 2064 696d 3a0a      if not dim:.
+0001e420: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+0001e430: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
+0001e440: 7265 7368 6170 6528 2d31 290a 2020 2020  reshape(-1).    
+0001e450: 2020 2020 2020 2020 6469 6d20 3d20 300a          dim = 0.
+0001e460: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001e470: 3d20 6d73 2e6f 7073 2e67 6174 6865 725f  = ms.ops.gather_
+0001e480: 6428 696e 7075 745f 6d73 2c20 6469 6d2c  d(input_ms, dim,
+0001e490: 2069 6e64 6963 6573 290a 2020 2020 2020   indices).      
+0001e4a0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+0001e4b0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+0001e4c0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+0001e4d0: 2073 696e 6328 7365 6c66 293a 0a20 2020   sinc(self):.   
+0001e4e0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0001e4f0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0001e500: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+0001e510: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+0001e520: 7369 6e63 2869 6e70 7574 5f6d 7329 0a20  sinc(input_ms). 
+0001e530: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+0001e540: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+0001e550: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+0001e560: 2020 6465 6620 7369 6e63 5f28 7365 6c66    def sinc_(self
+0001e570: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+0001e580: 7420 3d20 7365 6c66 2e73 696e 6328 290a  t = self.sinc().
+0001e590: 2020 2020 2020 2020 7265 7475 726e 205f          return _
+0001e5a0: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
+0001e5b0: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
+0001e5c0: 7574 2c20 2273 696e 635f 222c 2022 7369  ut, "sinc_", "si
+0001e5d0: 6e63 2229 0a0a 2020 2020 6465 6620 7369  nc")..    def si
+0001e5e0: 6e68 2873 656c 6629 3a0a 2020 2020 2020  nh(self):.      
+0001e5f0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+0001e600: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+0001e610: 656c 6629 0a20 2020 2020 2020 206f 7574  elf).        out
+0001e620: 7075 7420 3d20 6d73 2e6f 7073 2e73 696e  put = ms.ops.sin
+0001e630: 6828 696e 7075 745f 6d73 290a 2020 2020  h(input_ms).    
+0001e640: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+0001e650: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+0001e660: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+0001e670: 6566 2073 696e 685f 2873 656c 6629 3a0a  ef sinh_(self):.
+0001e680: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0001e690: 2073 656c 662e 7369 6e68 2829 0a20 2020   self.sinh().   
+0001e6a0: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
+0001e6b0: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
+0001e6c0: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
+0001e6d0: 2022 7369 6e68 5f22 2c20 2273 696e 6822   "sinh_", "sinh"
+0001e6e0: 290a 0a0a 2020 2020 6465 6620 6861 7264  )...    def hard
+0001e6f0: 7368 7269 6e6b 2873 656c 662c 206c 616d  shrink(self, lam
+0001e700: 6264 3d30 2e35 293a 0a20 2020 2020 2020  bd=0.5):.       
+0001e710: 2023 2073 7570 706f 7274 206f 6e6c 7920   # support only 
+0001e720: 666c 6f61 7431 3620 616e 6420 666c 6f61  float16 and floa
+0001e730: 7433 320a 2020 2020 2020 2020 696e 7075  t32.        inpu
+0001e740: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+0001e750: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+0001e760: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0001e770: 6d73 2e6f 7073 2e68 6172 6473 6872 696e  ms.ops.hardshrin
+0001e780: 6b28 696e 7075 745f 6d73 2c20 6c61 6d62  k(input_ms, lamb
+0001e790: 6429 0a20 2020 2020 2020 2072 6574 7572  d).        retur
+0001e7a0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0001e7b0: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0001e7c0: 0a0a 2020 2020 6465 6620 6873 706c 6974  ..    def hsplit
+0001e7d0: 2873 656c 662c 2073 706c 6974 5f73 697a  (self, split_siz
+0001e7e0: 655f 6f72 5f73 6563 7469 6f6e 7329 3a0a  e_or_sections):.
+0001e7f0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+0001e800: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+0001e810: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+0001e820: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+0001e830: 7073 2e68 7370 6c69 7428 696e 7075 745f  ps.hsplit(input_
+0001e840: 6d73 2c20 7370 6c69 745f 7369 7a65 5f6f  ms, split_size_o
+0001e850: 725f 7365 6374 696f 6e73 290a 2020 2020  r_sections).    
+0001e860: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+0001e870: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+0001e880: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+0001e890: 6566 2068 7970 6f74 2873 656c 662c 206f  ef hypot(self, o
+0001e8a0: 7468 6572 293a 0a20 2020 2020 2020 2069  ther):.        i
+0001e8b0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0001e8c0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0001e8d0: 290a 2020 2020 2020 2020 6f74 6865 725f  ).        other_
+0001e8e0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0001e8f0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+0001e900: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+0001e910: 732e 6f70 732e 6879 706f 7428 696e 7075  s.ops.hypot(inpu
+0001e920: 745f 6d73 2c20 6f74 6865 725f 6d73 290a  t_ms, other_ms).
+0001e930: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+0001e940: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+0001e950: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+0001e960: 2020 2064 6566 2068 7970 6f74 5f28 7365     def hypot_(se
+0001e970: 6c66 2c20 6f74 6865 7229 3a0a 2020 2020  lf, other):.    
+0001e980: 2020 2020 6f75 7470 7574 203d 2073 656c      output = sel
+0001e990: 662e 6879 706f 7428 6f74 6865 7229 0a20  f.hypot(other). 
+0001e9a0: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
+0001e9b0: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
+0001e9c0: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
+0001e9d0: 742c 2022 6879 706f 745f 222c 2022 6879  t, "hypot_", "hy
+0001e9e0: 706f 7422 290a 0a20 2020 2064 6566 206c  pot")..    def l
+0001e9f0: 6f67 3130 2873 656c 6629 3a0a 2020 2020  og10(self):.    
+0001ea00: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+0001ea10: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0001ea20: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+0001ea30: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6c  utput = ms.ops.l
+0001ea40: 6f67 3130 2869 6e70 7574 5f6d 7329 0a20  og10(input_ms). 
+0001ea50: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+0001ea60: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+0001ea70: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+0001ea80: 2020 6465 6620 6c6f 6731 305f 2873 656c    def log10_(sel
+0001ea90: 6629 3a0a 2020 2020 2020 2020 6f75 7470  f):.        outp
+0001eaa0: 7574 203d 2073 656c 662e 6c6f 6731 3028  ut = self.log10(
+0001eab0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0001eac0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+0001ead0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+0001eae0: 7470 7574 2c20 226c 6f67 3130 5f22 2c20  tput, "log10_", 
+0001eaf0: 226c 6f67 3130 2229 0a0a 2020 2020 6465  "log10")..    de
+0001eb00: 6620 6c6f 6731 7028 7365 6c66 293a 0a20  f log1p(self):. 
+0001eb10: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+0001eb20: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0001eb30: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+0001eb40: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+0001eb50: 732e 6c6f 6731 7028 696e 7075 745f 6d73  s.log1p(input_ms
+0001eb60: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+0001eb70: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+0001eb80: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+0001eb90: 0a20 2020 2064 6566 206c 6f67 3170 5f28  .    def log1p_(
+0001eba0: 7365 6c66 293a 0a20 2020 2020 2020 206f  self):.        o
+0001ebb0: 7574 7075 7420 3d20 7365 6c66 2e6c 6f67  utput = self.log
+0001ebc0: 3170 2829 0a20 2020 2020 2020 2072 6574  1p().        ret
+0001ebd0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+0001ebe0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+0001ebf0: 206f 7574 7075 742c 2022 6c6f 6731 705f   output, "log1p_
+0001ec00: 222c 2022 6c6f 6731 7022 290a 0a20 2020  ", "log1p")..   
+0001ec10: 2064 6566 206c 6f67 6164 6465 7870 2873   def logaddexp(s
+0001ec20: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
+0001ec30: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0001ec40: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0001ec50: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+0001ec60: 6f74 6865 725f 6d73 203d 2063 6173 745f  other_ms = cast_
+0001ec70: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
+0001ec80: 6572 290a 2020 2020 2020 2020 6f75 7470  er).        outp
+0001ec90: 7574 203d 206d 732e 6f70 732e 6c6f 6761  ut = ms.ops.loga
+0001eca0: 6464 6578 7028 696e 7075 745f 6d73 2c20  ddexp(input_ms, 
+0001ecb0: 6f74 6865 725f 6d73 290a 2020 2020 2020  other_ms).      
+0001ecc0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+0001ecd0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+0001ece0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+0001ecf0: 206c 6f67 6465 7428 7365 6c66 293a 0a20   logdet(self):. 
+0001ed00: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+0001ed10: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0001ed20: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+0001ed30: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+0001ed40: 732e 6c6f 6764 6574 2869 6e70 7574 5f6d  s.logdet(input_m
+0001ed50: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+0001ed60: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+0001ed70: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+0001ed80: 0a0a 2020 2020 6465 6620 6c6f 6769 6361  ..    def logica
+0001ed90: 6c5f 6e6f 7428 7365 6c66 293a 0a20 2020  l_not(self):.   
+0001eda0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+0001edb0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+0001edc0: 7228 7365 6c66 292e 6173 7479 7065 286d  r(self).astype(m
+0001edd0: 732e 626f 6f6c 5f29 0a20 2020 2020 2020  s.bool_).       
+0001ede0: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+0001edf0: 2e6c 6f67 6963 616c 5f6e 6f74 2869 6e70  .logical_not(inp
+0001ee00: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
+0001ee10: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+0001ee20: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+0001ee30: 7075 7429 0a0a 2020 2020 6465 6620 6c6f  put)..    def lo
+0001ee40: 6769 6361 6c5f 6e6f 745f 2873 656c 6629  gical_not_(self)
+0001ee50: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
+0001ee60: 203d 2073 656c 662e 6c6f 6769 6361 6c5f   = self.logical_
+0001ee70: 6e6f 7428 292e 6173 7479 7065 2873 656c  not().astype(sel
+0001ee80: 662e 6474 7970 6529 0a20 2020 2020 2020  f.dtype).       
+0001ee90: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+0001eea0: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+0001eeb0: 656c 662c 206f 7574 7075 742c 2022 6c6f  elf, output, "lo
+0001eec0: 6769 6361 6c5f 6e6f 745f 222c 2022 6c6f  gical_not_", "lo
+0001eed0: 6769 6361 6c5f 6e6f 7422 290a 0a20 2020  gical_not")..   
+0001eee0: 2064 6566 206c 6f67 6963 616c 5f6f 7228   def logical_or(
+0001eef0: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
+0001ef00: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0001ef10: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0001ef20: 6f72 2873 656c 6629 2e61 7374 7970 6528  or(self).astype(
+0001ef30: 6d73 2e62 6f6f 6c5f 290a 2020 2020 2020  ms.bool_).      
+0001ef40: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
+0001ef50: 6f74 6865 722c 2054 656e 736f 7229 3a0a  other, Tensor):.
+0001ef60: 2020 2020 2020 2020 2020 2020 6f74 6865              othe
+0001ef70: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
+0001ef80: 735f 7465 6e73 6f72 286f 7468 6572 292e  s_tensor(other).
+0001ef90: 6173 7479 7065 286d 732e 626f 6f6c 5f29  astype(ms.bool_)
+0001efa0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001efb0: 3d20 6d73 2e6f 7073 2e6c 6f67 6963 616c  = ms.ops.logical
+0001efc0: 5f6f 7228 696e 7075 745f 6d73 2c20 6f74  _or(input_ms, ot
+0001efd0: 6865 725f 6d73 290a 2020 2020 2020 2020  her_ms).        
+0001efe0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+0001eff0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+0001f000: 7470 7574 290a 0a20 2020 2064 6566 206c  tput)..    def l
+0001f010: 6f67 6963 616c 5f6f 725f 2873 656c 662c  ogical_or_(self,
+0001f020: 206f 7468 6572 293a 0a20 2020 2020 2020   other):.       
+0001f030: 206f 7574 7075 7420 3d20 7365 6c66 2e6c   output = self.l
+0001f040: 6f67 6963 616c 5f6f 7228 6f74 6865 7229  ogical_or(other)
+0001f050: 2e61 7374 7970 6528 7365 6c66 2e64 7479  .astype(self.dty
+0001f060: 7065 290a 2020 2020 2020 2020 7265 7475  pe).        retu
+0001f070: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+0001f080: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+0001f090: 6f75 7470 7574 2c20 226c 6f67 6963 616c  output, "logical
+0001f0a0: 5f6f 725f 222c 2022 6c6f 6769 6361 6c5f  _or_", "logical_
+0001f0b0: 6f72 2229 0a0a 2020 2020 6465 6620 6c6f  or")..    def lo
+0001f0c0: 6769 6361 6c5f 786f 7228 7365 6c66 2c20  gical_xor(self, 
+0001f0d0: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
+0001f0e0: 6966 2069 7369 6e73 7461 6e63 6528 7365  if isinstance(se
+0001f0f0: 6c66 2c20 5465 6e73 6f72 293a 0a20 2020  lf, Tensor):.   
+0001f100: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
+0001f110: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+0001f120: 656e 736f 7228 7365 6c66 292e 6173 7479  ensor(self).asty
+0001f130: 7065 286d 732e 626f 6f6c 5f29 0a20 2020  pe(ms.bool_).   
+0001f140: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
+0001f150: 6365 286f 7468 6572 2c20 5465 6e73 6f72  ce(other, Tensor
+0001f160: 293a 0a20 2020 2020 2020 2020 2020 206f  ):.            o
+0001f170: 7468 6572 203d 2063 6173 745f 746f 5f6d  ther = cast_to_m
+0001f180: 735f 7465 6e73 6f72 286f 7468 6572 292e  s_tensor(other).
+0001f190: 6173 7479 7065 286d 732e 626f 6f6c 5f29  astype(ms.bool_)
+0001f1a0: 0a0a 2020 2020 2020 2020 2320 544f 444f  ..        # TODO
+0001f1b0: 3a20 6d73 2e6f 7073 2e6c 6f67 6963 616c  : ms.ops.logical
+0001f1c0: 5f78 6f72 2074 6f20 7375 7070 6f72 7465  _xor to supporte
+0001f1d0: 6420 4750 550a 2020 2020 2020 2020 6966  d GPU.        if
+0001f1e0: 2069 735f 756e 6465 725f 6770 755f 636f   is_under_gpu_co
+0001f1f0: 6e74 6578 7428 293a 0a20 2020 2020 2020  ntext():.       
+0001f200: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+0001f210: 2e6e 756d 7079 2e6c 6f67 6963 616c 5f78  .numpy.logical_x
+0001f220: 6f72 2869 6e70 7574 5f6d 732c 206f 7468  or(input_ms, oth
+0001f230: 6572 290a 2020 2020 2020 2020 656c 7365  er).        else
+0001f240: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
+0001f250: 7470 7574 203d 206d 732e 6f70 732e 6c6f  tput = ms.ops.lo
+0001f260: 6769 6361 6c5f 786f 7228 696e 7075 745f  gical_xor(input_
+0001f270: 6d73 2c20 6f74 6865 7229 0a20 2020 2020  ms, other).     
+0001f280: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+0001f290: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0001f2a0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+0001f2b0: 6620 6c6f 6769 6361 6c5f 786f 725f 2873  f logical_xor_(s
+0001f2c0: 656c 662c 206f 7468 6572 293a 0a20 2020  elf, other):.   
+0001f2d0: 2020 2020 206f 7574 7075 7420 3d20 7365       output = se
+0001f2e0: 6c66 2e6c 6f67 6963 616c 5f78 6f72 286f  lf.logical_xor(o
+0001f2f0: 7468 6572 292e 6173 7479 7065 2873 656c  ther).astype(sel
+0001f300: 662e 6474 7970 6529 0a20 2020 2020 2020  f.dtype).       
+0001f310: 2072 6574 7572 6e20 5f74 656e 736f 725f   return _tensor_
+0001f320: 696e 706c 6163 655f 6173 7369 676e 2873  inplace_assign(s
+0001f330: 656c 662c 206f 7574 7075 742c 2022 6c6f  elf, output, "lo
+0001f340: 6769 6361 6c5f 786f 725f 222c 2022 6c6f  gical_xor_", "lo
+0001f350: 6769 6361 6c5f 786f 7222 290a 0a20 2020  gical_xor")..   
+0001f360: 2064 6566 2061 646a 6f69 6e74 2873 656c   def adjoint(sel
+0001f370: 6629 3a0a 2020 2020 2020 2020 696e 7075  f):.        inpu
+0001f380: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+0001f390: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+0001f3a0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+0001f3b0: 6d73 2e6f 7073 2e61 646a 6f69 6e74 2869  ms.ops.adjoint(i
+0001f3c0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
+0001f3d0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+0001f3e0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+0001f3f0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
+0001f400: 6c65 7270 2873 656c 662c 2065 6e64 2c20  lerp(self, end, 
+0001f410: 7765 6967 6874 293a 0a20 2020 2020 2020  weight):.       
+0001f420: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+0001f430: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+0001f440: 6c66 290a 2020 2020 2020 2020 656e 645f  lf).        end_
+0001f450: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0001f460: 7465 6e73 6f72 2865 6e64 290a 2020 2020  tensor(end).    
+0001f470: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+0001f480: 6528 7765 6967 6874 2c20 5465 6e73 6f72  e(weight, Tensor
+0001f490: 293a 0a20 2020 2020 2020 2020 2020 2077  ):.            w
+0001f4a0: 6569 6768 7420 3d20 6361 7374 5f74 6f5f  eight = cast_to_
+0001f4b0: 6d73 5f74 656e 736f 7228 7765 6967 6874  ms_tensor(weight
+0001f4c0: 290a 2020 2020 2020 2020 656c 6966 206e  ).        elif n
+0001f4d0: 6f74 2069 7369 6e73 7461 6e63 6528 7765  ot isinstance(we
+0001f4e0: 6967 6874 2c20 666c 6f61 7429 3a0a 2020  ight, float):.  
+0001f4f0: 2020 2020 2020 2020 2020 7765 6967 6874            weight
+0001f500: 203d 2066 6c6f 6174 2877 6569 6768 7429   = float(weight)
+0001f510: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+0001f520: 3d20 6d73 2e6f 7073 2e6c 6572 7028 696e  = ms.ops.lerp(in
+0001f530: 7075 745f 6d73 2c20 656e 645f 6d73 2c20  put_ms, end_ms, 
+0001f540: 7765 6967 6874 290a 2020 2020 2020 2020  weight).        
+0001f550: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+0001f560: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+0001f570: 7470 7574 290a 0a20 2020 2064 6566 206c  tput)..    def l
+0001f580: 6572 705f 2873 656c 662c 2065 6e64 2c20  erp_(self, end, 
+0001f590: 7765 6967 6874 293a 0a20 2020 2020 2020  weight):.       
+0001f5a0: 206f 7574 7075 7420 3d20 7365 6c66 2e6c   output = self.l
+0001f5b0: 6572 7028 656e 642c 2077 6569 6768 7429  erp(end, weight)
+0001f5c0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001f5d0: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+0001f5e0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+0001f5f0: 7075 742c 2022 6c65 7270 5f22 2c20 226c  put, "lerp_", "l
+0001f600: 6572 7022 290a 0a20 2020 2064 6566 206c  erp")..    def l
+0001f610: 7528 7365 6c66 2c20 2a2c 2070 6976 6f74  u(self, *, pivot
+0001f620: 3d54 7275 652c 2067 6574 5f69 6e66 6f73  =True, get_infos
+0001f630: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
+0001f640: 2069 6620 6765 745f 696e 666f 733a 0a20   if get_infos:. 
+0001f650: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+0001f660: 7431 2c20 696e 666f 203d 205f 6c75 5f66  t1, info = _lu_f
+0001f670: 6163 746f 725f 6578 2873 656c 662c 2070  actor_ex(self, p
+0001f680: 6976 6f74 3d70 6976 6f74 290a 2020 2020  ivot=pivot).    
+0001f690: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+0001f6a0: 206f 7574 7075 7431 202b 2028 696e 666f   output1 + (info
+0001f6b0: 2c29 0a20 2020 2020 2020 2065 6c73 653a  ,).        else:
+0001f6c0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+0001f6d0: 7075 7420 3d20 5f6c 755f 6661 6374 6f72  put = _lu_factor
+0001f6e0: 2873 656c 662c 2070 6976 6f74 3d70 6976  (self, pivot=piv
+0001f6f0: 6f74 290a 2020 2020 2020 2020 7265 7475  ot).        retu
+0001f700: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+0001f710: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+0001f720: 290a 0a20 2020 2064 6566 206c 755f 736f  )..    def lu_so
+0001f730: 6c76 6528 7365 6c66 2c20 4c55 5f64 6174  lve(self, LU_dat
+0001f740: 612c 204c 555f 7069 766f 7473 293a 0a20  a, LU_pivots):. 
+0001f750: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
+0001f760: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+0001f770: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
+0001f780: 2020 4c55 5f64 6174 6120 3d20 6361 7374    LU_data = cast
+0001f790: 5f74 6f5f 6d73 5f74 656e 736f 7228 4c55  _to_ms_tensor(LU
+0001f7a0: 5f64 6174 6129 0a20 2020 2020 2020 204c  _data).        L
+0001f7b0: 555f 7069 766f 7473 203d 2063 6173 745f  U_pivots = cast_
+0001f7c0: 746f 5f6d 735f 7465 6e73 6f72 284c 555f  to_ms_tensor(LU_
+0001f7d0: 7069 766f 7473 290a 2020 2020 2020 2020  pivots).        
+0001f7e0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+0001f7f0: 6c75 5f73 6f6c 7665 2869 6e70 7574 5f6d  lu_solve(input_m
+0001f800: 732c 204c 555f 6461 7461 2c20 4c55 5f70  s, LU_data, LU_p
+0001f810: 6976 6f74 7329 0a20 2020 2020 2020 2072  ivots).        r
+0001f820: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+0001f830: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+0001f840: 7075 7429 0a0a 2020 2020 6465 6620 6d61  put)..    def ma
+0001f850: 736b 6564 5f73 656c 6563 7428 7365 6c66  sked_select(self
+0001f860: 2c20 6d61 736b 293a 0a20 2020 2020 2020  , mask):.       
+0001f870: 206d 6173 6b5f 6d73 203d 2063 6173 745f   mask_ms = cast_
+0001f880: 746f 5f6d 735f 7465 6e73 6f72 286d 6173  to_ms_tensor(mas
+0001f890: 6b29 0a20 2020 2020 2020 206d 6173 6b5f  k).        mask_
+0001f8a0: 6474 7970 6520 3d20 6d61 736b 2e64 7479  dtype = mask.dty
+0001f8b0: 7065 0a20 2020 2020 2020 2069 6620 6d61  pe.        if ma
+0001f8c0: 736b 5f64 7479 7065 206e 6f74 2069 6e20  sk_dtype not in 
+0001f8d0: 286d 732e 626f 6f6c 5f2c 206d 732e 7569  (ms.bool_, ms.ui
+0001f8e0: 6e74 3829 3a0a 2020 2020 2020 2020 2020  nt8):.          
+0001f8f0: 2020 7261 6973 6520 5275 6e74 696d 6545    raise RuntimeE
+0001f900: 7272 6f72 2822 6d61 736b 6564 5f73 656c  rror("masked_sel
+0001f910: 6563 743a 2065 7870 6563 7465 6420 426f  ect: expected Bo
+0001f920: 6f6c 5465 6e73 6f72 206f 7220 4279 7465  olTensor or Byte
+0001f930: 5465 6e73 6f72 2066 6f72 206d 6173 6b22  Tensor for mask"
+0001f940: 290a 2020 2020 2020 2020 696e 7075 745f  ).        input_
+0001f950: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+0001f960: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+0001f970: 2020 2020 2069 6620 6d61 736b 5f64 7479       if mask_dty
+0001f980: 7065 203d 3d20 6d73 2e75 696e 7438 3a0a  pe == ms.uint8:.
+0001f990: 2020 2020 2020 2020 2020 2020 7761 726e              warn
+0001f9a0: 696e 6728 226d 6173 6b65 645f 7365 6c65  ing("masked_sele
+0001f9b0: 6374 2072 6563 6569 7665 6420 6120 6d61  ct received a ma
+0001f9c0: 736b 2077 6974 6820 6474 7970 6520 746f  sk with dtype to
+0001f9d0: 7263 682e 7569 6e74 382c 2074 6869 7320  rch.uint8, this 
+0001f9e0: 6265 6861 7669 6f72 2069 7320 6e6f 7720  behavior is now 
+0001f9f0: 6465 7072 6563 6174 6564 2c20 2220 5c0a  deprecated, " \.
+0001fa00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fa10: 2020 2020 2270 6c65 6173 6520 7573 6520      "please use 
+0001fa20: 6120 6d61 736b 2077 6974 6820 6474 7970  a mask with dtyp
+0001fa30: 6520 746f 7263 682e 626f 6f6c 2069 6e73  e torch.bool ins
+0001fa40: 7465 6164 2229 0a20 2020 2020 2020 2020  tead").         
+0001fa50: 2020 206d 6173 6b5f 6d73 203d 206d 6173     mask_ms = mas
+0001fa60: 6b5f 6d73 2e61 7374 7970 6528 6d73 2e62  k_ms.astype(ms.b
+0001fa70: 6f6f 6c5f 290a 2020 2020 2020 2020 6f75  ool_).        ou
+0001fa80: 7470 7574 203d 206d 732e 6f70 732e 6d61  tput = ms.ops.ma
+0001fa90: 736b 6564 5f73 656c 6563 7428 696e 7075  sked_select(inpu
+0001faa0: 745f 6d73 2c20 6d61 736b 5f6d 7329 0a20  t_ms, mask_ms). 
+0001fab0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+0001fac0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+0001fad0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+0001fae0: 2020 6465 6620 616e 676c 6528 7365 6c66    def angle(self
+0001faf0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0001fb00: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0001fb10: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0001fb20: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+0001fb30: 732e 6f70 732e 616e 676c 6528 696e 7075  s.ops.angle(inpu
+0001fb40: 745f 6d73 290a 2020 2020 2020 2020 7265  t_ms).        re
+0001fb50: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0001fb60: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+0001fb70: 7574 290a 0a20 2020 2064 6566 2065 6c65  ut)..    def ele
+0001fb80: 6d65 6e74 5f73 697a 6528 7365 6c66 293a  ment_size(self):
+0001fb90: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001fba0: 7365 6c66 2e69 7465 6d73 697a 650a 0a20  self.itemsize.. 
+0001fbb0: 2020 2064 6566 2061 7267 7768 6572 6528     def argwhere(
+0001fbc0: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
+0001fbd0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+0001fbe0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+0001fbf0: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+0001fc00: 203d 206d 732e 6f70 732e 6172 6777 6865   = ms.ops.argwhe
+0001fc10: 7265 2869 6e70 7574 5f6d 7329 0a20 2020  re(input_ms).   
+0001fc20: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+0001fc30: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+0001fc40: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+0001fc50: 6465 6620 6361 7563 6879 5f28 7365 6c66  def cauchy_(self
+0001fc60: 2c20 6d65 6469 616e 3d30 2c20 7369 676d  , median=0, sigm
+0001fc70: 613d 312c 202a 2c20 6765 6e65 7261 746f  a=1, *, generato
+0001fc80: 723d 4e6f 6e65 293a 0a20 2020 2020 2020  r=None):.       
+0001fc90: 2069 6620 6765 6e65 7261 746f 723a 0a20   if generator:. 
+0001fca0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0001fcb0: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+0001fcc0: 7272 6f72 2822 466f 7220 7465 6e73 6f72  rror("For tensor
+0001fcd0: 2e63 6175 6368 792c 2067 656e 6572 6174  .cauchy, generat
+0001fce0: 6f72 2068 6173 206e 6f74 2062 6565 6e20  or has not been 
+0001fcf0: 7375 7070 6f72 7465 642e 2229 0a0a 2020  supported.")..  
+0001fd00: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+0001fd10: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+0001fd20: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+0001fd30: 205f 7368 6170 6520 3d20 696e 7075 745f   _shape = input_
+0001fd40: 6d73 2e73 6861 7065 0a20 2020 2020 2020  ms.shape.       
+0001fd50: 206f 7574 7075 7420 3d20 5f67 6574 5f63   output = _get_c
+0001fd60: 6163 6865 5f70 7269 6d28 6d73 2e6f 7073  ache_prim(ms.ops
+0001fd70: 2e43 6175 6368 7929 286c 6973 7428 5f73  .Cauchy)(list(_s
+0001fd80: 6861 7065 292c 2073 6967 6d61 3d66 6c6f  hape), sigma=flo
+0001fd90: 6174 2873 6967 6d61 292c 206d 6564 6961  at(sigma), media
+0001fda0: 6e3d 666c 6f61 7428 6d65 6469 616e 2929  n=float(median))
+0001fdb0: 2829 0a0a 2020 2020 2020 2020 7265 7475  ()..        retu
+0001fdc0: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+0001fdd0: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+0001fde0: 6f75 7470 7574 2c20 2263 6175 6368 795f  output, "cauchy_
+0001fdf0: 222c 2022 6361 7563 6879 2229 0a0a 2020  ", "cauchy")..  
+0001fe00: 2020 6465 6620 636f 6e6a 5f70 6879 7369    def conj_physi
+0001fe10: 6361 6c28 7365 6c66 293a 0a20 2020 2020  cal(self):.     
+0001fe20: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+0001fe30: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+0001fe40: 7365 6c66 290a 2020 2020 2020 2020 6966  self).        if
+0001fe50: 206d 732e 6f70 732e 6973 5f63 6f6d 706c   ms.ops.is_compl
+0001fe60: 6578 2869 6e70 7574 5f6d 7329 3a0a 2020  ex(input_ms):.  
+0001fe70: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+0001fe80: 203d 206d 732e 6f70 732e 636f 6e6a 2869   = ms.ops.conj(i
+0001fe90: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
+0001fea0: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+0001feb0: 2020 206f 7574 7075 7420 3d20 696e 7075     output = inpu
+0001fec0: 745f 6d73 0a20 2020 2020 2020 2072 6574  t_ms.        ret
+0001fed0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+0001fee0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+0001fef0: 7429 0a0a 2020 2020 6465 6620 636f 6e6a  t)..    def conj
+0001ff00: 5f70 6879 7369 6361 6c5f 2873 656c 6629  _physical_(self)
+0001ff10: 3a0a 2020 2020 2020 2020 6f75 7470 7574  :.        output
+0001ff20: 203d 2073 656c 662e 636f 6e6a 5f70 6879   = self.conj_phy
+0001ff30: 7369 6361 6c28 290a 2020 2020 2020 2020  sical().        
+0001ff40: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
+0001ff50: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
+0001ff60: 6c66 2c20 6f75 7470 7574 2c20 2263 6f6e  lf, output, "con
+0001ff70: 6a5f 7068 7973 6963 616c 5f22 2c20 2263  j_physical_", "c
+0001ff80: 6f6e 6a5f 7068 7973 6963 616c 2229 0a0a  onj_physical")..
+0001ff90: 2020 2020 6465 6620 706f 7369 7469 7665      def positive
+0001ffa0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+0001ffb0: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+0001ffc0: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+0001ffd0: 6629 0a20 2020 2020 2020 206f 7574 7075  f).        outpu
+0001ffe0: 7420 3d20 6d73 2e6f 7073 2e70 6f73 6974  t = ms.ops.posit
+0001fff0: 6976 6528 696e 7075 745f 6d73 290a 2020  ive(input_ms).  
+00020000: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00020010: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00020020: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00020030: 2064 6566 206f 7574 6572 2873 656c 662c   def outer(self,
+00020040: 2076 6563 3229 3a0a 2020 2020 2020 2020   vec2):.        
+00020050: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+00020060: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00020070: 6629 0a20 2020 2020 2020 2076 6563 3220  f).        vec2 
+00020080: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00020090: 736f 7228 7665 6332 290a 2020 2020 2020  sor(vec2).      
+000200a0: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+000200b0: 732e 6f75 7465 7228 696e 7075 745f 6d73  s.outer(input_ms
+000200c0: 2c20 7665 6332 290a 2020 2020 2020 2020  , vec2).        
+000200d0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+000200e0: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+000200f0: 7470 7574 290a 0a20 2020 2064 6566 2073  tput)..    def s
+00020100: 676e 2873 656c 6629 3a0a 2020 2020 2020  gn(self):.      
+00020110: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+00020120: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+00020130: 656c 6629 0a20 2020 2020 2020 2069 6620  elf).        if 
+00020140: 2742 6f6f 6c27 2069 6e20 7374 7228 696e  'Bool' in str(in
+00020150: 7075 745f 6d73 2e64 7479 7065 2920 6f72  put_ms.dtype) or
+00020160: 2027 496e 7427 2069 6e20 7374 7228 696e   'Int' in str(in
+00020170: 7075 745f 6d73 2e64 7479 7065 293a 0a20  put_ms.dtype):. 
+00020180: 2020 2020 2020 2020 2020 2074 7970 6520             type 
+00020190: 3d20 696e 7075 745f 6d73 2e64 7479 7065  = input_ms.dtype
+000201a0: 0a20 2020 2020 2020 2020 2020 2069 6e70  .            inp
+000201b0: 7574 5f6d 7320 3d20 696e 7075 745f 6d73  ut_ms = input_ms
+000201c0: 2e61 7374 7970 6528 6d73 2e66 6c6f 6174  .astype(ms.float
+000201d0: 3332 290a 2020 2020 2020 2020 2020 2020  32).            
+000201e0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+000201f0: 7367 6e28 696e 7075 745f 6d73 292e 6173  sgn(input_ms).as
+00020200: 7479 7065 2874 7970 6529 0a20 2020 2020  type(type).     
+00020210: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00020220: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+00020230: 2e6f 7073 2e73 676e 2869 6e70 7574 5f6d  .ops.sgn(input_m
+00020240: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+00020250: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00020260: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00020270: 0a0a 2020 2020 6465 6620 7367 6e5f 2873  ..    def sgn_(s
+00020280: 656c 6629 3a0a 2020 2020 2020 2020 6f75  elf):.        ou
+00020290: 7470 7574 203d 2073 656c 662e 7367 6e28  tput = self.sgn(
+000202a0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000202b0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+000202c0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+000202d0: 7470 7574 2c20 2273 676e 5f22 2c20 2273  tput, "sgn_", "s
+000202e0: 676e 2229 0a0a 2020 2020 6465 6620 6c6f  gn")..    def lo
+000202f0: 6769 6361 6c5f 616e 6428 7365 6c66 2c20  gical_and(self, 
+00020300: 6f74 6865 7229 3a0a 2020 2020 2020 2020  other):.        
+00020310: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
+00020320: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
+00020330: 6629 2e61 7374 7970 6528 6d73 2e62 6f6f  f).astype(ms.boo
+00020340: 6c5f 290a 2020 2020 2020 2020 6966 2069  l_).        if i
+00020350: 7369 6e73 7461 6e63 6528 6f74 6865 722c  sinstance(other,
+00020360: 2054 656e 736f 7229 3a0a 2020 2020 2020   Tensor):.      
+00020370: 2020 2020 2020 6f74 6865 7220 3d20 6361        other = ca
+00020380: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00020390: 6f74 6865 7229 2e61 7374 7970 6528 6d73  other).astype(ms
+000203a0: 7479 7065 2e62 6f6f 6c5f 290a 2020 2020  type.bool_).    
+000203b0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+000203c0: 6f70 732e 6c6f 6769 6361 6c5f 616e 6428  ops.logical_and(
+000203d0: 696e 7075 745f 6d73 2c20 6f74 6865 7229  input_ms, other)
+000203e0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+000203f0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00020400: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+00020410: 2020 2020 6465 6620 6c6f 6769 6361 6c5f      def logical_
+00020420: 616e 645f 2873 656c 662c 206f 7468 6572  and_(self, other
+00020430: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+00020440: 7420 3d20 7365 6c66 2e6c 6f67 6963 616c  t = self.logical
+00020450: 5f61 6e64 286f 7468 6572 292e 6173 7479  _and(other).asty
+00020460: 7065 2873 656c 662e 6474 7970 6529 0a20  pe(self.dtype). 
+00020470: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
+00020480: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
+00020490: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
+000204a0: 742c 2022 6c6f 6769 6361 6c5f 616e 645f  t, "logical_and_
+000204b0: 222c 2022 6c6f 6769 6361 6c5f 616e 6422  ", "logical_and"
+000204c0: 290a 0a20 2020 2064 6566 2069 6761 6d6d  )..    def igamm
+000204d0: 6128 7365 6c66 2c20 6f74 6865 7229 3a0a  a(self, other):.
+000204e0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+000204f0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00020500: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00020510: 2020 206f 7468 6572 5f6d 7320 3d20 6361     other_ms = ca
+00020520: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00020530: 6f74 6865 7229 0a20 2020 2020 2020 2023  other).        #
+00020540: 2054 4f44 4f3a 2061 6674 6572 206d 732e   TODO: after ms.
+00020550: 6f70 732e 6967 616d 6d61 2073 7570 706f  ops.igamma suppo
+00020560: 7274 2066 6c6f 6174 3136 2c20 6465 6c65  rt float16, dele
+00020570: 7465 2063 6f64 6520 6265 6c6f 770a 2020  te code below.  
+00020580: 2020 2020 2020 696e 7075 745f 6d73 2c20        input_ms, 
+00020590: 6f74 6865 725f 6d73 2c20 666c 6167 203d  other_ms, flag =
+000205a0: 205f 6761 6d6d 615f 7479 7065 2869 6e70   _gamma_type(inp
+000205b0: 7574 5f6d 732c 206f 7468 6572 5f6d 7329  ut_ms, other_ms)
+000205c0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+000205d0: 3d20 6d73 2e6f 7073 2e69 6761 6d6d 6128  = ms.ops.igamma(
+000205e0: 696e 7075 745f 6d73 2c20 6f74 6865 725f  input_ms, other_
+000205f0: 6d73 290a 2020 2020 2020 2020 6966 2066  ms).        if f
+00020600: 6c61 673a 0a20 2020 2020 2020 2020 2020  lag:.           
+00020610: 206f 7574 7075 7420 3d20 6f75 7470 7574   output = output
+00020620: 2e61 7374 7970 6528 6d73 2e66 6c6f 6174  .astype(ms.float
+00020630: 3136 290a 2020 2020 2020 2020 7265 7475  16).        retu
+00020640: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00020650: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+00020660: 290a 0a20 2020 2064 6566 2069 6761 6d6d  )..    def igamm
+00020670: 6163 2873 656c 662c 206f 7468 6572 293a  ac(self, other):
+00020680: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+00020690: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+000206a0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+000206b0: 2020 2020 6f74 6865 725f 6d73 203d 2063      other_ms = c
+000206c0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+000206d0: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
+000206e0: 2320 544f 444f 3a20 6166 7465 7220 6d73  # TODO: after ms
+000206f0: 2e6f 7073 2e69 6761 6d6d 6163 2073 7570  .ops.igammac sup
+00020700: 706f 7274 2066 6c6f 6174 3136 2c20 6465  port float16, de
+00020710: 6c65 7465 2063 6f64 6520 6265 6c6f 770a  lete code below.
+00020720: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00020730: 2c20 6f74 6865 725f 6d73 2c20 666c 6167  , other_ms, flag
+00020740: 203d 205f 6761 6d6d 615f 7479 7065 2869   = _gamma_type(i
+00020750: 6e70 7574 5f6d 732c 206f 7468 6572 5f6d  nput_ms, other_m
+00020760: 7329 0a20 2020 2020 2020 206f 7574 7075  s).        outpu
+00020770: 7420 3d20 6d73 2e6f 7073 2e69 6761 6d6d  t = ms.ops.igamm
+00020780: 6163 2869 6e70 7574 5f6d 732c 206f 7468  ac(input_ms, oth
+00020790: 6572 5f6d 7329 0a20 2020 2020 2020 2069  er_ms).        i
+000207a0: 6620 666c 6167 3a0a 2020 2020 2020 2020  f flag:.        
+000207b0: 2020 2020 6f75 7470 7574 203d 206f 7574      output = out
+000207c0: 7075 742e 6173 7479 7065 286d 732e 666c  put.astype(ms.fl
+000207d0: 6f61 7431 3629 0a20 2020 2020 2020 2072  oat16).        r
+000207e0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+000207f0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00020800: 7075 7429 0a0a 2020 2020 6465 6620 6c63  put)..    def lc
+00020810: 6d28 7365 6c66 2c20 6f74 6865 7229 3a0a  m(self, other):.
+00020820: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00020830: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00020840: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00020850: 2020 206f 7468 6572 5f6d 7320 3d20 6361     other_ms = ca
+00020860: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00020870: 6f74 6865 7229 0a20 2020 2020 2020 206f  other).        o
+00020880: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6c  utput = ms.ops.l
+00020890: 636d 2869 6e70 7574 5f6d 732c 206f 7468  cm(input_ms, oth
+000208a0: 6572 5f6d 7329 0a20 2020 2020 2020 2072  er_ms).        r
+000208b0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+000208c0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+000208d0: 7075 7429 0a0a 2020 2020 6465 6620 6c63  put)..    def lc
+000208e0: 6d5f 2873 656c 662c 206f 7468 6572 293a  m_(self, other):
+000208f0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+00020900: 3d20 7365 6c66 2e6c 636d 286f 7468 6572  = self.lcm(other
+00020910: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00020920: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+00020930: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+00020940: 7470 7574 2c20 226c 636d 5f22 2c20 226c  tput, "lcm_", "l
+00020950: 636d 2229 0a0a 2020 2020 6465 6620 696e  cm")..    def in
+00020960: 6e65 7228 7365 6c66 2c20 6f74 6865 7229  ner(self, other)
+00020970: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+00020980: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00020990: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+000209a0: 2020 2020 206f 7468 6572 5f6d 7320 3d20       other_ms = 
+000209b0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+000209c0: 7228 6f74 6865 7229 0a20 2020 2020 2020  r(other).       
+000209d0: 2069 6620 6973 5f75 6e64 6572 5f67 7075   if is_under_gpu
+000209e0: 5f63 6f6e 7465 7874 2829 2061 6e64 2069  _context() and i
+000209f0: 6e70 7574 5f6d 732e 6474 7970 6520 696e  nput_ms.dtype in
+00020a00: 2061 6c6c 5f69 6e74 5f74 7970 653a 0a20   all_int_type:. 
+00020a10: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00020a20: 5f74 7970 6520 3d20 696e 7075 745f 6d73  _type = input_ms
+00020a30: 2e64 7479 7065 0a20 2020 2020 2020 2020  .dtype.         
+00020a40: 2020 206f 7468 6572 5f74 7970 6520 3d20     other_type = 
+00020a50: 6f74 6865 725f 6d73 2e64 7479 7065 0a20  other_ms.dtype. 
+00020a60: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00020a70: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
+00020a80: 7374 7970 6528 6d73 7479 7065 2e66 6c6f  stype(mstype.flo
+00020a90: 6174 3332 290a 2020 2020 2020 2020 2020  at32).          
+00020aa0: 2020 6f74 6865 725f 6d73 203d 206f 7468    other_ms = oth
+00020ab0: 6572 5f6d 732e 6173 7479 7065 286d 7374  er_ms.astype(mst
+00020ac0: 7970 652e 666c 6f61 7433 3229 0a20 2020  ype.float32).   
+00020ad0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00020ae0: 3d20 6d73 2e6f 7073 2e69 6e6e 6572 2869  = ms.ops.inner(i
+00020af0: 6e70 7574 5f6d 732c 206f 7468 6572 5f6d  nput_ms, other_m
+00020b00: 7329 0a20 2020 2020 2020 2020 2020 206f  s).            o
+00020b10: 7574 7075 7420 3d20 6d73 2e6f 7073 2e63  utput = ms.ops.c
+00020b20: 6173 7428 6f75 7470 7574 2c20 7072 6f6d  ast(output, prom
+00020b30: 6f74 655f 7479 7065 5f6c 6f6f 6b75 7028  ote_type_lookup(
+00020b40: 696e 7075 745f 7479 7065 2c20 6f74 6865  input_type, othe
+00020b50: 725f 7479 7065 2929 0a20 2020 2020 2020  r_type)).       
+00020b60: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00020b70: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+00020b80: 7073 2e69 6e6e 6572 2869 6e70 7574 5f6d  ps.inner(input_m
+00020b90: 732c 206f 7468 6572 5f6d 7329 0a20 2020  s, other_ms).   
+00020ba0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00020bb0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00020bc0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00020bd0: 6465 6620 726f 6c6c 2873 656c 662c 2073  def roll(self, s
+00020be0: 6869 6674 732c 2064 696d 733d 4e6f 6e65  hifts, dims=None
+00020bf0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+00020c00: 5f6d 7320 203d 2063 6173 745f 746f 5f6d  _ms  = cast_to_m
+00020c10: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00020c20: 2020 2020 2020 2023 2054 4f44 4f3a 2073         # TODO: s
+00020c30: 7570 706f 7274 2072 6f6c 6c20 6f6e 2043  upport roll on C
+00020c40: 5055 2061 6e64 2041 7363 656e 6420 706c  PU and Ascend pl
+00020c50: 6174 666f 726d 2e20 4375 7272 656e 746c  atform. Currentl
+00020c60: 7920 7573 6520 6e75 6d70 7920 6675 6e63  y use numpy func
+00020c70: 0a20 2020 2020 2020 2023 2054 4f44 4f3a  .        # TODO:
+00020c80: 206f 6e20 4173 6365 6e64 2c20 6d73 2e6f   on Ascend, ms.o
+00020c90: 7073 2e72 6f6c 6c20 6361 6e20 6f6e 6c79  ps.roll can only
+00020ca0: 2061 6363 6570 7420 7368 6966 7473 2077   accept shifts w
+00020cb0: 6974 6820 7369 6e67 6c65 206e 756d 6265  ith single numbe
+00020cc0: 722e 0a20 2020 2020 2020 2069 6620 6e6f  r..        if no
+00020cd0: 7420 6973 5f75 6e64 6572 5f67 7075 5f63  t is_under_gpu_c
+00020ce0: 6f6e 7465 7874 2829 3a0a 2020 2020 2020  ontext():.      
+00020cf0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00020d00: 732e 6e75 6d70 792e 726f 6c6c 2869 6e70  s.numpy.roll(inp
+00020d10: 7574 5f6d 732c 2073 6869 6674 732c 2064  ut_ms, shifts, d
+00020d20: 696d 7329 0a20 2020 2020 2020 2065 6c73  ims).        els
+00020d30: 653a 0a20 2020 2020 2020 2020 2020 206f  e:.            o
+00020d40: 7574 7075 7420 3d20 6d73 2e6f 7073 2e72  utput = ms.ops.r
+00020d50: 6f6c 6c28 696e 7075 745f 6d73 2c20 7368  oll(input_ms, sh
+00020d60: 6966 7473 2c20 6469 6d73 290a 2020 2020  ifts, dims).    
+00020d70: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+00020d80: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00020d90: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+00020da0: 6566 2075 6e66 6f6c 6428 7365 6c66 2c20  ef unfold(self, 
+00020db0: 6469 6d65 6e73 696f 6e2c 2073 697a 652c  dimension, size,
+00020dc0: 2073 7465 7029 3a0a 2020 2020 2020 2020   step):.        
+00020dd0: 2320 544f 444f 3a20 6d69 6e64 7370 6f72  # TODO: mindspor
+00020de0: 6520 646f 206e 6f74 2068 6176 6520 7265  e do not have re
+00020df0: 6c61 7465 6420 696e 7465 7266 6163 652c  lated interface,
+00020e00: 206d 732e 6f70 732e 756e 666f 6c64 2069   ms.ops.unfold i
+00020e10: 7320 6e6f 7420 7468 6520 7361 6d65 2061  s not the same a
+00020e20: 7320 7468 6973 2069 6e74 6572 6661 6365  s this interface
+00020e30: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+00020e40: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00020e50: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+00020e60: 2020 2020 5f69 6e64 6963 6573 2c20 5f64      _indices, _d
+00020e70: 696d 656e 7369 6f6e 203d 205f 6765 745f  imension = _get_
+00020e80: 756e 666f 6c64 5f69 6e64 6963 6573 2869  unfold_indices(i
+00020e90: 6e70 7574 5f6d 732e 7368 6170 652c 2064  nput_ms.shape, d
+00020ea0: 696d 656e 7369 6f6e 2c20 7369 7a65 2c20  imension, size, 
+00020eb0: 7374 6570 290a 2020 2020 2020 2020 696e  step).        in
+00020ec0: 6469 6365 7320 3d20 6d73 2e54 656e 736f  dices = ms.Tenso
+00020ed0: 7228 5f69 6e64 6963 6573 292e 6173 7479  r(_indices).asty
+00020ee0: 7065 286d 732e 696e 7433 3229 0a20 2020  pe(ms.int32).   
+00020ef0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+00020f00: 2e6f 7073 2e67 6174 6865 7228 696e 7075  .ops.gather(inpu
+00020f10: 745f 6d73 2c20 696e 6469 6365 732c 2061  t_ms, indices, a
+00020f20: 7869 733d 5f64 696d 656e 7369 6f6e 290a  xis=_dimension).
+00020f30: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00020f40: 206d 732e 6f70 732e 6d6f 7665 6178 6973   ms.ops.moveaxis
+00020f50: 286f 7574 7075 742c 205f 6469 6d65 6e73  (output, _dimens
+00020f60: 696f 6e20 2b20 312c 202d 3129 0a20 2020  ion + 1, -1).   
+00020f70: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00020f80: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00020f90: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00020fa0: 6465 6620 736c 6f67 6465 7428 7365 6c66  def slogdet(self
+00020fb0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+00020fc0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+00020fd0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+00020fe0: 2020 2020 2020 7369 676e 2c20 6f75 7470        sign, outp
+00020ff0: 7574 203d 206d 732e 6f70 732e 736c 6f67  ut = ms.ops.slog
+00021000: 6465 7428 696e 7075 745f 6d73 290a 2020  det(input_ms).  
+00021010: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00021020: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00021030: 736f 7228 2873 6967 6e2c 206f 7574 7075  sor((sign, outpu
+00021040: 7429 290a 0a20 2020 2064 6566 2073 6c69  t))..    def sli
+00021050: 6365 5f73 6361 7474 6572 2873 656c 662c  ce_scatter(self,
+00021060: 2073 7263 2c20 6469 6d3d 302c 2073 7461   src, dim=0, sta
+00021070: 7274 3d4e 6f6e 652c 2065 6e64 3d4e 6f6e  rt=None, end=Non
+00021080: 652c 2073 7465 703d 3129 3a0a 2020 2020  e, step=1):.    
+00021090: 2020 2020 2320 544f 444f 3a20 6d73 2e6f      # TODO: ms.o
+000210a0: 7073 2e73 6c69 6365 5f73 6361 7474 6572  ps.slice_scatter
+000210b0: 206e 6f74 2073 7570 706f 7274 0a20 2020   not support.   
+000210c0: 2020 2020 2078 203d 2063 6173 745f 746f       x = cast_to
+000210d0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+000210e0: 0a20 2020 2020 2020 2073 7263 203d 2063  .        src = c
+000210f0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00021100: 2873 7263 290a 2020 2020 2020 2020 785f  (src).        x_
+00021110: 7368 6170 6520 3d20 782e 7368 6170 650a  shape = x.shape.
+00021120: 2020 2020 2020 2020 785f 7261 6e6b 2c20          x_rank, 
+00021130: 696e 6465 782c 2064 696d 203d 205f 6765  index, dim = _ge
+00021140: 745f 736c 6963 655f 7363 6174 7465 725f  t_slice_scatter_
+00021150: 636f 6e73 7428 785f 7368 6170 652c 2064  const(x_shape, d
+00021160: 696d 2c20 7374 6172 742c 2065 6e64 2c20  im, start, end, 
+00021170: 7374 6570 290a 0a20 2020 2020 2020 2073  step)..        s
+00021180: 7263 5f73 6861 7065 203d 2073 7263 2e73  rc_shape = src.s
+00021190: 6861 7065 0a20 2020 2020 2020 2069 6e64  hape.        ind
+000211a0: 6578 5f74 656e 736f 7220 3d20 6d73 2e54  ex_tensor = ms.T
+000211b0: 656e 736f 7228 696e 6465 7829 0a20 2020  ensor(index).   
+000211c0: 2020 2020 2066 6f72 205f 2069 6e20 7261       for _ in ra
+000211d0: 6e67 6528 6469 6d29 3a0a 2020 2020 2020  nge(dim):.      
+000211e0: 2020 2020 2020 7372 6320 3d20 7372 632e        src = src.
+000211f0: 6578 7061 6e64 5f64 696d 7328 3029 0a20  expand_dims(0). 
+00021200: 2020 2020 2020 2020 2020 2069 6e64 6578             index
+00021210: 5f74 656e 736f 7220 3d20 696e 6465 785f  _tensor = index_
+00021220: 7465 6e73 6f72 2e65 7870 616e 645f 6469  tensor.expand_di
+00021230: 6d73 2830 290a 0a20 2020 2020 2020 2069  ms(0)..        i
+00021240: 6620 6469 6d20 3d3d 2078 5f72 616e 6b20  f dim == x_rank 
+00021250: 2d20 313a 0a20 2020 2020 2020 2020 2020  - 1:.           
+00021260: 2073 7263 203d 2073 7263 2e62 726f 6164   src = src.broad
+00021270: 6361 7374 5f74 6f28 782e 7368 6170 655b  cast_to(x.shape[
+00021280: 303a 6469 6d5d 202b 2073 7263 5f73 6861  0:dim] + src_sha
+00021290: 7065 290a 2020 2020 2020 2020 656c 7365  pe).        else
+000212a0: 3a0a 2020 2020 2020 2020 2020 2020 666f  :.            fo
+000212b0: 7220 5f20 696e 2072 616e 6765 286c 656e  r _ in range(len
+000212c0: 2873 7263 5f73 6861 7065 2929 3a0a 2020  (src_shape)):.  
+000212d0: 2020 2020 2020 2020 2020 2020 2020 696e                in
+000212e0: 6465 785f 7465 6e73 6f72 203d 2069 6e64  dex_tensor = ind
+000212f0: 6578 5f74 656e 736f 722e 6578 7061 6e64  ex_tensor.expand
+00021300: 5f64 696d 7328 2d31 290a 2020 2020 2020  _dims(-1).      
+00021310: 2020 2020 2020 7372 6320 3d20 7372 632e        src = src.
+00021320: 6272 6f61 6463 6173 745f 746f 2878 2e73  broadcast_to(x.s
+00021330: 6861 7065 5b30 3a64 696d 5d20 2b20 286c  hape[0:dim] + (l
+00021340: 656e 2869 6e64 6578 292c 292b 2073 7263  en(index),)+ src
+00021350: 5f73 6861 7065 290a 0a20 2020 2020 2020  _shape)..       
+00021360: 2069 6e64 6578 5f74 656e 736f 7220 3d20   index_tensor = 
+00021370: 696e 6465 785f 7465 6e73 6f72 2e62 726f  index_tensor.bro
+00021380: 6164 6361 7374 5f74 6f28 7372 632e 7368  adcast_to(src.sh
+00021390: 6170 6529 0a20 2020 2020 2020 206f 7574  ape).        out
+000213a0: 7075 7420 3d20 6d73 2e6f 7073 2e74 656e  put = ms.ops.ten
+000213b0: 736f 725f 7363 6174 7465 725f 656c 656d  sor_scatter_elem
+000213c0: 656e 7473 2878 2c20 6178 6973 3d64 696d  ents(x, axis=dim
+000213d0: 2c20 696e 6469 6365 733d 696e 6465 785f  , indices=index_
+000213e0: 7465 6e73 6f72 2c20 7570 6461 7465 733d  tensor, updates=
+000213f0: 7372 6329 0a20 2020 2020 2020 2072 6574  src).        ret
+00021400: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+00021410: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+00021420: 7429 0a0a 2020 2020 6465 6620 7365 6c65  t)..    def sele
+00021430: 6374 5f73 6361 7474 6572 2873 656c 662c  ct_scatter(self,
+00021440: 2073 7263 2c20 6469 6d2c 2069 6e64 6578   src, dim, index
+00021450: 293a 0a20 2020 2020 2020 2072 6574 7572  ):.        retur
+00021460: 6e20 7365 6c66 2e73 6c69 6365 5f73 6361  n self.slice_sca
+00021470: 7474 6572 2873 7263 2c20 6469 6d2c 2073  tter(src, dim, s
+00021480: 7461 7274 3d69 6e64 6578 2c20 656e 643d  tart=index, end=
+00021490: 696e 6465 7820 2b20 3129 0a0a 2020 2020  index + 1)..    
+000214a0: 6465 6620 6967 616d 6d61 5f28 7365 6c66  def igamma_(self
+000214b0: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+000214c0: 2020 666c 6167 3332 203d 2046 616c 7365    flag32 = False
+000214d0: 0a20 2020 2020 2020 2066 6c61 6731 3620  .        flag16 
+000214e0: 3d20 4661 6c73 650a 2020 2020 2020 2020  = False.        
+000214f0: 6966 2073 656c 662e 6474 7970 6520 3d3d  if self.dtype ==
+00021500: 206d 732e 666c 6f61 7433 323a 0a20 2020   ms.float32:.   
+00021510: 2020 2020 2020 2020 2066 6c61 6733 3220           flag32 
+00021520: 3d20 5472 7565 0a20 2020 2020 2020 2069  = True.        i
+00021530: 6620 7365 6c66 2e64 7479 7065 203d 3d20  f self.dtype == 
+00021540: 6d73 2e66 6c6f 6174 3136 3a0a 2020 2020  ms.float16:.    
+00021550: 2020 2020 2020 2020 666c 6167 3136 203d          flag16 =
+00021560: 2054 7275 650a 2020 2020 2020 2020 6f75   True.        ou
+00021570: 7470 7574 203d 2073 656c 662e 6967 616d  tput = self.igam
+00021580: 6d61 286f 7468 6572 290a 2020 2020 2020  ma(other).      
+00021590: 2020 6966 2066 6c61 6733 323a 0a20 2020    if flag32:.   
+000215a0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+000215b0: 3d20 6f75 7470 7574 2e61 7374 7970 6528  = output.astype(
+000215c0: 6d73 2e66 6c6f 6174 3332 290a 2020 2020  ms.float32).    
+000215d0: 2020 2020 6966 2066 6c61 6731 363a 0a20      if flag16:. 
+000215e0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+000215f0: 7420 3d20 6f75 7470 7574 2e61 7374 7970  t = output.astyp
+00021600: 6528 6d73 2e66 6c6f 6174 3136 290a 2020  e(ms.float16).  
+00021610: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
+00021620: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
+00021630: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
+00021640: 2c20 2269 6761 6d6d 615f 222c 2022 6967  , "igamma_", "ig
+00021650: 616d 6d61 2229 0a0a 2020 2020 6465 6620  amma")..    def 
+00021660: 6967 616d 6d61 635f 2873 656c 662c 206f  igammac_(self, o
+00021670: 7468 6572 293a 0a20 2020 2020 2020 2066  ther):.        f
+00021680: 6c61 6733 3220 3d20 4661 6c73 650a 2020  lag32 = False.  
+00021690: 2020 2020 2020 666c 6167 3136 203d 2046        flag16 = F
+000216a0: 616c 7365 0a20 2020 2020 2020 2069 6620  alse.        if 
+000216b0: 7365 6c66 2e64 7479 7065 203d 3d20 6d73  self.dtype == ms
+000216c0: 2e66 6c6f 6174 3332 3a0a 2020 2020 2020  .float32:.      
+000216d0: 2020 2020 2020 666c 6167 3332 203d 2054        flag32 = T
+000216e0: 7275 650a 2020 2020 2020 2020 6966 2073  rue.        if s
+000216f0: 656c 662e 6474 7970 6520 3d3d 206d 732e  elf.dtype == ms.
+00021700: 666c 6f61 7431 363a 0a20 2020 2020 2020  float16:.       
+00021710: 2020 2020 2066 6c61 6731 3620 3d20 5472       flag16 = Tr
+00021720: 7565 0a20 2020 2020 2020 206f 7574 7075  ue.        outpu
+00021730: 7420 3d20 7365 6c66 2e69 6761 6d6d 6163  t = self.igammac
+00021740: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
+00021750: 6966 2066 6c61 6733 323a 0a20 2020 2020  if flag32:.     
+00021760: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00021770: 6f75 7470 7574 2e61 7374 7970 6528 6d73  output.astype(ms
+00021780: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
+00021790: 2020 6966 2066 6c61 6731 363a 0a20 2020    if flag16:.   
+000217a0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+000217b0: 3d20 6f75 7470 7574 2e61 7374 7970 6528  = output.astype(
+000217c0: 6d73 2e66 6c6f 6174 3136 290a 2020 2020  ms.float16).    
+000217d0: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+000217e0: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+000217f0: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+00021800: 2269 6761 6d6d 6163 5f22 2c20 2269 6761  "igammac_", "iga
+00021810: 6d6d 6163 2229 0a0a 2020 2020 6465 6620  mmac")..    def 
+00021820: 6c67 616d 6d61 2873 656c 6629 3a0a 2020  lgamma(self):.  
+00021830: 2020 2020 2020 2320 544f 444f 3a20 6d73        # TODO: ms
+00021840: 2e6f 7073 2e6c 6761 6d6d 6120 746f 2073  .ops.lgamma to s
+00021850: 7570 706f 7274 2061 7363 656e 640a 2020  upport ascend.  
+00021860: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00021870: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00021880: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00021890: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+000218a0: 2e6c 6761 6d6d 6128 696e 7075 745f 6d73  .lgamma(input_ms
+000218b0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000218c0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+000218d0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+000218e0: 0a20 2020 2064 6566 206c 6761 6d6d 615f  .    def lgamma_
+000218f0: 2873 656c 6629 3a0a 2020 2020 2020 2020  (self):.        
+00021900: 2320 544f 444f 3a20 6d73 2e6f 7073 2e6c  # TODO: ms.ops.l
+00021910: 6761 6d6d 6120 746f 2073 7570 706f 7274  gamma to support
+00021920: 2061 7363 656e 640a 2020 2020 2020 2020   ascend.        
+00021930: 6f75 7470 7574 203d 2073 656c 662e 6c67  output = self.lg
+00021940: 616d 6d61 2829 0a20 2020 2020 2020 2072  amma().        r
+00021950: 6574 7572 6e20 5f74 656e 736f 725f 696e  eturn _tensor_in
+00021960: 706c 6163 655f 6173 7369 676e 2873 656c  place_assign(sel
+00021970: 662c 206f 7574 7075 742c 2022 6c67 616d  f, output, "lgam
+00021980: 6d61 5f22 2c20 226c 6761 6d6d 6122 290a  ma_", "lgamma").
+00021990: 0a20 2020 2064 6566 206d 756c 7469 6e6f  .    def multino
+000219a0: 6d69 616c 2873 656c 662c 206e 756d 5f73  mial(self, num_s
+000219b0: 616d 706c 652c 2072 6570 6c61 6365 6d65  ample, replaceme
+000219c0: 6e74 3d46 616c 7365 2c20 7365 6564 3d4e  nt=False, seed=N
+000219d0: 6f6e 6529 3a0a 2020 2020 2020 2020 696e  one):.        in
+000219e0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+000219f0: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+00021a00: 0a20 2020 2020 2020 2069 6620 7265 706c  .        if repl
+00021a10: 6163 656d 656e 7420 616e 6420 696e 7075  acement and inpu
+00021a20: 745f 6d73 2e6e 6469 6d20 3d3d 2031 3a0a  t_ms.ndim == 1:.
+00021a30: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00021a40: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
+00021a50: 756e 7371 7565 657a 6528 3029 0a20 2020  unsqueeze(0).   
+00021a60: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00021a70: 3d20 6d73 2e6f 7073 2e6d 756c 7469 6e6f  = ms.ops.multino
+00021a80: 6d69 616c 2869 6e70 7574 5f6d 732c 206e  mial(input_ms, n
+00021a90: 756d 5f73 616d 706c 652c 2072 6570 6c61  um_sample, repla
+00021aa0: 6365 6d65 6e74 2c20 7365 6564 290a 2020  cement, seed).  
+00021ab0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00021ac0: 203d 206f 7574 7075 742e 7371 7565 657a   = output.squeez
+00021ad0: 6528 3029 0a20 2020 2020 2020 2065 6c73  e(0).        els
+00021ae0: 653a 0a20 2020 2020 2020 2020 2020 206f  e:.            o
+00021af0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e6d  utput = ms.ops.m
+00021b00: 756c 7469 6e6f 6d69 616c 2869 6e70 7574  ultinomial(input
+00021b10: 5f6d 732c 206e 756d 5f73 616d 706c 652c  _ms, num_sample,
+00021b20: 2072 6570 6c61 6365 6d65 6e74 2c20 7365   replacement, se
+00021b30: 6564 290a 2020 2020 2020 2020 6f75 7470  ed).        outp
+00021b40: 7574 203d 206f 7574 7075 742e 6173 7479  ut = output.asty
+00021b50: 7065 286d 732e 696e 7436 3429 0a20 2020  pe(ms.int64).   
+00021b60: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00021b70: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00021b80: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00021b90: 6465 6620 636f 7628 7365 6c66 2c20 2a2c  def cov(self, *,
+00021ba0: 2063 6f72 7265 6374 696f 6e3d 312c 2066   correction=1, f
+00021bb0: 7765 6967 6874 733d 4e6f 6e65 2c20 6177  weights=None, aw
+00021bc0: 6569 6768 7473 3d4e 6f6e 6529 3a0a 2020  eights=None):.  
+00021bd0: 2020 2020 2020 2320 544f 444f 3a20 6d73        # TODO: ms
+00021be0: 2e6f 7073 2e63 6f76 2074 6f20 7375 7070  .ops.cov to supp
+00021bf0: 6f72 7420 666c 6f61 7436 3420 616e 6420  ort float64 and 
+00021c00: 636f 6d70 6c65 7820 696e 7075 740a 2020  complex input.  
+00021c10: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00021c20: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00021c30: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00021c40: 2069 6620 6677 6569 6768 7473 2069 7320   if fweights is 
+00021c50: 6e6f 7420 4e6f 6e65 3a0a 2020 2020 2020  not None:.      
+00021c60: 2020 2020 2020 6677 6569 6768 7473 203d        fweights =
+00021c70: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00021c80: 6f72 2866 7765 6967 6874 7329 0a20 2020  or(fweights).   
+00021c90: 2020 2020 2069 6620 6177 6569 6768 7473       if aweights
+00021ca0: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+00021cb0: 2020 2020 2020 2020 2020 6177 6569 6768            aweigh
+00021cc0: 7473 203d 2063 6173 745f 746f 5f6d 735f  ts = cast_to_ms_
+00021cd0: 7465 6e73 6f72 2861 7765 6967 6874 7329  tensor(aweights)
+00021ce0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+00021cf0: 3d20 6d73 2e6f 7073 2e63 6f76 2869 6e70  = ms.ops.cov(inp
+00021d00: 7574 5f6d 732c 2063 6f72 7265 6374 696f  ut_ms, correctio
+00021d10: 6e3d 636f 7272 6563 7469 6f6e 2c20 6677  n=correction, fw
+00021d20: 6569 6768 7473 3d66 7765 6967 6874 732c  eights=fweights,
+00021d30: 2061 7765 6967 6874 733d 6177 6569 6768   aweights=aweigh
+00021d40: 7473 290a 2020 2020 2020 2020 7265 7475  ts).        retu
+00021d50: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00021d60: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+00021d70: 290a 0a20 2020 2064 6566 2072 6f74 3930  )..    def rot90
+00021d80: 2873 656c 662c 206b 2c20 6469 6d73 293a  (self, k, dims):
+00021d90: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+00021da0: 7320 3d20 6361 7374 5f74 6f5f 6d73 5f74  s = cast_to_ms_t
+00021db0: 656e 736f 7228 7365 6c66 290a 2020 2020  ensor(self).    
+00021dc0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00021dd0: 6f70 732e 726f 7439 3028 696e 7075 745f  ops.rot90(input_
+00021de0: 6d73 2c20 6b2c 2064 696d 7329 0a20 2020  ms, k, dims).   
+00021df0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00021e00: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00021e10: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+00021e20: 6465 6620 6d65 6469 616e 2873 656c 662c  def median(self,
+00021e30: 2064 696d 3d4e 6f6e 652c 206b 6565 7064   dim=None, keepd
+00021e40: 696d 3d46 616c 7365 293a 0a20 2020 2020  im=False):.     
+00021e50: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+00021e60: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00021e70: 7365 6c66 290a 2020 2020 2020 2020 6966  self).        if
+00021e80: 2064 696d 2069 7320 4e6f 6e65 3a0a 2020   dim is None:.  
+00021e90: 2020 2020 2020 2020 2020 2320 6d73 2e6f            # ms.o
+00021ea0: 7073 2e6d 6564 6961 6e20 6361 6e20 6e6f  ps.median can no
+00021eb0: 7420 636f 6d70 7574 6520 7468 6520 6d65  t compute the me
+00021ec0: 6469 616e 2076 616c 7565 2061 6c6f 6e67  dian value along
+00021ed0: 2061 6c6c 2064 696d 656e 7469 6f6e 730a   all dimentions.
+00021ee0: 2020 2020 2020 2020 2020 2020 2320 6f6e              # on
+00021ef0: 6c79 206d 732e 6f70 732e 4d65 6469 616e  ly ms.ops.Median
+00021f00: 2867 6c6f 6261 6c5f 6d65 6469 616e 3d54  (global_median=T
+00021f10: 7275 6529 2063 616e 2064 6f20 7468 6174  rue) can do that
+00021f20: 2e0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+00021f30: 736f 2063 616e 206e 6f74 2072 6570 6c61  so can not repla
+00021f40: 6365 206d 732e 6f70 732e 4d65 6469 616e  ce ms.ops.Median
+00021f50: 2074 6f20 6d73 2e6f 7073 2e6d 6564 6961   to ms.ops.media
+00021f60: 6e0a 2020 2020 2020 2020 2020 2020 6f75  n.            ou
+00021f70: 7470 7574 2c20 5f20 3d20 5f67 6574 5f63  tput, _ = _get_c
+00021f80: 6163 6865 5f70 7269 6d28 6d73 2e6f 7073  ache_prim(ms.ops
+00021f90: 2e4d 6564 6961 6e29 2854 7275 6529 2869  .Median)(True)(i
+00021fa0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
+00021fb0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00021fc0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00021fd0: 6f72 286f 7574 7075 7429 0a20 2020 2020  or(output).     
+00021fe0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00021ff0: 2020 2020 2023 2054 4f44 4f3a 204f 6e20       # TODO: On 
+00022000: 4750 552c 206d 732e 6f70 732e 6d65 6469  GPU, ms.ops.medi
+00022010: 616e 2074 6865 2072 6574 7572 6e20 696e  an the return in
+00022020: 6469 6365 7320 6d61 7920 6265 2077 726f  dices may be wro
+00022030: 6e67 2e0a 2020 2020 2020 2020 2020 2020  ng..            
+00022040: 7661 6c75 652c 2069 6e64 6963 6573 203d  value, indices =
+00022050: 206d 732e 6f70 732e 6d65 6469 616e 2869   ms.ops.median(i
+00022060: 6e70 7574 5f6d 732c 2064 696d 2c20 6b65  nput_ms, dim, ke
+00022070: 6570 6469 6d29 0a20 2020 2020 2020 2020  epdim).         
+00022080: 2020 2069 6620 7079 6e61 7469 7665 5f6d     if pynative_m
+00022090: 6f64 655f 636f 6e64 6974 696f 6e28 293a  ode_condition():
+000220a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000220b0: 2070 6f69 6e74 203d 2073 6574 5f6e 616d   point = set_nam
+000220c0: 655f 7475 706c 6528 276d 6564 6961 6e27  e_tuple('median'
+000220d0: 290a 2020 2020 2020 2020 2020 2020 2020  ).              
+000220e0: 2020 726c 7420 3d20 706f 696e 7428 6361    rlt = point(ca
+000220f0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00022100: 6e73 6f72 2876 616c 7565 292c 2063 6173  nsor(value), cas
+00022110: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00022120: 736f 7228 696e 6469 6365 7329 290a 2020  sor(indices)).  
+00022130: 2020 2020 2020 2020 2020 2020 2020 7265                re
+00022140: 7475 726e 2072 6c74 0a20 2020 2020 2020  turn rlt.       
+00022150: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+00022160: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+00022170: 6f72 2876 616c 7565 292c 2063 6173 745f  or(value), cast_
+00022180: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00022190: 7228 696e 6469 6365 7329 0a0a 2020 2020  r(indices)..    
+000221a0: 6465 6620 6672 6163 2873 656c 6629 3a0a  def frac(self):.
+000221b0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+000221c0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000221d0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+000221e0: 2020 206f 7574 7075 7420 3d20 6d73 2e6f     output = ms.o
+000221f0: 7073 2e66 7261 6328 696e 7075 745f 6d73  ps.frac(input_ms
+00022200: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00022210: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00022220: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+00022230: 0a20 2020 2064 6566 2066 7261 635f 2873  .    def frac_(s
+00022240: 656c 6629 3a0a 2020 2020 2020 2020 6f75  elf):.        ou
+00022250: 7470 7574 203d 2073 656c 662e 6672 6163  tput = self.frac
+00022260: 2829 0a20 2020 2020 2020 2072 6574 7572  ().        retur
+00022270: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+00022280: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00022290: 7574 7075 742c 2022 6672 6163 5f22 2c20  utput, "frac_", 
+000222a0: 2266 7261 6322 290a 0a20 2020 2064 6566  "frac")..    def
+000222b0: 2067 6364 2873 656c 662c 206f 7468 6572   gcd(self, other
+000222c0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+000222d0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+000222e0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+000222f0: 2020 2020 2020 6f74 6865 725f 6d73 203d        other_ms =
+00022300: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00022310: 6f72 286f 7468 6572 290a 2020 2020 2020  or(other).      
+00022320: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+00022330: 732e 6763 6428 696e 7075 745f 6d73 2c20  s.gcd(input_ms, 
+00022340: 6f74 6865 725f 6d73 290a 2020 2020 2020  other_ms).      
+00022350: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+00022360: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+00022370: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+00022380: 2067 6364 5f28 7365 6c66 2c20 6f74 6865   gcd_(self, othe
+00022390: 7229 3a0a 2020 2020 2020 2020 6f75 7470  r):.        outp
+000223a0: 7574 203d 2073 656c 662e 6763 6428 6f74  ut = self.gcd(ot
+000223b0: 6865 7229 0a20 2020 2020 2020 2072 6574  her).        ret
+000223c0: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+000223d0: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+000223e0: 206f 7574 7075 742c 2022 6763 645f 222c   output, "gcd_",
+000223f0: 2022 6763 6422 290a 0a20 2020 2040 7072   "gcd")..    @pr
+00022400: 6f70 6572 7479 0a20 2020 2064 6566 2069  operty.    def i
+00022410: 6d61 6728 7365 6c66 293a 0a20 2020 2020  mag(self):.     
+00022420: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+00022430: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00022440: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
+00022450: 7470 7574 203d 206d 732e 6f70 732e 696d  tput = ms.ops.im
+00022460: 6167 2869 6e70 7574 5f6d 7329 0a20 2020  ag(input_ms).   
+00022470: 2020 2020 206f 7574 7075 7420 3d20 6361       output = ca
+00022480: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00022490: 6e73 6f72 286f 7574 7075 7429 0a20 2020  nsor(output).   
+000224a0: 2020 2020 206f 7574 7075 742e 6e65 675f       output.neg_
+000224b0: 6269 7420 3d20 5472 7565 0a20 2020 2020  bit = True.     
+000224c0: 2020 2072 6574 7572 6e20 6f75 7470 7574     return output
+000224d0: 0a0a 2020 2020 6465 6620 6c64 6578 7028  ..    def ldexp(
+000224e0: 7365 6c66 2c20 6f74 6865 7229 3a0a 2020  self, other):.  
+000224f0: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00022500: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00022510: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00022520: 206f 7468 6572 5f6d 7320 3d20 6361 7374   other_ms = cast
+00022530: 5f74 6f5f 6d73 5f74 656e 736f 7228 6f74  _to_ms_tensor(ot
+00022540: 6865 7229 0a20 2020 2020 2020 206f 7574  her).        out
+00022550: 7075 7420 3d20 6d73 2e6f 7073 2e6c 6465  put = ms.ops.lde
+00022560: 7870 2869 6e70 7574 5f6d 732c 206f 7468  xp(input_ms, oth
+00022570: 6572 5f6d 7329 0a20 2020 2020 2020 2072  er_ms).        r
+00022580: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00022590: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+000225a0: 7075 7429 0a0a 2020 2020 6465 6620 6c64  put)..    def ld
+000225b0: 6578 705f 2873 656c 662c 206f 7468 6572  exp_(self, other
+000225c0: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+000225d0: 7420 3d20 7365 6c66 2e6c 6465 7870 286f  t = self.ldexp(o
+000225e0: 7468 6572 290a 2020 2020 2020 2020 7265  ther).        re
+000225f0: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+00022600: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+00022610: 2c20 6f75 7470 7574 2c20 226c 6465 7870  , output, "ldexp
+00022620: 5f22 2c20 226c 6465 7870 2229 0a0a 2020  _", "ldexp")..  
+00022630: 2020 6465 6620 6372 6f73 7328 7365 6c66    def cross(self
+00022640: 2c20 6f74 6865 722c 2064 696d 3d4e 6f6e  , other, dim=Non
+00022650: 6529 3a0a 2020 2020 2020 2020 2354 4f44  e):.        #TOD
+00022660: 4f3a 2077 6865 6e20 6469 6d3d 4e6f 6e65  O: when dim=None
+00022670: 2c20 6f70 732e 6469 6d20 6f6e 2041 7363  , ops.dim on Asc
+00022680: 656e 6420 6861 7320 6275 6720 746f 2062  end has bug to b
+00022690: 6520 6669 782e 0a20 2020 2020 2020 2069  e fix..        i
+000226a0: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+000226b0: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+000226c0: 290a 2020 2020 2020 2020 6f74 6865 7220  ).        other 
+000226d0: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+000226e0: 736f 7228 6f74 6865 7229 0a20 2020 2020  sor(other).     
+000226f0: 2020 2023 2054 4f44 4f3a 2061 6674 6572     # TODO: after
+00022700: 206d 732e 6f70 732e 6372 6f73 7320 7375   ms.ops.cross su
+00022710: 7070 6f72 7420 4750 552c 2072 656d 6f76  pport GPU, remov
+00022720: 6520 636f 6465 2062 656c 6f77 0a20 2020  e code below.   
+00022730: 2020 2020 2069 6620 6973 5f75 6e64 6572       if is_under
+00022740: 5f67 7075 5f63 6f6e 7465 7874 2829 3a0a  _gpu_context():.
+00022750: 2020 2020 2020 2020 2020 2020 6966 2064              if d
+00022760: 696d 2069 7320 4e6f 6e65 3a0a 2020 2020  im is None:.    
+00022770: 2020 2020 2020 2020 2020 2020 6469 6d20              dim 
+00022780: 3d20 2d36 3535 3330 0a20 2020 2020 2020  = -65530.       
+00022790: 2020 2020 205f 6f70 203d 205f 6765 745f       _op = _get_
+000227a0: 6361 6368 655f 7072 696d 286d 732e 6f70  cache_prim(ms.op
+000227b0: 732e 4372 6f73 7329 2864 696d 3d64 696d  s.Cross)(dim=dim
+000227c0: 290a 2020 2020 2020 2020 2020 2020 5f6f  ).            _o
+000227d0: 702e 7365 745f 6465 7669 6365 2822 4350  p.set_device("CP
+000227e0: 5522 290a 2020 2020 2020 2020 2020 2020  U").            
+000227f0: 6f75 7470 7574 203d 205f 6f70 2869 6e70  output = _op(inp
+00022800: 7574 5f6d 732c 206f 7468 6572 290a 2020  ut_ms, other).  
+00022810: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00022820: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00022830: 206d 732e 6f70 732e 6372 6f73 7328 696e   ms.ops.cross(in
+00022840: 7075 745f 6d73 2c20 6f74 6865 722c 2064  put_ms, other, d
+00022850: 696d 290a 2020 2020 2020 2020 7265 7475  im).        retu
+00022860: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00022870: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+00022880: 290a 0a20 2020 2064 6566 2066 696c 6c5f  )..    def fill_
+00022890: 6469 6167 6f6e 616c 5f28 7365 6c66 2c20  diagonal_(self, 
+000228a0: 6669 6c6c 5f76 616c 7565 2c20 7772 6170  fill_value, wrap
+000228b0: 3d46 616c 7365 293a 0a20 2020 2020 2020  =False):.       
+000228c0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+000228d0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+000228e0: 6c66 290a 2020 2020 2020 2020 2320 6d73  lf).        # ms
+000228f0: 2e6f 7073 2e46 696c 6c44 6961 676f 6e61  .ops.FillDiagona
+00022900: 6c20 6e65 6564 2060 6669 6c6c 5f76 616c  l need `fill_val
+00022910: 7565 6020 746f 2062 6520 666c 6f61 7420  ue` to be float 
+00022920: 7479 7065 0a20 2020 2020 2020 205f 6f70  type.        _op
+00022930: 203d 205f 6765 745f 6361 6368 655f 7072   = _get_cache_pr
+00022940: 696d 286d 732e 6f70 732e 4669 6c6c 4469  im(ms.ops.FillDi
+00022950: 6167 6f6e 616c 2928 666c 6f61 7428 6669  agonal)(float(fi
+00022960: 6c6c 5f76 616c 7565 292c 2077 7261 7029  ll_value), wrap)
+00022970: 0a20 2020 2020 2020 2023 206d 732e 6f70  .        # ms.op
+00022980: 732e 4669 6c6c 4469 6167 6f6e 616c 2069  s.FillDiagonal i
+00022990: 7320 6e6f 7420 6120 696e 2d70 6c61 6365  s not a in-place
+000229a0: 206f 700a 2020 2020 2020 2020 6f75 7470   op.        outp
+000229b0: 7574 203d 205f 6f70 2869 6e70 7574 5f6d  ut = _op(input_m
+000229c0: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+000229d0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+000229e0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+000229f0: 7574 7075 742c 2022 6669 6c6c 5f64 6961  utput, "fill_dia
+00022a00: 676f 6e61 6c5f 222c 2022 6669 6c6c 5f64  gonal_", "fill_d
+00022a10: 6961 676f 6e61 6c22 290a 0a20 2020 2064  iagonal")..    d
+00022a20: 6566 206d 7628 7365 6c66 2c20 7665 6329  ef mv(self, vec)
+00022a30: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+00022a40: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00022a50: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+00022a60: 2020 2020 2076 6563 5f6d 7320 3d20 6361       vec_ms = ca
+00022a70: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00022a80: 7665 6329 0a20 2020 2020 2020 206f 7574  vec).        out
+00022a90: 7075 7420 3d20 6d73 2e6f 7073 2e6d 7628  put = ms.ops.mv(
+00022aa0: 696e 7075 745f 6d73 2c20 7665 635f 6d73  input_ms, vec_ms
+00022ab0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00022ac0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00022ad0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+00022ae0: 0a20 2020 2064 6566 2068 6973 7463 2873  .    def histc(s
+00022af0: 656c 662c 2062 696e 733d 3130 302c 206d  elf, bins=100, m
+00022b00: 696e 3d30 2c20 6d61 783d 3029 3a0a 2020  in=0, max=0):.  
+00022b10: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00022b20: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00022b30: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00022b40: 2069 6e70 7574 5f64 7479 7065 203d 2069   input_dtype = i
+00022b50: 6e70 7574 5f6d 732e 6474 7970 650a 2020  nput_ms.dtype.  
+00022b60: 2020 2020 2020 2354 4f44 4f3a 2063 7572        #TODO: cur
+00022b70: 7265 6e74 6c79 206e 6f74 2073 7570 706f  rently not suppo
+00022b80: 7274 2068 6973 7463 206f 6e20 4750 550a  rt histc on GPU.
+00022b90: 2020 2020 2020 2020 6966 2069 735f 756e          if is_un
+00022ba0: 6465 725f 6770 755f 636f 6e74 6578 7428  der_gpu_context(
+00022bb0: 293a 0a20 2020 2020 2020 2020 2020 2069  ):.            i
+00022bc0: 6620 6d61 7820 3d3d 206d 696e 3a0a 2020  f max == min:.  
+00022bd0: 2020 2020 2020 2020 2020 2020 2020 6d61                ma
+00022be0: 782c 205f 203d 206d 732e 6f70 732e 6d61  x, _ = ms.ops.ma
+00022bf0: 7828 696e 7075 745f 6d73 290a 2020 2020  x(input_ms).    
+00022c00: 2020 2020 2020 2020 2020 2020 6d69 6e2c              min,
+00022c10: 205f 203d 206d 732e 6f70 732e 6d69 6e28   _ = ms.ops.min(
+00022c20: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
+00022c30: 2020 2020 2020 6f75 7470 7574 2c20 5f20        output, _ 
+00022c40: 3d20 6d73 2e6e 756d 7079 2e68 6973 746f  = ms.numpy.histo
+00022c50: 6772 616d 2869 6e70 7574 5f6d 732c 2062  gram(input_ms, b
+00022c60: 696e 732c 2028 6d69 6e2c 206d 6178 2929  ins, (min, max))
+00022c70: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00022c80: 2020 2020 2020 2020 2020 2069 6620 696e             if in
+00022c90: 7075 745f 6474 7970 6520 6e6f 7420 696e  put_dtype not in
+00022ca0: 2028 6d73 2e66 6c6f 6174 3136 2c20 6d73   (ms.float16, ms
+00022cb0: 2e66 6c6f 6174 3332 2c20 6d73 2e69 6e74  .float32, ms.int
+00022cc0: 3332 293a 0a20 2020 2020 2020 2020 2020  32):.           
+00022cd0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00022ce0: 696e 7075 745f 6d73 2e61 7374 7970 6528  input_ms.astype(
+00022cf0: 6d73 2e66 6c6f 6174 3332 290a 2020 2020  ms.float32).    
+00022d00: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00022d10: 206d 732e 6f70 732e 6869 7374 6328 696e   ms.ops.histc(in
+00022d20: 7075 745f 6d73 2c20 6269 6e73 2c20 6d69  put_ms, bins, mi
+00022d30: 6e2c 206d 6178 290a 2020 2020 2020 2020  n, max).        
+00022d40: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00022d50: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00022d60: 7470 7574 2e61 7374 7970 6528 696e 7075  tput.astype(inpu
+00022d70: 745f 6474 7970 6529 290a 0a20 2020 2064  t_dtype))..    d
+00022d80: 6566 2068 6973 746f 6772 616d 2873 656c  ef histogram(sel
+00022d90: 662c 2062 696e 732c 202a 2c20 7261 6e67  f, bins, *, rang
+00022da0: 653d 4e6f 6e65 2c20 7765 6967 6874 3d4e  e=None, weight=N
+00022db0: 6f6e 652c 2064 656e 7369 7479 3d46 616c  one, density=Fal
+00022dc0: 7365 293a 0a20 2020 2020 2020 2069 6e70  se):.        inp
+00022dd0: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+00022de0: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00022df0: 2020 2020 2020 2020 5f62 696e 7320 3d20          _bins = 
+00022e00: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00022e10: 7228 6269 6e73 290a 2020 2020 2020 2020  r(bins).        
+00022e20: 6966 2077 6569 6768 7420 6973 206e 6f74  if weight is not
+00022e30: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+00022e40: 2020 2077 6569 6768 7420 3d20 6361 7374     weight = cast
+00022e50: 5f74 6f5f 6d73 5f74 656e 736f 7228 7765  _to_ms_tensor(we
+00022e60: 6967 6874 290a 2020 2020 2020 2020 2320  ight).        # 
+00022e70: 544f 444f 3a20 6d73 2e6f 7073 2e68 6973  TODO: ms.ops.his
+00022e80: 746f 6772 616d 2069 7320 6e6f 7420 7375  togram is not su
+00022e90: 7070 6f72 7420 6e6f 772e 0a20 2020 2020  pport now..     
+00022ea0: 2020 206f 7574 7075 7420 3d20 6d73 2e6e     output = ms.n
+00022eb0: 756d 7079 2e68 6973 746f 6772 616d 2869  umpy.histogram(i
+00022ec0: 6e70 7574 5f6d 732c 205f 6269 6e73 2c20  nput_ms, _bins, 
+00022ed0: 7261 6e67 652c 2077 6569 6768 742c 2064  range, weight, d
+00022ee0: 656e 7369 7479 290a 2020 2020 2020 2020  ensity).        
+00022ef0: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00022f00: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
+00022f10: 7470 7574 290a 0a20 2020 2064 6566 2067  tput)..    def g
+00022f20: 6571 7266 2873 656c 6629 3a0a 2020 2020  eqrf(self):.    
+00022f30: 2020 2020 2320 544f 444f 3a20 4f6e 2041      # TODO: On A
+00022f40: 7363 656e 642c 206d 732e 6f70 732e 6765  scend, ms.ops.ge
+00022f50: 7172 6620 646f 206e 6f74 2073 7570 706f  qrf do not suppo
+00022f60: 7274 2069 6e70 7574 2e6e 6469 6d20 3e20  rt input.ndim > 
+00022f70: 322e 0a20 2020 2020 2020 2069 6e70 7574  2..        input
+00022f80: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+00022f90: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+00022fa0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00022fb0: 732e 6f70 732e 6765 7172 6628 696e 7075  s.ops.geqrf(inpu
+00022fc0: 745f 6d73 290a 2020 2020 2020 2020 7265  t_ms).        re
+00022fd0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00022fe0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00022ff0: 7574 290a 0a20 2020 2064 6566 206c 6f67  ut)..    def log
+00023000: 6164 6465 7870 3228 7365 6c66 2c20 6f74  addexp2(self, ot
+00023010: 6865 7229 3a0a 2020 2020 2020 2020 696e  her):.        in
+00023020: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+00023030: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+00023040: 0a20 2020 2020 2020 206f 7468 6572 203d  .        other =
+00023050: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00023060: 6f72 286f 7468 6572 290a 2020 2020 2020  or(other).      
+00023070: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+00023080: 732e 6c6f 6761 6464 6578 7032 2869 6e70  s.logaddexp2(inp
+00023090: 7574 5f6d 732c 206f 7468 6572 290a 2020  ut_ms, other).  
+000230a0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+000230b0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+000230c0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+000230d0: 2064 6566 2066 6c6f 6f72 5f64 6976 6964   def floor_divid
+000230e0: 6528 7365 6c66 2c20 7661 6c75 6529 3a0a  e(self, value):.
+000230f0: 2020 2020 2020 2020 2320 6d73 2e6f 7073          # ms.ops
+00023100: 2e66 6c6f 6f72 5f64 6976 6964 6520 646f  .floor_divide do
+00023110: 6573 6e27 7420 726f 756e 6420 7468 6520  esn't round the 
+00023120: 7175 6f74 6965 6e74 2074 6f77 6172 6473  quotient towards
+00023130: 2030 0a20 2020 2020 2020 2023 2073 616d   0.        # sam
+00023140: 6520 6265 6861 7669 6f72 2061 7320 746f  e behavior as to
+00023150: 7263 6820 7665 7273 696f 6e20 6c6f 7765  rch version lowe
+00023160: 7220 7468 616e 2031 2e31 330a 2020 2020  r than 1.13.    
+00023170: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+00023180: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00023190: 2873 656c 6629 0a20 2020 2020 2020 2076  (self).        v
+000231a0: 616c 7565 203d 2063 6173 745f 746f 5f6d  alue = cast_to_m
+000231b0: 735f 7465 6e73 6f72 2876 616c 7565 290a  s_tensor(value).
+000231c0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000231d0: 206d 732e 6f70 732e 6469 7628 696e 7075   ms.ops.div(inpu
+000231e0: 745f 6d73 2c20 7661 6c75 652c 2072 6f75  t_ms, value, rou
+000231f0: 6e64 696e 675f 6d6f 6465 3d27 7472 756e  nding_mode='trun
+00023200: 6327 290a 2020 2020 2020 2020 7265 7475  c').        retu
+00023210: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00023220: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+00023230: 290a 0a20 2020 2064 6566 2066 6c6f 6f72  )..    def floor
+00023240: 5f64 6976 6964 655f 2873 656c 662c 2076  _divide_(self, v
+00023250: 616c 7565 293a 0a20 2020 2020 2020 206f  alue):.        o
+00023260: 7574 7075 7420 3d20 7365 6c66 2e66 6c6f  utput = self.flo
+00023270: 6f72 5f64 6976 6964 6528 7661 6c75 6529  or_divide(value)
+00023280: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00023290: 5f74 656e 736f 725f 696e 706c 6163 655f  _tensor_inplace_
+000232a0: 6173 7369 676e 2873 656c 662c 206f 7574  assign(self, out
+000232b0: 7075 742c 2022 666c 6f6f 725f 6469 7669  put, "floor_divi
+000232c0: 6465 5f22 2c20 2266 6c6f 6f72 5f64 6976  de_", "floor_div
+000232d0: 6964 6522 290a 0a20 2020 2064 6566 2072  ide")..    def r
+000232e0: 656e 6f72 6d28 7365 6c66 2c20 702c 2064  enorm(self, p, d
+000232f0: 696d 2c20 6d61 786e 6f72 6d29 3a0a 2020  im, maxnorm):.  
+00023300: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00023310: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00023320: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00023330: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00023340: 2e72 656e 6f72 6d28 696e 7075 745f 6d73  .renorm(input_ms
+00023350: 2c20 696e 7428 7029 2c20 6469 6d2c 2066  , int(p), dim, f
+00023360: 6c6f 6174 286d 6178 6e6f 726d 2929 0a20  loat(maxnorm)). 
+00023370: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00023380: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00023390: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+000233a0: 2020 6465 6620 7265 6e6f 726d 5f28 7365    def renorm_(se
+000233b0: 6c66 2c20 702c 2064 696d 2c20 6d61 786e  lf, p, dim, maxn
+000233c0: 6f72 6d29 3a0a 2020 2020 2020 2020 6f75  orm):.        ou
+000233d0: 7470 7574 203d 2073 656c 662e 7265 6e6f  tput = self.reno
+000233e0: 726d 2870 2c20 6469 6d2c 206d 6178 6e6f  rm(p, dim, maxno
+000233f0: 726d 290a 2020 2020 2020 2020 7265 7475  rm).        retu
+00023400: 726e 205f 7465 6e73 6f72 5f69 6e70 6c61  rn _tensor_inpla
+00023410: 6365 5f61 7373 6967 6e28 7365 6c66 2c20  ce_assign(self, 
+00023420: 6f75 7470 7574 2c20 2272 656e 6f72 6d5f  output, "renorm_
+00023430: 222c 2022 7265 6e6f 726d 2229 0a0a 2020  ", "renorm")..  
+00023440: 2020 6465 6620 6d76 6c67 616d 6d61 2873    def mvlgamma(s
+00023450: 656c 662c 2070 293a 0a20 2020 2020 2020  elf, p):.       
+00023460: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+00023470: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+00023480: 6c66 290a 2020 2020 2020 2020 6f75 7470  lf).        outp
+00023490: 7574 203d 206d 732e 6f70 732e 6d76 6c67  ut = ms.ops.mvlg
+000234a0: 616d 6d61 2869 6e70 7574 5f6d 732c 2070  amma(input_ms, p
+000234b0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000234c0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+000234d0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+000234e0: 0a20 2020 2064 6566 206d 766c 6761 6d6d  .    def mvlgamm
+000234f0: 615f 2873 656c 662c 2070 293a 0a20 2020  a_(self, p):.   
+00023500: 2020 2020 206f 7574 7075 7420 3d20 7365       output = se
+00023510: 6c66 2e6d 766c 6761 6d6d 6128 7029 0a20  lf.mvlgamma(p). 
+00023520: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
+00023530: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
+00023540: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
+00023550: 742c 2022 6d76 6c67 616d 6d61 5f22 2c20  t, "mvlgamma_", 
+00023560: 226d 766c 6761 6d6d 6122 290a 0a20 2020  "mvlgamma")..   
+00023570: 2064 6566 206f 7267 7172 2873 656c 662c   def orgqr(self,
+00023580: 2069 6e70 7574 3229 3a0a 2020 2020 2020   input2):.      
+00023590: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+000235a0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+000235b0: 656c 6629 0a20 2020 2020 2020 2069 6e70  elf).        inp
+000235c0: 7574 3220 3d20 6361 7374 5f74 6f5f 6d73  ut2 = cast_to_ms
+000235d0: 5f74 656e 736f 7228 696e 7075 7432 290a  _tensor(input2).
+000235e0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000235f0: 206d 732e 6f70 732e 6f72 6771 7228 696e   ms.ops.orgqr(in
+00023600: 7075 745f 6d73 2c20 696e 7075 7432 290a  put_ms, input2).
+00023610: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00023620: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+00023630: 656e 736f 7228 6f75 7470 7574 290a 0a20  ensor(output).. 
+00023640: 2020 2064 6566 2071 7228 7365 6c66 2c20     def qr(self, 
+00023650: 736f 6d65 3d54 7275 6529 3a0a 2020 2020  some=True):.    
+00023660: 2020 2020 696e 7075 745f 6d73 203d 2063      input_ms = c
+00023670: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00023680: 2873 656c 6629 0a20 2020 2020 2020 2069  (self).        i
+00023690: 6620 736f 6d65 3a0a 2020 2020 2020 2020  f some:.        
+000236a0: 2020 2020 6d6f 6465 203d 2022 7265 6475      mode = "redu
+000236b0: 6365 6422 0a20 2020 2020 2020 2065 6c73  ced".        els
+000236c0: 653a 0a20 2020 2020 2020 2020 2020 206d  e:.            m
+000236d0: 6f64 6520 3d20 2263 6f6d 706c 6574 6522  ode = "complete"
+000236e0: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+000236f0: 3d20 6d73 2e6f 7073 2e71 7228 696e 7075  = ms.ops.qr(inpu
+00023700: 745f 6d73 2c20 6d6f 6465 290a 2020 2020  t_ms, mode).    
+00023710: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+00023720: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00023730: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+00023740: 6566 2069 3028 7365 6c66 293a 0a20 2020  ef i0(self):.   
+00023750: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00023760: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00023770: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00023780: 2320 544f 444f efbc 9a6d 732e 6f70 732e  # TODO...ms.ops.
+00023790: 6265 7373 656c 5f69 3020 746f 2073 7570  bessel_i0 to sup
+000237a0: 706f 7274 206f 6e20 4173 6365 6e64 0a20  port on Ascend. 
+000237b0: 2020 2020 2020 2069 6620 6973 5f75 6e64         if is_und
+000237c0: 6572 5f61 7363 656e 645f 636f 6e74 6578  er_ascend_contex
+000237d0: 7428 293a 0a20 2020 2020 2020 2020 2020  t():.           
+000237e0: 2069 305f 6f70 203d 206e 756d 7079 5f63   i0_op = numpy_c
+000237f0: 656c 6c2e 4e75 6d70 7949 3028 2769 3027  ell.NumpyI0('i0'
+00023800: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
+00023810: 7470 7574 203d 2069 305f 6f70 2869 6e70  tput = i0_op(inp
+00023820: 7574 5f6d 7329 0a20 2020 2020 2020 2065  ut_ms).        e
+00023830: 6c73 653a 0a20 2020 2020 2020 2020 2020  lse:.           
+00023840: 2069 6620 696e 7075 745f 6d73 2e64 7479   if input_ms.dty
+00023850: 7065 2069 6e20 6d69 6e64 746f 7263 685f  pe in mindtorch_
+00023860: 6474 7970 652e 616c 6c5f 696e 745f 7479  dtype.all_int_ty
+00023870: 7065 3a0a 2020 2020 2020 2020 2020 2020  pe:.            
+00023880: 2020 2020 696e 7075 745f 6d73 203d 2069      input_ms = i
+00023890: 6e70 7574 5f6d 732e 6173 7479 7065 286d  nput_ms.astype(m
+000238a0: 732e 666c 6f61 7433 3229 0a20 2020 2020  s.float32).     
+000238b0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+000238c0: 6d73 2e6f 7073 2e62 6573 7365 6c5f 6930  ms.ops.bessel_i0
+000238d0: 2869 6e70 7574 5f6d 7329 0a20 2020 2020  (input_ms).     
+000238e0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+000238f0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+00023900: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00023910: 6620 6930 5f28 7365 6c66 293a 0a20 2020  f i0_(self):.   
+00023920: 2020 2020 206f 7574 7075 7420 3d20 7365       output = se
+00023930: 6c66 2e69 3028 290a 2020 2020 2020 2020  lf.i0().        
+00023940: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
+00023950: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
+00023960: 6c66 2c20 6f75 7470 7574 2c20 2269 305f  lf, output, "i0_
+00023970: 222c 2022 6930 2229 0a0a 2020 2020 6465  ", "i0")..    de
+00023980: 6620 6e65 7874 6166 7465 7228 7365 6c66  f nextafter(self
+00023990: 2c20 6f74 6865 7229 3a0a 2020 2020 2020  , other):.      
+000239a0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+000239b0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+000239c0: 656c 6629 0a20 2020 2020 2020 206f 7468  elf).        oth
+000239d0: 6572 203d 2063 6173 745f 746f 5f6d 735f  er = cast_to_ms_
+000239e0: 7465 6e73 6f72 286f 7468 6572 290a 2020  tensor(other).  
+000239f0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00023a00: 732e 6f70 732e 6e65 7874 6166 7465 7228  s.ops.nextafter(
+00023a10: 696e 7075 745f 6d73 2c20 6f74 6865 7229  input_ms, other)
+00023a20: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00023a30: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00023a40: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+00023a50: 2020 2020 6465 6620 6e65 7874 6166 7465      def nextafte
+00023a60: 725f 2873 656c 662c 206f 7468 6572 293a  r_(self, other):
+00023a70: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
+00023a80: 3d20 7365 6c66 2e6e 6578 7461 6674 6572  = self.nextafter
+00023a90: 286f 7468 6572 290a 2020 2020 2020 2020  (other).        
+00023aa0: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
+00023ab0: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
+00023ac0: 6c66 2c20 6f75 7470 7574 2c20 226e 6578  lf, output, "nex
+00023ad0: 7461 6674 6572 5f22 2c20 226e 6578 7461  tafter_", "nexta
+00023ae0: 6674 6572 2229 0a0a 2020 2020 6465 6620  fter")..    def 
+00023af0: 6c6f 6769 7428 7365 6c66 2c20 6570 733d  logit(self, eps=
+00023b00: 4e6f 6e65 293a 0a20 2020 2020 2020 2069  None):.        i
+00023b10: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+00023b20: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00023b30: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+00023b40: 203d 206d 732e 6f70 732e 6c6f 6769 7428   = ms.ops.logit(
+00023b50: 696e 7075 745f 6d73 2c20 6570 7329 0a20  input_ms, eps). 
+00023b60: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00023b70: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00023b80: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+00023b90: 2020 6465 6620 6c6f 6769 745f 2873 656c    def logit_(sel
+00023ba0: 662c 2065 7073 3d4e 6f6e 6529 3a0a 2020  f, eps=None):.  
+00023bb0: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
+00023bc0: 656c 662e 6c6f 6769 7428 6570 733d 6570  elf.logit(eps=ep
+00023bd0: 7329 0a20 2020 2020 2020 2072 6574 7572  s).        retur
+00023be0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+00023bf0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00023c00: 7574 7075 742c 2022 6c6f 6769 745f 222c  utput, "logit_",
+00023c10: 2022 6c6f 6769 7422 290a 0a20 2020 2064   "logit")..    d
+00023c20: 6566 206d 6174 7269 785f 706f 7765 7228  ef matrix_power(
+00023c30: 7365 6c66 2c20 6e29 3a0a 2020 2020 2020  self, n):.      
+00023c40: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+00023c50: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+00023c60: 656c 6629 0a20 2020 2020 2020 2069 6e70  elf).        inp
+00023c70: 7574 5f74 7970 6520 3d20 696e 7075 745f  ut_type = input_
+00023c80: 6d73 2e64 7479 7065 0a20 2020 2020 2020  ms.dtype.       
+00023c90: 2069 6620 696e 7075 745f 7479 7065 206e   if input_type n
+00023ca0: 6f74 2069 6e20 286d 732e 666c 6f61 7433  ot in (ms.float3
+00023cb0: 322c 206d 732e 666c 6f61 7431 3629 3a0a  2, ms.float16):.
+00023cc0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00023cd0: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
+00023ce0: 6173 7479 7065 286d 732e 666c 6f61 7433  astype(ms.float3
+00023cf0: 3229 0a20 2020 2020 2020 2069 6620 6e6f  2).        if no
+00023d00: 7420 6973 5f75 6e64 6572 5f67 7075 5f63  t is_under_gpu_c
+00023d10: 6f6e 7465 7874 2829 3a0a 2020 2020 2020  ontext():.      
+00023d20: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+00023d30: 732e 6f70 732e 6d61 7472 6978 5f70 6f77  s.ops.matrix_pow
+00023d40: 6572 2869 6e70 7574 5f6d 732c 206e 290a  er(input_ms, n).
+00023d50: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+00023d60: 2020 2020 2020 2020 2020 2354 4f44 4f3a            #TODO:
+00023d70: 2075 7365 6420 6f70 7320 6675 6e63 206f   used ops func o
+00023d80: 6e20 4750 550a 2020 2020 2020 2020 2020  n GPU.          
+00023d90: 2020 6f75 7470 7574 203d 206d 732e 6e75    output = ms.nu
+00023da0: 6d70 792e 6d61 7472 6978 5f70 6f77 6572  mpy.matrix_power
+00023db0: 2869 6e70 7574 5f6d 732c 206e 290a 2020  (input_ms, n).  
+00023dc0: 2020 2020 2020 6966 2069 6e70 7574 5f74        if input_t
+00023dd0: 7970 6520 6e6f 7420 696e 2028 6d73 2e66  ype not in (ms.f
+00023de0: 6c6f 6174 3332 2c20 6d73 2e66 6c6f 6174  loat32, ms.float
+00023df0: 3136 293a 0a20 2020 2020 2020 2020 2020  16):.           
+00023e00: 206f 7574 7075 7420 3d20 6f75 7470 7574   output = output
+00023e10: 2e61 7374 7970 6528 696e 7075 745f 7479  .astype(input_ty
+00023e20: 7065 290a 2020 2020 2020 2020 7265 7475  pe).        retu
+00023e30: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00023e40: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+00023e50: 290a 0a20 2020 2064 6566 2069 6e64 6578  )..    def index
+00023e60: 5f61 6464 2873 656c 662c 2064 696d 2c20  _add(self, dim, 
+00023e70: 696e 6465 782c 2073 6f75 7263 652c 202a  index, source, *
+00023e80: 2c20 616c 7068 613d 3129 3a0a 2020 2020  , alpha=1):.    
+00023e90: 2020 2020 2320 544f 444f 3a20 746f 2073      # TODO: to s
+00023ea0: 7570 706f 7274 2069 6e70 7574 206f 6620  upport input of 
+00023eb0: 6d6f 7265 2074 6861 6e20 322d 4420 2620  more than 2-D & 
+00023ec0: 6469 6d20 3e3d 2031 2c20 746f 2073 7570  dim >= 1, to sup
+00023ed0: 706f 7274 2047 5241 5048 206d 6f64 650a  port GRAPH mode.
+00023ee0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00023ef0: 6474 7970 6520 213d 2073 6f75 7263 652e  dtype != source.
+00023f00: 6474 7970 653a 0a20 2020 2020 2020 2020  dtype:.         
+00023f10: 2020 2072 6169 7365 2052 756e 7469 6d65     raise Runtime
+00023f20: 4572 726f 7228 6622 696e 6465 785f 6164  Error(f"index_ad
+00023f30: 6428 293a 2073 656c 6620 287b 7365 6c66  d(): self ({self
+00023f40: 2e64 7479 7065 7d29 2061 6e64 2073 6f75  .dtype}) and sou
+00023f50: 7263 6520 287b 736f 7572 6365 2e64 7479  rce ({source.dty
+00023f60: 7065 7d29 2022 0a20 2020 2020 2020 2020  pe}) ".         
+00023f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00023f80: 2020 2020 2020 6622 6d75 7374 2068 6176        f"must hav
+00023f90: 6520 7468 6520 7361 6d65 2073 6361 6c61  e the same scala
+00023fa0: 7220 7479 7065 2229 0a20 2020 2020 2020  r type").       
+00023fb0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+00023fc0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+00023fd0: 6c66 290a 2020 2020 2020 2020 736f 7572  lf).        sour
+00023fe0: 6365 203d 2063 6173 745f 746f 5f6d 735f  ce = cast_to_ms_
+00023ff0: 7465 6e73 6f72 2873 6f75 7263 6529 0a20  tensor(source). 
+00024000: 2020 2020 2020 2069 6e64 6578 203d 2063         index = c
+00024010: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00024020: 2869 6e64 6578 292e 6173 7479 7065 286d  (index).astype(m
+00024030: 7374 7970 652e 696e 7433 3229 0a20 2020  stype.int32).   
+00024040: 2020 2020 2023 206d 732e 5465 6e73 6f72       # ms.Tensor
+00024050: 2e69 6e64 6578 5f61 6464 2069 7320 616e  .index_add is an
+00024060: 2069 6e2d 706c 6163 6520 6f70 6572 6174   in-place operat
+00024070: 696f 6e2c 2073 6f20 7765 206e 6565 6420  ion, so we need 
+00024080: 746f 2064 6565 7063 6f70 7920 696e 7075  to deepcopy inpu
+00024090: 7420 6669 7273 740a 2020 2020 2020 2020  t first.        
+000240a0: 696e 7075 745f 636f 7079 203d 2064 6565  input_copy = dee
+000240b0: 7063 6f70 795f 6f70 2869 6e70 7574 5f6d  pcopy_op(input_m
+000240c0: 7329 0a20 2020 2020 2020 2073 6f75 7263  s).        sourc
+000240d0: 6520 3d20 736f 7572 6365 202a 2061 6c70  e = source * alp
+000240e0: 6861 0a20 2020 2020 2020 2069 6620 696e  ha.        if in
+000240f0: 7075 745f 636f 7079 2e64 7479 7065 203d  put_copy.dtype =
+00024100: 3d20 6d73 7479 7065 2e69 6e74 3634 3a0a  = mstype.int64:.
+00024110: 2020 2020 2020 2020 2020 2020 2320 6d73              # ms
+00024120: 2e6f 7073 2e69 6e64 6578 5f61 6464 2074  .ops.index_add t
+00024130: 616b 6573 206f 6e6c 7920 5061 7261 6d65  akes only Parame
+00024140: 7465 7220 696e 7075 742c 2073 6f20 7765  ter input, so we
+00024150: 2075 7365 206d 732e 5465 6e73 6f72 2e69   use ms.Tensor.i
+00024160: 6e64 6578 5f61 6464 2068 6572 650a 2020  ndex_add here.  
+00024170: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00024180: 203d 2069 6e70 7574 5f63 6f70 792e 696e   = input_copy.in
+00024190: 7428 292e 696e 6465 785f 6164 6428 6469  t().index_add(di
+000241a0: 6d2c 2069 6e64 6578 2c20 736f 7572 6365  m, index, source
+000241b0: 2e69 6e74 2829 292e 6173 7479 7065 286d  .int()).astype(m
+000241c0: 7374 7970 652e 696e 7436 3429 0a20 2020  stype.int64).   
+000241d0: 2020 2020 2065 6c73 653a 0a20 2020 2020       else:.     
+000241e0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+000241f0: 696e 7075 745f 636f 7079 2e69 6e64 6578  input_copy.index
+00024200: 5f61 6464 2864 696d 2c20 696e 6465 782c  _add(dim, index,
+00024210: 2073 6f75 7263 6529 0a20 2020 2020 2020   source).       
+00024220: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+00024230: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
+00024240: 7574 7075 7429 0a0a 0a20 2020 2064 6566  utput)...    def
+00024250: 2069 6e64 6578 5f61 6464 5f28 7365 6c66   index_add_(self
+00024260: 2c20 6469 6d2c 2069 6e64 6578 2c20 736f  , dim, index, so
+00024270: 7572 6365 2c20 2a2c 2061 6c70 6861 3d31  urce, *, alpha=1
+00024280: 293a 0a20 2020 2020 2020 2023 2054 4f44  ):.        # TOD
+00024290: 4f3a 2074 6f20 7375 7070 6f72 7420 696e  O: to support in
+000242a0: 7075 7420 6f66 206d 6f72 6520 7468 616e  put of more than
+000242b0: 2032 2d44 2026 2064 696d 203e 3d20 312c   2-D & dim >= 1,
+000242c0: 2074 6f20 7375 7070 6f72 7420 4752 4150   to support GRAP
+000242d0: 4820 6d6f 6465 0a20 2020 2020 2020 206f  H mode.        o
+000242e0: 7574 7075 7420 3d20 7365 6c66 2e69 6e64  utput = self.ind
+000242f0: 6578 5f61 6464 2864 696d 2c20 696e 6465  ex_add(dim, inde
+00024300: 782c 2073 6f75 7263 652c 2061 6c70 6861  x, source, alpha
+00024310: 3d61 6c70 6861 290a 2020 2020 2020 2020  =alpha).        
+00024320: 7265 7475 726e 205f 7465 6e73 6f72 5f69  return _tensor_i
+00024330: 6e70 6c61 6365 5f61 7373 6967 6e28 7365  nplace_assign(se
+00024340: 6c66 2c20 6f75 7470 7574 2c20 2269 6e64  lf, output, "ind
+00024350: 6578 5f61 6464 5f22 2c20 2269 6e64 6578  ex_add_", "index
+00024360: 5f61 6464 2229 0a0a 2020 2020 6465 6620  _add")..    def 
+00024370: 7363 6174 7465 725f 6164 6428 7365 6c66  scatter_add(self
+00024380: 2c20 6469 6d2c 2069 6e64 6578 2c20 7372  , dim, index, sr
+00024390: 6329 3a0a 2020 2020 2020 2020 2320 544f  c):.        # TO
+000243a0: 444f 3a20 7375 7070 6f72 7420 7372 6320  DO: support src 
+000243b0: 616e 6420 696e 6465 7820 6f66 2064 6966  and index of dif
+000243c0: 6665 7265 6e74 2073 6861 7065 0a20 2020  ferent shape.   
+000243d0: 2020 2020 2023 206d 732e 6f70 732e 7363       # ms.ops.sc
+000243e0: 6174 7465 725f 6164 6420 6861 7320 6d6f  atter_add has mo
+000243f0: 7265 2072 6573 7472 6963 7469 6f6e 7320  re restrictions 
+00024400: 6f6e 2074 6865 2073 6861 7065 206f 6620  on the shape of 
+00024410: 696e 7075 7473 0a20 2020 2020 2020 2069  inputs.        i
+00024420: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
+00024430: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
+00024440: 290a 2020 2020 2020 2020 696e 6465 7820  ).        index 
+00024450: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00024460: 736f 7228 696e 6465 7829 0a20 2020 2020  sor(index).     
+00024470: 2020 2073 7263 203d 2063 6173 745f 746f     src = cast_to
+00024480: 5f6d 735f 7465 6e73 6f72 2873 7263 290a  _ms_tensor(src).
+00024490: 2020 2020 2020 2020 2320 544f 444f 3a20          # TODO: 
+000244a0: 6173 6365 6e64 2064 6f65 7320 6e6f 7420  ascend does not 
+000244b0: 7375 7070 6f72 7420 7465 6e73 6f72 5f73  support tensor_s
+000244c0: 6361 7474 6572 5f65 6c65 6d65 6e74 730a  catter_elements.
+000244d0: 2020 2020 2020 2020 6966 2069 735f 756e          if is_un
+000244e0: 6465 725f 6173 6365 6e64 5f63 6f6e 7465  der_ascend_conte
+000244f0: 7874 2829 3a0a 2020 2020 2020 2020 2020  xt():.          
+00024500: 2020 6966 2064 696d 203e 2030 3a0a 2020    if dim > 0:.  
+00024510: 2020 2020 2020 2020 2020 2020 2020 6e64                nd
+00024520: 5f69 6478 2c20 6e64 5f69 6e70 7574 2c20  _idx, nd_input, 
+00024530: 6e64 5f73 7263 203d 2073 656c 662e 5f67  nd_src = self._g
+00024540: 6574 5f73 6361 7474 6572 5f6e 6469 6d5f  et_scatter_ndim_
+00024550: 696e 7075 7428 696e 7075 745f 6d73 2c20  input(input_ms, 
+00024560: 696e 6465 782c 2073 7263 2c20 6469 6d29  index, src, dim)
+00024570: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00024580: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00024590: 2e73 6361 7474 6572 5f6e 645f 6164 6428  .scatter_nd_add(
+000245a0: 6e64 5f69 6e70 7574 2c20 6e64 5f69 6478  nd_input, nd_idx
+000245b0: 2c20 6e64 5f73 7263 292e 7371 7565 657a  , nd_src).squeez
+000245c0: 6528 2d31 290a 2020 2020 2020 2020 2020  e(-1).          
+000245d0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+000245e0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000245f0: 206d 732e 6f70 732e 7363 6174 7465 725f   ms.ops.scatter_
+00024600: 6164 6428 696e 7075 745f 6d73 2c20 696e  add(input_ms, in
+00024610: 6465 782c 2073 7263 290a 2020 2020 2020  dex, src).      
+00024620: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+00024630: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
+00024640: 6f70 732e 7465 6e73 6f72 5f73 6361 7474  ops.tensor_scatt
+00024650: 6572 5f65 6c65 6d65 6e74 7328 696e 7075  er_elements(inpu
+00024660: 745f 6d73 2c20 696e 6465 782c 2073 7263  t_ms, index, src
+00024670: 2c20 6178 6973 3d64 696d 2c20 7265 6475  , axis=dim, redu
+00024680: 6374 696f 6e3d 2261 6464 2229 0a20 2020  ction="add").   
+00024690: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+000246a0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+000246b0: 6f72 286f 7574 7075 7429 0a0a 2020 2020  or(output)..    
+000246c0: 6465 6620 7363 6174 7465 725f 6164 645f  def scatter_add_
+000246d0: 2873 656c 662c 2064 696d 2c20 696e 6465  (self, dim, inde
+000246e0: 782c 2073 7263 293a 0a20 2020 2020 2020  x, src):.       
+000246f0: 206f 7574 7075 7420 3d20 7365 6c66 2e73   output = self.s
+00024700: 6361 7474 6572 5f61 6464 2864 696d 2c20  catter_add(dim, 
+00024710: 696e 6465 782c 2073 7263 290a 2020 2020  index, src).    
+00024720: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
+00024730: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
+00024740: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
+00024750: 2273 6361 7474 6572 5f61 6464 5f22 2c20  "scatter_add_", 
+00024760: 2273 6361 7474 6572 5f61 6464 2229 0a0a  "scatter_add")..
+00024770: 2020 2020 6465 6620 696e 6465 785f 636f      def index_co
+00024780: 7079 2873 656c 662c 2064 696d 2c20 696e  py(self, dim, in
+00024790: 6465 782c 2074 656e 736f 7232 293a 0a20  dex, tensor2):. 
+000247a0: 2020 2020 2020 2023 2054 4f44 4f3a 2074         # TODO: t
+000247b0: 6f20 7375 7070 6f72 7420 696e 7075 7420  o support input 
+000247c0: 6f66 206d 6f72 6520 7468 616e 2032 2d44  of more than 2-D
+000247d0: 2026 2064 696d 203e 3d20 312c 2074 6f20   & dim >= 1, to 
+000247e0: 7375 7070 6f72 7420 4752 4150 4820 6d6f  support GRAPH mo
+000247f0: 6465 0a20 2020 2020 2020 2023 2054 4f44  de.        # TOD
+00024800: 4f3a 2072 6570 6c61 6365 2077 6974 6820  O: replace with 
+00024810: 6d73 2e6f 7073 2e69 6e64 6578 5f63 6f70  ms.ops.index_cop
+00024820: 790a 2020 2020 2020 2020 6966 2073 656c  y.        if sel
+00024830: 662e 6474 7970 6520 213d 2074 656e 736f  f.dtype != tenso
+00024840: 7232 2e64 7479 7065 3a0a 2020 2020 2020  r2.dtype:.      
+00024850: 2020 2020 2020 7261 6973 6520 5275 6e74        raise Runt
+00024860: 696d 6545 7272 6f72 2866 2269 6e64 6578  imeError(f"index
+00024870: 5f61 6464 2829 3a20 7365 6c66 2028 7b73  _add(): self ({s
+00024880: 656c 662e 6474 7970 657d 2920 616e 6420  elf.dtype}) and 
+00024890: 736f 7572 6365 2028 7b74 656e 736f 7232  source ({tensor2
+000248a0: 2e64 7479 7065 7d29 2022 0a20 2020 2020  .dtype}) ".     
+000248b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000248c0: 2020 2020 2020 2020 2020 6622 6d75 7374            f"must
+000248d0: 2068 6176 6520 7468 6520 7361 6d65 2073   have the same s
+000248e0: 6361 6c61 7220 7479 7065 2229 0a20 2020  calar type").   
+000248f0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00024900: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00024910: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00024920: 736f 7572 6365 203d 2063 6173 745f 746f  source = cast_to
+00024930: 5f6d 735f 7465 6e73 6f72 2874 656e 736f  _ms_tensor(tenso
+00024940: 7232 290a 2020 2020 2020 2020 696e 6465  r2).        inde
+00024950: 7820 3d20 6361 7374 5f74 6f5f 6d73 5f74  x = cast_to_ms_t
+00024960: 656e 736f 7228 696e 6465 7829 2e61 7374  ensor(index).ast
+00024970: 7970 6528 6d73 7479 7065 2e69 6e74 3332  ype(mstype.int32
+00024980: 290a 2020 2020 2020 2020 6966 2069 6e64  ).        if ind
+00024990: 6578 2e6e 6469 6d20 3d3d 2030 3a0a 2020  ex.ndim == 0:.  
+000249a0: 2020 2020 2020 2020 2020 696e 6465 7820            index 
+000249b0: 3d20 6d73 2e6f 7073 2e75 6e73 7175 6565  = ms.ops.unsquee
+000249c0: 7a65 2869 6e64 6578 2c20 3029 0a0a 2020  ze(index, 0)..  
+000249d0: 2020 2020 2020 6966 2073 656c 662e 6474        if self.dt
+000249e0: 7970 6520 3d3d 206d 7374 7970 652e 696e  ype == mstype.in
+000249f0: 7436 343a 0a20 2020 2020 2020 2020 2020  t64:.           
+00024a00: 2069 6e70 7574 5f6d 7320 3d20 696e 7075   input_ms = inpu
+00024a10: 745f 6d73 2e61 7374 7970 6528 6d73 7479  t_ms.astype(msty
+00024a20: 7065 2e69 6e74 3332 290a 2020 2020 2020  pe.int32).      
+00024a30: 2020 2020 2020 736f 7572 6365 203d 2073        source = s
+00024a40: 6f75 7263 652e 6173 7479 7065 286d 7374  ource.astype(mst
+00024a50: 7970 652e 696e 7433 3229 0a20 2020 2020  ype.int32).     
+00024a60: 2020 2073 656c 6563 7420 3d20 6d73 2e6f     select = ms.o
+00024a70: 7073 2e69 6e64 6578 5f73 656c 6563 7428  ps.index_select(
+00024a80: 696e 7075 745f 6d73 2c20 6469 6d2c 2069  input_ms, dim, i
+00024a90: 6e64 6578 290a 2020 2020 2020 2020 2320  ndex).        # 
+00024aa0: 6d73 2e54 656e 736f 722e 696e 6465 785f  ms.Tensor.index_
+00024ab0: 6164 6420 6973 2061 6e20 696e 2d70 6c61  add is an in-pla
+00024ac0: 6365 206f 7065 7261 7469 6f6e 2c20 736f  ce operation, so
+00024ad0: 2077 6520 6e65 6564 2074 6f20 6465 6570   we need to deep
+00024ae0: 636f 7079 2069 6e70 7574 2066 6972 7374  copy input first
+00024af0: 0a20 2020 2020 2020 2069 6e70 7574 5f63  .        input_c
+00024b00: 6f70 7920 3d20 6465 6570 636f 7079 5f6f  opy = deepcopy_o
+00024b10: 7028 696e 7075 745f 6d73 290a 2020 2020  p(input_ms).    
+00024b20: 2020 2020 2320 6d73 2e6f 7073 2e69 6e64      # ms.ops.ind
+00024b30: 6578 5f61 6464 2073 7570 706f 7274 7320  ex_add supports 
+00024b40: 6f6e 6c79 2050 6172 616d 6574 6572 2069  only Parameter i
+00024b50: 6e70 7574 2073 6f20 7765 2075 7365 206d  nput so we use m
+00024b60: 732e 5465 6e73 6f72 2e69 6e64 6578 5f61  s.Tensor.index_a
+00024b70: 6464 2068 6572 650a 2020 2020 2020 2020  dd here.        
+00024b80: 6f75 7470 7574 3020 3d20 696e 7075 745f  output0 = input_
+00024b90: 636f 7079 2e69 6e64 6578 5f61 6464 2864  copy.index_add(d
+00024ba0: 696d 2c20 696e 6465 782c 2073 656c 6563  im, index, selec
+00024bb0: 742c 2061 6c70 6861 3d2d 3129 0a20 2020  t, alpha=-1).   
+00024bc0: 2020 2020 206f 7574 7075 7420 3d20 6f75       output = ou
+00024bd0: 7470 7574 302e 696e 6465 785f 6164 6428  tput0.index_add(
+00024be0: 6469 6d2c 2069 6e64 6578 2c20 736f 7572  dim, index, sour
+00024bf0: 6365 290a 2020 2020 2020 2020 6966 2073  ce).        if s
+00024c00: 656c 662e 6474 7970 6520 3d3d 206d 7374  elf.dtype == mst
+00024c10: 7970 652e 696e 7436 343a 0a20 2020 2020  ype.int64:.     
+00024c20: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00024c30: 6f75 7470 7574 2e61 7374 7970 6528 6d73  output.astype(ms
+00024c40: 7479 7065 2e69 6e74 3634 290a 2020 2020  type.int64).    
+00024c50: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+00024c60: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+00024c70: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+00024c80: 6566 2069 6e64 6578 5f63 6f70 795f 2873  ef index_copy_(s
+00024c90: 656c 662c 2064 696d 2c20 696e 6465 782c  elf, dim, index,
+00024ca0: 2074 656e 736f 7229 3a0a 2020 2020 2020   tensor):.      
+00024cb0: 2020 2320 544f 444f 3a20 746f 2073 7570    # TODO: to sup
+00024cc0: 706f 7274 2069 6e70 7574 206f 6620 6d6f  port input of mo
+00024cd0: 7265 2074 6861 6e20 322d 4420 2620 6469  re than 2-D & di
+00024ce0: 6d20 3e3d 2031 2c20 746f 2073 7570 706f  m >= 1, to suppo
+00024cf0: 7274 2047 5241 5048 206d 6f64 650a 2020  rt GRAPH mode.  
+00024d00: 2020 2020 2020 6f75 7470 7574 203d 2073        output = s
+00024d10: 656c 662e 696e 6465 785f 636f 7079 2864  elf.index_copy(d
+00024d20: 696d 2c20 696e 6465 782c 2074 656e 736f  im, index, tenso
+00024d30: 7229 0a20 2020 2020 2020 2072 6574 7572  r).        retur
+00024d40: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+00024d50: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00024d60: 7574 7075 742c 2022 696e 6465 785f 636f  utput, "index_co
+00024d70: 7079 5f22 2c20 2269 6e64 6578 5f63 6f70  py_", "index_cop
+00024d80: 7922 290a 0a20 2020 2064 6566 2064 6961  y")..    def dia
+00024d90: 675f 656d 6265 6428 7365 6c66 2c20 6f66  g_embed(self, of
+00024da0: 6673 6574 3d30 2c20 6469 6d31 3d2d 322c  fset=0, dim1=-2,
+00024db0: 2064 696d 323d 2d31 293a 0a20 2020 2020   dim2=-1):.     
+00024dc0: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+00024dd0: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+00024de0: 7365 6c66 290a 2020 2020 2020 2020 6f75  self).        ou
+00024df0: 7470 7574 203d 206d 732e 6f70 732e 6469  tput = ms.ops.di
+00024e00: 6167 5f65 6d62 6564 2869 6e70 7574 5f6d  ag_embed(input_m
+00024e10: 732c 206f 6666 7365 743d 6f66 6673 6574  s, offset=offset
+00024e20: 2c20 6469 6d31 3d64 696d 312c 2064 696d  , dim1=dim1, dim
+00024e30: 323d 6469 6d32 290a 2020 2020 2020 2020  2=dim2).        
 00024e40: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
 00024e50: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
 00024e60: 7470 7574 290a 0a20 2020 2064 6566 2069  tput)..    def i
-00024e70: 6e64 6578 5f70 7574 5f28 7365 6c66 2c20  ndex_put_(self, 
-00024e80: 696e 6469 6365 732c 2076 616c 7565 732c  indices, values,
-00024e90: 2061 6363 756d 756c 6174 653d 4661 6c73   accumulate=Fals
-00024ea0: 6529 3a0a 2020 2020 2020 2020 6f75 7470  e):.        outp
-00024eb0: 7574 203d 2073 656c 662e 696e 6465 785f  ut = self.index_
-00024ec0: 7075 7428 696e 6469 6365 732c 2076 616c  put(indices, val
-00024ed0: 7565 732c 2061 6363 756d 756c 6174 653d  ues, accumulate=
-00024ee0: 6163 6375 6d75 6c61 7465 290a 2020 2020  accumulate).    
-00024ef0: 2020 2020 7265 7475 726e 205f 7465 6e73      return _tens
-00024f00: 6f72 5f69 6e70 6c61 6365 5f61 7373 6967  or_inplace_assig
-00024f10: 6e28 7365 6c66 2c20 6f75 7470 7574 2c20  n(self, output, 
-00024f20: 2269 6e64 6578 5f70 7574 5f22 2c20 2269  "index_put_", "i
-00024f30: 6e64 6578 5f70 7574 2229 0a0a 2020 2020  ndex_put")..    
-00024f40: 6465 6620 6c6f 6763 756d 7375 6d65 7870  def logcumsumexp
-00024f50: 2873 656c 662c 2064 696d 293a 0a20 2020  (self, dim):.   
-00024f60: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00024f70: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00024f80: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00024f90: 6f75 7470 7574 203d 2069 6e70 7574 5f6d  output = input_m
-00024fa0: 732e 6c6f 6763 756d 7375 6d65 7870 2864  s.logcumsumexp(d
-00024fb0: 696d 290a 2020 2020 2020 2020 7265 7475  im).        retu
-00024fc0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-00024fd0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-00024fe0: 290a 0a0a 2020 2020 2354 4f44 4f3a 2063  )...    #TODO: c
-00024ff0: 7572 7265 6e74 6c79 206d 696e 6473 706f  urrently mindspo
-00025000: 7265 2064 6f65 206e 6f74 2073 7570 706f  re doe not suppo
-00025010: 7274 206b 7468 7661 6c75 650a 2020 2020  rt kthvalue.    
-00025020: 6465 6620 6b74 6876 616c 7565 2873 656c  def kthvalue(sel
-00025030: 662c 206b 2c20 6469 6d3d 4e6f 6e65 2c20  f, k, dim=None, 
-00025040: 6b65 6570 6469 6d3d 4661 6c73 6529 3a0a  keepdim=False):.
-00025050: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00025060: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00025070: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00025080: 2020 2069 6e70 7574 5f74 7970 6520 3d20     input_type = 
-00025090: 696e 7075 745f 6d73 2e64 7479 7065 0a20  input_ms.dtype. 
-000250a0: 2020 2020 2020 2074 7970 655f 7472 616e         type_tran
-000250b0: 7320 3d20 4661 6c73 650a 2020 2020 2020  s = False.      
-000250c0: 2020 6966 2069 6e70 7574 5f74 7970 6520    if input_type 
-000250d0: 6e6f 7420 696e 2028 6d73 2e66 6c6f 6174  not in (ms.float
-000250e0: 3136 2c20 6d73 2e66 6c6f 6174 3332 2c20  16, ms.float32, 
-000250f0: 6d73 2e69 6e74 3332 293a 0a20 2020 2020  ms.int32):.     
-00025100: 2020 2020 2020 2074 7970 655f 7472 616e         type_tran
-00025110: 7320 3d20 5472 7565 0a20 2020 2020 2020  s = True.       
-00025120: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00025130: 696e 7075 745f 6d73 2e61 7374 7970 6528  input_ms.astype(
-00025140: 6d73 2e66 6c6f 6174 3332 290a 2020 2020  ms.float32).    
-00025150: 2020 2020 7661 6c75 6573 2c20 696e 6469      values, indi
-00025160: 6365 7320 3d20 6d73 2e6f 7073 2e74 6f70  ces = ms.ops.top
-00025170: 6b28 696e 7075 745f 6d73 2c20 6b2c 2064  k(input_ms, k, d
-00025180: 696d 2c20 6c61 7267 6573 743d 4661 6c73  im, largest=Fals
-00025190: 652c 2073 6f72 7465 643d 5472 7565 290a  e, sorted=True).
-000251a0: 2020 2020 2020 2020 6966 2064 696d 2069          if dim i
-000251b0: 7320 4e6f 6e65 3a0a 2020 2020 2020 2020  s None:.        
-000251c0: 2020 2020 6469 6d20 3d20 7661 6c75 6573      dim = values
-000251d0: 2e6e 6469 6d2d 310a 2020 2020 2020 2020  .ndim-1.        
-000251e0: 7661 6c75 6573 3d6d 732e 6f70 732e 696e  values=ms.ops.in
-000251f0: 6465 785f 7365 6c65 6374 2876 616c 7565  dex_select(value
-00025200: 732c 2064 696d 2c20 6d73 2e54 656e 736f  s, dim, ms.Tenso
-00025210: 7228 5b6b 2d31 5d29 290a 2020 2020 2020  r([k-1])).      
-00025220: 2020 696e 6469 6365 733d 6d73 2e6f 7073    indices=ms.ops
-00025230: 2e69 6e64 6578 5f73 656c 6563 7428 696e  .index_select(in
-00025240: 6469 6365 732c 2064 696d 2c20 6d73 2e54  dices, dim, ms.T
-00025250: 656e 736f 7228 5b6b 2d31 5d29 290a 2020  ensor([k-1])).  
-00025260: 2020 2020 2020 7661 6c75 6573 203d 2076        values = v
-00025270: 616c 7565 732e 7371 7565 657a 6528 290a  alues.squeeze().
-00025280: 2020 2020 2020 2020 696e 6469 6365 7320          indices 
-00025290: 3d20 696e 6469 6365 732e 7371 7565 657a  = indices.squeez
-000252a0: 6528 290a 2020 2020 2020 2020 6966 206b  e().        if k
-000252b0: 6565 7064 696d 3a0a 2020 2020 2020 2020  eepdim:.        
-000252c0: 2020 2020 7661 6c75 6573 203d 2076 616c      values = val
-000252d0: 7565 732e 756e 7371 7565 657a 6528 6469  ues.unsqueeze(di
-000252e0: 6d29 0a20 2020 2020 2020 2020 2020 2069  m).            i
-000252f0: 6e64 6963 6573 203d 2069 6e64 6963 6573  ndices = indices
-00025300: 2e75 6e73 7175 6565 7a65 2864 696d 290a  .unsqueeze(dim).
-00025310: 2020 2020 2020 2020 6966 2074 7970 655f          if type_
-00025320: 7472 616e 733a 0a20 2020 2020 2020 2020  trans:.         
-00025330: 2020 2076 616c 7565 7320 3d20 7661 6c75     values = valu
-00025340: 6573 2e61 7374 7970 6528 696e 7075 745f  es.astype(input_
-00025350: 7479 7065 290a 2020 2020 2020 2020 696e  type).        in
-00025360: 6469 6365 7320 3d20 696e 6469 6365 732e  dices = indices.
-00025370: 6173 7479 7065 286d 732e 696e 7436 3429  astype(ms.int64)
-00025380: 0a20 2020 2020 2020 2069 6620 7079 6e61  .        if pyna
-00025390: 7469 7665 5f6d 6f64 655f 636f 6e64 6974  tive_mode_condit
-000253a0: 696f 6e28 293a 0a20 2020 2020 2020 2020  ion():.         
-000253b0: 2020 2070 6f69 6e74 203d 2073 6574 5f6e     point = set_n
-000253c0: 616d 655f 7475 706c 6528 276b 7468 7661  ame_tuple('kthva
-000253d0: 6c75 6527 290a 2020 2020 2020 2020 2020  lue').          
-000253e0: 2020 726c 7420 3d20 706f 696e 7428 6361    rlt = point(ca
-000253f0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00025400: 6e73 6f72 2876 616c 7565 7329 2c20 6361  nsor(values), ca
-00025410: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00025420: 6e73 6f72 2869 6e64 6963 6573 2929 0a20  nsor(indices)). 
-00025430: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00025440: 6e20 726c 740a 2020 2020 2020 2020 7265  n rlt.        re
-00025450: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
-00025460: 7074 6572 5f74 656e 736f 7228 7661 6c75  pter_tensor(valu
-00025470: 6573 292c 2063 6173 745f 746f 5f61 6461  es), cast_to_ada
-00025480: 7074 6572 5f74 656e 736f 7228 696e 6469  pter_tensor(indi
-00025490: 6365 7329 0a0a 2020 2020 6465 6620 5f67  ces)..    def _g
-000254a0: 6574 5f73 6361 7474 6572 5f6e 6469 6d5f  et_scatter_ndim_
-000254b0: 696e 7075 7428 7365 6c66 2c20 696e 7075  input(self, inpu
-000254c0: 742c 2069 6e64 6578 2c20 7372 632c 2064  t, index, src, d
-000254d0: 696d 293a 0a20 2020 2020 2020 2069 6e64  im):.        ind
-000254e0: 6578 5f73 746b 203d 2028 290a 2020 2020  ex_stk = ().    
-000254f0: 2020 2020 666f 7220 6920 696e 2072 616e      for i in ran
-00025500: 6765 286c 656e 2869 6e64 6578 2e73 6861  ge(len(index.sha
-00025510: 7065 2929 3a0a 2020 2020 2020 2020 2020  pe)):.          
-00025520: 2020 6e65 775f 7368 6170 653d 2869 6e64    new_shape=(ind
-00025530: 6578 2e73 6861 7065 5b69 5d2c 2920 2b20  ex.shape[i],) + 
-00025540: 2831 2c29 202a 2028 6c65 6e28 696e 6465  (1,) * (len(inde
-00025550: 782e 7368 6170 6529 202d 2031 202d 2069  x.shape) - 1 - i
-00025560: 290a 2020 2020 2020 2020 2020 2020 6966  ).            if
-00025570: 2069 203d 3d20 6469 6d3a 0a20 2020 2020   i == dim:.     
-00025580: 2020 2020 2020 2020 2020 2069 6e64 6578             index
-00025590: 5f73 746b 203d 2069 6e64 6578 5f73 746b  _stk = index_stk
-000255a0: 202b 2028 696e 6465 782e 666c 6f61 7428   + (index.float(
-000255b0: 292c 290a 2020 2020 2020 2020 2020 2020  ),).            
-000255c0: 656c 7365 3a0a 2020 2020 2020 2020 2020  else:.          
-000255d0: 2020 2020 2020 696e 6465 785f 7374 6b20        index_stk 
-000255e0: 3d20 696e 6465 785f 7374 6b20 2b20 5c0a  = index_stk + \.
-000255f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00025600: 286d 732e 6f70 732e 6172 616e 6765 2830  (ms.ops.arange(0
-00025610: 2c20 696e 6465 782e 7368 6170 655b 695d  , index.shape[i]
-00025620: 292e 666c 6f61 7428 292e 7265 7368 6170  ).float().reshap
-00025630: 6528 6e65 775f 7368 6170 6529 2e62 726f  e(new_shape).bro
-00025640: 6164 6361 7374 5f74 6f28 696e 6465 782e  adcast_to(index.
-00025650: 7368 6170 6529 2c29 0a20 2020 2020 2020  shape),).       
-00025660: 206e 645f 6964 7820 3d20 6d73 2e6f 7073   nd_idx = ms.ops
-00025670: 2e73 7461 636b 2869 6e64 6578 5f73 746b  .stack(index_stk
-00025680: 2c20 2d31 292e 6c6f 6e67 2829 0a20 2020  , -1).long().   
-00025690: 2020 2020 206e 645f 696e 7075 7420 3d20       nd_input = 
-000256a0: 696e 7075 742e 756e 7371 7565 657a 6528  input.unsqueeze(
-000256b0: 2d31 290a 2020 2020 2020 2020 6e64 5f73  -1).        nd_s
-000256c0: 7263 203d 2073 7263 5b2e 2e2e 2c20 3a69  rc = src[..., :i
-000256d0: 6e64 6578 2e73 6861 7065 5b2d 325d 2c20  ndex.shape[-2], 
-000256e0: 3a69 6e64 6578 2e73 6861 7065 5b2d 315d  :index.shape[-1]
-000256f0: 5d2e 756e 7371 7565 657a 6528 2d31 290a  ].unsqueeze(-1).
-00025700: 2020 2020 2020 2020 7265 7475 726e 206e          return n
-00025710: 645f 6964 782c 206e 645f 696e 7075 742c  d_idx, nd_input,
-00025720: 206e 645f 7372 630a 0a20 2020 2064 6566   nd_src..    def
-00025730: 2073 6361 7474 6572 5f72 6564 7563 6528   scatter_reduce(
-00025740: 7365 6c66 2c20 6469 6d2c 2069 6e64 6578  self, dim, index
-00025750: 2c20 7372 632c 2072 6564 7563 652c 202a  , src, reduce, *
-00025760: 2c20 696e 636c 7564 655f 7365 6c66 3d54  , include_self=T
-00025770: 7275 6529 3a0a 2020 2020 2020 2020 2320  rue):.        # 
-00025780: 544f 444f 3a20 746f 2073 7570 706f 7274  TODO: to support
-00025790: 2072 6564 7563 653d 276d 6561 6e27 0a20   reduce='mean'. 
-000257a0: 2020 2020 2020 2069 6620 7265 6475 6365         if reduce
-000257b0: 203d 3d20 276d 6561 6e27 3a0a 2020 2020   == 'mean':.    
-000257c0: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
-000257d0: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
-000257e0: 7228 2273 6361 7474 6572 5f72 6564 7563  r("scatter_reduc
-000257f0: 6520 6375 7272 656e 746c 7920 646f 6573  e currently does
-00025800: 6e27 7420 7375 7070 6f72 7420 7265 6475  n't support redu
-00025810: 6365 3d3d 276d 6561 6e27 2229 0a0a 2020  ce=='mean'")..  
-00025820: 2020 2020 2020 696e 7075 7420 3d20 7365        input = se
-00025830: 6c66 0a20 2020 2020 2020 2069 6e70 7574  lf.        input
-00025840: 5f6d 696e 203d 202d 666c 6f61 7428 2769  _min = -float('i
-00025850: 6e66 2729 0a20 2020 2020 2020 2069 6e70  nf').        inp
-00025860: 7574 5f6d 6178 203d 2066 6c6f 6174 2827  ut_max = float('
-00025870: 696e 6627 290a 0a20 2020 2020 2020 2069  inf')..        i
-00025880: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-00025890: 6f5f 6d73 5f74 656e 736f 7228 696e 7075  o_ms_tensor(inpu
-000258a0: 7429 0a20 2020 2020 2020 2069 6e64 6578  t).        index
-000258b0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-000258c0: 6e73 6f72 2869 6e64 6578 290a 2020 2020  nsor(index).    
-000258d0: 2020 2020 7372 6320 3d20 6361 7374 5f74      src = cast_t
-000258e0: 6f5f 6d73 5f74 656e 736f 7228 7372 6329  o_ms_tensor(src)
-000258f0: 0a0a 2020 2020 2020 2020 6966 2064 696d  ..        if dim
-00025900: 203e 2030 3a0a 2020 2020 2020 2020 2020   > 0:.          
-00025910: 2020 6e64 5f69 6478 2c20 6e64 5f69 6e70    nd_idx, nd_inp
-00025920: 7574 2c20 6e64 5f73 7263 203d 2073 656c  ut, nd_src = sel
-00025930: 662e 5f67 6574 5f73 6361 7474 6572 5f6e  f._get_scatter_n
-00025940: 6469 6d5f 696e 7075 7428 696e 7075 745f  dim_input(input_
-00025950: 6d73 2c20 696e 6465 782c 2073 7263 2c20  ms, index, src, 
-00025960: 6469 6d29 0a0a 2020 2020 2020 2020 6966  dim)..        if
-00025970: 2072 6564 7563 6520 3d3d 2027 7375 6d27   reduce == 'sum'
-00025980: 3a0a 2020 2020 2020 2020 2020 2020 6966  :.            if
-00025990: 2069 6e63 6c75 6465 5f73 656c 6620 6973   include_self is
-000259a0: 2046 616c 7365 3a0a 2020 2020 2020 2020   False:.        
-000259b0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-000259c0: 203d 2069 6e70 7574 5f6d 732e 7363 6174   = input_ms.scat
-000259d0: 7465 7228 6469 6d2c 2069 6e64 6578 2c20  ter(dim, index, 
-000259e0: 6d73 2e6f 7073 2e7a 6572 6f73 5f6c 696b  ms.ops.zeros_lik
-000259f0: 6528 696e 6465 782c 2064 7479 7065 3d69  e(index, dtype=i
-00025a00: 6e70 7574 5f6d 732e 6474 7970 6529 290a  nput_ms.dtype)).
-00025a10: 2020 2020 2020 2020 2020 2020 6966 2064              if d
-00025a20: 696d 203e 2030 3a0a 2020 2020 2020 2020  im > 0:.        
-00025a30: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00025a40: 206d 732e 6f70 732e 7363 6174 7465 725f   ms.ops.scatter_
-00025a50: 6e64 5f61 6464 286e 645f 696e 7075 742c  nd_add(nd_input,
-00025a60: 206e 645f 6964 782c 206e 645f 7372 6329   nd_idx, nd_src)
-00025a70: 2e73 7175 6565 7a65 282d 3129 0a20 2020  .squeeze(-1).   
-00025a80: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
-00025a90: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00025aa0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e73  utput = ms.ops.s
-00025ab0: 6361 7474 6572 5f61 6464 2869 6e70 7574  catter_add(input
-00025ac0: 5f6d 732c 2069 6e64 6578 2c20 7372 6329  _ms, index, src)
-00025ad0: 0a20 2020 2020 2020 2065 6c69 6620 7265  .        elif re
-00025ae0: 6475 6365 203d 3d20 2770 726f 6427 3a0a  duce == 'prod':.
-00025af0: 2020 2020 2020 2020 2020 2020 6966 2069              if i
-00025b00: 6e63 6c75 6465 5f73 656c 6620 6973 2046  nclude_self is F
-00025b10: 616c 7365 3a0a 2020 2020 2020 2020 2020  alse:.          
-00025b20: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00025b30: 2069 6e70 7574 5f6d 732e 7363 6174 7465   input_ms.scatte
-00025b40: 7228 6469 6d2c 2069 6e64 6578 2c20 6d73  r(dim, index, ms
-00025b50: 2e6f 7073 2e6f 6e65 735f 6c69 6b65 2869  .ops.ones_like(i
-00025b60: 6e64 6578 2c20 6474 7970 653d 696e 7075  ndex, dtype=inpu
-00025b70: 745f 6d73 2e64 7479 7065 2929 0a20 2020  t_ms.dtype)).   
-00025b80: 2020 2020 2020 2020 2069 6620 6469 6d20           if dim 
-00025b90: 3e20 303a 0a20 2020 2020 2020 2020 2020  > 0:.           
-00025ba0: 2020 2020 2023 2054 4f44 4f3a 206d 732e       # TODO: ms.
-00025bb0: 6f70 732e 7363 6174 7465 725f 6e64 5f6d  ops.scatter_nd_m
-00025bc0: 756c 2074 6f20 7375 7070 6f72 7420 4173  ul to support As
-00025bd0: 6365 6e64 0a20 2020 2020 2020 2020 2020  cend.           
-00025be0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00025bf0: 2e6f 7073 2e73 6361 7474 6572 5f6e 645f  .ops.scatter_nd_
-00025c00: 6d75 6c28 6e64 5f69 6e70 7574 2c20 6e64  mul(nd_input, nd
-00025c10: 5f69 6478 2c20 6e64 5f73 7263 292e 7371  _idx, nd_src).sq
-00025c20: 7565 657a 6528 2d31 290a 2020 2020 2020  ueeze(-1).      
-00025c30: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00025c40: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00025c50: 7574 203d 206d 732e 6f70 732e 7363 6174  ut = ms.ops.scat
-00025c60: 7465 725f 6d75 6c28 696e 7075 745f 6d73  ter_mul(input_ms
-00025c70: 2c20 696e 6465 782c 2073 7263 290a 2020  , index, src).  
-00025c80: 2020 2020 2020 656c 6966 2072 6564 7563        elif reduc
-00025c90: 6520 3d3d 2027 616d 6178 273a 0a20 2020  e == 'amax':.   
-00025ca0: 2020 2020 2020 2020 2069 6620 696e 636c           if incl
-00025cb0: 7564 655f 7365 6c66 2069 7320 4661 6c73  ude_self is Fals
-00025cc0: 653a 0a20 2020 2020 2020 2020 2020 2020  e:.             
-00025cd0: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
-00025ce0: 7075 745f 6d73 2e73 6361 7474 6572 2864  put_ms.scatter(d
-00025cf0: 696d 2c20 696e 6465 782c 206d 732e 6f70  im, index, ms.op
-00025d00: 732e 6675 6c6c 5f6c 696b 6528 696e 6465  s.full_like(inde
-00025d10: 782c 2069 6e70 7574 5f6d 696e 2c20 6474  x, input_min, dt
-00025d20: 7970 653d 696e 7075 745f 6d73 2e64 7479  ype=input_ms.dty
-00025d30: 7065 2929 0a20 2020 2020 2020 2020 2020  pe)).           
-00025d40: 2069 6620 6469 6d20 3e20 303a 0a20 2020   if dim > 0:.   
-00025d50: 2020 2020 2020 2020 2020 2020 206f 7574               out
-00025d60: 7075 7420 3d20 6d73 2e6f 7073 2e73 6361  put = ms.ops.sca
-00025d70: 7474 6572 5f6e 645f 6d61 7828 6e64 5f69  tter_nd_max(nd_i
-00025d80: 6e70 7574 2c20 6e64 5f69 6478 2c20 6e64  nput, nd_idx, nd
-00025d90: 5f73 7263 292e 7371 7565 657a 6528 2d31  _src).squeeze(-1
-00025da0: 290a 2020 2020 2020 2020 2020 2020 656c  ).            el
-00025db0: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00025dc0: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00025dd0: 6f70 732e 7363 6174 7465 725f 6d61 7828  ops.scatter_max(
-00025de0: 696e 7075 745f 6d73 2c20 696e 6465 782c  input_ms, index,
-00025df0: 2073 7263 290a 2020 2020 2020 2020 656c   src).        el
-00025e00: 6966 2072 6564 7563 6520 3d3d 2027 616d  if reduce == 'am
-00025e10: 696e 273a 0a20 2020 2020 2020 2020 2020  in':.           
-00025e20: 2069 6620 696e 636c 7564 655f 7365 6c66   if include_self
-00025e30: 2069 7320 4661 6c73 653a 0a20 2020 2020   is False:.     
-00025e40: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00025e50: 5f6d 7320 3d20 696e 7075 745f 6d73 2e73  _ms = input_ms.s
-00025e60: 6361 7474 6572 2864 696d 2c20 696e 6465  catter(dim, inde
-00025e70: 782c 206d 732e 6f70 732e 6675 6c6c 5f6c  x, ms.ops.full_l
-00025e80: 696b 6528 696e 6465 782c 2069 6e70 7574  ike(index, input
-00025e90: 5f6d 6178 2c20 6474 7970 653d 696e 7075  _max, dtype=inpu
-00025ea0: 745f 6d73 2e64 7479 7065 2929 0a20 2020  t_ms.dtype)).   
-00025eb0: 2020 2020 2020 2020 2069 6620 6469 6d20           if dim 
-00025ec0: 3e20 303a 0a20 2020 2020 2020 2020 2020  > 0:.           
-00025ed0: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00025ee0: 2e6f 7073 2e73 6361 7474 6572 5f6e 645f  .ops.scatter_nd_
-00025ef0: 6d69 6e28 6e64 5f69 6e70 7574 2c20 6e64  min(nd_input, nd
-00025f00: 5f69 6478 2c20 6e64 5f73 7263 292e 7371  _idx, nd_src).sq
-00025f10: 7565 657a 6528 2d31 290a 2020 2020 2020  ueeze(-1).      
-00025f20: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00025f30: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-00025f40: 7574 203d 206d 732e 6f70 732e 7363 6174  ut = ms.ops.scat
-00025f50: 7465 725f 6d69 6e28 696e 7075 745f 6d73  ter_min(input_ms
-00025f60: 2c20 696e 6465 782c 2073 7263 290a 2020  , index, src).  
-00025f70: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
-00025f80: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
-00025f90: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
-00025fa0: 7228 2266 6f72 2061 6461 7074 6572 2c20  r("for adapter, 
-00025fb0: 2772 6564 7563 6527 2061 7267 756d 656e  'reduce' argumen
-00025fc0: 7420 6d75 7374 2062 6520 6569 7468 6572  t must be either
-00025fd0: 2027 7375 6d27 2c20 2770 726f 6427 2c20   'sum', 'prod', 
-00025fe0: 276d 6561 6e27 2c20 2761 6d61 7827 206f  'mean', 'amax' o
-00025ff0: 7220 220a 2020 2020 2020 2020 2020 2020  r ".            
-00026000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026010: 2020 2020 2020 2020 2020 6622 2761 6d69            f"'ami
-00026020: 6e27 2c20 6275 7420 676f 7420 277b 7265  n', but got '{re
-00026030: 6475 6365 7d27 2229 0a20 2020 2020 2020  duce}'").       
-00026040: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00026050: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00026060: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-00026070: 7363 6174 7465 725f 7265 6475 6365 5f28  scatter_reduce_(
-00026080: 7365 6c66 2c20 6469 6d2c 2069 6e64 6578  self, dim, index
-00026090: 2c20 7372 632c 2072 6564 7563 652c 202a  , src, reduce, *
-000260a0: 2c20 696e 636c 7564 655f 7365 6c66 3d54  , include_self=T
-000260b0: 7275 6529 3a0a 2020 2020 2020 2020 6f75  rue):.        ou
-000260c0: 7470 7574 203d 2073 656c 662e 7363 6174  tput = self.scat
-000260d0: 7465 725f 7265 6475 6365 2864 696d 2c20  ter_reduce(dim, 
-000260e0: 696e 6465 782c 2073 7263 2c20 7265 6475  index, src, redu
-000260f0: 6365 2c20 696e 636c 7564 655f 7365 6c66  ce, include_self
-00026100: 3d69 6e63 6c75 6465 5f73 656c 6629 0a20  =include_self). 
-00026110: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
-00026120: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
-00026130: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
-00026140: 742c 2022 7363 6174 7465 725f 7265 6475  t, "scatter_redu
-00026150: 6365 5f22 2c20 2273 6361 7474 6572 5f72  ce_", "scatter_r
-00026160: 6564 7563 6522 290a 0a0a 2020 2020 6465  educe")...    de
-00026170: 6620 6578 706f 6e65 6e74 6961 6c5f 2873  f exponential_(s
-00026180: 656c 662c 206c 616d 6264 3d31 2e2c 202a  elf, lambd=1., *
-00026190: 2c20 6765 6e65 7261 746f 723d 4e6f 6e65  , generator=None
-000261a0: 293a 0a20 2020 2020 2020 2069 6620 6765  ):.        if ge
-000261b0: 6e65 7261 746f 7220 6973 206e 6f74 204e  nerator is not N
-000261c0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
-000261d0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-000261e0: 7228 2260 6765 6e65 7261 746f 7260 2063  r("`generator` c
-000261f0: 616e 206e 6f74 2062 6520 7375 7070 6f72  an not be suppor
-00026200: 7465 642e 2229 0a20 2020 2020 2020 206f  ted.").        o
-00026210: 7574 7075 7420 3d20 6e70 2e72 616e 646f  utput = np.rando
-00026220: 6d2e 6578 706f 6e65 6e74 6961 6c28 7363  m.exponential(sc
-00026230: 616c 653d 6c61 6d62 642c 2073 697a 653d  ale=lambd, size=
-00026240: 7365 6c66 2e73 6861 7065 290a 2020 2020  self.shape).    
-00026250: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00026260: 5465 6e73 6f72 286f 7574 7075 7429 2e61  Tensor(output).a
-00026270: 7374 7970 6528 7365 6c66 2e64 7479 7065  stype(self.dtype
-00026280: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00026290: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
-000262a0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
-000262b0: 7470 7574 2c20 2265 7870 6f6e 656e 7469  tput, "exponenti
-000262c0: 616c 5f22 2c20 2265 7870 6f6e 656e 7469  al_", "exponenti
-000262d0: 616c 2229 0a0a 2020 2020 6465 6620 696e  al")..    def in
-000262e0: 6465 785f 7265 6475 6365 2873 656c 662c  dex_reduce(self,
-000262f0: 2064 696d 2c20 696e 6465 782c 2073 6f75   dim, index, sou
-00026300: 7263 652c 2072 6564 7563 652c 202a 2c20  rce, reduce, *, 
-00026310: 696e 636c 7564 655f 7365 6c66 3d54 7275  include_self=Tru
-00026320: 6529 3a0a 2020 2020 2020 2020 6966 2073  e):.        if s
-00026330: 656c 662e 6474 7970 6520 696e 206d 7364  elf.dtype in msd
-00026340: 6170 7465 725f 6474 7970 652e 616c 6c5f  apter_dtype.all_
-00026350: 696e 745f 7479 7065 3a0a 2020 2020 2020  int_type:.      
-00026360: 2020 2020 2020 696e 7075 745f 6d61 7820        input_max 
-00026370: 3d20 6969 6e66 6f28 7365 6c66 2e64 7479  = iinfo(self.dty
-00026380: 7065 292e 6d61 780a 2020 2020 2020 2020  pe).max.        
-00026390: 2020 2020 696e 7075 745f 6d69 6e20 3d20      input_min = 
-000263a0: 6969 6e66 6f28 7365 6c66 2e64 7479 7065  iinfo(self.dtype
-000263b0: 292e 6d69 6e0a 2020 2020 2020 2020 656c  ).min.        el
-000263c0: 6966 2073 656c 662e 6474 7970 6520 696e  if self.dtype in
-000263d0: 206d 7364 6170 7465 725f 6474 7970 652e   msdapter_dtype.
-000263e0: 616c 6c5f 666c 6f61 745f 7479 7065 3a0a  all_float_type:.
-000263f0: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
-00026400: 745f 6d61 7820 3d20 6669 6e66 6f28 7365  t_max = finfo(se
-00026410: 6c66 2e64 7479 7065 292e 6d61 780a 2020  lf.dtype).max.  
-00026420: 2020 2020 2020 2020 2020 696e 7075 745f            input_
-00026430: 6d69 6e20 3d20 6669 6e66 6f28 7365 6c66  min = finfo(self
-00026440: 2e64 7479 7065 292e 6d69 6e0a 0a20 2020  .dtype).min..   
-00026450: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00026460: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00026470: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00026480: 6964 7820 3d20 6361 7374 5f74 6f5f 6d73  idx = cast_to_ms
-00026490: 5f74 656e 736f 7228 696e 6465 7829 0a20  _tensor(index). 
-000264a0: 2020 2020 2020 2073 7263 203d 2063 6173         src = cas
-000264b0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
-000264c0: 6f75 7263 6529 0a20 2020 2020 2020 2069  ource).        i
-000264d0: 6620 6469 6d20 3e20 303a 0a20 2020 2020  f dim > 0:.     
-000264e0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-000264f0: 3d20 696e 7075 745f 6d73 2e73 7761 7061  = input_ms.swapa
-00026500: 7865 7328 302c 2064 696d 290a 2020 2020  xes(0, dim).    
-00026510: 2020 2020 2020 2020 7372 6320 3d20 7372          src = sr
-00026520: 632e 7377 6170 6178 6573 2830 2c20 6469  c.swapaxes(0, di
-00026530: 6d29 0a20 2020 2020 2020 2069 6620 7265  m).        if re
-00026540: 6475 6365 203d 3d20 2270 726f 6422 3a0a  duce == "prod":.
-00026550: 2020 2020 2020 2020 2020 2020 6966 2069              if i
-00026560: 6e63 6c75 6465 5f73 656c 6620 6973 2046  nclude_self is F
-00026570: 616c 7365 3a0a 2020 2020 2020 2020 2020  alse:.          
-00026580: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
-00026590: 206d 732e 6f70 732e 7363 6174 7465 725f   ms.ops.scatter_
-000265a0: 7570 6461 7465 286d 732e 5061 7261 6d65  update(ms.Parame
-000265b0: 7465 7228 696e 7075 745f 6d73 292c 2069  ter(input_ms), i
-000265c0: 6478 2c0a 2020 2020 2020 2020 2020 2020  dx,.            
-000265d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000265e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000265f0: 2020 6d73 2e6f 7073 2e6f 6e65 735f 6c69    ms.ops.ones_li
-00026600: 6b65 2873 7263 2c20 6474 7970 653d 7372  ke(src, dtype=sr
-00026610: 632e 6474 7970 6529 290a 2020 2020 2020  c.dtype)).      
-00026620: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
-00026630: 732e 6f70 732e 7363 6174 7465 725f 6d75  s.ops.scatter_mu
-00026640: 6c28 6d73 2e50 6172 616d 6574 6572 2869  l(ms.Parameter(i
-00026650: 6e70 7574 5f6d 7329 2c20 6964 782c 2073  nput_ms), idx, s
-00026660: 7263 290a 2020 2020 2020 2020 656c 6966  rc).        elif
-00026670: 2072 6564 7563 6520 3d3d 2022 616d 6178   reduce == "amax
-00026680: 223a 0a20 2020 2020 2020 2020 2020 2069  ":.            i
-00026690: 6620 696e 636c 7564 655f 7365 6c66 2069  f include_self i
-000266a0: 7320 4661 6c73 653a 0a20 2020 2020 2020  s False:.       
-000266b0: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
-000266c0: 7320 3d20 6d73 2e6f 7073 2e73 6361 7474  s = ms.ops.scatt
-000266d0: 6572 5f75 7064 6174 6528 6d73 2e50 6172  er_update(ms.Par
-000266e0: 616d 6574 6572 2869 6e70 7574 5f6d 7329  ameter(input_ms)
-000266f0: 2c20 6964 782c 0a20 2020 2020 2020 2020  , idx,.         
-00026700: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026720: 2020 2020 206d 732e 6f70 732e 6675 6c6c       ms.ops.full
-00026730: 5f6c 696b 6528 7372 632c 2069 6e70 7574  _like(src, input
-00026740: 5f6d 696e 2c20 6474 7970 653d 7372 632e  _min, dtype=src.
-00026750: 6474 7970 6529 290a 2020 2020 2020 2020  dtype)).        
-00026760: 2020 2020 6f75 7470 7574 203d 206d 732e      output = ms.
-00026770: 6f70 732e 7363 6174 7465 725f 6d61 7828  ops.scatter_max(
-00026780: 6d73 2e50 6172 616d 6574 6572 2869 6e70  ms.Parameter(inp
-00026790: 7574 5f6d 7329 2c20 6964 782c 2073 7263  ut_ms), idx, src
-000267a0: 290a 2020 2020 2020 2020 656c 6966 2072  ).        elif r
-000267b0: 6564 7563 6520 3d3d 2022 616d 696e 223a  educe == "amin":
-000267c0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-000267d0: 696e 636c 7564 655f 7365 6c66 2069 7320  include_self is 
-000267e0: 4661 6c73 653a 0a20 2020 2020 2020 2020  False:.         
-000267f0: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00026800: 3d20 6d73 2e6f 7073 2e73 6361 7474 6572  = ms.ops.scatter
-00026810: 5f75 7064 6174 6528 6d73 2e50 6172 616d  _update(ms.Param
-00026820: 6574 6572 2869 6e70 7574 5f6d 7329 2c20  eter(input_ms), 
-00026830: 6964 782c 0a20 2020 2020 2020 2020 2020  idx,.           
-00026840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026860: 2020 206d 732e 6f70 732e 6675 6c6c 5f6c     ms.ops.full_l
-00026870: 696b 6528 7372 632c 2069 6e70 7574 5f6d  ike(src, input_m
-00026880: 6178 2c20 6474 7970 653d 7372 632e 6474  ax, dtype=src.dt
-00026890: 7970 6529 290a 2020 2020 2020 2020 2020  ype)).          
-000268a0: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
-000268b0: 732e 7363 6174 7465 725f 6d69 6e28 6d73  s.scatter_min(ms
-000268c0: 2e50 6172 616d 6574 6572 2869 6e70 7574  .Parameter(input
-000268d0: 5f6d 7329 2c20 6964 782c 2073 7263 290a  _ms), idx, src).
-000268e0: 2020 2020 2020 2020 656c 6966 2072 6564          elif red
-000268f0: 7563 6520 3d3d 2022 6d65 616e 223a 0a20  uce == "mean":. 
-00026900: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00026910: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
-00026920: 7272 6f72 2822 7363 6174 7465 725f 7265  rror("scatter_re
-00026930: 6475 6365 2063 7572 7265 6e74 6c79 2064  duce currently d
-00026940: 6f65 736e 2774 2073 7570 706f 7274 2072  oesn't support r
-00026950: 6564 7563 653d 3d27 6d65 616e 2722 290a  educe=='mean'").
-00026960: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
-00026970: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00026980: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
-00026990: 726f 7228 2266 6f72 2061 6461 7074 6572  ror("for adapter
-000269a0: 2c20 2772 6564 7563 6527 2061 7267 756d  , 'reduce' argum
-000269b0: 656e 7420 6d75 7374 2062 6520 6569 7468  ent must be eith
-000269c0: 6572 2027 7072 6f64 272c 2027 6d65 616e  er 'prod', 'mean
-000269d0: 272c 2027 616d 6178 2720 6f72 2022 0a20  ', 'amax' or ". 
-000269e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000269f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00026a00: 2020 2020 2066 2227 616d 696e 272c 2062       f"'amin', b
-00026a10: 7574 2067 6f74 2027 7b72 6564 7563 657d  ut got '{reduce}
-00026a20: 2722 290a 2020 2020 2020 2020 6966 2064  '").        if d
-00026a30: 696d 203e 2030 3a0a 2020 2020 2020 2020  im > 0:.        
-00026a40: 2020 2020 6f75 7470 7574 203d 206f 7574      output = out
-00026a50: 7075 742e 7377 6170 6178 6573 2830 2c20  put.swapaxes(0, 
-00026a60: 6469 6d29 0a20 2020 2020 2020 2072 6574  dim).        ret
-00026a70: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-00026a80: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-00026a90: 7429 0a0a 2020 2020 6465 6620 696e 6465  t)..    def inde
-00026aa0: 785f 7265 6475 6365 5f28 7365 6c66 2c20  x_reduce_(self, 
-00026ab0: 6469 6d2c 2069 6e64 6578 2c20 736f 7572  dim, index, sour
-00026ac0: 6365 2c20 7265 6475 6365 2c20 2a2c 2069  ce, reduce, *, i
-00026ad0: 6e63 6c75 6465 5f73 656c 663d 5472 7565  nclude_self=True
-00026ae0: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
-00026af0: 7420 3d20 7365 6c66 2e69 6e64 6578 5f72  t = self.index_r
-00026b00: 6564 7563 6528 6469 6d2c 2069 6e64 6578  educe(dim, index
-00026b10: 2c20 736f 7572 6365 2c20 7265 6475 6365  , source, reduce
-00026b20: 2c20 696e 636c 7564 655f 7365 6c66 3d69  , include_self=i
-00026b30: 6e63 6c75 6465 5f73 656c 6629 0a20 2020  nclude_self).   
-00026b40: 2020 2020 2072 6574 7572 6e20 5f74 656e       return _ten
-00026b50: 736f 725f 696e 706c 6163 655f 6173 7369  sor_inplace_assi
-00026b60: 676e 2873 656c 662c 206f 7574 7075 742c  gn(self, output,
-00026b70: 2022 696e 6465 785f 7265 6475 6365 5f22   "index_reduce_"
-00026b80: 2c20 2269 6e64 6578 5f72 6564 7563 6522  , "index_reduce"
-00026b90: 290a 0a20 2020 2023 2074 656e 736f 722e  )..    # tensor.
-00026ba0: 6c6f 675f 736f 6674 6d61 7820 6973 206e  log_softmax is n
-00026bb0: 6f74 2064 6973 706c 6179 6564 206f 6e20  ot displayed on 
-00026bc0: 7468 6520 6f66 6669 6369 616c 2077 6562  the official web
-00026bd0: 7369 7465 0a20 2020 2064 6566 206c 6f67  site.    def log
-00026be0: 5f73 6f66 746d 6178 2873 656c 662c 2064  _softmax(self, d
-00026bf0: 696d 3d4e 6f6e 652c 205f 7374 6163 6b6c  im=None, _stackl
-00026c00: 6576 656c 3d33 2c20 6474 7970 653d 4e6f  evel=3, dtype=No
-00026c10: 6e65 293a 0a20 2020 2020 2020 2075 6e73  ne):.        uns
-00026c20: 7570 706f 7274 6564 5f61 7474 7228 5f73  upported_attr(_s
-00026c30: 7461 636b 6c65 7665 6c29 2023 2060 5f73  tacklevel) # `_s
-00026c40: 7461 636b 6c65 7665 6c60 2069 6e20 746f  tacklevel` in to
-00026c50: 7263 6820 6973 2064 6570 7265 6361 7465  rch is deprecate
-00026c60: 640a 2020 2020 2020 2020 6966 2064 696d  d.        if dim
-00026c70: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
-00026c80: 2020 2020 2020 6469 6d20 3d20 2d31 0a0a        dim = -1..
-00026c90: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00026ca0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00026cb0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00026cc0: 2020 2069 6620 6474 7970 6520 6973 206e     if dtype is n
-00026cd0: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
-00026ce0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00026cf0: 696e 7075 745f 6d73 2e61 7374 7970 6528  input_ms.astype(
-00026d00: 6474 7970 6529 0a0a 2020 2020 2020 2020  dtype)..        
-00026d10: 6f75 7420 3d20 6d73 2e6f 7073 2e6c 6f67  out = ms.ops.log
-00026d20: 5f73 6f66 746d 6178 2869 6e70 7574 5f6d  _softmax(input_m
-00026d30: 732c 2064 696d 290a 2020 2020 2020 2020  s, dim).        
-00026d40: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
-00026d50: 6461 7074 6572 5f74 656e 736f 7228 6f75  dapter_tensor(ou
-00026d60: 7429 0a0a 2020 2020 6465 6620 6d61 736b  t)..    def mask
-00026d70: 6564 5f73 6361 7474 6572 2873 656c 662c  ed_scatter(self,
-00026d80: 206d 6173 6b2c 2074 656e 736f 7229 3a0a   mask, tensor):.
-00026d90: 2020 2020 2020 2020 2320 544f 444f 3a20          # TODO: 
-00026da0: 6d73 2e6f 7073 2e6d 6173 6b65 645f 7363  ms.ops.masked_sc
-00026db0: 6174 7465 7220 646f 6573 206e 6f74 2073  atter does not s
-00026dc0: 7570 706f 7274 2069 6e70 7574 2074 6f20  upport input to 
-00026dd0: 6265 2062 726f 6164 6361 7374 6564 2074  be broadcasted t
-00026de0: 6f20 7468 6520 7368 6170 6520 6f66 206d  o the shape of m
-00026df0: 6173 6b0a 2020 2020 2020 2020 696e 7075  ask.        inpu
-00026e00: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
-00026e10: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
-00026e20: 2020 2020 2020 206d 6173 6b20 3d20 6361         mask = ca
-00026e30: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00026e40: 6d61 736b 292e 626f 6f6c 2829 0a20 2020  mask).bool().   
-00026e50: 2020 2020 2074 656e 736f 7220 3d20 6361       tensor = ca
-00026e60: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
-00026e70: 7465 6e73 6f72 290a 2020 2020 2020 2020  tensor).        
-00026e80: 6f75 7470 7574 203d 2069 6e70 7574 5f6d  output = input_m
-00026e90: 732e 6d61 736b 6564 5f73 6361 7474 6572  s.masked_scatter
-00026ea0: 286d 6173 6b2c 2074 656e 736f 7229 0a20  (mask, tensor). 
-00026eb0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
-00026ec0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
-00026ed0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
-00026ee0: 2020 6465 6620 6d61 736b 6564 5f73 6361    def masked_sca
-00026ef0: 7474 6572 5f28 7365 6c66 2c20 6d61 736b  tter_(self, mask
-00026f00: 2c20 7465 6e73 6f72 293a 0a20 2020 2020  , tensor):.     
-00026f10: 2020 206f 7574 7075 7420 3d20 7365 6c66     output = self
-00026f20: 2e6d 6173 6b65 645f 7363 6174 7465 7228  .masked_scatter(
-00026f30: 6d61 736b 2c20 7465 6e73 6f72 290a 2020  mask, tensor).  
-00026f40: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-00026f50: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-00026f60: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-00026f70: 2c20 226d 6173 6b65 645f 7363 6174 7465  , "masked_scatte
-00026f80: 725f 222c 2022 6d61 736b 6564 5f73 6361  r_", "masked_sca
-00026f90: 7474 6572 2229 0a0a 2020 2020 6465 6620  tter")..    def 
-00026fa0: 636f 7272 636f 6566 2873 656c 6629 3a0a  corrcoef(self):.
-00026fb0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-00026fc0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00026fd0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00026fe0: 2020 2069 6620 6c65 6e28 696e 7075 745f     if len(input_
-00026ff0: 6d73 2e73 6861 7065 2920 3e20 323a 0a20  ms.shape) > 2:. 
-00027000: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00027010: 2056 616c 7565 4572 726f 7228 2263 6f72   ValueError("cor
-00027020: 7263 6f65 6628 293a 2065 7870 6563 7465  rcoef(): expecte
-00027030: 6420 696e 7075 7420 746f 2068 6176 6520  d input to have 
-00027040: 7477 6f20 6f72 2066 6577 6572 2064 696d  two or fewer dim
-00027050: 656e 7369 6f6e 7322 290a 2020 2020 2020  ensions").      
-00027060: 2020 2320 544f 444f 3a20 6d73 2e6f 7073    # TODO: ms.ops
-00027070: 2e63 6f76 2064 6f65 7320 6e6f 7420 7375  .cov does not su
-00027080: 7070 6f72 7420 636f 6d70 6c65 7820 696e  pport complex in
-00027090: 7075 740a 2020 2020 2020 2020 6f75 7470  put.        outp
-000270a0: 7574 203d 2069 6e70 7574 5f6d 732e 636f  ut = input_ms.co
-000270b0: 7628 290a 2020 2020 2020 2020 6966 206c  v().        if l
-000270c0: 656e 286f 7574 7075 742e 7368 6170 6529  en(output.shape)
-000270d0: 203d 3d20 303a 0a20 2020 2020 2020 2020   == 0:.         
-000270e0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
-000270f0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
-00027100: 286d 732e 6f70 732e 6f6e 6573 5f6c 696b  (ms.ops.ones_lik
-00027110: 6528 6f75 7470 7574 2929 0a20 2020 2020  e(output)).     
-00027120: 2020 2023 206e 6f72 6d61 6c69 7a65 2063     # normalize c
-00027130: 6f76 6172 6961 6e63 650a 2020 2020 2020  ovariance.      
-00027140: 2020 6420 3d20 6d73 2e6e 756d 7079 2e64    d = ms.numpy.d
-00027150: 6961 6728 6f75 7470 7574 290a 2020 2020  iag(output).    
-00027160: 2020 2020 2320 436c 6970 2072 6561 6c20      # Clip real 
-00027170: 616e 6420 696d 6167 696e 6172 7920 7061  and imaginary pa
-00027180: 7274 7320 746f 205b 2d31 2c20 315d 2e0a  rts to [-1, 1]..
-00027190: 2020 2020 2020 2020 6966 2069 6e70 7574          if input
-000271a0: 5f6d 732e 6474 7970 6520 3d3d 206d 732e  _ms.dtype == ms.
-000271b0: 636f 6d70 6c65 7836 343a 0a20 2020 2020  complex64:.     
-000271c0: 2020 2020 2020 2072 6561 6c5f 6f70 203d         real_op =
-000271d0: 205f 6765 745f 6361 6368 655f 7072 696d   _get_cache_prim
-000271e0: 286d 732e 6f70 732e 5265 616c 2928 290a  (ms.ops.Real)().
-000271f0: 2020 2020 2020 2020 2020 2020 696d 6167              imag
-00027200: 5f6f 7020 3d20 5f67 6574 5f63 6163 6865  _op = _get_cache
-00027210: 5f70 7269 6d28 6d73 2e6f 7073 2e49 6d61  _prim(ms.ops.Ima
-00027220: 6729 2829 0a20 2020 2020 2020 2020 2020  g)().           
-00027230: 2063 6f6d 706c 6578 5f6f 7020 3d20 5f67   complex_op = _g
-00027240: 6574 5f63 6163 6865 5f70 7269 6d28 6d73  et_cache_prim(ms
-00027250: 2e6f 7073 2e43 6f6d 706c 6578 2928 290a  .ops.Complex)().
-00027260: 2020 2020 2020 2020 2020 2020 645f 7265              d_re
-00027270: 616c 203d 2072 6561 6c5f 6f70 2864 290a  al = real_op(d).
-00027280: 2020 2020 2020 2020 2020 2020 7374 6464              stdd
-00027290: 6576 203d 206d 732e 6f70 732e 7371 7274  ev = ms.ops.sqrt
-000272a0: 2864 5f72 6561 6c29 0a20 2020 2020 2020  (d_real).       
-000272b0: 2020 2020 206f 7574 7075 7420 2f3d 206d       output /= m
-000272c0: 732e 6f70 732e 6578 7061 6e64 5f64 696d  s.ops.expand_dim
-000272d0: 7328 7374 6464 6576 2c20 2d31 290a 2020  s(stddev, -1).  
-000272e0: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-000272f0: 202f 3d20 6d73 2e6f 7073 2e65 7870 616e   /= ms.ops.expan
-00027300: 645f 6469 6d73 2873 7464 6465 762c 2030  d_dims(stddev, 0
-00027310: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
-00027320: 7470 7574 5f72 6561 6c20 3d20 7265 616c  tput_real = real
-00027330: 5f6f 7028 6f75 7470 7574 290a 2020 2020  _op(output).    
-00027340: 2020 2020 2020 2020 6f75 7470 7574 5f69          output_i
-00027350: 6d61 6720 3d20 696d 6167 5f6f 7028 6f75  mag = imag_op(ou
-00027360: 7470 7574 290a 2020 2020 2020 2020 2020  tput).          
-00027370: 2020 6f75 7470 7574 5f72 6561 6c20 3d20    output_real = 
-00027380: 6d73 2e6f 7073 2e63 6c69 705f 6279 5f76  ms.ops.clip_by_v
-00027390: 616c 7565 286f 7574 7075 745f 7265 616c  alue(output_real
-000273a0: 2c20 2d31 2c20 3129 0a20 2020 2020 2020  , -1, 1).       
-000273b0: 2020 2020 206f 7574 7075 745f 696d 6167       output_imag
-000273c0: 203d 206d 732e 6f70 732e 636c 6970 5f62   = ms.ops.clip_b
-000273d0: 795f 7661 6c75 6528 6f75 7470 7574 5f69  y_value(output_i
-000273e0: 6d61 672c 202d 312c 2031 290a 2020 2020  mag, -1, 1).    
-000273f0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
-00027400: 2063 6f6d 706c 6578 5f6f 7028 6f75 7470   complex_op(outp
-00027410: 7574 5f72 6561 6c2c 206f 7574 7075 745f  ut_real, output_
-00027420: 696d 6167 290a 2020 2020 2020 2020 656c  imag).        el
-00027430: 7365 3a0a 2020 2020 2020 2020 2020 2020  se:.            
-00027440: 7374 6464 6576 203d 206d 732e 6f70 732e  stddev = ms.ops.
-00027450: 7371 7274 2864 290a 2020 2020 2020 2020  sqrt(d).        
-00027460: 2020 2020 6f75 7470 7574 202f 3d20 6d73      output /= ms
-00027470: 2e6f 7073 2e65 7870 616e 645f 6469 6d73  .ops.expand_dims
-00027480: 2873 7464 6465 762c 202d 3129 0a20 2020  (stddev, -1).   
-00027490: 2020 2020 2020 2020 206f 7574 7075 7420           output 
-000274a0: 2f3d 206d 732e 6f70 732e 6578 7061 6e64  /= ms.ops.expand
-000274b0: 5f64 696d 7328 7374 6464 6576 2c20 3029  _dims(stddev, 0)
-000274c0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-000274d0: 7075 7420 3d20 6d73 2e6f 7073 2e63 6c69  put = ms.ops.cli
-000274e0: 705f 6279 5f76 616c 7565 286f 7574 7075  p_by_value(outpu
-000274f0: 742c 202d 312c 2031 290a 2020 2020 2020  t, -1, 1).      
-00027500: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-00027510: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-00027520: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-00027530: 2067 656f 6d65 7472 6963 5f28 7365 6c66   geometric_(self
-00027540: 2c20 702c 202a 2c20 6765 6e65 7261 746f  , p, *, generato
-00027550: 723d 4e6f 6e65 293a 0a20 2020 2020 2020  r=None):.       
-00027560: 2069 6620 6765 6e65 7261 746f 7220 6973   if generator is
-00027570: 206e 6f74 204e 6f6e 653a 0a20 2020 2020   not None:.     
-00027580: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-00027590: 7565 4572 726f 7228 2260 6765 6e65 7261  ueError("`genera
-000275a0: 746f 7260 2063 616e 206e 6f74 2062 6520  tor` can not be 
-000275b0: 7375 7070 6f72 7465 642e 2229 0a20 2020  supported.").   
-000275c0: 2020 2020 206f 7574 7075 7420 3d20 6e70       output = np
-000275d0: 2e72 616e 646f 6d2e 6765 6f6d 6574 7269  .random.geometri
-000275e0: 6328 703d 702c 2073 697a 653d 7365 6c66  c(p=p, size=self
-000275f0: 2e73 6861 7065 290a 2020 2020 2020 2020  .shape).        
-00027600: 6f75 7470 7574 203d 206d 732e 5465 6e73  output = ms.Tens
-00027610: 6f72 286f 7574 7075 7429 2e61 7374 7970  or(output).astyp
-00027620: 6528 7365 6c66 2e64 7479 7065 290a 2020  e(self.dtype).  
-00027630: 2020 2020 2020 7265 7475 726e 205f 7465        return _te
-00027640: 6e73 6f72 5f69 6e70 6c61 6365 5f61 7373  nsor_inplace_ass
-00027650: 6967 6e28 7365 6c66 2c20 6f75 7470 7574  ign(self, output
-00027660: 2c20 2267 656f 6d65 7472 6963 5f22 2c20  , "geometric_", 
-00027670: 2267 656f 6d65 7472 6963 2229 0a0a 2020  "geometric")..  
-00027680: 2020 6465 6620 6c6f 675f 6e6f 726d 616c    def log_normal
-00027690: 5f28 7365 6c66 2c20 6d65 616e 3d31 2c20  _(self, mean=1, 
-000276a0: 7374 643d 322c 202a 2c20 6765 6e65 7261  std=2, *, genera
-000276b0: 746f 723d 4e6f 6e65 293a 0a20 2020 2020  tor=None):.     
-000276c0: 2020 2069 6620 6765 6e65 7261 746f 7220     if generator 
-000276d0: 6973 206e 6f74 204e 6f6e 653a 0a20 2020  is not None:.   
-000276e0: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-000276f0: 616c 7565 4572 726f 7228 2260 6765 6e65  alueError("`gene
-00027700: 7261 746f 7260 2063 616e 206e 6f74 2062  rator` can not b
-00027710: 6520 7375 7070 6f72 7465 642e 2229 0a20  e supported."). 
-00027720: 2020 2020 2020 2069 6e70 7574 5f6d 7320         input_ms 
-00027730: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
-00027740: 736f 7228 7365 6c66 290a 2020 2020 2020  sor(self).      
-00027750: 2020 6e6f 726d 616c 5f6f 7020 3d20 5f67    normal_op = _g
-00027760: 6574 5f63 6163 6865 5f70 7269 6d28 6d73  et_cache_prim(ms
-00027770: 2e6f 7073 2e4c 6f67 4e6f 726d 616c 5265  .ops.LogNormalRe
-00027780: 7665 7273 6529 286d 6561 6e3d 6d65 616e  verse)(mean=mean
-00027790: 2c20 7374 643d 7374 6429 0a20 2020 2020  , std=std).     
-000277a0: 2020 206f 7574 7075 7420 3d20 6e6f 726d     output = norm
-000277b0: 616c 5f6f 7028 696e 7075 745f 6d73 290a  al_op(input_ms).
-000277c0: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-000277d0: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-000277e0: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-000277f0: 7574 2c20 226c 6f67 5f6e 6f72 6d61 6c5f  ut, "log_normal_
-00027800: 222c 2022 6c6f 675f 6e6f 726d 616c 2229  ", "log_normal")
-00027810: 0a0a 2020 2020 6465 6620 6d61 705f 2873  ..    def map_(s
-00027820: 656c 662c 2074 656e 736f 722c 2063 616c  elf, tensor, cal
-00027830: 6c61 626c 6529 3a0a 2020 2020 2020 2020  lable):.        
-00027840: 696e 7075 745f 6d73 203d 2063 6173 745f  input_ms = cast_
-00027850: 746f 5f6d 735f 7465 6e73 6f72 2873 656c  to_ms_tensor(sel
-00027860: 6629 0a20 2020 2020 2020 2074 656e 736f  f).        tenso
-00027870: 725f 6d73 203d 2063 6173 745f 746f 5f6d  r_ms = cast_to_m
-00027880: 735f 7465 6e73 6f72 2874 656e 736f 7229  s_tensor(tensor)
-00027890: 0a20 2020 2020 2020 206f 7574 7075 7420  .        output 
-000278a0: 3d20 6361 6c6c 6162 6c65 2869 6e70 7574  = callable(input
-000278b0: 5f6d 732c 2074 656e 736f 725f 6d73 290a  _ms, tensor_ms).
-000278c0: 2020 2020 2020 2020 7265 7475 726e 205f          return _
-000278d0: 7465 6e73 6f72 5f69 6e70 6c61 6365 5f61  tensor_inplace_a
-000278e0: 7373 6967 6e28 7365 6c66 2c20 6f75 7470  ssign(self, outp
-000278f0: 7574 2c20 226d 6170 5f22 2c20 226d 6170  ut, "map_", "map
-00027900: 2229 0a0a 2020 2020 6465 6620 6170 706c  ")..    def appl
-00027910: 795f 2873 656c 662c 2066 6e29 3a0a 2020  y_(self, fn):.  
-00027920: 2020 2020 2020 2320 5468 6973 2066 756e        # This fun
-00027930: 6374 696f 6e20 7368 6f75 6c64 206e 6f74  ction should not
-00027940: 2062 6520 7573 6564 2069 6e20 636f 6465   be used in code
-00027950: 2073 6563 7469 6f6e 7320 7468 6174 2072   sections that r
-00027960: 6571 7569 7265 2068 6967 6820 7065 7266  equire high perf
-00027970: 6f72 6d61 6e63 650a 2020 2020 2020 2020  ormance.        
-00027980: 6966 206e 6f74 2063 616c 6c61 626c 6528  if not callable(
-00027990: 666e 293a 0a20 2020 2020 2020 2020 2020  fn):.           
-000279a0: 2072 6169 7365 2054 7970 6545 7272 6f72   raise TypeError
-000279b0: 2866 2266 6f72 2074 656e 736f 722e 6170  (f"for tensor.ap
-000279c0: 706c 795f 2866 6e29 2c20 666e 206d 7573  ply_(fn), fn mus
-000279d0: 7420 6265 2063 616c 6c61 626c 652c 2062  t be callable, b
-000279e0: 7574 2067 6f74 207b 7479 7065 2866 6e29  ut got {type(fn)
-000279f0: 2e5f 5f6e 616d 655f 5f7d 2e22 290a 2020  .__name__}.").  
-00027a00: 2020 2020 2020 666f 7220 692c 2065 6c65        for i, ele
-00027a10: 6d20 696e 2065 6e75 6d65 7261 7465 2873  m in enumerate(s
-00027a20: 656c 6629 3a0a 2020 2020 2020 2020 2020  elf):.          
-00027a30: 2020 7365 6c66 5b69 5d20 3d20 666e 2865    self[i] = fn(e
-00027a40: 6c65 6d29 0a20 2020 2020 2020 2072 6574  lem).        ret
-00027a50: 7572 6e20 7365 6c66 0a0a 2020 2020 6465  urn self..    de
-00027a60: 6620 6469 6167 6f6e 616c 5f73 6361 7474  f diagonal_scatt
-00027a70: 6572 2873 656c 662c 2073 7263 2c20 6f66  er(self, src, of
-00027a80: 6673 6574 3d30 2c20 6469 6d31 3d30 2c20  fset=0, dim1=0, 
-00027a90: 6469 6d32 3d31 293a 0a20 2020 2020 2020  dim2=1):.       
-00027aa0: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
-00027ab0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
-00027ac0: 6c66 290a 2020 2020 2020 2020 7372 635f  lf).        src_
-00027ad0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
-00027ae0: 7465 6e73 6f72 2873 7263 290a 0a20 2020  tensor(src)..   
-00027af0: 2020 2020 2069 6e70 7574 5f73 6861 7065       input_shape
-00027b00: 203d 2069 6e70 7574 5f6d 732e 7368 6170   = input_ms.shap
-00027b10: 650a 0a20 2020 2020 2020 2069 6e64 6578  e..        index
-00027b20: 5f6e 7020 3d20 5f67 6574 5f64 6961 676f  _np = _get_diago
-00027b30: 6e61 6c5f 7363 6174 7465 725f 696e 6465  nal_scatter_inde
-00027b40: 7828 696e 7075 745f 7368 6170 652c 206f  x(input_shape, o
-00027b50: 6666 7365 742c 2064 696d 312c 2064 696d  ffset, dim1, dim
-00027b60: 3229 0a20 2020 2020 2020 2069 6e64 6578  2).        index
-00027b70: 203d 206d 732e 5465 6e73 6f72 2e66 726f   = ms.Tensor.fro
-00027b80: 6d5f 6e75 6d70 7928 696e 6465 785f 6e70  m_numpy(index_np
-00027b90: 290a 0a20 2020 2020 2020 2069 6620 6f66  )..        if of
-00027ba0: 6673 6574 203c 2030 3a0a 2020 2020 2020  fset < 0:.      
-00027bb0: 2020 2020 2020 7372 635f 6c65 6e20 3d20        src_len = 
-00027bc0: 7372 635f 6d73 2e73 6861 7065 5b2d 315d  src_ms.shape[-1]
-00027bd0: 0a20 2020 2020 2020 2020 2020 2074 6d70  .            tmp
-00027be0: 203d 206d 732e 6f70 732e 7a65 726f 7328   = ms.ops.zeros(
-00027bf0: 7372 635f 6d73 2e73 6861 7065 5b3a 2d31  src_ms.shape[:-1
-00027c00: 5d2c 2073 7263 5f6d 732e 6474 7970 6529  ], src_ms.dtype)
-00027c10: 0a20 2020 2020 2020 2020 2020 2074 6d70  .            tmp
-00027c20: 203d 2074 6d70 2e65 7870 616e 645f 6469   = tmp.expand_di
-00027c30: 6d73 282d 3129 0a20 2020 2020 2020 2020  ms(-1).         
-00027c40: 2020 2066 6f72 205f 2069 6e20 7261 6e67     for _ in rang
-00027c50: 6528 7372 635f 6c65 6e2c 2069 6e70 7574  e(src_len, input
-00027c60: 5f73 6861 7065 5b64 696d 315d 293a 0a20  _shape[dim1]):. 
-00027c70: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00027c80: 7263 5f6d 7320 3d20 6d73 2e6f 7073 2e63  rc_ms = ms.ops.c
-00027c90: 6174 285b 746d 702c 2073 7263 5f6d 735d  at([tmp, src_ms]
-00027ca0: 2c20 2d31 290a 0a20 2020 2020 2020 2073  , -1)..        s
-00027cb0: 7263 5f6d 7320 3d20 7372 635f 6d73 2e6d  rc_ms = src_ms.m
-00027cc0: 6f76 6561 7869 7328 2d31 2c20 6469 6d31  oveaxis(-1, dim1
-00027cd0: 290a 2020 2020 2020 2020 7372 635f 6d73  ).        src_ms
-00027ce0: 203d 2073 7263 5f6d 732e 6578 7061 6e64   = src_ms.expand
-00027cf0: 5f64 696d 7328 6469 6d32 290a 0a20 2020  _dims(dim2)..   
-00027d00: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00027d10: 2e6f 7073 2e74 656e 736f 725f 7363 6174  .ops.tensor_scat
-00027d20: 7465 725f 656c 656d 656e 7473 2869 6e70  ter_elements(inp
-00027d30: 7574 5f6d 732c 2069 6e64 6578 2c20 7372  ut_ms, index, sr
-00027d40: 635f 6d73 2c20 6178 6973 3d64 696d 3229  c_ms, axis=dim2)
-00027d50: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00027d60: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00027d70: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00027d80: 2020 2020 2320 7465 6e73 6f72 2e73 6f66      # tensor.sof
-00027d90: 746d 6178 2069 7320 6e6f 7420 6469 7370  tmax is not disp
-00027da0: 6c61 7965 6420 6f6e 2074 6865 206f 6666  layed on the off
-00027db0: 6963 6961 6c20 7765 6273 6974 650a 2020  icial website.  
-00027dc0: 2020 6465 6620 736f 6674 6d61 7828 7365    def softmax(se
-00027dd0: 6c66 2c20 6469 6d2c 2064 7479 7065 3d4e  lf, dim, dtype=N
-00027de0: 6f6e 6529 3a0a 2020 2020 2020 2020 696e  one):.        in
-00027df0: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
-00027e00: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
-00027e10: 0a20 2020 2020 2020 2069 6620 6474 7970  .        if dtyp
-00027e20: 6520 6973 206e 6f74 204e 6f6e 653a 0a20  e is not None:. 
-00027e30: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00027e40: 5f6d 7320 3d20 696e 7075 745f 6d73 2e61  _ms = input_ms.a
-00027e50: 7374 7970 6528 6474 7970 6529 0a20 2020  stype(dtype).   
-00027e60: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
-00027e70: 2e6f 7073 2e73 6f66 746d 6178 2869 6e70  .ops.softmax(inp
-00027e80: 7574 5f6d 732c 2064 696d 290a 2020 2020  ut_ms, dim).    
-00027e90: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
-00027ea0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
-00027eb0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
-00027ec0: 6566 206e 616e 6d65 6469 616e 2873 656c  ef nanmedian(sel
-00027ed0: 662c 2064 696d 3d4e 6f6e 652c 206b 6565  f, dim=None, kee
-00027ee0: 7064 696d 3d46 616c 7365 293a 0a20 2020  pdim=False):.   
-00027ef0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00027f00: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00027f10: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
-00027f20: 6966 2064 696d 2069 7320 4e6f 6e65 3a0a  if dim is None:.
-00027f30: 2020 2020 2020 2020 2020 2020 2320 6d73              # ms
-00027f40: 2e6f 7073 2e6d 6564 6961 6e20 6361 6e20  .ops.median can 
-00027f50: 6e6f 7420 636f 6d70 7574 6520 7468 6520  not compute the 
-00027f60: 6d65 6469 616e 2076 616c 7565 2061 6c6f  median value alo
-00027f70: 6e67 2061 6c6c 2064 696d 656e 7469 6f6e  ng all dimention
-00027f80: 730a 2020 2020 2020 2020 2020 2020 2320  s.            # 
-00027f90: 6f6e 6c79 206d 732e 6f70 732e 4d65 6469  only ms.ops.Medi
-00027fa0: 616e 2867 6c6f 6261 6c5f 6d65 6469 616e  an(global_median
-00027fb0: 3d54 7275 6529 2063 616e 2064 6f20 7468  =True) can do th
-00027fc0: 6174 2e0a 2020 2020 2020 2020 2020 2020  at..            
-00027fd0: 2320 736f 2063 616e 206e 6f74 2072 6570  # so can not rep
-00027fe0: 6c61 6365 206d 732e 6f70 732e 4d65 6469  lace ms.ops.Medi
-00027ff0: 616e 2074 6f20 6d73 2e6f 7073 2e6d 6564  an to ms.ops.med
-00028000: 6961 6e0a 2020 2020 2020 2020 2020 2020  ian.            
-00028010: 6f75 7470 7574 2c20 5f20 3d20 5f67 6574  output, _ = _get
-00028020: 5f63 6163 6865 5f70 7269 6d28 6d73 2e6f  _cache_prim(ms.o
-00028030: 7073 2e4d 6564 6961 6e29 2867 6c6f 6261  ps.Median)(globa
-00028040: 6c5f 6d65 6469 616e 3d54 7275 652c 2069  l_median=True, i
-00028050: 676e 6f72 655f 6e61 6e3d 5472 7565 2928  gnore_nan=True)(
-00028060: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
-00028070: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
-00028080: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
-00028090: 736f 7228 6f75 7470 7574 290a 2020 2020  sor(output).    
-000280a0: 2020 2020 656c 7365 3a0a 2020 2020 2020      else:.      
-000280b0: 2020 2020 2020 2320 544f 444f 3a20 4f6e        # TODO: On
-000280c0: 2047 5055 2c20 6d73 2e6f 7073 2e6d 6564   GPU, ms.ops.med
-000280d0: 6961 6e20 7468 6520 7265 7475 726e 2069  ian the return i
-000280e0: 6e64 6963 6573 206d 6179 2062 6520 7772  ndices may be wr
-000280f0: 6f6e 672e 0a20 2020 2020 2020 2020 2020  ong..           
-00028100: 206e 616e 6d65 6469 616e 5f20 3d20 5f67   nanmedian_ = _g
-00028110: 6574 5f63 6163 6865 5f70 7269 6d28 6d73  et_cache_prim(ms
-00028120: 2e6f 7073 2e4d 6564 6961 6e29 2867 6c6f  .ops.Median)(glo
-00028130: 6261 6c5f 6d65 6469 616e 3d46 616c 7365  bal_median=False
-00028140: 2c20 6178 6973 3d64 696d 2c20 6b65 6570  , axis=dim, keep
-00028150: 5f64 696d 733d 6b65 6570 6469 6d2c 0a20  _dims=keepdim,. 
-00028160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028180: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00028190: 2020 2020 2020 2069 676e 6f72 655f 6e61         ignore_na
-000281a0: 6e3d 5472 7565 290a 2020 2020 2020 2020  n=True).        
-000281b0: 2020 2020 7661 6c75 652c 2069 6e64 6963      value, indic
-000281c0: 6573 203d 206e 616e 6d65 6469 616e 5f28  es = nanmedian_(
-000281d0: 696e 7075 745f 6d73 290a 2020 2020 2020  input_ms).      
-000281e0: 2020 2020 2020 6966 2070 796e 6174 6976        if pynativ
-000281f0: 655f 6d6f 6465 5f63 6f6e 6469 7469 6f6e  e_mode_condition
-00028200: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-00028210: 2020 2020 706f 696e 7420 3d20 7365 745f      point = set_
-00028220: 6e61 6d65 5f74 7570 6c65 2827 6e61 6e6d  name_tuple('nanm
-00028230: 6564 6961 6e27 290a 2020 2020 2020 2020  edian').        
-00028240: 2020 2020 2020 2020 726c 7420 3d20 706f          rlt = po
-00028250: 696e 7428 6361 7374 5f74 6f5f 6164 6170  int(cast_to_adap
-00028260: 7465 725f 7465 6e73 6f72 2876 616c 7565  ter_tensor(value
-00028270: 292c 2063 6173 745f 746f 5f61 6461 7074  ), cast_to_adapt
-00028280: 6572 5f74 656e 736f 7228 696e 6469 6365  er_tensor(indice
-00028290: 7329 290a 2020 2020 2020 2020 2020 2020  s)).            
-000282a0: 2020 2020 7265 7475 726e 2072 6c74 0a20      return rlt. 
-000282b0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-000282c0: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
-000282d0: 725f 7465 6e73 6f72 2876 616c 7565 292c  r_tensor(value),
-000282e0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-000282f0: 5f74 656e 736f 7228 696e 6469 6365 7329  _tensor(indices)
-00028300: 0a0a 2020 2020 6465 6620 6261 636b 7761  ..    def backwa
-00028310: 7264 2873 656c 662c 2067 7261 6469 656e  rd(self, gradien
-00028320: 743d 4e6f 6e65 2c20 7265 7461 696e 5f67  t=None, retain_g
-00028330: 7261 7068 3d4e 6f6e 652c 2063 7265 6174  raph=None, creat
-00028340: 655f 6772 6170 683d 4661 6c73 652c 2069  e_graph=False, i
-00028350: 6e70 7574 733d 4e6f 6e65 293a 0a20 2020  nputs=None):.   
-00028360: 2020 2020 2075 6e73 7570 706f 7274 6564       unsupported
-00028370: 5f61 7474 7228 6772 6164 6965 6e74 290a  _attr(gradient).
-00028380: 2020 2020 2020 2020 756e 7375 7070 6f72          unsuppor
-00028390: 7465 645f 6174 7472 2872 6574 6169 6e5f  ted_attr(retain_
-000283a0: 6772 6170 6829 0a20 2020 2020 2020 2075  graph).        u
-000283b0: 6e73 7570 706f 7274 6564 5f61 7474 7228  nsupported_attr(
-000283c0: 6372 6561 7465 5f67 7261 7068 290a 2020  create_graph).  
-000283d0: 2020 2020 2020 756e 7375 7070 6f72 7465        unsupporte
-000283e0: 645f 6174 7472 2869 6e70 7574 7329 0a20  d_attr(inputs). 
-000283f0: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
-00028400: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
-00028410: 280a 2020 2020 2020 2020 2020 2020 2274  (.            "t
-00028420: 656e 736f 722e 6261 636b 7761 7264 2829  ensor.backward()
-00028430: 206e 6f74 2073 7570 706f 7274 2079 6574   not support yet
-00028440: 2e20 706c 6561 7365 2075 7365 2022 0a20  . please use ". 
-00028450: 2020 2020 2020 2020 2020 2022 6d69 6e64             "mind
-00028460: 7370 6f72 652e 7661 6c75 655f 616e 645f  spore.value_and_
-00028470: 6772 6164 220a 2020 2020 2020 2020 2020  grad".          
-00028480: 2020 2228 6874 7470 733a 2f2f 7777 772e    "(https://www.
-00028490: 6d69 6e64 7370 6f72 652e 636e 2f64 6f63  mindspore.cn/doc
-000284a0: 732f 7a68 2d43 4e2f 7232 2e30 2f61 7069  s/zh-CN/r2.0/api
-000284b0: 5f70 7974 686f 6e2f 6d69 6e64 7370 6f72  _python/mindspor
-000284c0: 652f 6d69 6e64 7370 6f72 652e 7661 6c75  e/mindspore.valu
-000284d0: 655f 616e 645f 6772 6164 2e68 746d 6c29  e_and_grad.html)
-000284e0: 2022 0a20 2020 2020 2020 2020 2020 2022   ".            "
-000284f0: 6f72 206d 696e 6473 706f 7265 2e67 7261  or mindspore.gra
-00028500: 6422 0a20 2020 2020 2020 2020 2020 2022  d".            "
-00028510: 2868 7474 7073 3a2f 2f77 7777 2e6d 696e  (https://www.min
-00028520: 6473 706f 7265 2e63 6e2f 646f 6373 2f7a  dspore.cn/docs/z
-00028530: 682d 434e 2f72 322e 302f 6170 695f 7079  h-CN/r2.0/api_py
-00028540: 7468 6f6e 2f6d 696e 6473 706f 7265 2f6d  thon/mindspore/m
-00028550: 696e 6473 706f 7265 2e67 7261 642e 6874  indspore.grad.ht
-00028560: 6d6c 2920 220a 2020 2020 2020 2020 2020  ml) ".          
-00028570: 2020 2274 6f20 636f 6d70 7574 6520 6772    "to compute gr
-00028580: 6164 6965 6e74 2061 6e64 2073 656e 6420  adient and send 
-00028590: 7468 6520 6772 6164 6965 6e74 2074 6f20  the gradient to 
-000285a0: 7468 6520 6f70 7469 6d69 7a65 722e 2022  the optimizer. "
-000285b0: 0a20 2020 2020 2020 2020 2020 2022 706c  .            "pl
-000285c0: 6561 7365 2072 6566 6572 2074 6f20 6d6f  ease refer to mo
-000285d0: 6269 6c65 6e65 745f 7632 2065 7861 6d70  bilenet_v2 examp
-000285e0: 6c65 3a20 220a 2020 2020 2020 2020 2020  le: ".          
-000285f0: 2020 2268 7474 7073 3a2f 2f6f 7065 6e69    "https://openi
-00028600: 2e70 636c 2e61 632e 636e 2f4f 7065 6e49  .pcl.ac.cn/OpenI
-00028610: 2f4d 696e 6454 6f72 6368 4d6f 6465 6c5a  /MindTorchModelZ
-00028620: 6f6f 2f73 7263 2f62 7261 6e63 682f 6d61  oo/src/branch/ma
-00028630: 7374 6572 2f6f 6666 6963 6961 6c2f 6376  ster/official/cv
-00028640: 2f22 0a20 2020 2020 2020 2020 2020 2022  /".            "
-00028650: 6d6f 6269 6c65 6e65 745f 7632 2f6d 6f62  mobilenet_v2/mob
-00028660: 696c 656e 6574 5f76 325f 6164 6170 7465  ilenet_v2_adapte
-00028670: 722e 7079 2229 0a0a 2020 2020 4070 726f  r.py")..    @pro
-00028680: 7065 7274 790a 2020 2020 6465 6620 6772  perty.    def gr
-00028690: 6164 2873 656c 6629 3a0a 2020 2020 2020  ad(self):.      
-000286a0: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
-000286b0: 6d65 6e74 6564 4572 726f 7228 0a20 2020  mentedError(.   
-000286c0: 2020 2020 2020 2020 2022 7465 6e73 6f72           "tensor
-000286d0: 2e67 7261 6420 6e6f 7420 7375 7070 6f72  .grad not suppor
-000286e0: 7420 7965 742e 2070 6c65 6175 7365 2075  t yet. pleause u
-000286f0: 7365 2022 0a20 2020 2020 2020 2020 2020  se ".           
-00028700: 2022 6d69 6e64 7370 6f72 652e 7661 6c75   "mindspore.valu
-00028710: 655f 616e 645f 6772 6164 220a 2020 2020  e_and_grad".    
-00028720: 2020 2020 2020 2020 2228 6874 7470 733a          "(https:
-00028730: 2f2f 7777 772e 6d69 6e64 7370 6f72 652e  //www.mindspore.
-00028740: 636e 2f64 6f63 732f 7a68 2d43 4e2f 7232  cn/docs/zh-CN/r2
-00028750: 2e30 2f61 7069 5f70 7974 686f 6e2f 6d69  .0/api_python/mi
-00028760: 6e64 7370 6f72 652f 6d69 6e64 7370 6f72  ndspore/mindspor
-00028770: 652e 7661 6c75 655f 616e 645f 6772 6164  e.value_and_grad
-00028780: 2e68 746d 6c29 2022 0a20 2020 2020 2020  .html) ".       
-00028790: 2020 2020 2022 6f72 206d 696e 6473 706f       "or mindspo
-000287a0: 7265 2e67 7261 6422 0a20 2020 2020 2020  re.grad".       
-000287b0: 2020 2020 2022 2868 7474 7073 3a2f 2f77       "(https://w
-000287c0: 7777 2e6d 696e 6473 706f 7265 2e63 6e2f  ww.mindspore.cn/
-000287d0: 646f 6373 2f7a 682d 434e 2f72 322e 302f  docs/zh-CN/r2.0/
-000287e0: 6170 695f 7079 7468 6f6e 2f6d 696e 6473  api_python/minds
-000287f0: 706f 7265 2f6d 696e 6473 706f 7265 2e67  pore/mindspore.g
-00028800: 7261 642e 6874 6d6c 2920 220a 2020 2020  rad.html) ".    
-00028810: 2020 2020 2020 2020 2274 6f20 6765 7420          "to get 
-00028820: 7468 6520 6772 6164 6965 6e74 2e20 416e  the gradient. An
-00028830: 6420 7461 6b65 206f 7574 2074 6865 2063  d take out the c
-00028840: 6f72 7265 7370 6f6e 6469 6e67 2065 6c65  orresponding ele
-00028850: 6d65 6e74 2061 7320 6772 6164 2e22 0a20  ment as grad.". 
-00028860: 2020 2020 2020 2029 0a0a 2020 2020 6465         )..    de
-00028870: 6620 6672 6578 7028 7365 6c66 293a 0a20  f frexp(self):. 
-00028880: 2020 2020 2020 2023 2054 4f44 4f3a 2074         # TODO: t
-00028890: 6f20 7573 6520 6d73 2e6f 7073 2e66 7265  o use ms.ops.fre
-000288a0: 7870 0a20 2020 2020 2020 2069 6e70 7574  xp.        input
-000288b0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-000288c0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-000288d0: 2020 2020 2020 6966 2069 6e70 7574 5f6d        if input_m
-000288e0: 732e 6474 7970 6520 3d3d 206d 732e 666c  s.dtype == ms.fl
-000288f0: 6f61 7431 363a 0a20 2020 2020 2020 2020  oat16:.         
-00028900: 2020 2069 6e70 7574 5f6d 7320 3d20 696e     input_ms = in
-00028910: 7075 745f 6d73 2e61 7374 7970 6528 6d73  put_ms.astype(ms
-00028920: 2e66 6c6f 6174 3332 290a 2020 2020 2020  .float32).      
-00028930: 2020 2020 2020 7369 676e 203d 206d 732e        sign = ms.
-00028940: 6f70 732e 7369 676e 2869 6e70 7574 5f6d  ops.sign(input_m
-00028950: 7329 0a20 2020 2020 2020 2020 2020 2069  s).            i
-00028960: 6e70 7574 5f6d 7320 3d20 6d73 2e6f 7073  nput_ms = ms.ops
-00028970: 2e61 6273 2869 6e70 7574 5f6d 7329 0a20  .abs(input_ms). 
-00028980: 2020 2020 2020 2020 2020 2065 7870 203d             exp =
-00028990: 206d 732e 6f70 732e 666c 6f6f 7228 6d73   ms.ops.floor(ms
-000289a0: 2e6f 7073 2e6c 6f67 3228 696e 7075 745f  .ops.log2(input_
-000289b0: 6d73 2929 202b 2031 0a20 2020 2020 2020  ms)) + 1.       
-000289c0: 2020 2020 206d 616e 7469 7373 6120 3d20       mantissa = 
-000289d0: 2869 6e70 7574 5f6d 7320 2a20 7369 676e  (input_ms * sign
-000289e0: 202f 2028 3220 2a2a 2065 7870 2929 2e61   / (2 ** exp)).a
-000289f0: 7374 7970 6528 6d73 2e66 6c6f 6174 3136  stype(ms.float16
-00028a00: 290a 2020 2020 2020 2020 656c 7365 3a0a  ).        else:.
-00028a10: 2020 2020 2020 2020 2020 2020 7369 676e              sign
-00028a20: 203d 206d 732e 6f70 732e 7369 676e 2869   = ms.ops.sign(i
-00028a30: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-00028a40: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
-00028a50: 6d73 2e6f 7073 2e61 6273 2869 6e70 7574  ms.ops.abs(input
-00028a60: 5f6d 7329 0a20 2020 2020 2020 2020 2020  _ms).           
-00028a70: 2065 7870 203d 206d 732e 6f70 732e 666c   exp = ms.ops.fl
-00028a80: 6f6f 7228 6d73 2e6f 7073 2e6c 6f67 3228  oor(ms.ops.log2(
-00028a90: 696e 7075 745f 6d73 2929 202b 2031 0a20  input_ms)) + 1. 
-00028aa0: 2020 2020 2020 2020 2020 206d 616e 7469             manti
-00028ab0: 7373 6120 3d20 696e 7075 745f 6d73 202a  ssa = input_ms *
-00028ac0: 2073 6967 6e20 2f20 2832 202a 2a20 6578   sign / (2 ** ex
-00028ad0: 7029 0a20 2020 2020 2020 206f 7574 7075  p).        outpu
-00028ae0: 7420 3d20 286d 616e 7469 7373 612c 2065  t = (mantissa, e
-00028af0: 7870 2e61 7374 7970 6528 6d73 2e69 6e74  xp.astype(ms.int
-00028b00: 3332 2929 0a20 2020 2020 2020 2072 6574  32)).        ret
-00028b10: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
-00028b20: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-00028b30: 7429 0a0a 2020 2020 6465 6620 6f72 6d71  t)..    def ormq
-00028b40: 7228 7365 6c66 2c20 7461 752c 206f 7468  r(self, tau, oth
-00028b50: 6572 2c20 6c65 6674 3d54 7275 652c 2074  er, left=True, t
-00028b60: 7261 6e73 706f 7365 3d46 616c 7365 293a  ranspose=False):
-00028b70: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00028b80: 6973 5f75 6e64 6572 5f67 7075 5f63 6f6e  is_under_gpu_con
-00028b90: 7465 7874 2829 3a0a 2020 2020 2020 2020  text():.        
-00028ba0: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
-00028bb0: 6c65 6d65 6e74 6564 4572 726f 7228 226f  lementedError("o
-00028bc0: 726d 7172 2063 7572 7265 6e74 6c79 206e  rmqr currently n
-00028bd0: 6f74 2073 7570 706f 7274 6564 206f 6e20  ot supported on 
-00028be0: 4350 5520 6e6f 7220 4173 6365 6e64 2229  CPU nor Ascend")
-00028bf0: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
-00028c00: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00028c10: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
-00028c20: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
-00028c30: 2020 2020 2020 2020 2020 7461 7520 3d20            tau = 
-00028c40: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
-00028c50: 7228 7461 7529 0a20 2020 2020 2020 2020  r(tau).         
-00028c60: 2020 206f 7468 6572 203d 2063 6173 745f     other = cast_
-00028c70: 746f 5f6d 735f 7465 6e73 6f72 286f 7468  to_ms_tensor(oth
-00028c80: 6572 290a 2020 2020 2020 2020 2020 2020  er).            
-00028c90: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
-00028ca0: 6f72 6d71 7228 696e 7075 745f 6d73 2c20  ormqr(input_ms, 
-00028cb0: 7461 752c 206f 7468 6572 2c20 6c65 6674  tau, other, left
-00028cc0: 2c20 7472 616e 7370 6f73 6529 0a20 2020  , transpose).   
-00028cd0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00028ce0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
-00028cf0: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
-00028d00: 2020 2020 6465 6620 7472 6961 6e67 756c      def triangul
-00028d10: 6172 5f73 6f6c 7665 2873 656c 662c 2041  ar_solve(self, A
-00028d20: 2c20 7570 7065 723d 5472 7565 2c20 7472  , upper=True, tr
-00028d30: 616e 7370 6f73 653d 4661 6c73 652c 2075  anspose=False, u
-00028d40: 6e69 7472 6961 6e67 756c 6172 3d46 616c  nitriangular=Fal
-00028d50: 7365 293a 0a20 2020 2020 2020 2069 6620  se):.        if 
-00028d60: 6973 5f75 6e64 6572 5f61 7363 656e 645f  is_under_ascend_
-00028d70: 636f 6e74 6578 7428 293a 0a20 2020 2020  context():.     
-00028d80: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
-00028d90: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
-00028da0: 2822 7472 6961 6e67 756c 6172 5f73 6f6c  ("triangular_sol
-00028db0: 7665 2063 7572 7265 6e74 6c79 206e 6f74  ve currently not
-00028dc0: 2073 7570 706f 7274 6564 206f 6e20 4173   supported on As
-00028dd0: 6365 6e64 2229 0a20 2020 2020 2020 2042  cend").        B
-00028de0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00028df0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00028e00: 2020 2041 203d 2063 6173 745f 746f 5f6d     A = cast_to_m
-00028e10: 735f 7465 6e73 6f72 2841 290a 2020 2020  s_tensor(A).    
-00028e20: 2020 2020 7472 616e 7320 3d20 2754 2720      trans = 'T' 
-00028e30: 6966 2074 7261 6e73 706f 7365 2065 6c73  if transpose els
-00028e40: 6520 274e 270a 2020 2020 2020 2020 736f  e 'N'.        so
-00028e50: 6c76 655f 6f70 203d 205f 6765 745f 6361  lve_op = _get_ca
-00028e60: 6368 655f 7072 696d 2853 6f6c 7665 5472  che_prim(SolveTr
-00028e70: 6961 6e67 756c 6172 2928 6c6f 7765 723d  iangular)(lower=
-00028e80: 286e 6f74 2075 7070 6572 292c 2075 6e69  (not upper), uni
-00028e90: 745f 6469 6167 6f6e 616c 3d75 6e69 7472  t_diagonal=unitr
-00028ea0: 6961 6e67 756c 6172 2c20 7472 616e 733d  iangular, trans=
-00028eb0: 7472 616e 7329 0a20 2020 2020 2020 206f  trans).        o
-00028ec0: 7574 7075 7420 3d20 736f 6c76 655f 6f70  utput = solve_op
-00028ed0: 2841 2c20 4229 0a20 2020 2020 2020 2069  (A, B).        i
-00028ee0: 6620 7079 6e61 7469 7665 5f6d 6f64 655f  f pynative_mode_
-00028ef0: 636f 6e64 6974 696f 6e28 293a 0a20 2020  condition():.   
-00028f00: 2020 2020 2020 2020 2074 7269 616e 6775           triangu
-00028f10: 6c61 725f 736f 6c76 655f 6e61 6d65 6474  lar_solve_namedt
-00028f20: 7570 6c65 203d 2073 6574 5f6d 756c 7469  uple = set_multi
-00028f30: 706c 655f 6e61 6d65 5f74 7570 6c65 2827  ple_name_tuple('
-00028f40: 7472 6961 6e67 756c 6172 5f73 6f6c 7665  triangular_solve
-00028f50: 272c 2027 736f 6c75 7469 6f6e 2c20 636c  ', 'solution, cl
-00028f60: 6f6e 6564 5f63 6f65 6666 6963 6965 6e74  oned_coefficient
-00028f70: 2729 0a20 2020 2020 2020 2020 2020 206f  ').            o
-00028f80: 7574 7075 7420 3d20 7472 6961 6e67 756c  utput = triangul
-00028f90: 6172 5f73 6f6c 7665 5f6e 616d 6564 7475  ar_solve_namedtu
-00028fa0: 706c 6528 6361 7374 5f74 6f5f 6164 6170  ple(cast_to_adap
-00028fb0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-00028fc0: 7429 2c20 6361 7374 5f74 6f5f 6164 6170  t), cast_to_adap
-00028fd0: 7465 725f 7465 6e73 6f72 2841 2929 0a20  ter_tensor(A)). 
-00028fe0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00028ff0: 6e20 6f75 7470 7574 0a20 2020 2020 2020  n output.       
-00029000: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-00029010: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-00029020: 7574 7075 7429 2c20 6361 7374 5f74 6f5f  utput), cast_to_
-00029030: 6164 6170 7465 725f 7465 6e73 6f72 2841  adapter_tensor(A
-00029040: 290a 0a20 2020 2064 6566 2072 656c 7528  )..    def relu(
-00029050: 7365 6c66 293a 0a20 2020 2020 2020 2069  self):.        i
-00029060: 6e70 7574 5f6d 7320 3d20 6361 7374 5f74  nput_ms = cast_t
-00029070: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00029080: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-00029090: 203d 206d 732e 6f70 732e 7265 6c75 2869   = ms.ops.relu(i
-000290a0: 6e70 7574 5f6d 7329 0a20 2020 2020 2020  nput_ms).       
-000290b0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
-000290c0: 6164 6170 7465 725f 7465 6e73 6f72 286f  adapter_tensor(o
-000290d0: 7574 7075 7429 0a0a 2020 2020 6465 6620  utput)..    def 
-000290e0: 6266 6c6f 6174 3136 2873 656c 662c 206d  bfloat16(self, m
-000290f0: 656d 6f72 795f 666f 726d 6174 3d4e 6f6e  emory_format=Non
-00029100: 6529 3a0a 2020 2020 2020 2020 6966 206d  e):.        if m
-00029110: 656d 6f72 795f 666f 726d 6174 3a0a 2020  emory_format:.  
-00029120: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00029130: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
-00029140: 726f 7228 226d 656d 6f72 795f 666f 726d  ror("memory_form
-00029150: 6174 2069 7320 6e6f 7420 7375 7070 6f72  at is not suppor
-00029160: 7465 642e 2229 0a20 2020 2020 2020 2078  ted.").        x
-00029170: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00029180: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-00029190: 2020 206f 7574 7075 7420 3d20 782e 6173     output = x.as
-000291a0: 7479 7065 286d 732e 6266 6c6f 6174 3136  type(ms.bfloat16
-000291b0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-000291c0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
-000291d0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
-000291e0: 0a20 2020 2064 6566 2063 666c 6f61 7428  .    def cfloat(
-000291f0: 7365 6c66 2c20 6d65 6d6f 7279 5f66 6f72  self, memory_for
-00029200: 6d61 743d 4e6f 6e65 293a 0a20 2020 2020  mat=None):.     
-00029210: 2020 2069 6620 6d65 6d6f 7279 5f66 6f72     if memory_for
-00029220: 6d61 743a 0a20 2020 2020 2020 2020 2020  mat:.           
-00029230: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
-00029240: 656e 7465 6445 7272 6f72 2822 6d65 6d6f  entedError("memo
-00029250: 7279 5f66 6f72 6d61 7420 6973 206e 6f74  ry_format is not
-00029260: 2073 7570 706f 7274 6564 2e22 290a 2020   supported.").  
-00029270: 2020 2020 2020 7820 3d20 6361 7374 5f74        x = cast_t
-00029280: 6f5f 6d73 5f74 656e 736f 7228 7365 6c66  o_ms_tensor(self
-00029290: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
-000292a0: 203d 2078 2e61 7374 7970 6528 6d73 2e63   = x.astype(ms.c
-000292b0: 6f6d 706c 6578 3634 290a 2020 2020 2020  omplex64).      
-000292c0: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
-000292d0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-000292e0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
-000292f0: 2063 646f 7562 6c65 2873 656c 662c 206d   cdouble(self, m
-00029300: 656d 6f72 795f 666f 726d 6174 3d4e 6f6e  emory_format=Non
-00029310: 6529 3a0a 2020 2020 2020 2020 6966 206d  e):.        if m
-00029320: 656d 6f72 795f 666f 726d 6174 3a0a 2020  emory_format:.  
-00029330: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00029340: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
-00029350: 726f 7228 226d 656d 6f72 795f 666f 726d  ror("memory_form
-00029360: 6174 2069 7320 6e6f 7420 7375 7070 6f72  at is not suppor
-00029370: 7465 642e 2229 0a20 2020 2020 2020 2078  ted.").        x
-00029380: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
-00029390: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
-000293a0: 2020 206f 7574 7075 7420 3d20 782e 6173     output = x.as
-000293b0: 7479 7065 286d 732e 636f 6d70 6c65 7831  type(ms.complex1
-000293c0: 3238 290a 2020 2020 2020 2020 7265 7475  28).        retu
-000293d0: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
-000293e0: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
-000293f0: 290a 0a0a 636c 6173 7320 5f54 7970 6554  )...class _TypeT
-00029400: 656e 736f 7228 5465 6e73 6f72 293a 0a20  ensor(Tensor):. 
-00029410: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00029420: 7365 6c66 2c20 2a69 6e70 7574 5f64 6174  self, *input_dat
-00029430: 612c 2064 7479 7065 5f6e 616d 6529 3a0a  a, dtype_name):.
-00029440: 2020 2020 2020 2020 7375 7065 7228 5f54          super(_T
-00029450: 7970 6554 656e 736f 722c 2073 656c 6629  ypeTensor, self)
-00029460: 2e5f 5f69 6e69 745f 5f28 2a69 6e70 7574  .__init__(*input
-00029470: 5f64 6174 612c 2064 7479 7065 3d64 7479  _data, dtype=dty
-00029480: 7065 5f6e 616d 652c 2069 6e6e 6572 3d46  pe_name, inner=F
-00029490: 616c 7365 290a 0a0a 636c 6173 7320 426f  alse)...class Bo
-000294a0: 6f6c 5465 6e73 6f72 285f 5479 7065 5465  olTensor(_TypeTe
-000294b0: 6e73 6f72 293a 0a20 2020 2064 6566 205f  nsor):.    def _
-000294c0: 5f69 6e69 745f 5f28 7365 6c66 2c20 2a69  _init__(self, *i
-000294d0: 6e70 7574 5f64 6174 6129 3a0a 2020 2020  nput_data):.    
-000294e0: 2020 2020 7375 7065 7228 426f 6f6c 5465      super(BoolTe
-000294f0: 6e73 6f72 2c20 7365 6c66 292e 5f5f 696e  nsor, self).__in
-00029500: 6974 5f5f 282a 696e 7075 745f 6461 7461  it__(*input_data
-00029510: 2c20 6474 7970 655f 6e61 6d65 3d27 626f  , dtype_name='bo
-00029520: 6f6c 2729 0a0a 0a63 6c61 7373 2042 7974  ol')...class Byt
-00029530: 6554 656e 736f 7228 5f54 7970 6554 656e  eTensor(_TypeTen
-00029540: 736f 7229 3a0a 2020 2020 6465 6620 5f5f  sor):.    def __
-00029550: 696e 6974 5f5f 2873 656c 662c 202a 696e  init__(self, *in
-00029560: 7075 745f 6461 7461 293a 0a20 2020 2020  put_data):.     
-00029570: 2020 2073 7570 6572 2842 7974 6554 656e     super(ByteTen
-00029580: 736f 722c 2073 656c 6629 2e5f 5f69 6e69  sor, self).__ini
-00029590: 745f 5f28 2a69 6e70 7574 5f64 6174 612c  t__(*input_data,
-000295a0: 2064 7479 7065 5f6e 616d 653d 2775 696e   dtype_name='uin
-000295b0: 7438 2729 0a0a 0a63 6c61 7373 2043 6861  t8')...class Cha
-000295c0: 7254 656e 736f 7228 5f54 7970 6554 656e  rTensor(_TypeTen
-000295d0: 736f 7229 3a0a 2020 2020 6465 6620 5f5f  sor):.    def __
-000295e0: 696e 6974 5f5f 2873 656c 662c 202a 696e  init__(self, *in
-000295f0: 7075 745f 6461 7461 293a 0a20 2020 2020  put_data):.     
-00029600: 2020 2073 7570 6572 2843 6861 7254 656e     super(CharTen
-00029610: 736f 722c 2073 656c 6629 2e5f 5f69 6e69  sor, self).__ini
-00029620: 745f 5f28 2a69 6e70 7574 5f64 6174 612c  t__(*input_data,
-00029630: 2064 7479 7065 5f6e 616d 653d 2769 6e74   dtype_name='int
-00029640: 3827 290a 0a0a 636c 6173 7320 5368 6f72  8')...class Shor
-00029650: 7454 656e 736f 7228 5f54 7970 6554 656e  tTensor(_TypeTen
-00029660: 736f 7229 3a0a 2020 2020 6465 6620 5f5f  sor):.    def __
-00029670: 696e 6974 5f5f 2873 656c 662c 202a 696e  init__(self, *in
-00029680: 7075 745f 6461 7461 293a 0a20 2020 2020  put_data):.     
-00029690: 2020 2073 7570 6572 2853 686f 7274 5465     super(ShortTe
-000296a0: 6e73 6f72 2c20 7365 6c66 292e 5f5f 696e  nsor, self).__in
-000296b0: 6974 5f5f 282a 696e 7075 745f 6461 7461  it__(*input_data
-000296c0: 2c20 6474 7970 655f 6e61 6d65 3d27 696e  , dtype_name='in
-000296d0: 7431 3627 290a 0a0a 636c 6173 7320 496e  t16')...class In
-000296e0: 7454 656e 736f 7228 5f54 7970 6554 656e  tTensor(_TypeTen
-000296f0: 736f 7229 3a0a 2020 2020 6465 6620 5f5f  sor):.    def __
-00029700: 696e 6974 5f5f 2873 656c 662c 202a 696e  init__(self, *in
-00029710: 7075 745f 6461 7461 293a 0a20 2020 2020  put_data):.     
-00029720: 2020 2073 7570 6572 2849 6e74 5465 6e73     super(IntTens
-00029730: 6f72 2c20 7365 6c66 292e 5f5f 696e 6974  or, self).__init
-00029740: 5f5f 282a 696e 7075 745f 6461 7461 2c20  __(*input_data, 
-00029750: 6474 7970 655f 6e61 6d65 3d27 696e 7433  dtype_name='int3
-00029760: 3227 290a 0a0a 636c 6173 7320 4861 6c66  2')...class Half
-00029770: 5465 6e73 6f72 285f 5479 7065 5465 6e73  Tensor(_TypeTens
-00029780: 6f72 293a 0a20 2020 2064 6566 205f 5f69  or):.    def __i
-00029790: 6e69 745f 5f28 7365 6c66 2c20 2a69 6e70  nit__(self, *inp
-000297a0: 7574 5f64 6174 6129 3a0a 2020 2020 2020  ut_data):.      
-000297b0: 2020 7375 7065 7228 4861 6c66 5465 6e73    super(HalfTens
-000297c0: 6f72 2c20 7365 6c66 292e 5f5f 696e 6974  or, self).__init
-000297d0: 5f5f 282a 696e 7075 745f 6461 7461 2c20  __(*input_data, 
-000297e0: 6474 7970 655f 6e61 6d65 3d27 666c 6f61  dtype_name='floa
-000297f0: 7431 3627 290a 0a0a 636c 6173 7320 466c  t16')...class Fl
-00029800: 6f61 7454 656e 736f 7228 5f54 7970 6554  oatTensor(_TypeT
-00029810: 656e 736f 7229 3a0a 2020 2020 6465 6620  ensor):.    def 
-00029820: 5f5f 696e 6974 5f5f 2873 656c 662c 202a  __init__(self, *
-00029830: 696e 7075 745f 6461 7461 293a 0a20 2020  input_data):.   
-00029840: 2020 2020 2073 7570 6572 2846 6c6f 6174       super(Float
-00029850: 5465 6e73 6f72 2c20 7365 6c66 292e 5f5f  Tensor, self).__
-00029860: 696e 6974 5f5f 282a 696e 7075 745f 6461  init__(*input_da
-00029870: 7461 2c20 6474 7970 655f 6e61 6d65 3d27  ta, dtype_name='
-00029880: 666c 6f61 7433 3227 290a 0a0a 636c 6173  float32')...clas
-00029890: 7320 446f 7562 6c65 5465 6e73 6f72 285f  s DoubleTensor(_
-000298a0: 5479 7065 5465 6e73 6f72 293a 0a20 2020  TypeTensor):.   
-000298b0: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
-000298c0: 6c66 2c20 2a69 6e70 7574 5f64 6174 6129  lf, *input_data)
-000298d0: 3a0a 2020 2020 2020 2020 7375 7065 7228  :.        super(
-000298e0: 446f 7562 6c65 5465 6e73 6f72 2c20 7365  DoubleTensor, se
-000298f0: 6c66 292e 5f5f 696e 6974 5f5f 282a 696e  lf).__init__(*in
-00029900: 7075 745f 6461 7461 2c20 6474 7970 655f  put_data, dtype_
-00029910: 6e61 6d65 3d27 666c 6f61 7436 3427 290a  name='float64').
-00029920: 0a0a 636c 6173 7320 4c6f 6e67 5465 6e73  ..class LongTens
-00029930: 6f72 285f 5479 7065 5465 6e73 6f72 293a  or(_TypeTensor):
-00029940: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00029950: 5f28 7365 6c66 2c20 2a69 6e70 7574 5f64  _(self, *input_d
-00029960: 6174 6129 3a0a 2020 2020 2020 2020 7375  ata):.        su
-00029970: 7065 7228 4c6f 6e67 5465 6e73 6f72 2c20  per(LongTensor, 
-00029980: 7365 6c66 292e 5f5f 696e 6974 5f5f 282a  self).__init__(*
-00029990: 696e 7075 745f 6461 7461 2c20 6474 7970  input_data, dtyp
-000299a0: 655f 6e61 6d65 3d27 696e 7436 3427 290a  e_name='int64').
-000299b0: 0a63 6c61 7373 2042 466c 6f61 7431 3654  .class BFloat16T
-000299c0: 656e 736f 7228 5f54 7970 6554 656e 736f  ensor(_TypeTenso
-000299d0: 7229 3a0a 2020 2020 6465 6620 5f5f 696e  r):.    def __in
-000299e0: 6974 5f5f 2873 656c 662c 202a 696e 7075  it__(self, *inpu
-000299f0: 745f 6461 7461 293a 0a20 2020 2020 2020  t_data):.       
-00029a00: 2073 7570 6572 2842 466c 6f61 7431 3654   super(BFloat16T
-00029a10: 656e 736f 722c 2073 656c 6629 2e5f 5f69  ensor, self).__i
-00029a20: 6e69 745f 5f28 2a69 6e70 7574 5f64 6174  nit__(*input_dat
-00029a30: 612c 2064 7479 7065 5f6e 616d 653d 2762  a, dtype_name='b
-00029a40: 666c 6f61 7431 3627 290a 0a0a 5f6e 705f  float16')..._np_
-00029a50: 6670 5f74 7970 6573 203d 2028 6e70 2e66  fp_types = (np.f
-00029a60: 6c6f 6174 3136 2c20 6e70 2e66 6c6f 6174  loat16, np.float
-00029a70: 3332 2c20 6e70 2e66 6c6f 6174 3634 290a  32, np.float64).
-00029a80: 0a64 6566 205f 6765 745f 6465 6661 756c  .def _get_defaul
-00029a90: 745f 6474 7970 655f 6279 5f64 6174 6128  t_dtype_by_data(
-00029aa0: 6461 7461 293a 0a20 2020 2069 6620 6973  data):.    if is
-00029ab0: 696e 7374 616e 6365 2864 6174 612c 206e  instance(data, n
-00029ac0: 702e 6e64 6172 7261 7929 3a0a 2020 2020  p.ndarray):.    
-00029ad0: 2020 2020 6f72 6967 696e 5f64 7479 7065      origin_dtype
-00029ae0: 203d 2064 6174 612e 6474 7970 650a 2020   = data.dtype.  
-00029af0: 2020 656c 6966 2069 7369 6e73 7461 6e63    elif isinstanc
-00029b00: 6528 6461 7461 2c20 2874 7570 6c65 2c20  e(data, (tuple, 
-00029b10: 6c69 7374 2929 3a0a 2020 2020 2020 2020  list)):.        
-00029b20: 6f72 6967 696e 5f64 7479 7065 203d 206e  origin_dtype = n
-00029b30: 702e 6172 7261 7928 6461 7461 292e 6474  p.array(data).dt
-00029b40: 7970 650a 2020 2020 656c 6966 2069 7369  ype.    elif isi
-00029b50: 6e73 7461 6e63 6528 6461 7461 2c20 666c  nstance(data, fl
-00029b60: 6f61 7429 3a0a 2020 2020 2020 2020 696e  oat):.        in
-00029b70: 7075 745f 6461 7461 203d 206e 702e 6172  put_data = np.ar
-00029b80: 7261 7928 6461 7461 290a 2020 2020 2020  ray(data).      
-00029b90: 2020 6f72 6967 696e 5f64 7479 7065 203d    origin_dtype =
-00029ba0: 2069 6e70 7574 5f64 6174 612e 6474 7970   input_data.dtyp
-00029bb0: 650a 2020 2020 656c 7365 3a0a 2020 2020  e.    else:.    
-00029bc0: 2020 2020 7265 7475 726e 204e 6f6e 650a      return None.
-00029bd0: 0a20 2020 2069 6620 6f72 6967 696e 5f64  .    if origin_d
-00029be0: 7479 7065 2069 6e20 5f6e 705f 6670 5f74  type in _np_fp_t
-00029bf0: 7970 6573 3a0a 2020 2020 2020 2020 6465  ypes:.        de
-00029c00: 6661 756c 745f 6474 7970 6520 3d20 6765  fault_dtype = ge
-00029c10: 745f 6465 6661 756c 745f 6474 7970 6528  t_default_dtype(
-00029c20: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
-00029c30: 2064 6566 6175 6c74 5f64 7479 7065 0a20   default_dtype. 
-00029c40: 2020 2072 6574 7572 6e20 4e6f 6e65 0a0a     return None..
-00029c50: 6465 6620 7465 6e73 6f72 2864 6174 612c  def tensor(data,
-00029c60: 2064 7479 7065 3d4e 6f6e 652c 2064 6576   dtype=None, dev
-00029c70: 6963 653d 4e6f 6e65 2c20 7265 7175 6972  ice=None, requir
-00029c80: 6573 5f67 7261 643d 5472 7565 293a 0a20  es_grad=True):. 
-00029c90: 2020 2075 6e73 7570 706f 7274 6564 5f61     unsupported_a
-00029ca0: 7474 7228 6465 7669 6365 290a 2020 2020  ttr(device).    
-00029cb0: 6966 2072 6571 7569 7265 735f 6772 6164  if requires_grad
-00029cc0: 2069 7320 4661 6c73 653a 0a20 2020 2020   is False:.     
-00029cd0: 2020 206d 7367 203d 2028 2249 6e20 4d69     msg = ("In Mi
-00029ce0: 6e64 546f 7263 682c 2054 656e 736f 7227  ndTorch, Tensor'
-00029cf0: 7320 6072 6571 7569 7265 735f 6772 6164  s `requires_grad
-00029d00: 6020 6973 2061 6c77 6179 7320 2754 7275  ` is always 'Tru
-00029d10: 6527 2c20 6361 6e20 6e6f 7420 6265 2073  e', can not be s
-00029d20: 6574 2074 6f20 2746 616c 7365 272e 2022  et to 'False'. "
-00029d30: 290a 2020 2020 2020 2020 7761 726e 696e  ).        warnin
-00029d40: 6728 6d73 6729 0a0a 2020 2020 6966 2064  g(msg)..    if d
-00029d50: 7479 7065 2069 7320 4e6f 6e65 2061 6e64  type is None and
-00029d60: 205f 6e6f 745f 6465 6661 756c 745f 6670   _not_default_fp
-00029d70: 3332 5f64 7479 7065 2829 3a0a 2020 2020  32_dtype():.    
-00029d80: 2020 2020 6474 7970 6520 3d20 5f67 6574      dtype = _get
-00029d90: 5f64 6566 6175 6c74 5f64 7479 7065 5f62  _default_dtype_b
-00029da0: 795f 6461 7461 2864 6174 6129 0a0a 2020  y_data(data)..  
-00029db0: 2020 7265 7475 726e 2054 656e 736f 7228    return Tensor(
-00029dc0: 6461 7461 2c20 6474 7970 653d 6474 7970  data, dtype=dtyp
-00029dd0: 652c 2069 6e6e 6572 3d54 7275 6529 0a0a  e, inner=True)..
-00029de0: 6465 6620 6361 7374 5f74 6f5f 6d73 5f74  def cast_to_ms_t
-00029df0: 656e 736f 7228 696e 7075 7473 293a 0a20  ensor(inputs):. 
-00029e00: 2020 2022 2222 0a20 2020 2043 6173 7420     """.    Cast 
-00029e10: 4d69 6e64 546f 7263 682e 5465 6e73 6f72  MindTorch.Tensor
-00029e20: 2074 6f20 4d69 6e64 5370 6f72 652e 5465   to MindSpore.Te
-00029e30: 6e73 6f72 2062 6566 6f72 6520 6361 6c6c  nsor before call
-00029e40: 206d 696e 6473 706f 7265 2041 5049 2e0a   mindspore API..
-00029e50: 2020 2020 2222 220a 2020 2020 6465 6620      """.    def 
-00029e60: 5f63 6173 7428 696e 7075 7473 293a 0a20  _cast(inputs):. 
-00029e70: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-00029e80: 616e 6365 2869 6e70 7574 732c 2054 656e  ance(inputs, Ten
-00029e90: 736f 7229 3a0a 2020 2020 2020 2020 2020  sor):.          
-00029ea0: 2020 696e 7075 7473 203d 2069 6e6e 6572    inputs = inner
-00029eb0: 2e63 6f6e 7665 7274 5f74 6f5f 6d73 5f74  .convert_to_ms_t
-00029ec0: 656e 736f 7228 696e 7075 7473 290a 2020  ensor(inputs).  
-00029ed0: 2020 2020 2020 656c 6966 2069 7369 6e73        elif isins
-00029ee0: 7461 6e63 6528 696e 7075 7473 2c20 7475  tance(inputs, tu
-00029ef0: 706c 6529 3a0a 2020 2020 2020 2020 2020  ple):.          
-00029f00: 2020 696e 7075 7473 5f74 7570 6c65 203d    inputs_tuple =
-00029f10: 2028 290a 2020 2020 2020 2020 2020 2020   ().            
-00029f20: 666f 7220 7661 6c75 6520 696e 2069 6e70  for value in inp
-00029f30: 7574 733a 0a20 2020 2020 2020 2020 2020  uts:.           
-00029f40: 2020 2020 2069 6e70 7574 735f 7475 706c       inputs_tupl
-00029f50: 6520 2b3d 2028 5f63 6173 7428 7661 6c75  e += (_cast(valu
-00029f60: 6529 2c20 290a 2020 2020 2020 2020 2020  e), ).          
-00029f70: 2020 696e 7075 7473 203d 2069 6e70 7574    inputs = input
-00029f80: 735f 7475 706c 650a 2020 2020 2020 2020  s_tuple.        
-00029f90: 656c 6966 2069 7369 6e73 7461 6e63 6528  elif isinstance(
-00029fa0: 696e 7075 7473 2c20 6c69 7374 293a 0a20  inputs, list):. 
-00029fb0: 2020 2020 2020 2020 2020 2069 6e70 7574             input
-00029fc0: 735f 6c69 7374 203d 205b 5d0a 2020 2020  s_list = [].    
-00029fd0: 2020 2020 2020 2020 666f 7220 7661 6c75          for valu
-00029fe0: 6520 696e 2069 6e70 7574 733a 0a20 2020  e in inputs:.   
-00029ff0: 2020 2020 2020 2020 2020 2020 2069 6e70               inp
-0002a000: 7574 735f 6c69 7374 2e61 7070 656e 6428  uts_list.append(
-0002a010: 5f63 6173 7428 7661 6c75 6529 290a 2020  _cast(value)).  
-0002a020: 2020 2020 2020 2020 2020 696e 7075 7473            inputs
-0002a030: 203d 2069 6e70 7574 735f 6c69 7374 0a20   = inputs_list. 
-0002a040: 2020 2020 2020 2065 6c69 6620 6973 696e         elif isin
-0002a050: 7374 616e 6365 2869 6e70 7574 732c 2064  stance(inputs, d
-0002a060: 6963 7429 3a0a 2020 2020 2020 2020 2020  ict):.          
-0002a070: 2020 666f 7220 6b65 792c 2076 616c 7565    for key, value
-0002a080: 2069 6e20 696e 7075 7473 2e69 7465 6d73   in inputs.items
-0002a090: 2829 3a0a 2020 2020 2020 2020 2020 2020  ():.            
-0002a0a0: 2020 2020 696e 7075 7473 5b6b 6579 5d20      inputs[key] 
-0002a0b0: 3d20 5f63 6173 7428 7661 6c75 6529 0a20  = _cast(value). 
-0002a0c0: 2020 2020 2020 2072 6574 7572 6e20 696e         return in
-0002a0d0: 7075 7473 0a0a 2020 2020 696e 7075 7473  puts..    inputs
-0002a0e0: 203d 205f 6361 7374 2869 6e70 7574 7329   = _cast(inputs)
-0002a0f0: 0a20 2020 2072 6574 7572 6e20 696e 7075  .    return inpu
-0002a100: 7473 0a0a 0a64 6566 2063 6173 745f 746f  ts...def cast_to
-0002a110: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
-0002a120: 6f75 7470 7574 7329 3a0a 2020 2020 2222  outputs):.    ""
-0002a130: 220a 2020 2020 4361 7374 204d 696e 6453  ".    Cast MindS
-0002a140: 706f 7265 2e54 656e 736f 7220 746f 204d  pore.Tensor to M
-0002a150: 696e 6454 6f72 6368 2e54 656e 736f 7220  indTorch.Tensor 
-0002a160: 6166 7465 7220 6361 6c6c 206d 696e 6473  after call minds
-0002a170: 706f 7265 2041 5049 2e0a 2020 2020 2222  pore API..    ""
-0002a180: 220a 2020 2020 6465 6620 5f63 6173 7428  ".    def _cast(
-0002a190: 6f75 7470 7574 7329 3a0a 2020 2020 2020  outputs):.      
-0002a1a0: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-0002a1b0: 6f75 7470 7574 732c 206d 732e 5465 6e73  outputs, ms.Tens
-0002a1c0: 6f72 293a 0a20 2020 2020 2020 2020 2020  or):.           
-0002a1d0: 206f 7574 7075 7473 203d 2069 6e6e 6572   outputs = inner
-0002a1e0: 2e63 6f6e 7665 7274 5f74 6f5f 6164 6170  .convert_to_adap
-0002a1f0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
-0002a200: 7473 290a 2020 2020 2020 2020 656c 6966  ts).        elif
-0002a210: 2069 7369 6e73 7461 6e63 6528 6f75 7470   isinstance(outp
-0002a220: 7574 732c 2074 7570 6c65 293a 0a20 2020  uts, tuple):.   
-0002a230: 2020 2020 2020 2020 206f 7574 7075 7473           outputs
-0002a240: 5f74 7570 6c65 203d 2028 290a 2020 2020  _tuple = ().    
-0002a250: 2020 2020 2020 2020 666f 7220 7661 6c75          for valu
-0002a260: 6520 696e 206f 7574 7075 7473 3a0a 2020  e in outputs:.  
-0002a270: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-0002a280: 7470 7574 735f 7475 706c 6520 2b3d 2028  tputs_tuple += (
-0002a290: 5f63 6173 7428 7661 6c75 6529 2c20 290a  _cast(value), ).
-0002a2a0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-0002a2b0: 7574 7320 3d20 6f75 7470 7574 735f 7475  uts = outputs_tu
-0002a2c0: 706c 650a 2020 2020 2020 2020 656c 6966  ple.        elif
-0002a2d0: 2069 7369 6e73 7461 6e63 6528 6f75 7470   isinstance(outp
-0002a2e0: 7574 732c 206c 6973 7429 3a0a 2020 2020  uts, list):.    
-0002a2f0: 2020 2020 2020 2020 6f75 7470 7574 735f          outputs_
-0002a300: 6c69 7374 203d 205b 5d0a 2020 2020 2020  list = [].      
-0002a310: 2020 2020 2020 666f 7220 7661 6c75 6520        for value 
-0002a320: 696e 206f 7574 7075 7473 3a0a 2020 2020  in outputs:.    
-0002a330: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
-0002a340: 7574 735f 6c69 7374 2e61 7070 656e 6428  uts_list.append(
-0002a350: 5f63 6173 7428 7661 6c75 6529 290a 2020  _cast(value)).  
-0002a360: 2020 2020 2020 2020 2020 6f75 7470 7574            output
-0002a370: 7320 3d20 6f75 7470 7574 735f 6c69 7374  s = outputs_list
-0002a380: 0a20 2020 2020 2020 2065 6c69 6620 6973  .        elif is
-0002a390: 696e 7374 616e 6365 286f 7574 7075 7473  instance(outputs
-0002a3a0: 2c20 6469 6374 293a 0a20 2020 2020 2020  , dict):.       
-0002a3b0: 2020 2020 2066 6f72 206b 6579 2c20 7661       for key, va
-0002a3c0: 6c75 6520 696e 206f 7574 7075 7473 2e69  lue in outputs.i
-0002a3d0: 7465 6d73 2829 3a0a 2020 2020 2020 2020  tems():.        
-0002a3e0: 2020 2020 2020 2020 6f75 7470 7574 735b          outputs[
-0002a3f0: 6b65 795d 203d 205f 6361 7374 2876 616c  key] = _cast(val
-0002a400: 7565 290a 2020 2020 2020 2020 7265 7475  ue).        retu
-0002a410: 726e 206f 7574 7075 7473 0a0a 2020 2020  rn outputs..    
-0002a420: 6f75 7470 7574 7320 3d20 5f63 6173 7428  outputs = _cast(
-0002a430: 6f75 7470 7574 7329 0a20 2020 2072 6574  outputs).    ret
-0002a440: 7572 6e20 6f75 7470 7574 730a 0a0a 6465  urn outputs...de
-0002a450: 6620 5f74 656e 736f 725f 696e 706c 6163  f _tensor_inplac
-0002a460: 655f 6173 7369 676e 2869 6e70 7574 2c20  e_assign(input, 
-0002a470: 6f75 7470 7574 2c20 6f70 5f6e 616d 652c  output, op_name,
-0002a480: 2072 6570 6c61 6365 5f6f 7029 3a0a 2020   replace_op):.  
-0002a490: 2020 2320 6966 2070 796e 6174 6976 655f    # if pynative_
-0002a4a0: 6d6f 6465 5f63 6f6e 6469 7469 6f6e 2829  mode_condition()
-0002a4b0: 3a20 2023 2054 4f44 4f3a 206d 735f 6675  :  # TODO: ms_fu
-0002a4c0: 6e63 7469 6f6e 0a20 2020 2023 2020 2020  nction.    #    
-0002a4d0: 2069 6e70 7574 2e61 7373 6967 6e5f 7661   input.assign_va
-0002a4e0: 6c75 6528 6f75 7470 7574 290a 2020 2020  lue(output).    
-0002a4f0: 2320 2020 2020 7265 7475 726e 2069 6e70  #     return inp
-0002a500: 7574 0a0a 2020 2020 2320 544f 444f 3a20  ut..    # TODO: 
-0002a510: 7465 6e73 6f72 2061 7069 2077 696c 6c20  tensor api will 
-0002a520: 6265 2075 7365 6420 696e 2069 6e69 7420  be used in init 
-0002a530: 6461 7461 2c20 6275 7420 6974 2063 616e  data, but it can
-0002a540: 206e 6f74 2062 6520 7573 6564 2069 6e20   not be used in 
-0002a550: 6772 6170 682e 0a20 2020 2069 6620 6772  graph..    if gr
-0002a560: 6170 685f 6d6f 6465 5f63 6f6e 6469 7469  aph_mode_conditi
-0002a570: 6f6e 2829 3a0a 2020 2020 2020 2020 7261  on():.        ra
-0002a580: 6973 6520 5275 6e74 696d 6545 7272 6f72  ise RuntimeError
-0002a590: 2827 6054 656e 736f 722e 7b61 7d60 2069  ('`Tensor.{a}` i
-0002a5a0: 7320 616e 2069 6e2d 706c 6163 6520 6f70  s an in-place op
-0002a5b0: 6572 6174 696f 6e20 616e 6420 2278 2e7b  eration and "x.{
-0002a5c0: 617d 2829 2220 6973 206e 6f74 2073 7570  a}()" is not sup
-0002a5d0: 706f 7274 6564 2074 6f20 7573 6520 270a  ported to use '.
-0002a5e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0002a5f0: 2020 2020 2020 2020 2020 2027 696e 204d             'in M
-0002a600: 696e 6453 706f 7265 2073 7461 7469 6320  indSpore static 
-0002a610: 6772 6170 6820 6d6f 6465 2e20 506c 6561  graph mode. Plea
-0002a620: 7365 2075 7365 2022 7820 3d20 782e 7b62  se use "x = x.{b
-0002a630: 7d28 2922 206f 7220 6f74 6865 7220 4150  }()" or other AP
-0002a640: 4920 270a 2020 2020 2020 2020 2020 2020  I '.            
-0002a650: 2020 2020 2020 2020 2020 2020 2020 2027                 '
-0002a660: 696e 7374 6561 642e 272e 666f 726d 6174  instead.'.format
-0002a670: 2861 3d6f 705f 6e61 6d65 2c20 623d 7265  (a=op_name, b=re
-0002a680: 706c 6163 655f 6f70 2929 0a0a 2020 2020  place_op))..    
-0002a690: 7761 726e 696e 6728 2760 5465 6e73 6f72  warning('`Tensor
-0002a6a0: 2e7b 617d 6020 6973 2061 6e20 696e 2d70  .{a}` is an in-p
-0002a6b0: 6c61 6365 206f 7065 7261 7469 6f6e 2061  lace operation a
-0002a6c0: 6e64 2022 782e 7b61 7d28 2922 2069 7320  nd "x.{a}()" is 
-0002a6d0: 6e6f 7420 656e 636f 7572 6167 6564 2074  not encouraged t
-0002a6e0: 6f20 7573 6520 696e 204d 696e 6453 706f  o use in MindSpo
-0002a6f0: 7265 2e20 2720 5c0a 2020 2020 2020 2020  re. ' \.        
-0002a700: 2020 2020 2750 6c65 6173 6520 7573 6520      'Please use 
-0002a710: 2278 203d 2078 2e7b 627d 2829 2220 6f72  "x = x.{b}()" or
-0002a720: 206f 7468 6572 2041 5049 2069 6e73 7465   other API inste
-0002a730: 6164 2e27 2e66 6f72 6d61 7428 613d 6f70  ad.'.format(a=op
-0002a740: 5f6e 616d 652c 2062 3d72 6570 6c61 6365  _name, b=replace
-0002a750: 5f6f 7029 290a 2020 2020 756e 7375 7070  _op)).    unsupp
-0002a760: 6f72 7465 645f 6174 7472 286f 705f 6e61  orted_attr(op_na
-0002a770: 6d65 290a 2020 2020 756e 7375 7070 6f72  me).    unsuppor
-0002a780: 7465 645f 6174 7472 2872 6570 6c61 6365  ted_attr(replace
-0002a790: 5f6f 7029 0a20 2020 2023 2050 6173 7320  _op).    # Pass 
-0002a7a0: 6063 6173 745f 746f 5f6d 735f 7465 6e73  `cast_to_ms_tens
-0002a7b0: 6f72 286f 7574 7075 7429 6020 666f 7220  or(output)` for 
-0002a7c0: 7065 7266 6f72 6d61 6e63 652c 2061 6464  performance, add
-0002a7d0: 2069 7420 6261 636b 2077 6865 6e20 6e65   it back when ne
-0002a7e0: 6564 6564 2e0a 2020 2020 696e 7075 742e  eded..    input.
-0002a7f0: 6173 7369 676e 5f76 616c 7565 286f 7574  assign_value(out
-0002a800: 7075 7429 0a20 2020 2072 6574 7572 6e20  put).    return 
-0002a810: 696e 7075 740a 0a64 6566 205f 6761 6d6d  input..def _gamm
-0002a820: 615f 7479 7065 2869 6e70 7574 5f6d 732c  a_type(input_ms,
-0002a830: 206f 7468 6572 5f6d 7329 3a0a 2020 2020   other_ms):.    
-0002a840: 696e 7075 745f 7479 7065 203d 2069 6e70  input_type = inp
-0002a850: 7574 5f6d 732e 6474 7970 650a 2020 2020  ut_ms.dtype.    
-0002a860: 6f74 6865 725f 7479 7065 203d 206f 7468  other_type = oth
-0002a870: 6572 5f6d 732e 6474 7970 650a 2020 2020  er_ms.dtype.    
-0002a880: 666c 6f61 745f 666c 6167 203d 2046 616c  float_flag = Fal
-0002a890: 7365 0a20 2020 2069 6620 696e 7075 745f  se.    if input_
-0002a8a0: 7479 7065 203d 3d20 6d73 2e66 6c6f 6174  type == ms.float
-0002a8b0: 3634 206f 7220 6f74 6865 725f 7479 7065  64 or other_type
-0002a8c0: 203d 3d20 6d73 2e66 6c6f 6174 3634 3a0a   == ms.float64:.
-0002a8d0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
-0002a8e0: 203d 2069 6e70 7574 5f6d 732e 6173 7479   = input_ms.asty
-0002a8f0: 7065 286d 732e 666c 6f61 7436 3429 0a20  pe(ms.float64). 
-0002a900: 2020 2020 2020 206f 7468 6572 5f6d 7320         other_ms 
-0002a910: 3d20 6f74 6865 725f 6d73 2e61 7374 7970  = other_ms.astyp
-0002a920: 6528 6d73 2e66 6c6f 6174 3634 290a 2020  e(ms.float64).  
-0002a930: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
-0002a940: 6966 2069 6e70 7574 5f74 7970 6520 3d3d  if input_type ==
-0002a950: 206d 732e 666c 6f61 7431 3620 616e 6420   ms.float16 and 
-0002a960: 6f74 6865 725f 7479 7065 203d 3d20 6d73  other_type == ms
-0002a970: 2e66 6c6f 6174 3136 3a0a 2020 2020 2020  .float16:.      
-0002a980: 2020 2020 2020 666c 6f61 745f 666c 6167        float_flag
-0002a990: 203d 2054 7275 650a 2020 2020 2020 2020   = True.        
-0002a9a0: 696e 7075 745f 6d73 203d 2069 6e70 7574  input_ms = input
-0002a9b0: 5f6d 732e 6173 7479 7065 286d 732e 666c  _ms.astype(ms.fl
-0002a9c0: 6f61 7433 3229 0a20 2020 2020 2020 206f  oat32).        o
-0002a9d0: 7468 6572 5f6d 7320 3d20 6f74 6865 725f  ther_ms = other_
-0002a9e0: 6d73 2e61 7374 7970 6528 6d73 2e66 6c6f  ms.astype(ms.flo
-0002a9f0: 6174 3332 290a 2020 2020 7265 7475 726e  at32).    return
-0002aa00: 2069 6e70 7574 5f6d 732c 206f 7468 6572   input_ms, other
-0002aa10: 5f6d 732c 2066 6c6f 6174 5f66 6c61 670a  _ms, float_flag.
-0002aa20: 0a64 6566 205f 6c75 5f66 6163 746f 7228  .def _lu_factor(
-0002aa30: 412c 202a 2c20 7069 766f 743d 5472 7565  A, *, pivot=True
-0002aa40: 293a 0a20 2020 2023 544f 444f 3a20 4d69  ):.    #TODO: Mi
-0002aa50: 6e64 7370 6f72 6520 646f 6573 206e 6f74  ndspore does not
-0002aa60: 2073 7570 706f 7274 2070 6976 6f74 3d46   support pivot=F
-0002aa70: 616c 7365 2063 6f6e 6469 7469 6f6e 0a20  alse condition. 
-0002aa80: 2020 2069 6620 6e6f 7420 7069 766f 743a     if not pivot:
-0002aa90: 0a20 2020 2020 2020 2072 6169 7365 204e  .        raise N
-0002aaa0: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
-0002aab0: 6f72 2822 6c75 2063 7572 7265 6e74 6c79  or("lu currently
-0002aac0: 206e 6f74 2073 7570 706f 7274 6564 2070   not supported p
-0002aad0: 6976 6f74 3d46 616c 7365 2229 0a20 2020  ivot=False").   
-0002aae0: 2069 6e6e 6572 5f6c 755f 6661 6374 6f72   inner_lu_factor
-0002aaf0: 5f6f 7020 3d20 6e75 6d70 795f 6365 6c6c  _op = numpy_cell
-0002ab00: 2e4e 756d 7079 4c55 4661 6374 6f72 2827  .NumpyLUFactor('
-0002ab10: 6c75 2729 0a20 2020 206f 7574 7075 7420  lu').    output 
-0002ab20: 3d20 696e 6e65 725f 6c75 5f66 6163 746f  = inner_lu_facto
-0002ab30: 725f 6f70 2841 290a 2020 2020 7265 7475  r_op(A).    retu
-0002ab40: 726e 206f 7574 7075 740a 0a64 6566 205f  rn output..def _
-0002ab50: 6c75 5f66 6163 746f 725f 6578 2841 2c20  lu_factor_ex(A, 
-0002ab60: 2a2c 2070 6976 6f74 3d54 7275 6529 3a0a  *, pivot=True):.
-0002ab70: 2020 2020 2354 4f44 4f3a 204d 696e 6473      #TODO: Minds
-0002ab80: 706f 7265 2064 6f65 7320 6e6f 7420 7375  pore does not su
-0002ab90: 7070 6f72 7420 7069 766f 743d 4661 6c73  pport pivot=Fals
-0002aba0: 6520 636f 6e64 6974 696f 6e0a 2020 2020  e condition.    
-0002abb0: 6966 206e 6f74 2070 6976 6f74 3a0a 2020  if not pivot:.  
-0002abc0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
-0002abd0: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
-0002abe0: 226c 7520 6375 7272 656e 746c 7920 6e6f  "lu currently no
-0002abf0: 7420 7375 7070 6f72 7465 6420 7069 766f  t supported pivo
-0002ac00: 743d 4661 6c73 6522 290a 2020 2020 696e  t=False").    in
-0002ac10: 6e65 725f 6c75 5f66 6163 746f 725f 6f70  ner_lu_factor_op
-0002ac20: 203d 206e 756d 7079 5f63 656c 6c2e 4e75   = numpy_cell.Nu
-0002ac30: 6d70 794c 5546 6163 746f 7228 276c 7527  mpyLUFactor('lu'
-0002ac40: 290a 2020 2020 6f75 7470 7574 203d 2069  ).    output = i
-0002ac50: 6e6e 6572 5f6c 755f 6661 6374 6f72 5f6f  nner_lu_factor_o
-0002ac60: 7028 4129 0a20 2020 2069 6e66 6f20 3d20  p(A).    info = 
-0002ac70: 300a 2020 2020 7265 7475 726e 206f 7574  0.    return out
-0002ac80: 7075 742c 2069 6e66 6f0a                 put, info.
+00024e70: 735f 6e65 6728 7365 6c66 293a 0a20 2020  s_neg(self):.   
+00024e80: 2020 2020 2069 6620 6e6f 7420 6861 7361       if not hasa
+00024e90: 7474 7228 7365 6c66 2c20 226e 6567 5f62  ttr(self, "neg_b
+00024ea0: 6974 2229 3a0a 2020 2020 2020 2020 2020  it"):.          
+00024eb0: 2020 7265 7475 726e 2046 616c 7365 0a20    return False. 
+00024ec0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00024ed0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00024ee0: 7365 6c66 2e6e 6567 5f62 6974 0a0a 2020  self.neg_bit..  
+00024ef0: 2020 6465 6620 7265 736f 6c76 655f 6e65    def resolve_ne
+00024f00: 6728 7365 6c66 293a 0a20 2020 2020 2020  g(self):.       
+00024f10: 206f 7574 7075 7420 3d20 6465 6570 636f   output = deepco
+00024f20: 7079 2873 656c 6629 0a20 2020 2020 2020  py(self).       
+00024f30: 206f 7574 7075 742e 6e65 675f 6269 7420   output.neg_bit 
+00024f40: 3d20 4661 6c73 650a 2020 2020 2020 2020  = False.        
+00024f50: 7265 7475 726e 206f 7574 7075 740a 0a20  return output.. 
+00024f60: 2020 2023 544f 444f 3a20 7069 6e76 2063     #TODO: pinv c
+00024f70: 7572 7265 6e74 6c79 206e 6f74 2073 7570  urrently not sup
+00024f80: 706f 7274 206f 6e20 4173 6365 6e64 0a20  port on Ascend. 
+00024f90: 2020 2064 6566 2070 696e 7665 7273 6528     def pinverse(
+00024fa0: 7365 6c66 2c20 7263 6f6e 643d 3165 2d31  self, rcond=1e-1
+00024fb0: 3529 3a0a 2020 2020 2020 2020 6966 2069  5):.        if i
+00024fc0: 735f 756e 6465 725f 6173 6365 6e64 5f63  s_under_ascend_c
+00024fd0: 6f6e 7465 7874 2829 3a0a 2020 2020 2020  ontext():.      
+00024fe0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+00024ff0: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+00025000: 2270 696e 7665 7273 6520 6375 7272 656e  "pinverse curren
+00025010: 746c 7920 6e6f 7420 7375 7070 6f72 7465  tly not supporte
+00025020: 6420 6f6e 2041 7363 656e 6422 290a 2020  d on Ascend").  
+00025030: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00025040: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00025050: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00025060: 206f 7574 7075 7420 3d20 6d73 2e6f 7073   output = ms.ops
+00025070: 2e70 696e 7628 696e 7075 745f 6d73 2c20  .pinv(input_ms, 
+00025080: 7274 6f6c 3d72 636f 6e64 290a 2020 2020  rtol=rcond).    
+00025090: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+000250a0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+000250b0: 7228 6f75 7470 7574 290a 0a20 2020 2023  r(output)..    #
+000250c0: 544f 444f 3a20 6e65 6564 2074 6f20 7573  TODO: need to us
+000250d0: 6520 6f70 7320 6675 6e63 0a20 2020 2064  e ops func.    d
+000250e0: 6566 2073 796d 6569 6728 7365 6c66 2c20  ef symeig(self, 
+000250f0: 6569 6765 6e76 6563 746f 7273 3d46 616c  eigenvectors=Fal
+00025100: 7365 2c20 7570 7065 723d 5472 7565 293a  se, upper=True):
+00025110: 0a20 2020 2020 2020 2073 796d 6569 675f  .        symeig_
+00025120: 6f70 203d 206e 756d 7079 5f63 656c 6c2e  op = numpy_cell.
+00025130: 4e75 6d70 7945 6967 6828 2773 796d 6569  NumpyEigh('symei
+00025140: 6727 290a 2020 2020 2020 2020 6966 2065  g').        if e
+00025150: 6967 656e 7665 6374 6f72 733a 0a20 2020  igenvectors:.   
+00025160: 2020 2020 2020 2020 2076 616c 7565 732c           values,
+00025170: 2076 6563 746f 7273 203d 2073 796d 6569   vectors = symei
+00025180: 675f 6f70 2873 656c 662c 206c 6f77 6572  g_op(self, lower
+00025190: 3d6e 6f74 2075 7070 6572 2c20 6569 6776  =not upper, eigv
+000251a0: 616c 735f 6f6e 6c79 3d46 616c 7365 290a  als_only=False).
+000251b0: 2020 2020 2020 2020 656c 7365 3a0a 2020          else:.  
+000251c0: 2020 2020 2020 2020 2020 7661 6c75 6573            values
+000251d0: 203d 2073 796d 6569 675f 6f70 2873 656c   = symeig_op(sel
+000251e0: 662c 206c 6f77 6572 3d6e 6f74 2075 7070  f, lower=not upp
+000251f0: 6572 2c20 6569 6776 616c 735f 6f6e 6c79  er, eigvals_only
+00025200: 3d54 7275 6529 0a20 2020 2020 2020 2020  =True).         
+00025210: 2020 2076 6563 746f 7273 203d 2067 6574     vectors = get
+00025220: 5f65 6d70 7479 5f74 656e 736f 7228 290a  _empty_tensor().
+00025230: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00025240: 2028 7661 6c75 6573 2c20 7665 6374 6f72   (values, vector
+00025250: 7329 0a20 2020 2020 2020 2069 6620 7079  s).        if py
+00025260: 6e61 7469 7665 5f6d 6f64 655f 636f 6e64  native_mode_cond
+00025270: 6974 696f 6e28 293a 0a20 2020 2020 2020  ition():.       
+00025280: 2020 2020 2073 796d 6569 675f 6e61 6d65       symeig_name
+00025290: 6474 7570 6c65 203d 2073 6574 5f6d 756c  dtuple = set_mul
+000252a0: 7469 706c 655f 6e61 6d65 5f74 7570 6c65  tiple_name_tuple
+000252b0: 2827 7379 6d65 6967 272c 2027 6569 6765  ('symeig', 'eige
+000252c0: 6e76 616c 7565 732c 2065 6967 656e 7665  nvalues, eigenve
+000252d0: 6374 6f72 7327 290a 2020 2020 2020 2020  ctors').        
+000252e0: 2020 2020 6966 2076 616c 7565 732e 6474      if values.dt
+000252f0: 7970 6520 696e 2028 6d73 2e63 6f6d 706c  ype in (ms.compl
+00025300: 6578 3634 2c20 6d73 2e63 6f6d 706c 6578  ex64, ms.complex
+00025310: 3132 3829 3a0a 2020 2020 2020 2020 2020  128):.          
+00025320: 2020 2020 2020 7661 6c75 6573 203d 2076        values = v
+00025330: 616c 7565 732e 7265 616c 2829 0a20 2020  alues.real().   
+00025340: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00025350: 3d20 7379 6d65 6967 5f6e 616d 6564 7475  = symeig_namedtu
+00025360: 706c 6528 6361 7374 5f74 6f5f 6164 6170  ple(cast_to_adap
+00025370: 7465 725f 7465 6e73 6f72 2876 616c 7565  ter_tensor(value
+00025380: 7329 2c20 6361 7374 5f74 6f5f 6164 6170  s), cast_to_adap
+00025390: 7465 725f 7465 6e73 6f72 2876 6563 746f  ter_tensor(vecto
+000253a0: 7273 2929 0a20 2020 2020 2020 2020 2020  rs)).           
+000253b0: 2072 6574 7572 6e20 6f75 7470 7574 0a20   return output. 
+000253c0: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+000253d0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+000253e0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+000253f0: 2020 6465 6620 6e61 6e5f 746f 5f6e 756d    def nan_to_num
+00025400: 2873 656c 662c 206e 616e 3d30 2e30 2c20  (self, nan=0.0, 
+00025410: 706f 7369 6e66 3d4e 6f6e 652c 206e 6567  posinf=None, neg
+00025420: 696e 663d 4e6f 6e65 293a 0a20 2020 2020  inf=None):.     
+00025430: 2020 2023 2054 4f44 4f3a 206d 732e 6f70     # TODO: ms.op
+00025440: 732e 6e61 6e5f 746f 5f6e 756d 2074 6f20  s.nan_to_num to 
+00025450: 7375 7070 6f72 7420 666c 6f61 7436 3420  support float64 
+00025460: 696e 7075 740a 2020 2020 2020 2020 696e  input.        in
+00025470: 7075 745f 6d73 203d 2063 6173 745f 746f  put_ms = cast_to
+00025480: 5f6d 735f 7465 6e73 6f72 2873 656c 6629  _ms_tensor(self)
+00025490: 0a20 2020 2020 2020 2023 544f 444f 3a20  .        #TODO: 
+000254a0: 322e 3120 6e6f 7420 7375 7070 6f72 7420  2.1 not support 
+000254b0: 6e65 6769 6e66 2f70 6f73 696e 6620 696e  neginf/posinf in
+000254c0: 7420 696e 7075 740a 2020 2020 2020 2020  t input.        
+000254d0: 6966 206e 6567 696e 6620 6973 206e 6f74  if neginf is not
+000254e0: 204e 6f6e 653a 0a20 2020 2020 2020 2020   None:.         
+000254f0: 2020 206e 6567 696e 6620 3d20 666c 6f61     neginf = floa
+00025500: 7428 6e65 6769 6e66 290a 2020 2020 2020  t(neginf).      
+00025510: 2020 6966 2070 6f73 696e 6620 6973 206e    if posinf is n
+00025520: 6f74 204e 6f6e 653a 0a20 2020 2020 2020  ot None:.       
+00025530: 2020 2020 2070 6f73 696e 6620 3d20 666c       posinf = fl
+00025540: 6f61 7428 706f 7369 6e66 290a 2020 2020  oat(posinf).    
+00025550: 2020 2020 696e 7075 745f 6474 7970 6520      input_dtype 
+00025560: 3d20 696e 7075 745f 6d73 2e64 7479 7065  = input_ms.dtype
+00025570: 0a20 2020 2020 2020 2069 6620 6973 5f75  .        if is_u
+00025580: 6e64 6572 5f67 7075 5f63 6f6e 7465 7874  nder_gpu_context
+00025590: 2829 206f 7220 696e 7075 745f 6474 7970  () or input_dtyp
+000255a0: 6520 3d3d 206d 7374 7970 652e 666c 6f61  e == mstype.floa
+000255b0: 7436 343a 0a20 2020 2020 2020 2020 2020  t64:.           
+000255c0: 206f 7574 7075 7420 3d20 696e 7075 745f   output = input_
+000255d0: 6d73 2e6d 6173 6b65 645f 6669 6c6c 2869  ms.masked_fill(i
+000255e0: 6e70 7574 5f6d 732e 6973 6e61 6e28 292c  nput_ms.isnan(),
+000255f0: 206e 616e 290a 2020 2020 2020 2020 2020   nan).          
+00025600: 2020 6966 2069 6e70 7574 5f6d 732e 6474    if input_ms.dt
+00025610: 7970 6520 696e 2061 6c6c 5f69 6e74 5f74  ype in all_int_t
+00025620: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
+00025630: 2020 2020 2069 6e70 7574 5f64 7479 7065       input_dtype
+00025640: 203d 2069 6e70 7574 5f6d 732e 6474 7970   = input_ms.dtyp
+00025650: 650a 2020 2020 2020 2020 2020 2020 2020  e.              
+00025660: 2020 6966 2070 6f73 696e 6620 6973 204e    if posinf is N
+00025670: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+00025680: 2020 2020 2020 2020 2070 6f73 696e 6620           posinf 
+00025690: 3d20 6969 6e66 6f28 696e 7075 745f 6d73  = iinfo(input_ms
+000256a0: 2e64 7479 7065 292e 6d61 780a 2020 2020  .dtype).max.    
+000256b0: 2020 2020 2020 2020 2020 2020 6966 206e              if n
+000256c0: 6567 696e 6620 6973 204e 6f6e 653a 0a20  eginf is None:. 
+000256d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000256e0: 2020 206e 6567 696e 6620 3d20 6969 6e66     neginf = iinf
+000256f0: 6f28 696e 7075 745f 6d73 2e64 7479 7065  o(input_ms.dtype
+00025700: 292e 6d69 6e0a 2020 2020 2020 2020 2020  ).min.          
+00025710: 2020 2020 2020 6f75 7470 7574 203d 206f        output = o
+00025720: 7574 7075 742e 6173 7479 7065 286d 732e  utput.astype(ms.
+00025730: 666c 6f61 7433 3229 0a20 2020 2020 2020  float32).       
+00025740: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00025750: 3d20 6f75 7470 7574 2e6d 6173 6b65 645f  = output.masked_
+00025760: 6669 6c6c 286f 7574 7075 742e 6973 6e65  fill(output.isne
+00025770: 6769 6e66 2829 2c20 6e65 6769 6e66 290a  ginf(), neginf).
+00025780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00025790: 6f75 7470 7574 203d 206f 7574 7075 742e  output = output.
+000257a0: 6d61 736b 6564 5f66 696c 6c28 6f75 7470  masked_fill(outp
+000257b0: 7574 2e69 7370 6f73 696e 6628 292c 2070  ut.isposinf(), p
+000257c0: 6f73 696e 6629 2e61 7374 7970 6528 696e  osinf).astype(in
+000257d0: 7075 745f 6474 7970 6529 0a20 2020 2020  put_dtype).     
+000257e0: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+000257f0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00025800: 706f 7369 6e66 2069 7320 4e6f 6e65 3a0a  posinf is None:.
+00025810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00025820: 2020 2020 706f 7369 6e66 203d 2066 696e      posinf = fin
+00025830: 666f 2869 6e70 7574 5f6d 732e 6474 7970  fo(input_ms.dtyp
+00025840: 6529 2e6d 6178 0a20 2020 2020 2020 2020  e).max.         
+00025850: 2020 2020 2020 2069 6620 6e65 6769 6e66         if neginf
+00025860: 2069 7320 4e6f 6e65 3a0a 2020 2020 2020   is None:.      
+00025870: 2020 2020 2020 2020 2020 2020 2020 6e65                ne
+00025880: 6769 6e66 203d 2066 696e 666f 2869 6e70  ginf = finfo(inp
+00025890: 7574 5f6d 732e 6474 7970 6529 2e6d 696e  ut_ms.dtype).min
+000258a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000258b0: 206f 7574 7075 7420 3d20 6f75 7470 7574   output = output
+000258c0: 2e6d 6173 6b65 645f 6669 6c6c 286f 7574  .masked_fill(out
+000258d0: 7075 742e 6973 6e65 6769 6e66 2829 2c20  put.isneginf(), 
+000258e0: 6e65 6769 6e66 290a 2020 2020 2020 2020  neginf).        
+000258f0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00025900: 206f 7574 7075 742e 6d61 736b 6564 5f66   output.masked_f
+00025910: 696c 6c28 6f75 7470 7574 2e69 7370 6f73  ill(output.ispos
+00025920: 696e 6628 292c 2070 6f73 696e 6629 0a20  inf(), posinf). 
+00025930: 2020 2020 2020 2065 6c69 6620 696e 7075         elif inpu
+00025940: 745f 6474 7970 6520 696e 2061 6c6c 5f69  t_dtype in all_i
+00025950: 6e74 5f74 7970 653a 0a20 2020 2020 2020  nt_type:.       
+00025960: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00025970: 696e 7075 745f 6d73 2e61 7374 7970 6528  input_ms.astype(
+00025980: 6d73 2e66 6c6f 6174 3332 290a 2020 2020  ms.float32).    
+00025990: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000259a0: 206d 732e 6f70 732e 6e61 6e5f 746f 5f6e   ms.ops.nan_to_n
+000259b0: 756d 2869 6e70 7574 5f6d 732c 206e 616e  um(input_ms, nan
+000259c0: 3d6e 616e 2c20 706f 7369 6e66 3d70 6f73  =nan, posinf=pos
+000259d0: 696e 662c 206e 6567 696e 663d 6e65 6769  inf, neginf=negi
+000259e0: 6e66 290a 2020 2020 2020 2020 2020 2020  nf).            
+000259f0: 6f75 7470 7574 203d 206f 7574 7075 742e  output = output.
+00025a00: 6173 7479 7065 2869 6e70 7574 5f64 7479  astype(input_dty
+00025a10: 7065 290a 2020 2020 2020 2020 656c 7365  pe).        else
+00025a20: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
+00025a30: 7470 7574 203d 206d 732e 6f70 732e 6e61  tput = ms.ops.na
+00025a40: 6e5f 746f 5f6e 756d 2869 6e70 7574 5f6d  n_to_num(input_m
+00025a50: 732c 206e 616e 3d6e 616e 2c20 706f 7369  s, nan=nan, posi
+00025a60: 6e66 3d70 6f73 696e 662c 206e 6567 696e  nf=posinf, negin
+00025a70: 663d 6e65 6769 6e66 290a 2020 2020 2020  f=neginf).      
+00025a80: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+00025a90: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+00025aa0: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+00025ab0: 206e 616e 5f74 6f5f 6e75 6d5f 2873 656c   nan_to_num_(sel
+00025ac0: 662c 206e 616e 3d30 2e30 2c20 706f 7369  f, nan=0.0, posi
+00025ad0: 6e66 3d4e 6f6e 652c 206e 6567 696e 663d  nf=None, neginf=
+00025ae0: 4e6f 6e65 293a 0a20 2020 2020 2020 2023  None):.        #
+00025af0: 2054 4f44 4f3a 206d 732e 6f70 732e 6e61   TODO: ms.ops.na
+00025b00: 6e5f 746f 5f6e 756d 2074 6f20 7375 7070  n_to_num to supp
+00025b10: 6f72 7420 666c 6f61 7436 3420 696e 7075  ort float64 inpu
+00025b20: 740a 2020 2020 2020 2020 6f75 7470 7574  t.        output
+00025b30: 203d 2073 656c 662e 6e61 6e5f 746f 5f6e   = self.nan_to_n
+00025b40: 756d 286e 616e 3d6e 616e 2c20 706f 7369  um(nan=nan, posi
+00025b50: 6e66 3d70 6f73 696e 662c 206e 6567 696e  nf=posinf, negin
+00025b60: 663d 6e65 6769 6e66 290a 2020 2020 2020  f=neginf).      
+00025b70: 2020 7265 7475 726e 205f 7465 6e73 6f72    return _tensor
+00025b80: 5f69 6e70 6c61 6365 5f61 7373 6967 6e28  _inplace_assign(
+00025b90: 7365 6c66 2c20 6f75 7470 7574 2c20 226e  self, output, "n
+00025ba0: 616e 5f74 6f5f 6e75 6d5f 222c 2022 6e61  an_to_num_", "na
+00025bb0: 6e5f 746f 5f6e 756d 2229 0a0a 2020 2020  n_to_num")..    
+00025bc0: 6465 6620 7075 745f 2873 656c 662c 2069  def put_(self, i
+00025bd0: 6e64 6578 2c20 736f 7572 6365 2c20 6163  ndex, source, ac
+00025be0: 6375 6d75 6c61 7465 3d46 616c 7365 293a  cumulate=False):
+00025bf0: 0a20 2020 2020 2020 2023 2054 4f44 4f3a  .        # TODO:
+00025c00: 2064 6f65 7320 6e6f 7420 7375 7070 6f72   does not suppor
+00025c10: 7420 4752 4150 4820 4d4f 4445 0a20 2020  t GRAPH MODE.   
+00025c20: 2020 2020 2023 2053 6361 7474 6572 5570       # ScatterUp
+00025c30: 6461 7465 2074 616b 6573 206f 6e6c 7920  date takes only 
+00025c40: 5061 7261 6d65 7465 7220 6f62 6a65 6374  Parameter object
+00025c50: 2061 7320 696e 7075 740a 2020 2020 2020   as input.      
+00025c60: 2020 2320 6275 7420 5061 7261 6d65 7465    # but Paramete
+00025c70: 7220 6f62 6a65 6374 2063 616e 2774 2062  r object can't b
+00025c80: 6520 6372 6561 7465 6420 696e 2063 6f6e  e created in con
+00025c90: 7374 7275 6374 2066 756e 6320 696e 2067  struct func in g
+00025ca0: 7261 7068 206d 6f64 650a 2020 2020 2020  raph mode.      
+00025cb0: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+00025cc0: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+00025cd0: 656c 6629 0a20 2020 2020 2020 2069 6e64  elf).        ind
+00025ce0: 6578 203d 2063 6173 745f 746f 5f6d 735f  ex = cast_to_ms_
+00025cf0: 7465 6e73 6f72 2869 6e64 6578 290a 2020  tensor(index).  
+00025d00: 2020 2020 2020 736f 7572 6365 203d 2063        source = c
+00025d10: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00025d20: 2873 6f75 7263 6529 0a20 2020 2020 2020  (source).       
+00025d30: 2069 6e70 7574 5f73 6861 7065 203d 2073   input_shape = s
+00025d40: 656c 662e 7368 6170 650a 2020 2020 2020  elf.shape.      
+00025d50: 2020 696e 7075 745f 7479 7065 203d 2073    input_type = s
+00025d60: 656c 662e 6474 7970 650a 2020 2020 2020  elf.dtype.      
+00025d70: 2020 696e 7075 745f 6d73 203d 2069 6e70    input_ms = inp
+00025d80: 7574 5f6d 732e 666c 6174 7465 6e28 290a  ut_ms.flatten().
+00025d90: 2020 2020 2020 2020 696e 6465 7820 3d20          index = 
+00025da0: 696e 6465 782e 666c 6174 7465 6e28 290a  index.flatten().
+00025db0: 2020 2020 2020 2020 736f 7572 6365 203d          source =
+00025dc0: 2073 6f75 7263 652e 666c 6174 7465 6e28   source.flatten(
+00025dd0: 290a 0a20 2020 2020 2020 2069 6620 6973  )..        if is
+00025de0: 5f75 6e64 6572 5f61 7363 656e 645f 636f  _under_ascend_co
+00025df0: 6e74 6578 7428 2920 616e 6420 696e 7075  ntext() and inpu
+00025e00: 745f 6d73 2e64 7479 7065 2069 6e20 6d69  t_ms.dtype in mi
+00025e10: 6e64 746f 7263 685f 6474 7970 652e 616c  ndtorch_dtype.al
+00025e20: 6c5f 696e 745f 7479 7065 3a0a 2020 2020  l_int_type:.    
+00025e30: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00025e40: 203d 2069 6e70 7574 5f6d 732e 6173 7479   = input_ms.asty
+00025e50: 7065 286d 732e 666c 6f61 7433 3229 0a20  pe(ms.float32). 
+00025e60: 2020 2020 2020 2020 2020 2073 6f75 7263             sourc
+00025e70: 6520 3d20 736f 7572 6365 2e61 7374 7970  e = source.astyp
+00025e80: 6528 6d73 2e66 6c6f 6174 3332 290a 0a20  e(ms.float32).. 
+00025e90: 2020 2020 2020 2023 2062 6568 6176 696f         # behavio
+00025ea0: 7220 6973 2075 6e64 6566 696e 6564 2077  r is undefined w
+00025eb0: 6865 6e20 6163 6375 6d75 6c61 7465 3d46  hen accumulate=F
+00025ec0: 616c 7365 2061 6e64 2069 6e64 6578 2063  alse and index c
+00025ed0: 6f6e 7461 696e 2064 7570 6c69 6361 7465  ontain duplicate
+00025ee0: 2065 6c65 6d65 6e74 732c 2073 616d 6520   elements, same 
+00025ef0: 6173 2074 6f72 6368 0a20 2020 2020 2020  as torch.       
+00025f00: 2069 6620 6163 6375 6d75 6c61 7465 2069   if accumulate i
+00025f10: 7320 4661 6c73 653a 0a20 2020 2020 2020  s False:.       
+00025f20: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+00025f30: 2e6f 7073 2e73 6361 7474 6572 5f75 7064  .ops.scatter_upd
+00025f40: 6174 6528 696e 7075 745f 6d73 2c20 696e  ate(input_ms, in
+00025f50: 6465 782c 2073 6f75 7263 6529 2e72 6573  dex, source).res
+00025f60: 6861 7065 2869 6e70 7574 5f73 6861 7065  hape(input_shape
+00025f70: 292e 6173 7479 7065 2869 6e70 7574 5f74  ).astype(input_t
+00025f80: 7970 6529 0a20 2020 2020 2020 2065 6c73  ype).        els
+00025f90: 653a 0a20 2020 2020 2020 2020 2020 2023  e:.            #
+00025fa0: 2049 6e64 6578 4164 6420 7375 7070 6f72   IndexAdd suppor
+00025fb0: 7473 206f 6e6c 7920 466c 6f61 7431 3620  ts only Float16 
+00025fc0: 466c 6f61 7433 3220 466c 6f61 7436 3420  Float32 Float64 
+00025fd0: 496e 7431 3620 496e 7433 3220 496e 7438  Int16 Int32 Int8
+00025fe0: 2055 496e 7438 2069 6e70 7574 2061 6e64   UInt8 input and
+00025ff0: 2049 6e74 3332 2069 6e64 6578 0a20 2020   Int32 index.   
+00026000: 2020 2020 2020 2020 2069 6e64 6578 203d           index =
+00026010: 2069 6e64 6578 2e61 7374 7970 6528 6d73   index.astype(ms
+00026020: 7479 7065 2e69 6e74 3332 290a 2020 2020  type.int32).    
+00026030: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00026040: 206d 732e 6f70 732e 696e 6465 785f 6164   ms.ops.index_ad
+00026050: 6428 696e 7075 745f 6d73 2e61 7374 7970  d(input_ms.astyp
+00026060: 6528 6d73 7479 7065 2e66 6c6f 6174 3332  e(mstype.float32
+00026070: 292c 2069 6e64 6578 2c20 736f 7572 6365  ), index, source
+00026080: 2c20 3029 205c 0a20 2020 2020 2020 2020  , 0) \.         
+00026090: 2020 2020 2020 202e 7265 7368 6170 6528         .reshape(
+000260a0: 696e 7075 745f 7368 6170 6529 2e61 7374  input_shape).ast
+000260b0: 7970 6528 696e 7075 745f 7479 7065 290a  ype(input_type).
+000260c0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000260d0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+000260e0: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+000260f0: 0a20 2020 2020 2020 2073 656c 662e 6173  .        self.as
+00026100: 7369 676e 5f76 616c 7565 286f 7574 7075  sign_value(outpu
+00026110: 7429 0a20 2020 2020 2020 2072 6574 7572  t).        retur
+00026120: 6e20 7365 6c66 0a0a 2020 2020 6465 6620  n self..    def 
+00026130: 706f 6c79 6761 6d6d 6128 7365 6c66 2c20  polygamma(self, 
+00026140: 6e29 3a0a 2020 2020 2020 2020 6e20 3d20  n):.        n = 
+00026150: 6d73 2e54 656e 736f 7228 6e29 0a20 2020  ms.Tensor(n).   
+00026160: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00026170: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00026180: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00026190: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+000261a0: 706f 6c79 6761 6d6d 6128 6e2c 2069 6e70  polygamma(n, inp
+000261b0: 7574 5f6d 7329 0a20 2020 2020 2020 2072  ut_ms).        r
+000261c0: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+000261d0: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+000261e0: 7075 7429 0a0a 2020 2020 6465 6620 706f  put)..    def po
+000261f0: 6c79 6761 6d6d 615f 2873 656c 662c 206e  lygamma_(self, n
+00026200: 293a 0a20 2020 2020 2020 206f 7574 7075  ):.        outpu
+00026210: 7420 3d20 7365 6c66 2e70 6f6c 7967 616d  t = self.polygam
+00026220: 6d61 286e 290a 2020 2020 2020 2020 7265  ma(n).        re
+00026230: 7475 726e 205f 7465 6e73 6f72 5f69 6e70  turn _tensor_inp
+00026240: 6c61 6365 5f61 7373 6967 6e28 7365 6c66  lace_assign(self
+00026250: 2c20 6f75 7470 7574 2c20 2270 6f6c 7967  , output, "polyg
+00026260: 616d 6d61 5f22 2c20 2270 6f6c 7967 616d  amma_", "polygam
+00026270: 6d61 2229 0a0a 2020 2020 6465 6620 696e  ma")..    def in
+00026280: 6465 785f 7075 7428 7365 6c66 2c20 696e  dex_put(self, in
+00026290: 6469 6365 732c 2076 616c 7565 732c 2061  dices, values, a
+000262a0: 6363 756d 756c 6174 653d 4661 6c73 6529  ccumulate=False)
+000262b0: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+000262c0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+000262d0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+000262e0: 2020 2020 2069 6e64 6963 6573 203d 2063       indices = c
+000262f0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+00026300: 2869 6e64 6963 6573 290a 2020 2020 2020  (indices).      
+00026310: 2020 7661 6c75 6573 203d 2063 6173 745f    values = cast_
+00026320: 746f 5f6d 735f 7465 6e73 6f72 2876 616c  to_ms_tensor(val
+00026330: 7565 7329 0a20 2020 2020 2020 2066 6f72  ues).        for
+00026340: 2069 6e64 6578 2069 6e20 696e 6469 6365   index in indice
+00026350: 733a 0a20 2020 2020 2020 2020 2020 2069  s:.            i
+00026360: 6620 696e 6465 782e 6e75 6d65 6c28 2920  f index.numel() 
+00026370: 3d3d 2030 3a0a 2020 2020 2020 2020 2020  == 0:.          
+00026380: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00026390: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+000263a0: 736f 7228 696e 7075 745f 6d73 290a 2020  sor(input_ms).  
+000263b0: 2020 2020 2020 2320 544f 444f 3a20 6d73        # TODO: ms
+000263c0: 2e6f 7073 2e69 6e64 6578 5f70 7574 2064  .ops.index_put d
+000263d0: 6f65 7320 6e6f 7420 7375 7070 6f72 7420  oes not support 
+000263e0: 7661 6c75 6573 2069 6e70 7574 2077 6974  values input wit
+000263f0: 6820 7261 6e6b 3e31 0a20 2020 2020 2020  h rank>1.       
+00026400: 2069 6478 203d 206d 732e 6f70 732e 6473   idx = ms.ops.ds
+00026410: 7461 636b 2869 6e64 6963 6573 295b 305d  tack(indices)[0]
+00026420: 0a20 2020 2020 2020 2069 6620 6163 6375  .        if accu
+00026430: 6d75 6c61 7465 2069 7320 4661 6c73 653a  mulate is False:
+00026440: 0a20 2020 2020 2020 2020 2020 206f 7020  .            op 
+00026450: 3d20 6d73 2e6f 7073 2e53 6361 7474 6572  = ms.ops.Scatter
+00026460: 4e64 5570 6461 7465 2829 0a20 2020 2020  NdUpdate().     
+00026470: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00026480: 2020 2020 206f 7020 3d20 6d73 2e6f 7073       op = ms.ops
+00026490: 2e53 6361 7474 6572 4e64 4164 6428 290a  .ScatterNdAdd().
+000264a0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000264b0: 206f 7028 696e 7075 745f 6d73 2c20 6964   op(input_ms, id
+000264c0: 782c 2076 616c 7565 7329 0a20 2020 2020  x, values).     
+000264d0: 2020 2072 6574 7572 6e20 6361 7374 5f74     return cast_t
+000264e0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+000264f0: 286f 7574 7075 7429 0a0a 2020 2020 6465  (output)..    de
+00026500: 6620 696e 6465 785f 7075 745f 2873 656c  f index_put_(sel
+00026510: 662c 2069 6e64 6963 6573 2c20 7661 6c75  f, indices, valu
+00026520: 6573 2c20 6163 6375 6d75 6c61 7465 3d46  es, accumulate=F
+00026530: 616c 7365 293a 0a20 2020 2020 2020 206f  alse):.        o
+00026540: 7574 7075 7420 3d20 7365 6c66 2e69 6e64  utput = self.ind
+00026550: 6578 5f70 7574 2869 6e64 6963 6573 2c20  ex_put(indices, 
+00026560: 7661 6c75 6573 2c20 6163 6375 6d75 6c61  values, accumula
+00026570: 7465 3d61 6363 756d 756c 6174 6529 0a20  te=accumulate). 
+00026580: 2020 2020 2020 2072 6574 7572 6e20 5f74         return _t
+00026590: 656e 736f 725f 696e 706c 6163 655f 6173  ensor_inplace_as
+000265a0: 7369 676e 2873 656c 662c 206f 7574 7075  sign(self, outpu
+000265b0: 742c 2022 696e 6465 785f 7075 745f 222c  t, "index_put_",
+000265c0: 2022 696e 6465 785f 7075 7422 290a 0a20   "index_put").. 
+000265d0: 2020 2064 6566 206c 6f67 6375 6d73 756d     def logcumsum
+000265e0: 6578 7028 7365 6c66 2c20 6469 6d29 3a0a  exp(self, dim):.
+000265f0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00026600: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00026610: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00026620: 2020 206f 7574 7075 7420 3d20 696e 7075     output = inpu
+00026630: 745f 6d73 2e6c 6f67 6375 6d73 756d 6578  t_ms.logcumsumex
+00026640: 7028 6469 6d29 0a20 2020 2020 2020 2072  p(dim).        r
+00026650: 6574 7572 6e20 6361 7374 5f74 6f5f 6164  eturn cast_to_ad
+00026660: 6170 7465 725f 7465 6e73 6f72 286f 7574  apter_tensor(out
+00026670: 7075 7429 0a0a 0a20 2020 2023 544f 444f  put)...    #TODO
+00026680: 3a20 6375 7272 656e 746c 7920 6d69 6e64  : currently mind
+00026690: 7370 6f72 6520 646f 6520 6e6f 7420 7375  spore doe not su
+000266a0: 7070 6f72 7420 6b74 6876 616c 7565 0a20  pport kthvalue. 
+000266b0: 2020 2064 6566 206b 7468 7661 6c75 6528     def kthvalue(
+000266c0: 7365 6c66 2c20 6b2c 2064 696d 3d4e 6f6e  self, k, dim=Non
+000266d0: 652c 206b 6565 7064 696d 3d46 616c 7365  e, keepdim=False
+000266e0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+000266f0: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+00026700: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+00026710: 2020 2020 2020 696e 7075 745f 7479 7065        input_type
+00026720: 203d 2069 6e70 7574 5f6d 732e 6474 7970   = input_ms.dtyp
+00026730: 650a 2020 2020 2020 2020 7479 7065 5f74  e.        type_t
+00026740: 7261 6e73 203d 2046 616c 7365 0a20 2020  rans = False.   
+00026750: 2020 2020 2069 6620 696e 7075 745f 7479       if input_ty
+00026760: 7065 206e 6f74 2069 6e20 286d 732e 666c  pe not in (ms.fl
+00026770: 6f61 7431 362c 206d 732e 666c 6f61 7433  oat16, ms.float3
+00026780: 322c 206d 732e 696e 7433 3229 3a0a 2020  2, ms.int32):.  
+00026790: 2020 2020 2020 2020 2020 7479 7065 5f74            type_t
+000267a0: 7261 6e73 203d 2054 7275 650a 2020 2020  rans = True.    
+000267b0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+000267c0: 203d 2069 6e70 7574 5f6d 732e 6173 7479   = input_ms.asty
+000267d0: 7065 286d 732e 666c 6f61 7433 3229 0a20  pe(ms.float32). 
+000267e0: 2020 2020 2020 2076 616c 7565 732c 2069         values, i
+000267f0: 6e64 6963 6573 203d 206d 732e 6f70 732e  ndices = ms.ops.
+00026800: 746f 706b 2869 6e70 7574 5f6d 732c 206b  topk(input_ms, k
+00026810: 2c20 6469 6d2c 206c 6172 6765 7374 3d46  , dim, largest=F
+00026820: 616c 7365 2c20 736f 7274 6564 3d54 7275  alse, sorted=Tru
+00026830: 6529 0a20 2020 2020 2020 2069 6620 6469  e).        if di
+00026840: 6d20 6973 204e 6f6e 653a 0a20 2020 2020  m is None:.     
+00026850: 2020 2020 2020 2064 696d 203d 2076 616c         dim = val
+00026860: 7565 732e 6e64 696d 2d31 0a20 2020 2020  ues.ndim-1.     
+00026870: 2020 2076 616c 7565 733d 6d73 2e6f 7073     values=ms.ops
+00026880: 2e69 6e64 6578 5f73 656c 6563 7428 7661  .index_select(va
+00026890: 6c75 6573 2c20 6469 6d2c 206d 732e 5465  lues, dim, ms.Te
+000268a0: 6e73 6f72 285b 6b2d 315d 2929 0a20 2020  nsor([k-1])).   
+000268b0: 2020 2020 2069 6e64 6963 6573 3d6d 732e       indices=ms.
+000268c0: 6f70 732e 696e 6465 785f 7365 6c65 6374  ops.index_select
+000268d0: 2869 6e64 6963 6573 2c20 6469 6d2c 206d  (indices, dim, m
+000268e0: 732e 5465 6e73 6f72 285b 6b2d 315d 2929  s.Tensor([k-1]))
+000268f0: 0a20 2020 2020 2020 2076 616c 7565 7320  .        values 
+00026900: 3d20 7661 6c75 6573 2e73 7175 6565 7a65  = values.squeeze
+00026910: 2829 0a20 2020 2020 2020 2069 6e64 6963  ().        indic
+00026920: 6573 203d 2069 6e64 6963 6573 2e73 7175  es = indices.squ
+00026930: 6565 7a65 2829 0a20 2020 2020 2020 2069  eeze().        i
+00026940: 6620 6b65 6570 6469 6d3a 0a20 2020 2020  f keepdim:.     
+00026950: 2020 2020 2020 2076 616c 7565 7320 3d20         values = 
+00026960: 7661 6c75 6573 2e75 6e73 7175 6565 7a65  values.unsqueeze
+00026970: 2864 696d 290a 2020 2020 2020 2020 2020  (dim).          
+00026980: 2020 696e 6469 6365 7320 3d20 696e 6469    indices = indi
+00026990: 6365 732e 756e 7371 7565 657a 6528 6469  ces.unsqueeze(di
+000269a0: 6d29 0a20 2020 2020 2020 2069 6620 7479  m).        if ty
+000269b0: 7065 5f74 7261 6e73 3a0a 2020 2020 2020  pe_trans:.      
+000269c0: 2020 2020 2020 7661 6c75 6573 203d 2076        values = v
+000269d0: 616c 7565 732e 6173 7479 7065 2869 6e70  alues.astype(inp
+000269e0: 7574 5f74 7970 6529 0a20 2020 2020 2020  ut_type).       
+000269f0: 2069 6e64 6963 6573 203d 2069 6e64 6963   indices = indic
+00026a00: 6573 2e61 7374 7970 6528 6d73 2e69 6e74  es.astype(ms.int
+00026a10: 3634 290a 2020 2020 2020 2020 6966 2070  64).        if p
+00026a20: 796e 6174 6976 655f 6d6f 6465 5f63 6f6e  ynative_mode_con
+00026a30: 6469 7469 6f6e 2829 3a0a 2020 2020 2020  dition():.      
+00026a40: 2020 2020 2020 706f 696e 7420 3d20 7365        point = se
+00026a50: 745f 6e61 6d65 5f74 7570 6c65 2827 6b74  t_name_tuple('kt
+00026a60: 6876 616c 7565 2729 0a20 2020 2020 2020  hvalue').       
+00026a70: 2020 2020 2072 6c74 203d 2070 6f69 6e74       rlt = point
+00026a80: 2863 6173 745f 746f 5f61 6461 7074 6572  (cast_to_adapter
+00026a90: 5f74 656e 736f 7228 7661 6c75 6573 292c  _tensor(values),
+00026aa0: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00026ab0: 5f74 656e 736f 7228 696e 6469 6365 7329  _tensor(indices)
+00026ac0: 290a 2020 2020 2020 2020 2020 2020 7265  ).            re
+00026ad0: 7475 726e 2072 6c74 0a20 2020 2020 2020  turn rlt.       
+00026ae0: 2072 6574 7572 6e20 6361 7374 5f74 6f5f   return cast_to_
+00026af0: 6164 6170 7465 725f 7465 6e73 6f72 2876  adapter_tensor(v
+00026b00: 616c 7565 7329 2c20 6361 7374 5f74 6f5f  alues), cast_to_
+00026b10: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
+00026b20: 6e64 6963 6573 290a 0a20 2020 2064 6566  ndices)..    def
+00026b30: 205f 6765 745f 7363 6174 7465 725f 6e64   _get_scatter_nd
+00026b40: 696d 5f69 6e70 7574 2873 656c 662c 2069  im_input(self, i
+00026b50: 6e70 7574 2c20 696e 6465 782c 2073 7263  nput, index, src
+00026b60: 2c20 6469 6d29 3a0a 2020 2020 2020 2020  , dim):.        
+00026b70: 696e 6465 785f 7374 6b20 3d20 2829 0a20  index_stk = (). 
+00026b80: 2020 2020 2020 2066 6f72 2069 2069 6e20         for i in 
+00026b90: 7261 6e67 6528 6c65 6e28 696e 6465 782e  range(len(index.
+00026ba0: 7368 6170 6529 293a 0a20 2020 2020 2020  shape)):.       
+00026bb0: 2020 2020 206e 6577 5f73 6861 7065 3d28       new_shape=(
+00026bc0: 696e 6465 782e 7368 6170 655b 695d 2c29  index.shape[i],)
+00026bd0: 202b 2028 312c 2920 2a20 286c 656e 2869   + (1,) * (len(i
+00026be0: 6e64 6578 2e73 6861 7065 2920 2d20 3120  ndex.shape) - 1 
+00026bf0: 2d20 6929 0a20 2020 2020 2020 2020 2020  - i).           
+00026c00: 2069 6620 6920 3d3d 2064 696d 3a0a 2020   if i == dim:.  
+00026c10: 2020 2020 2020 2020 2020 2020 2020 696e                in
+00026c20: 6465 785f 7374 6b20 3d20 696e 6465 785f  dex_stk = index_
+00026c30: 7374 6b20 2b20 2869 6e64 6578 2e66 6c6f  stk + (index.flo
+00026c40: 6174 2829 2c29 0a20 2020 2020 2020 2020  at(),).         
+00026c50: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00026c60: 2020 2020 2020 2020 2069 6e64 6578 5f73           index_s
+00026c70: 746b 203d 2069 6e64 6578 5f73 746b 202b  tk = index_stk +
+00026c80: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+00026c90: 2020 2028 6d73 2e6f 7073 2e61 7261 6e67     (ms.ops.arang
+00026ca0: 6528 302c 2069 6e64 6578 2e73 6861 7065  e(0, index.shape
+00026cb0: 5b69 5d29 2e66 6c6f 6174 2829 2e72 6573  [i]).float().res
+00026cc0: 6861 7065 286e 6577 5f73 6861 7065 292e  hape(new_shape).
+00026cd0: 6272 6f61 6463 6173 745f 746f 2869 6e64  broadcast_to(ind
+00026ce0: 6578 2e73 6861 7065 292c 290a 2020 2020  ex.shape),).    
+00026cf0: 2020 2020 6e64 5f69 6478 203d 206d 732e      nd_idx = ms.
+00026d00: 6f70 732e 7374 6163 6b28 696e 6465 785f  ops.stack(index_
+00026d10: 7374 6b2c 202d 3129 2e6c 6f6e 6728 290a  stk, -1).long().
+00026d20: 2020 2020 2020 2020 6e64 5f69 6e70 7574          nd_input
+00026d30: 203d 2069 6e70 7574 2e75 6e73 7175 6565   = input.unsquee
+00026d40: 7a65 282d 3129 0a20 2020 2020 2020 206e  ze(-1).        n
+00026d50: 645f 7372 6320 3d20 7372 635b 2e2e 2e2c  d_src = src[...,
+00026d60: 203a 696e 6465 782e 7368 6170 655b 2d32   :index.shape[-2
+00026d70: 5d2c 203a 696e 6465 782e 7368 6170 655b  ], :index.shape[
+00026d80: 2d31 5d5d 2e75 6e73 7175 6565 7a65 282d  -1]].unsqueeze(-
+00026d90: 3129 0a20 2020 2020 2020 2072 6574 7572  1).        retur
+00026da0: 6e20 6e64 5f69 6478 2c20 6e64 5f69 6e70  n nd_idx, nd_inp
+00026db0: 7574 2c20 6e64 5f73 7263 0a0a 2020 2020  ut, nd_src..    
+00026dc0: 6465 6620 7363 6174 7465 725f 7265 6475  def scatter_redu
+00026dd0: 6365 2873 656c 662c 2064 696d 2c20 696e  ce(self, dim, in
+00026de0: 6465 782c 2073 7263 2c20 7265 6475 6365  dex, src, reduce
+00026df0: 2c20 2a2c 2069 6e63 6c75 6465 5f73 656c  , *, include_sel
+00026e00: 663d 5472 7565 293a 0a20 2020 2020 2020  f=True):.       
+00026e10: 2023 2054 4f44 4f3a 2074 6f20 7375 7070   # TODO: to supp
+00026e20: 6f72 7420 7265 6475 6365 3d27 6d65 616e  ort reduce='mean
+00026e30: 270a 2020 2020 2020 2020 6966 2072 6564  '.        if red
+00026e40: 7563 6520 3d3d 2027 6d65 616e 273a 0a20  uce == 'mean':. 
+00026e50: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00026e60: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+00026e70: 7272 6f72 2822 7363 6174 7465 725f 7265  rror("scatter_re
+00026e80: 6475 6365 2063 7572 7265 6e74 6c79 2064  duce currently d
+00026e90: 6f65 736e 2774 2073 7570 706f 7274 2072  oesn't support r
+00026ea0: 6564 7563 653d 3d27 6d65 616e 2722 290a  educe=='mean'").
+00026eb0: 0a20 2020 2020 2020 2069 6e70 7574 203d  .        input =
+00026ec0: 2073 656c 660a 2020 2020 2020 2020 696e   self.        in
+00026ed0: 7075 745f 6d69 6e20 3d20 2d66 6c6f 6174  put_min = -float
+00026ee0: 2827 696e 6627 290a 2020 2020 2020 2020  ('inf').        
+00026ef0: 696e 7075 745f 6d61 7820 3d20 666c 6f61  input_max = floa
+00026f00: 7428 2769 6e66 2729 0a0a 2020 2020 2020  t('inf')..      
+00026f10: 2020 696e 7075 745f 6d73 203d 2063 6173    input_ms = cas
+00026f20: 745f 746f 5f6d 735f 7465 6e73 6f72 2869  t_to_ms_tensor(i
+00026f30: 6e70 7574 290a 2020 2020 2020 2020 696e  nput).        in
+00026f40: 6465 7820 3d20 6361 7374 5f74 6f5f 6d73  dex = cast_to_ms
+00026f50: 5f74 656e 736f 7228 696e 6465 7829 0a20  _tensor(index). 
+00026f60: 2020 2020 2020 2073 7263 203d 2063 6173         src = cas
+00026f70: 745f 746f 5f6d 735f 7465 6e73 6f72 2873  t_to_ms_tensor(s
+00026f80: 7263 290a 0a20 2020 2020 2020 2069 6620  rc)..        if 
+00026f90: 6469 6d20 3e20 303a 0a20 2020 2020 2020  dim > 0:.       
+00026fa0: 2020 2020 206e 645f 6964 782c 206e 645f       nd_idx, nd_
+00026fb0: 696e 7075 742c 206e 645f 7372 6320 3d20  input, nd_src = 
+00026fc0: 7365 6c66 2e5f 6765 745f 7363 6174 7465  self._get_scatte
+00026fd0: 725f 6e64 696d 5f69 6e70 7574 2869 6e70  r_ndim_input(inp
+00026fe0: 7574 5f6d 732c 2069 6e64 6578 2c20 7372  ut_ms, index, sr
+00026ff0: 632c 2064 696d 290a 0a20 2020 2020 2020  c, dim)..       
+00027000: 2069 6620 7265 6475 6365 203d 3d20 2773   if reduce == 's
+00027010: 756d 273a 0a20 2020 2020 2020 2020 2020  um':.           
+00027020: 2069 6620 696e 636c 7564 655f 7365 6c66   if include_self
+00027030: 2069 7320 4661 6c73 653a 0a20 2020 2020   is False:.     
+00027040: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00027050: 5f6d 7320 3d20 696e 7075 745f 6d73 2e73  _ms = input_ms.s
+00027060: 6361 7474 6572 2864 696d 2c20 696e 6465  catter(dim, inde
+00027070: 782c 206d 732e 6f70 732e 7a65 726f 735f  x, ms.ops.zeros_
+00027080: 6c69 6b65 2869 6e64 6578 2c20 6474 7970  like(index, dtyp
+00027090: 653d 696e 7075 745f 6d73 2e64 7479 7065  e=input_ms.dtype
+000270a0: 2929 0a20 2020 2020 2020 2020 2020 2069  )).            i
+000270b0: 6620 6469 6d20 3e20 303a 0a20 2020 2020  f dim > 0:.     
+000270c0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+000270d0: 7420 3d20 6d73 2e6f 7073 2e73 6361 7474  t = ms.ops.scatt
+000270e0: 6572 5f6e 645f 6164 6428 6e64 5f69 6e70  er_nd_add(nd_inp
+000270f0: 7574 2c20 6e64 5f69 6478 2c20 6e64 5f73  ut, nd_idx, nd_s
+00027100: 7263 292e 7371 7565 657a 6528 2d31 290a  rc).squeeze(-1).
+00027110: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00027120: 3a0a 2020 2020 2020 2020 2020 2020 2020  :.              
+00027130: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+00027140: 732e 7363 6174 7465 725f 6164 6428 696e  s.scatter_add(in
+00027150: 7075 745f 6d73 2c20 696e 6465 782c 2073  put_ms, index, s
+00027160: 7263 290a 2020 2020 2020 2020 656c 6966  rc).        elif
+00027170: 2072 6564 7563 6520 3d3d 2027 7072 6f64   reduce == 'prod
+00027180: 273a 0a20 2020 2020 2020 2020 2020 2069  ':.            i
+00027190: 6620 696e 636c 7564 655f 7365 6c66 2069  f include_self i
+000271a0: 7320 4661 6c73 653a 0a20 2020 2020 2020  s False:.       
+000271b0: 2020 2020 2020 2020 2069 6e70 7574 5f6d           input_m
+000271c0: 7320 3d20 696e 7075 745f 6d73 2e73 6361  s = input_ms.sca
+000271d0: 7474 6572 2864 696d 2c20 696e 6465 782c  tter(dim, index,
+000271e0: 206d 732e 6f70 732e 6f6e 6573 5f6c 696b   ms.ops.ones_lik
+000271f0: 6528 696e 6465 782c 2064 7479 7065 3d69  e(index, dtype=i
+00027200: 6e70 7574 5f6d 732e 6474 7970 6529 290a  nput_ms.dtype)).
+00027210: 2020 2020 2020 2020 2020 2020 6966 2064              if d
+00027220: 696d 203e 2030 3a0a 2020 2020 2020 2020  im > 0:.        
+00027230: 2020 2020 2020 2020 2320 544f 444f 3a20          # TODO: 
+00027240: 6d73 2e6f 7073 2e73 6361 7474 6572 5f6e  ms.ops.scatter_n
+00027250: 645f 6d75 6c20 746f 2073 7570 706f 7274  d_mul to support
+00027260: 2041 7363 656e 640a 2020 2020 2020 2020   Ascend.        
+00027270: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00027280: 206d 732e 6f70 732e 7363 6174 7465 725f   ms.ops.scatter_
+00027290: 6e64 5f6d 756c 286e 645f 696e 7075 742c  nd_mul(nd_input,
+000272a0: 206e 645f 6964 782c 206e 645f 7372 6329   nd_idx, nd_src)
+000272b0: 2e73 7175 6565 7a65 282d 3129 0a20 2020  .squeeze(-1).   
+000272c0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+000272d0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+000272e0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e73  utput = ms.ops.s
+000272f0: 6361 7474 6572 5f6d 756c 2869 6e70 7574  catter_mul(input
+00027300: 5f6d 732c 2069 6e64 6578 2c20 7372 6329  _ms, index, src)
+00027310: 0a20 2020 2020 2020 2065 6c69 6620 7265  .        elif re
+00027320: 6475 6365 203d 3d20 2761 6d61 7827 3a0a  duce == 'amax':.
+00027330: 2020 2020 2020 2020 2020 2020 6966 2069              if i
+00027340: 6e63 6c75 6465 5f73 656c 6620 6973 2046  nclude_self is F
+00027350: 616c 7365 3a0a 2020 2020 2020 2020 2020  alse:.          
+00027360: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00027370: 2069 6e70 7574 5f6d 732e 7363 6174 7465   input_ms.scatte
+00027380: 7228 6469 6d2c 2069 6e64 6578 2c20 6d73  r(dim, index, ms
+00027390: 2e6f 7073 2e66 756c 6c5f 6c69 6b65 2869  .ops.full_like(i
+000273a0: 6e64 6578 2c20 696e 7075 745f 6d69 6e2c  ndex, input_min,
+000273b0: 2064 7479 7065 3d69 6e70 7574 5f6d 732e   dtype=input_ms.
+000273c0: 6474 7970 6529 290a 2020 2020 2020 2020  dtype)).        
+000273d0: 2020 2020 6966 2064 696d 203e 2030 3a0a      if dim > 0:.
+000273e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000273f0: 6f75 7470 7574 203d 206d 732e 6f70 732e  output = ms.ops.
+00027400: 7363 6174 7465 725f 6e64 5f6d 6178 286e  scatter_nd_max(n
+00027410: 645f 696e 7075 742c 206e 645f 6964 782c  d_input, nd_idx,
+00027420: 206e 645f 7372 6329 2e73 7175 6565 7a65   nd_src).squeeze
+00027430: 282d 3129 0a20 2020 2020 2020 2020 2020  (-1).           
+00027440: 2065 6c73 653a 0a20 2020 2020 2020 2020   else:.         
+00027450: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00027460: 6d73 2e6f 7073 2e73 6361 7474 6572 5f6d  ms.ops.scatter_m
+00027470: 6178 2869 6e70 7574 5f6d 732c 2069 6e64  ax(input_ms, ind
+00027480: 6578 2c20 7372 6329 0a20 2020 2020 2020  ex, src).       
+00027490: 2065 6c69 6620 7265 6475 6365 203d 3d20   elif reduce == 
+000274a0: 2761 6d69 6e27 3a0a 2020 2020 2020 2020  'amin':.        
+000274b0: 2020 2020 6966 2069 6e63 6c75 6465 5f73      if include_s
+000274c0: 656c 6620 6973 2046 616c 7365 3a0a 2020  elf is False:.  
+000274d0: 2020 2020 2020 2020 2020 2020 2020 696e                in
+000274e0: 7075 745f 6d73 203d 2069 6e70 7574 5f6d  put_ms = input_m
+000274f0: 732e 7363 6174 7465 7228 6469 6d2c 2069  s.scatter(dim, i
+00027500: 6e64 6578 2c20 6d73 2e6f 7073 2e66 756c  ndex, ms.ops.ful
+00027510: 6c5f 6c69 6b65 2869 6e64 6578 2c20 696e  l_like(index, in
+00027520: 7075 745f 6d61 782c 2064 7479 7065 3d69  put_max, dtype=i
+00027530: 6e70 7574 5f6d 732e 6474 7970 6529 290a  nput_ms.dtype)).
+00027540: 2020 2020 2020 2020 2020 2020 6966 2064              if d
+00027550: 696d 203e 2030 3a0a 2020 2020 2020 2020  im > 0:.        
+00027560: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00027570: 206d 732e 6f70 732e 7363 6174 7465 725f   ms.ops.scatter_
+00027580: 6e64 5f6d 696e 286e 645f 696e 7075 742c  nd_min(nd_input,
+00027590: 206e 645f 6964 782c 206e 645f 7372 6329   nd_idx, nd_src)
+000275a0: 2e73 7175 6565 7a65 282d 3129 0a20 2020  .squeeze(-1).   
+000275b0: 2020 2020 2020 2020 2065 6c73 653a 0a20           else:. 
+000275c0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+000275d0: 7574 7075 7420 3d20 6d73 2e6f 7073 2e73  utput = ms.ops.s
+000275e0: 6361 7474 6572 5f6d 696e 2869 6e70 7574  catter_min(input
+000275f0: 5f6d 732c 2069 6e64 6578 2c20 7372 6329  _ms, index, src)
+00027600: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00027610: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00027620: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+00027630: 7272 6f72 2822 666f 7220 6164 6170 7465  rror("for adapte
+00027640: 722c 2027 7265 6475 6365 2720 6172 6775  r, 'reduce' argu
+00027650: 6d65 6e74 206d 7573 7420 6265 2065 6974  ment must be eit
+00027660: 6865 7220 2773 756d 272c 2027 7072 6f64  her 'sum', 'prod
+00027670: 272c 2027 6d65 616e 272c 2027 616d 6178  ', 'mean', 'amax
+00027680: 2720 6f72 2022 0a20 2020 2020 2020 2020  ' or ".         
+00027690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000276a0: 2020 2020 2020 2020 2020 2020 2066 2227               f"'
+000276b0: 616d 696e 272c 2062 7574 2067 6f74 2027  amin', but got '
+000276c0: 7b72 6564 7563 657d 2722 290a 2020 2020  {reduce}'").    
+000276d0: 2020 2020 7265 7475 726e 2063 6173 745f      return cast_
+000276e0: 746f 5f61 6461 7074 6572 5f74 656e 736f  to_adapter_tenso
+000276f0: 7228 6f75 7470 7574 290a 0a20 2020 2064  r(output)..    d
+00027700: 6566 2073 6361 7474 6572 5f72 6564 7563  ef scatter_reduc
+00027710: 655f 2873 656c 662c 2064 696d 2c20 696e  e_(self, dim, in
+00027720: 6465 782c 2073 7263 2c20 7265 6475 6365  dex, src, reduce
+00027730: 2c20 2a2c 2069 6e63 6c75 6465 5f73 656c  , *, include_sel
+00027740: 663d 5472 7565 293a 0a20 2020 2020 2020  f=True):.       
+00027750: 206f 7574 7075 7420 3d20 7365 6c66 2e73   output = self.s
+00027760: 6361 7474 6572 5f72 6564 7563 6528 6469  catter_reduce(di
+00027770: 6d2c 2069 6e64 6578 2c20 7372 632c 2072  m, index, src, r
+00027780: 6564 7563 652c 2069 6e63 6c75 6465 5f73  educe, include_s
+00027790: 656c 663d 696e 636c 7564 655f 7365 6c66  elf=include_self
+000277a0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000277b0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+000277c0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+000277d0: 7470 7574 2c20 2273 6361 7474 6572 5f72  tput, "scatter_r
+000277e0: 6564 7563 655f 222c 2022 7363 6174 7465  educe_", "scatte
+000277f0: 725f 7265 6475 6365 2229 0a0a 0a20 2020  r_reduce")...   
+00027800: 2064 6566 2065 7870 6f6e 656e 7469 616c   def exponential
+00027810: 5f28 7365 6c66 2c20 6c61 6d62 643d 312e  _(self, lambd=1.
+00027820: 2c20 2a2c 2067 656e 6572 6174 6f72 3d4e  , *, generator=N
+00027830: 6f6e 6529 3a0a 2020 2020 2020 2020 6966  one):.        if
+00027840: 2067 656e 6572 6174 6f72 2069 7320 6e6f   generator is no
+00027850: 7420 4e6f 6e65 3a0a 2020 2020 2020 2020  t None:.        
+00027860: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+00027870: 7272 6f72 2822 6067 656e 6572 6174 6f72  rror("`generator
+00027880: 6020 6361 6e20 6e6f 7420 6265 2073 7570  ` can not be sup
+00027890: 706f 7274 6564 2e22 290a 2020 2020 2020  ported.").      
+000278a0: 2020 6f75 7470 7574 203d 206e 702e 7261    output = np.ra
+000278b0: 6e64 6f6d 2e65 7870 6f6e 656e 7469 616c  ndom.exponential
+000278c0: 2873 6361 6c65 3d6c 616d 6264 2c20 7369  (scale=lambd, si
+000278d0: 7a65 3d73 656c 662e 7368 6170 6529 0a20  ze=self.shape). 
+000278e0: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+000278f0: 6d73 2e54 656e 736f 7228 6f75 7470 7574  ms.Tensor(output
+00027900: 292e 6173 7479 7065 2873 656c 662e 6474  ).astype(self.dt
+00027910: 7970 6529 0a20 2020 2020 2020 2072 6574  ype).        ret
+00027920: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+00027930: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+00027940: 206f 7574 7075 742c 2022 6578 706f 6e65   output, "expone
+00027950: 6e74 6961 6c5f 222c 2022 6578 706f 6e65  ntial_", "expone
+00027960: 6e74 6961 6c22 290a 0a20 2020 2064 6566  ntial")..    def
+00027970: 2069 6e64 6578 5f72 6564 7563 6528 7365   index_reduce(se
+00027980: 6c66 2c20 6469 6d2c 2069 6e64 6578 2c20  lf, dim, index, 
+00027990: 736f 7572 6365 2c20 7265 6475 6365 2c20  source, reduce, 
+000279a0: 2a2c 2069 6e63 6c75 6465 5f73 656c 663d  *, include_self=
+000279b0: 5472 7565 293a 0a20 2020 2020 2020 2069  True):.        i
+000279c0: 6620 7365 6c66 2e64 7479 7065 2069 6e20  f self.dtype in 
+000279d0: 6d69 6e64 746f 7263 685f 6474 7970 652e  mindtorch_dtype.
+000279e0: 616c 6c5f 696e 745f 7479 7065 3a0a 2020  all_int_type:.  
+000279f0: 2020 2020 2020 2020 2020 696e 7075 745f            input_
+00027a00: 6d61 7820 3d20 6969 6e66 6f28 7365 6c66  max = iinfo(self
+00027a10: 2e64 7479 7065 292e 6d61 780a 2020 2020  .dtype).max.    
+00027a20: 2020 2020 2020 2020 696e 7075 745f 6d69          input_mi
+00027a30: 6e20 3d20 6969 6e66 6f28 7365 6c66 2e64  n = iinfo(self.d
+00027a40: 7479 7065 292e 6d69 6e0a 2020 2020 2020  type).min.      
+00027a50: 2020 656c 6966 2073 656c 662e 6474 7970    elif self.dtyp
+00027a60: 6520 696e 206d 696e 6474 6f72 6368 5f64  e in mindtorch_d
+00027a70: 7479 7065 2e61 6c6c 5f66 6c6f 6174 5f74  type.all_float_t
+00027a80: 7970 653a 0a20 2020 2020 2020 2020 2020  ype:.           
+00027a90: 2069 6e70 7574 5f6d 6178 203d 2066 696e   input_max = fin
+00027aa0: 666f 2873 656c 662e 6474 7970 6529 2e6d  fo(self.dtype).m
+00027ab0: 6178 0a20 2020 2020 2020 2020 2020 2069  ax.            i
+00027ac0: 6e70 7574 5f6d 696e 203d 2066 696e 666f  nput_min = finfo
+00027ad0: 2873 656c 662e 6474 7970 6529 2e6d 696e  (self.dtype).min
+00027ae0: 0a0a 2020 2020 2020 2020 696e 7075 745f  ..        input_
+00027af0: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+00027b00: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+00027b10: 2020 2020 2069 6478 203d 2063 6173 745f       idx = cast_
+00027b20: 746f 5f6d 735f 7465 6e73 6f72 2869 6e64  to_ms_tensor(ind
+00027b30: 6578 290a 2020 2020 2020 2020 7372 6320  ex).        src 
+00027b40: 3d20 6361 7374 5f74 6f5f 6d73 5f74 656e  = cast_to_ms_ten
+00027b50: 736f 7228 736f 7572 6365 290a 2020 2020  sor(source).    
+00027b60: 2020 2020 6966 2064 696d 203e 2030 3a0a      if dim > 0:.
+00027b70: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00027b80: 745f 6d73 203d 2069 6e70 7574 5f6d 732e  t_ms = input_ms.
+00027b90: 7377 6170 6178 6573 2830 2c20 6469 6d29  swapaxes(0, dim)
+00027ba0: 0a20 2020 2020 2020 2020 2020 2073 7263  .            src
+00027bb0: 203d 2073 7263 2e73 7761 7061 7865 7328   = src.swapaxes(
+00027bc0: 302c 2064 696d 290a 2020 2020 2020 2020  0, dim).        
+00027bd0: 6966 2072 6564 7563 6520 3d3d 2022 7072  if reduce == "pr
+00027be0: 6f64 223a 0a20 2020 2020 2020 2020 2020  od":.           
+00027bf0: 2069 6620 696e 636c 7564 655f 7365 6c66   if include_self
+00027c00: 2069 7320 4661 6c73 653a 0a20 2020 2020   is False:.     
+00027c10: 2020 2020 2020 2020 2020 2069 6e70 7574             input
+00027c20: 5f6d 7320 3d20 6d73 2e6f 7073 2e73 6361  _ms = ms.ops.sca
+00027c30: 7474 6572 5f75 7064 6174 6528 6d73 2e50  tter_update(ms.P
+00027c40: 6172 616d 6574 6572 2869 6e70 7574 5f6d  arameter(input_m
+00027c50: 7329 2c20 6964 782c 0a20 2020 2020 2020  s), idx,.       
+00027c60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027c80: 2020 2020 2020 206d 732e 6f70 732e 6f6e         ms.ops.on
+00027c90: 6573 5f6c 696b 6528 7372 632c 2064 7479  es_like(src, dty
+00027ca0: 7065 3d73 7263 2e64 7479 7065 2929 0a20  pe=src.dtype)). 
+00027cb0: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+00027cc0: 7420 3d20 6d73 2e6f 7073 2e73 6361 7474  t = ms.ops.scatt
+00027cd0: 6572 5f6d 756c 286d 732e 5061 7261 6d65  er_mul(ms.Parame
+00027ce0: 7465 7228 696e 7075 745f 6d73 292c 2069  ter(input_ms), i
+00027cf0: 6478 2c20 7372 6329 0a20 2020 2020 2020  dx, src).       
+00027d00: 2065 6c69 6620 7265 6475 6365 203d 3d20   elif reduce == 
+00027d10: 2261 6d61 7822 3a0a 2020 2020 2020 2020  "amax":.        
+00027d20: 2020 2020 6966 2069 6e63 6c75 6465 5f73      if include_s
+00027d30: 656c 6620 6973 2046 616c 7365 3a0a 2020  elf is False:.  
+00027d40: 2020 2020 2020 2020 2020 2020 2020 696e                in
+00027d50: 7075 745f 6d73 203d 206d 732e 6f70 732e  put_ms = ms.ops.
+00027d60: 7363 6174 7465 725f 7570 6461 7465 286d  scatter_update(m
+00027d70: 732e 5061 7261 6d65 7465 7228 696e 7075  s.Parameter(inpu
+00027d80: 745f 6d73 292c 2069 6478 2c0a 2020 2020  t_ms), idx,.    
+00027d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027da0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027db0: 2020 2020 2020 2020 2020 6d73 2e6f 7073            ms.ops
+00027dc0: 2e66 756c 6c5f 6c69 6b65 2873 7263 2c20  .full_like(src, 
+00027dd0: 696e 7075 745f 6d69 6e2c 2064 7479 7065  input_min, dtype
+00027de0: 3d73 7263 2e64 7479 7065 2929 0a20 2020  =src.dtype)).   
+00027df0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00027e00: 3d20 6d73 2e6f 7073 2e73 6361 7474 6572  = ms.ops.scatter
+00027e10: 5f6d 6178 286d 732e 5061 7261 6d65 7465  _max(ms.Paramete
+00027e20: 7228 696e 7075 745f 6d73 292c 2069 6478  r(input_ms), idx
+00027e30: 2c20 7372 6329 0a20 2020 2020 2020 2065  , src).        e
+00027e40: 6c69 6620 7265 6475 6365 203d 3d20 2261  lif reduce == "a
+00027e50: 6d69 6e22 3a0a 2020 2020 2020 2020 2020  min":.          
+00027e60: 2020 6966 2069 6e63 6c75 6465 5f73 656c    if include_sel
+00027e70: 6620 6973 2046 616c 7365 3a0a 2020 2020  f is False:.    
+00027e80: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00027e90: 745f 6d73 203d 206d 732e 6f70 732e 7363  t_ms = ms.ops.sc
+00027ea0: 6174 7465 725f 7570 6461 7465 286d 732e  atter_update(ms.
+00027eb0: 5061 7261 6d65 7465 7228 696e 7075 745f  Parameter(input_
+00027ec0: 6d73 292c 2069 6478 2c0a 2020 2020 2020  ms), idx,.      
+00027ed0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027ee0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027ef0: 2020 2020 2020 2020 6d73 2e6f 7073 2e66          ms.ops.f
+00027f00: 756c 6c5f 6c69 6b65 2873 7263 2c20 696e  ull_like(src, in
+00027f10: 7075 745f 6d61 782c 2064 7479 7065 3d73  put_max, dtype=s
+00027f20: 7263 2e64 7479 7065 2929 0a20 2020 2020  rc.dtype)).     
+00027f30: 2020 2020 2020 206f 7574 7075 7420 3d20         output = 
+00027f40: 6d73 2e6f 7073 2e73 6361 7474 6572 5f6d  ms.ops.scatter_m
+00027f50: 696e 286d 732e 5061 7261 6d65 7465 7228  in(ms.Parameter(
+00027f60: 696e 7075 745f 6d73 292c 2069 6478 2c20  input_ms), idx, 
+00027f70: 7372 6329 0a20 2020 2020 2020 2065 6c69  src).        eli
+00027f80: 6620 7265 6475 6365 203d 3d20 226d 6561  f reduce == "mea
+00027f90: 6e22 3a0a 2020 2020 2020 2020 2020 2020  n":.            
+00027fa0: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
+00027fb0: 6e74 6564 4572 726f 7228 2273 6361 7474  ntedError("scatt
+00027fc0: 6572 5f72 6564 7563 6520 6375 7272 656e  er_reduce curren
+00027fd0: 746c 7920 646f 6573 6e27 7420 7375 7070  tly doesn't supp
+00027fe0: 6f72 7420 7265 6475 6365 3d3d 276d 6561  ort reduce=='mea
+00027ff0: 6e27 2229 0a20 2020 2020 2020 2065 6c73  n'").        els
+00028000: 653a 0a20 2020 2020 2020 2020 2020 2072  e:.            r
+00028010: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
+00028020: 7465 6445 7272 6f72 2822 666f 7220 6164  tedError("for ad
+00028030: 6170 7465 722c 2027 7265 6475 6365 2720  apter, 'reduce' 
+00028040: 6172 6775 6d65 6e74 206d 7573 7420 6265  argument must be
+00028050: 2065 6974 6865 7220 2770 726f 6427 2c20   either 'prod', 
+00028060: 276d 6561 6e27 2c20 2761 6d61 7827 206f  'mean', 'amax' o
+00028070: 7220 220a 2020 2020 2020 2020 2020 2020  r ".            
+00028080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00028090: 2020 2020 2020 2020 2020 6622 2761 6d69            f"'ami
+000280a0: 6e27 2c20 6275 7420 676f 7420 277b 7265  n', but got '{re
+000280b0: 6475 6365 7d27 2229 0a20 2020 2020 2020  duce}'").       
+000280c0: 2069 6620 6469 6d20 3e20 303a 0a20 2020   if dim > 0:.   
+000280d0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+000280e0: 3d20 6f75 7470 7574 2e73 7761 7061 7865  = output.swapaxe
+000280f0: 7328 302c 2064 696d 290a 2020 2020 2020  s(0, dim).      
+00028100: 2020 7265 7475 726e 2063 6173 745f 746f    return cast_to
+00028110: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+00028120: 6f75 7470 7574 290a 0a20 2020 2064 6566  output)..    def
+00028130: 2069 6e64 6578 5f72 6564 7563 655f 2873   index_reduce_(s
+00028140: 656c 662c 2064 696d 2c20 696e 6465 782c  elf, dim, index,
+00028150: 2073 6f75 7263 652c 2072 6564 7563 652c   source, reduce,
+00028160: 202a 2c20 696e 636c 7564 655f 7365 6c66   *, include_self
+00028170: 3d54 7275 6529 3a0a 2020 2020 2020 2020  =True):.        
+00028180: 6f75 7470 7574 203d 2073 656c 662e 696e  output = self.in
+00028190: 6465 785f 7265 6475 6365 2864 696d 2c20  dex_reduce(dim, 
+000281a0: 696e 6465 782c 2073 6f75 7263 652c 2072  index, source, r
+000281b0: 6564 7563 652c 2069 6e63 6c75 6465 5f73  educe, include_s
+000281c0: 656c 663d 696e 636c 7564 655f 7365 6c66  elf=include_self
+000281d0: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+000281e0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+000281f0: 5f61 7373 6967 6e28 7365 6c66 2c20 6f75  _assign(self, ou
+00028200: 7470 7574 2c20 2269 6e64 6578 5f72 6564  tput, "index_red
+00028210: 7563 655f 222c 2022 696e 6465 785f 7265  uce_", "index_re
+00028220: 6475 6365 2229 0a0a 2020 2020 2320 7465  duce")..    # te
+00028230: 6e73 6f72 2e6c 6f67 5f73 6f66 746d 6178  nsor.log_softmax
+00028240: 2069 7320 6e6f 7420 6469 7370 6c61 7965   is not displaye
+00028250: 6420 6f6e 2074 6865 206f 6666 6963 6961  d on the officia
+00028260: 6c20 7765 6273 6974 650a 2020 2020 6465  l website.    de
+00028270: 6620 6c6f 675f 736f 6674 6d61 7828 7365  f log_softmax(se
+00028280: 6c66 2c20 6469 6d3d 4e6f 6e65 2c20 5f73  lf, dim=None, _s
+00028290: 7461 636b 6c65 7665 6c3d 332c 2064 7479  tacklevel=3, dty
+000282a0: 7065 3d4e 6f6e 6529 3a0a 2020 2020 2020  pe=None):.      
+000282b0: 2020 756e 7375 7070 6f72 7465 645f 6174    unsupported_at
+000282c0: 7472 285f 7374 6163 6b6c 6576 656c 2920  tr(_stacklevel) 
+000282d0: 2320 605f 7374 6163 6b6c 6576 656c 6020  # `_stacklevel` 
+000282e0: 696e 2074 6f72 6368 2069 7320 6465 7072  in torch is depr
+000282f0: 6563 6174 6564 0a20 2020 2020 2020 2069  ecated.        i
+00028300: 6620 6469 6d20 6973 204e 6f6e 653a 0a20  f dim is None:. 
+00028310: 2020 2020 2020 2020 2020 2064 696d 203d             dim =
+00028320: 202d 310a 0a20 2020 2020 2020 2069 6e70   -1..        inp
+00028330: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+00028340: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00028350: 2020 2020 2020 2020 6966 2064 7479 7065          if dtype
+00028360: 2069 7320 6e6f 7420 4e6f 6e65 3a0a 2020   is not None:.  
+00028370: 2020 2020 2020 2020 2020 696e 7075 745f            input_
+00028380: 6d73 203d 2069 6e70 7574 5f6d 732e 6173  ms = input_ms.as
+00028390: 7479 7065 2864 7479 7065 290a 0a20 2020  type(dtype)..   
+000283a0: 2020 2020 206f 7574 203d 206d 732e 6f70       out = ms.op
+000283b0: 732e 6c6f 675f 736f 6674 6d61 7828 696e  s.log_softmax(in
+000283c0: 7075 745f 6d73 2c20 6469 6d29 0a20 2020  put_ms, dim).   
+000283d0: 2020 2020 2072 6574 7572 6e20 6361 7374       return cast
+000283e0: 5f74 6f5f 6164 6170 7465 725f 7465 6e73  _to_adapter_tens
+000283f0: 6f72 286f 7574 290a 0a20 2020 2064 6566  or(out)..    def
+00028400: 206d 6173 6b65 645f 7363 6174 7465 7228   masked_scatter(
+00028410: 7365 6c66 2c20 6d61 736b 2c20 7465 6e73  self, mask, tens
+00028420: 6f72 293a 0a20 2020 2020 2020 2023 2054  or):.        # T
+00028430: 4f44 4f3a 206d 732e 6f70 732e 6d61 736b  ODO: ms.ops.mask
+00028440: 6564 5f73 6361 7474 6572 2064 6f65 7320  ed_scatter does 
+00028450: 6e6f 7420 7375 7070 6f72 7420 696e 7075  not support inpu
+00028460: 7420 746f 2062 6520 6272 6f61 6463 6173  t to be broadcas
+00028470: 7465 6420 746f 2074 6865 2073 6861 7065  ted to the shape
+00028480: 206f 6620 6d61 736b 0a20 2020 2020 2020   of mask.       
+00028490: 2069 6e70 7574 5f6d 7320 3d20 6361 7374   input_ms = cast
+000284a0: 5f74 6f5f 6d73 5f74 656e 736f 7228 7365  _to_ms_tensor(se
+000284b0: 6c66 290a 2020 2020 2020 2020 6d61 736b  lf).        mask
+000284c0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000284d0: 6e73 6f72 286d 6173 6b29 2e62 6f6f 6c28  nsor(mask).bool(
+000284e0: 290a 2020 2020 2020 2020 7465 6e73 6f72  ).        tensor
+000284f0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00028500: 6e73 6f72 2874 656e 736f 7229 0a20 2020  nsor(tensor).   
+00028510: 2020 2020 206f 7574 7075 7420 3d20 696e       output = in
+00028520: 7075 745f 6d73 2e6d 6173 6b65 645f 7363  put_ms.masked_sc
+00028530: 6174 7465 7228 6d61 736b 2c20 7465 6e73  atter(mask, tens
+00028540: 6f72 290a 2020 2020 2020 2020 7265 7475  or).        retu
+00028550: 726e 2063 6173 745f 746f 5f61 6461 7074  rn cast_to_adapt
+00028560: 6572 5f74 656e 736f 7228 6f75 7470 7574  er_tensor(output
+00028570: 290a 0a20 2020 2064 6566 206d 6173 6b65  )..    def maske
+00028580: 645f 7363 6174 7465 725f 2873 656c 662c  d_scatter_(self,
+00028590: 206d 6173 6b2c 2074 656e 736f 7229 3a0a   mask, tensor):.
+000285a0: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+000285b0: 2073 656c 662e 6d61 736b 6564 5f73 6361   self.masked_sca
+000285c0: 7474 6572 286d 6173 6b2c 2074 656e 736f  tter(mask, tenso
+000285d0: 7229 0a20 2020 2020 2020 2072 6574 7572  r).        retur
+000285e0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+000285f0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00028600: 7574 7075 742c 2022 6d61 736b 6564 5f73  utput, "masked_s
+00028610: 6361 7474 6572 5f22 2c20 226d 6173 6b65  catter_", "maske
+00028620: 645f 7363 6174 7465 7222 290a 0a20 2020  d_scatter")..   
+00028630: 2064 6566 2063 6f72 7263 6f65 6628 7365   def corrcoef(se
+00028640: 6c66 293a 0a20 2020 2020 2020 2069 6e70  lf):.        inp
+00028650: 7574 5f6d 7320 3d20 6361 7374 5f74 6f5f  ut_ms = cast_to_
+00028660: 6d73 5f74 656e 736f 7228 7365 6c66 290a  ms_tensor(self).
+00028670: 2020 2020 2020 2020 6966 206c 656e 2869          if len(i
+00028680: 6e70 7574 5f6d 732e 7368 6170 6529 203e  nput_ms.shape) >
+00028690: 2032 3a0a 2020 2020 2020 2020 2020 2020   2:.            
+000286a0: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+000286b0: 2822 636f 7272 636f 6566 2829 3a20 6578  ("corrcoef(): ex
+000286c0: 7065 6374 6564 2069 6e70 7574 2074 6f20  pected input to 
+000286d0: 6861 7665 2074 776f 206f 7220 6665 7765  have two or fewe
+000286e0: 7220 6469 6d65 6e73 696f 6e73 2229 0a20  r dimensions"). 
+000286f0: 2020 2020 2020 2023 2054 4f44 4f3a 206d         # TODO: m
+00028700: 732e 6f70 732e 636f 7620 646f 6573 206e  s.ops.cov does n
+00028710: 6f74 2073 7570 706f 7274 2063 6f6d 706c  ot support compl
+00028720: 6578 2069 6e70 7574 0a20 2020 2020 2020  ex input.       
+00028730: 206f 7574 7075 7420 3d20 696e 7075 745f   output = input_
+00028740: 6d73 2e63 6f76 2829 0a20 2020 2020 2020  ms.cov().       
+00028750: 2069 6620 6c65 6e28 6f75 7470 7574 2e73   if len(output.s
+00028760: 6861 7065 2920 3d3d 2030 3a0a 2020 2020  hape) == 0:.    
+00028770: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+00028780: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+00028790: 656e 736f 7228 6d73 2e6f 7073 2e6f 6e65  ensor(ms.ops.one
+000287a0: 735f 6c69 6b65 286f 7574 7075 7429 290a  s_like(output)).
+000287b0: 2020 2020 2020 2020 2320 6e6f 726d 616c          # normal
+000287c0: 697a 6520 636f 7661 7269 616e 6365 0a20  ize covariance. 
+000287d0: 2020 2020 2020 2064 203d 206d 732e 6e75         d = ms.nu
+000287e0: 6d70 792e 6469 6167 286f 7574 7075 7429  mpy.diag(output)
+000287f0: 0a20 2020 2020 2020 2023 2043 6c69 7020  .        # Clip 
+00028800: 7265 616c 2061 6e64 2069 6d61 6769 6e61  real and imagina
+00028810: 7279 2070 6172 7473 2074 6f20 5b2d 312c  ry parts to [-1,
+00028820: 2031 5d2e 0a20 2020 2020 2020 2069 6620   1]..        if 
+00028830: 696e 7075 745f 6d73 2e64 7479 7065 203d  input_ms.dtype =
+00028840: 3d20 6d73 2e63 6f6d 706c 6578 3634 3a0a  = ms.complex64:.
+00028850: 2020 2020 2020 2020 2020 2020 7265 616c              real
+00028860: 5f6f 7020 3d20 5f67 6574 5f63 6163 6865  _op = _get_cache
+00028870: 5f70 7269 6d28 6d73 2e6f 7073 2e52 6561  _prim(ms.ops.Rea
+00028880: 6c29 2829 0a20 2020 2020 2020 2020 2020  l)().           
+00028890: 2069 6d61 675f 6f70 203d 205f 6765 745f   imag_op = _get_
+000288a0: 6361 6368 655f 7072 696d 286d 732e 6f70  cache_prim(ms.op
+000288b0: 732e 496d 6167 2928 290a 2020 2020 2020  s.Imag)().      
+000288c0: 2020 2020 2020 636f 6d70 6c65 785f 6f70        complex_op
+000288d0: 203d 205f 6765 745f 6361 6368 655f 7072   = _get_cache_pr
+000288e0: 696d 286d 732e 6f70 732e 436f 6d70 6c65  im(ms.ops.Comple
+000288f0: 7829 2829 0a20 2020 2020 2020 2020 2020  x)().           
+00028900: 2064 5f72 6561 6c20 3d20 7265 616c 5f6f   d_real = real_o
+00028910: 7028 6429 0a20 2020 2020 2020 2020 2020  p(d).           
+00028920: 2073 7464 6465 7620 3d20 6d73 2e6f 7073   stddev = ms.ops
+00028930: 2e73 7172 7428 645f 7265 616c 290a 2020  .sqrt(d_real).  
+00028940: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00028950: 202f 3d20 6d73 2e6f 7073 2e65 7870 616e   /= ms.ops.expan
+00028960: 645f 6469 6d73 2873 7464 6465 762c 202d  d_dims(stddev, -
+00028970: 3129 0a20 2020 2020 2020 2020 2020 206f  1).            o
+00028980: 7574 7075 7420 2f3d 206d 732e 6f70 732e  utput /= ms.ops.
+00028990: 6578 7061 6e64 5f64 696d 7328 7374 6464  expand_dims(stdd
+000289a0: 6576 2c20 3029 0a20 2020 2020 2020 2020  ev, 0).         
+000289b0: 2020 206f 7574 7075 745f 7265 616c 203d     output_real =
+000289c0: 2072 6561 6c5f 6f70 286f 7574 7075 7429   real_op(output)
+000289d0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+000289e0: 7075 745f 696d 6167 203d 2069 6d61 675f  put_imag = imag_
+000289f0: 6f70 286f 7574 7075 7429 0a20 2020 2020  op(output).     
+00028a00: 2020 2020 2020 206f 7574 7075 745f 7265         output_re
+00028a10: 616c 203d 206d 732e 6f70 732e 636c 6970  al = ms.ops.clip
+00028a20: 5f62 795f 7661 6c75 6528 6f75 7470 7574  _by_value(output
+00028a30: 5f72 6561 6c2c 202d 312c 2031 290a 2020  _real, -1, 1).  
+00028a40: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00028a50: 5f69 6d61 6720 3d20 6d73 2e6f 7073 2e63  _imag = ms.ops.c
+00028a60: 6c69 705f 6279 5f76 616c 7565 286f 7574  lip_by_value(out
+00028a70: 7075 745f 696d 6167 2c20 2d31 2c20 3129  put_imag, -1, 1)
+00028a80: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00028a90: 7075 7420 3d20 636f 6d70 6c65 785f 6f70  put = complex_op
+00028aa0: 286f 7574 7075 745f 7265 616c 2c20 6f75  (output_real, ou
+00028ab0: 7470 7574 5f69 6d61 6729 0a20 2020 2020  tput_imag).     
+00028ac0: 2020 2065 6c73 653a 0a20 2020 2020 2020     else:.       
+00028ad0: 2020 2020 2073 7464 6465 7620 3d20 6d73       stddev = ms
+00028ae0: 2e6f 7073 2e73 7172 7428 6429 0a20 2020  .ops.sqrt(d).   
+00028af0: 2020 2020 2020 2020 206f 7574 7075 7420           output 
+00028b00: 2f3d 206d 732e 6f70 732e 6578 7061 6e64  /= ms.ops.expand
+00028b10: 5f64 696d 7328 7374 6464 6576 2c20 2d31  _dims(stddev, -1
+00028b20: 290a 2020 2020 2020 2020 2020 2020 6f75  ).            ou
+00028b30: 7470 7574 202f 3d20 6d73 2e6f 7073 2e65  tput /= ms.ops.e
+00028b40: 7870 616e 645f 6469 6d73 2873 7464 6465  xpand_dims(stdde
+00028b50: 762c 2030 290a 2020 2020 2020 2020 2020  v, 0).          
+00028b60: 2020 6f75 7470 7574 203d 206d 732e 6f70    output = ms.op
+00028b70: 732e 636c 6970 5f62 795f 7661 6c75 6528  s.clip_by_value(
+00028b80: 6f75 7470 7574 2c20 2d31 2c20 3129 0a20  output, -1, 1). 
+00028b90: 2020 2020 2020 2072 6574 7572 6e20 6361         return ca
+00028ba0: 7374 5f74 6f5f 6164 6170 7465 725f 7465  st_to_adapter_te
+00028bb0: 6e73 6f72 286f 7574 7075 7429 0a0a 2020  nsor(output)..  
+00028bc0: 2020 6465 6620 6765 6f6d 6574 7269 635f    def geometric_
+00028bd0: 2873 656c 662c 2070 2c20 2a2c 2067 656e  (self, p, *, gen
+00028be0: 6572 6174 6f72 3d4e 6f6e 6529 3a0a 2020  erator=None):.  
+00028bf0: 2020 2020 2020 6966 2067 656e 6572 6174        if generat
+00028c00: 6f72 2069 7320 6e6f 7420 4e6f 6e65 3a0a  or is not None:.
+00028c10: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00028c20: 6520 5661 6c75 6545 7272 6f72 2822 6067  e ValueError("`g
+00028c30: 656e 6572 6174 6f72 6020 6361 6e20 6e6f  enerator` can no
+00028c40: 7420 6265 2073 7570 706f 7274 6564 2e22  t be supported."
+00028c50: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+00028c60: 203d 206e 702e 7261 6e64 6f6d 2e67 656f   = np.random.geo
+00028c70: 6d65 7472 6963 2870 3d70 2c20 7369 7a65  metric(p=p, size
+00028c80: 3d73 656c 662e 7368 6170 6529 0a20 2020  =self.shape).   
+00028c90: 2020 2020 206f 7574 7075 7420 3d20 6d73       output = ms
+00028ca0: 2e54 656e 736f 7228 6f75 7470 7574 292e  .Tensor(output).
+00028cb0: 6173 7479 7065 2873 656c 662e 6474 7970  astype(self.dtyp
+00028cc0: 6529 0a20 2020 2020 2020 2072 6574 7572  e).        retur
+00028cd0: 6e20 5f74 656e 736f 725f 696e 706c 6163  n _tensor_inplac
+00028ce0: 655f 6173 7369 676e 2873 656c 662c 206f  e_assign(self, o
+00028cf0: 7574 7075 742c 2022 6765 6f6d 6574 7269  utput, "geometri
+00028d00: 635f 222c 2022 6765 6f6d 6574 7269 6322  c_", "geometric"
+00028d10: 290a 0a20 2020 2064 6566 206c 6f67 5f6e  )..    def log_n
+00028d20: 6f72 6d61 6c5f 2873 656c 662c 206d 6561  ormal_(self, mea
+00028d30: 6e3d 312c 2073 7464 3d32 2c20 2a2c 2067  n=1, std=2, *, g
+00028d40: 656e 6572 6174 6f72 3d4e 6f6e 6529 3a0a  enerator=None):.
+00028d50: 2020 2020 2020 2020 6966 2067 656e 6572          if gener
+00028d60: 6174 6f72 2069 7320 6e6f 7420 4e6f 6e65  ator is not None
+00028d70: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+00028d80: 6973 6520 5661 6c75 6545 7272 6f72 2822  ise ValueError("
+00028d90: 6067 656e 6572 6174 6f72 6020 6361 6e20  `generator` can 
+00028da0: 6e6f 7420 6265 2073 7570 706f 7274 6564  not be supported
+00028db0: 2e22 290a 2020 2020 2020 2020 696e 7075  .").        inpu
+00028dc0: 745f 6d73 203d 2063 6173 745f 746f 5f6d  t_ms = cast_to_m
+00028dd0: 735f 7465 6e73 6f72 2873 656c 6629 0a20  s_tensor(self). 
+00028de0: 2020 2020 2020 206e 6f72 6d61 6c5f 6f70         normal_op
+00028df0: 203d 205f 6765 745f 6361 6368 655f 7072   = _get_cache_pr
+00028e00: 696d 286d 732e 6f70 732e 4c6f 674e 6f72  im(ms.ops.LogNor
+00028e10: 6d61 6c52 6576 6572 7365 2928 6d65 616e  malReverse)(mean
+00028e20: 3d6d 6561 6e2c 2073 7464 3d73 7464 290a  =mean, std=std).
+00028e30: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00028e40: 206e 6f72 6d61 6c5f 6f70 2869 6e70 7574   normal_op(input
+00028e50: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
+00028e60: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+00028e70: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+00028e80: 206f 7574 7075 742c 2022 6c6f 675f 6e6f   output, "log_no
+00028e90: 726d 616c 5f22 2c20 226c 6f67 5f6e 6f72  rmal_", "log_nor
+00028ea0: 6d61 6c22 290a 0a20 2020 2064 6566 206d  mal")..    def m
+00028eb0: 6170 5f28 7365 6c66 2c20 7465 6e73 6f72  ap_(self, tensor
+00028ec0: 2c20 6361 6c6c 6162 6c65 293a 0a20 2020  , callable):.   
+00028ed0: 2020 2020 2069 6e70 7574 5f6d 7320 3d20       input_ms = 
+00028ee0: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00028ef0: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00028f00: 7465 6e73 6f72 5f6d 7320 3d20 6361 7374  tensor_ms = cast
+00028f10: 5f74 6f5f 6d73 5f74 656e 736f 7228 7465  _to_ms_tensor(te
+00028f20: 6e73 6f72 290a 2020 2020 2020 2020 6f75  nsor).        ou
+00028f30: 7470 7574 203d 2063 616c 6c61 626c 6528  tput = callable(
+00028f40: 696e 7075 745f 6d73 2c20 7465 6e73 6f72  input_ms, tensor
+00028f50: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
+00028f60: 7572 6e20 5f74 656e 736f 725f 696e 706c  urn _tensor_inpl
+00028f70: 6163 655f 6173 7369 676e 2873 656c 662c  ace_assign(self,
+00028f80: 206f 7574 7075 742c 2022 6d61 705f 222c   output, "map_",
+00028f90: 2022 6d61 7022 290a 0a20 2020 2064 6566   "map")..    def
+00028fa0: 2061 7070 6c79 5f28 7365 6c66 2c20 666e   apply_(self, fn
+00028fb0: 293a 0a20 2020 2020 2020 2023 2054 6869  ):.        # Thi
+00028fc0: 7320 6675 6e63 7469 6f6e 2073 686f 756c  s function shoul
+00028fd0: 6420 6e6f 7420 6265 2075 7365 6420 696e  d not be used in
+00028fe0: 2063 6f64 6520 7365 6374 696f 6e73 2074   code sections t
+00028ff0: 6861 7420 7265 7175 6972 6520 6869 6768  hat require high
+00029000: 2070 6572 666f 726d 616e 6365 0a20 2020   performance.   
+00029010: 2020 2020 2069 6620 6e6f 7420 6361 6c6c       if not call
+00029020: 6162 6c65 2866 6e29 3a0a 2020 2020 2020  able(fn):.      
+00029030: 2020 2020 2020 7261 6973 6520 5479 7065        raise Type
+00029040: 4572 726f 7228 6622 666f 7220 7465 6e73  Error(f"for tens
+00029050: 6f72 2e61 7070 6c79 5f28 666e 292c 2066  or.apply_(fn), f
+00029060: 6e20 6d75 7374 2062 6520 6361 6c6c 6162  n must be callab
+00029070: 6c65 2c20 6275 7420 676f 7420 7b74 7970  le, but got {typ
+00029080: 6528 666e 292e 5f5f 6e61 6d65 5f5f 7d2e  e(fn).__name__}.
+00029090: 2229 0a20 2020 2020 2020 2066 6f72 2069  ").        for i
+000290a0: 2c20 656c 656d 2069 6e20 656e 756d 6572  , elem in enumer
+000290b0: 6174 6528 7365 6c66 293a 0a20 2020 2020  ate(self):.     
+000290c0: 2020 2020 2020 2073 656c 665b 695d 203d         self[i] =
+000290d0: 2066 6e28 656c 656d 290a 2020 2020 2020   fn(elem).      
+000290e0: 2020 7265 7475 726e 2073 656c 660a 0a20    return self.. 
+000290f0: 2020 2064 6566 2064 6961 676f 6e61 6c5f     def diagonal_
+00029100: 7363 6174 7465 7228 7365 6c66 2c20 7372  scatter(self, sr
+00029110: 632c 206f 6666 7365 743d 302c 2064 696d  c, offset=0, dim
+00029120: 313d 302c 2064 696d 323d 3129 3a0a 2020  1=0, dim2=1):.  
+00029130: 2020 2020 2020 696e 7075 745f 6d73 203d        input_ms =
+00029140: 2063 6173 745f 746f 5f6d 735f 7465 6e73   cast_to_ms_tens
+00029150: 6f72 2873 656c 6629 0a20 2020 2020 2020  or(self).       
+00029160: 2073 7263 5f6d 7320 3d20 6361 7374 5f74   src_ms = cast_t
+00029170: 6f5f 6d73 5f74 656e 736f 7228 7372 6329  o_ms_tensor(src)
+00029180: 0a0a 2020 2020 2020 2020 696e 7075 745f  ..        input_
+00029190: 7368 6170 6520 3d20 696e 7075 745f 6d73  shape = input_ms
+000291a0: 2e73 6861 7065 0a0a 2020 2020 2020 2020  .shape..        
+000291b0: 696e 6465 785f 6e70 203d 205f 6765 745f  index_np = _get_
+000291c0: 6469 6167 6f6e 616c 5f73 6361 7474 6572  diagonal_scatter
+000291d0: 5f69 6e64 6578 2869 6e70 7574 5f73 6861  _index(input_sha
+000291e0: 7065 2c20 6f66 6673 6574 2c20 6469 6d31  pe, offset, dim1
+000291f0: 2c20 6469 6d32 290a 2020 2020 2020 2020  , dim2).        
+00029200: 696e 6465 7820 3d20 6d73 2e54 656e 736f  index = ms.Tenso
+00029210: 722e 6672 6f6d 5f6e 756d 7079 2869 6e64  r.from_numpy(ind
+00029220: 6578 5f6e 7029 0a0a 2020 2020 2020 2020  ex_np)..        
+00029230: 6966 206f 6666 7365 7420 3c20 303a 0a20  if offset < 0:. 
+00029240: 2020 2020 2020 2020 2020 2073 7263 5f6c             src_l
+00029250: 656e 203d 2073 7263 5f6d 732e 7368 6170  en = src_ms.shap
+00029260: 655b 2d31 5d0a 2020 2020 2020 2020 2020  e[-1].          
+00029270: 2020 746d 7020 3d20 6d73 2e6f 7073 2e7a    tmp = ms.ops.z
+00029280: 6572 6f73 2873 7263 5f6d 732e 7368 6170  eros(src_ms.shap
+00029290: 655b 3a2d 315d 2c20 7372 635f 6d73 2e64  e[:-1], src_ms.d
+000292a0: 7479 7065 290a 2020 2020 2020 2020 2020  type).          
+000292b0: 2020 746d 7020 3d20 746d 702e 6578 7061    tmp = tmp.expa
+000292c0: 6e64 5f64 696d 7328 2d31 290a 2020 2020  nd_dims(-1).    
+000292d0: 2020 2020 2020 2020 666f 7220 5f20 696e          for _ in
+000292e0: 2072 616e 6765 2873 7263 5f6c 656e 2c20   range(src_len, 
+000292f0: 696e 7075 745f 7368 6170 655b 6469 6d31  input_shape[dim1
+00029300: 5d29 3a0a 2020 2020 2020 2020 2020 2020  ]):.            
+00029310: 2020 2020 7372 635f 6d73 203d 206d 732e      src_ms = ms.
+00029320: 6f70 732e 6361 7428 5b74 6d70 2c20 7372  ops.cat([tmp, sr
+00029330: 635f 6d73 5d2c 202d 3129 0a0a 2020 2020  c_ms], -1)..    
+00029340: 2020 2020 7372 635f 6d73 203d 2073 7263      src_ms = src
+00029350: 5f6d 732e 6d6f 7665 6178 6973 282d 312c  _ms.moveaxis(-1,
+00029360: 2064 696d 3129 0a20 2020 2020 2020 2073   dim1).        s
+00029370: 7263 5f6d 7320 3d20 7372 635f 6d73 2e65  rc_ms = src_ms.e
+00029380: 7870 616e 645f 6469 6d73 2864 696d 3229  xpand_dims(dim2)
+00029390: 0a0a 2020 2020 2020 2020 6f75 7470 7574  ..        output
+000293a0: 203d 206d 732e 6f70 732e 7465 6e73 6f72   = ms.ops.tensor
+000293b0: 5f73 6361 7474 6572 5f65 6c65 6d65 6e74  _scatter_element
+000293c0: 7328 696e 7075 745f 6d73 2c20 696e 6465  s(input_ms, inde
+000293d0: 782c 2073 7263 5f6d 732c 2061 7869 733d  x, src_ms, axis=
+000293e0: 6469 6d32 290a 2020 2020 2020 2020 7265  dim2).        re
+000293f0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+00029400: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+00029410: 7574 290a 0a20 2020 2023 2074 656e 736f  ut)..    # tenso
+00029420: 722e 736f 6674 6d61 7820 6973 206e 6f74  r.softmax is not
+00029430: 2064 6973 706c 6179 6564 206f 6e20 7468   displayed on th
+00029440: 6520 6f66 6669 6369 616c 2077 6562 7369  e official websi
+00029450: 7465 0a20 2020 2064 6566 2073 6f66 746d  te.    def softm
+00029460: 6178 2873 656c 662c 2064 696d 2c20 6474  ax(self, dim, dt
+00029470: 7970 653d 4e6f 6e65 293a 0a20 2020 2020  ype=None):.     
+00029480: 2020 2069 6e70 7574 5f6d 7320 3d20 6361     input_ms = ca
+00029490: 7374 5f74 6f5f 6d73 5f74 656e 736f 7228  st_to_ms_tensor(
+000294a0: 7365 6c66 290a 2020 2020 2020 2020 6966  self).        if
+000294b0: 2064 7479 7065 2069 7320 6e6f 7420 4e6f   dtype is not No
+000294c0: 6e65 3a0a 2020 2020 2020 2020 2020 2020  ne:.            
+000294d0: 696e 7075 745f 6d73 203d 2069 6e70 7574  input_ms = input
+000294e0: 5f6d 732e 6173 7479 7065 2864 7479 7065  _ms.astype(dtype
+000294f0: 290a 2020 2020 2020 2020 6f75 7470 7574  ).        output
+00029500: 203d 206d 732e 6f70 732e 736f 6674 6d61   = ms.ops.softma
+00029510: 7828 696e 7075 745f 6d73 2c20 6469 6d29  x(input_ms, dim)
+00029520: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00029530: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+00029540: 7465 6e73 6f72 286f 7574 7075 7429 0a0a  tensor(output)..
+00029550: 2020 2020 6465 6620 6e61 6e6d 6564 6961      def nanmedia
+00029560: 6e28 7365 6c66 2c20 6469 6d3d 4e6f 6e65  n(self, dim=None
+00029570: 2c20 6b65 6570 6469 6d3d 4661 6c73 6529  , keepdim=False)
+00029580: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+00029590: 6d73 203d 2063 6173 745f 746f 5f6d 735f  ms = cast_to_ms_
+000295a0: 7465 6e73 6f72 2873 656c 6629 0a20 2020  tensor(self).   
+000295b0: 2020 2020 2069 6620 6469 6d20 6973 204e       if dim is N
+000295c0: 6f6e 653a 0a20 2020 2020 2020 2020 2020  one:.           
+000295d0: 2023 206d 732e 6f70 732e 6d65 6469 616e   # ms.ops.median
+000295e0: 2063 616e 206e 6f74 2063 6f6d 7075 7465   can not compute
+000295f0: 2074 6865 206d 6564 6961 6e20 7661 6c75   the median valu
+00029600: 6520 616c 6f6e 6720 616c 6c20 6469 6d65  e along all dime
+00029610: 6e74 696f 6e73 0a20 2020 2020 2020 2020  ntions.         
+00029620: 2020 2023 206f 6e6c 7920 6d73 2e6f 7073     # only ms.ops
+00029630: 2e4d 6564 6961 6e28 676c 6f62 616c 5f6d  .Median(global_m
+00029640: 6564 6961 6e3d 5472 7565 2920 6361 6e20  edian=True) can 
+00029650: 646f 2074 6861 742e 0a20 2020 2020 2020  do that..       
+00029660: 2020 2020 2023 2073 6f20 6361 6e20 6e6f       # so can no
+00029670: 7420 7265 706c 6163 6520 6d73 2e6f 7073  t replace ms.ops
+00029680: 2e4d 6564 6961 6e20 746f 206d 732e 6f70  .Median to ms.op
+00029690: 732e 6d65 6469 616e 0a20 2020 2020 2020  s.median.       
+000296a0: 2020 2020 206f 7574 7075 742c 205f 203d       output, _ =
+000296b0: 205f 6765 745f 6361 6368 655f 7072 696d   _get_cache_prim
+000296c0: 286d 732e 6f70 732e 4d65 6469 616e 2928  (ms.ops.Median)(
+000296d0: 676c 6f62 616c 5f6d 6564 6961 6e3d 5472  global_median=Tr
+000296e0: 7565 2c20 6967 6e6f 7265 5f6e 616e 3d54  ue, ignore_nan=T
+000296f0: 7275 6529 2869 6e70 7574 5f6d 7329 0a20  rue)(input_ms). 
+00029700: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+00029710: 6e20 6361 7374 5f74 6f5f 6164 6170 7465  n cast_to_adapte
+00029720: 725f 7465 6e73 6f72 286f 7574 7075 7429  r_tensor(output)
+00029730: 0a20 2020 2020 2020 2065 6c73 653a 0a20  .        else:. 
+00029740: 2020 2020 2020 2020 2020 2023 2054 4f44             # TOD
+00029750: 4f3a 204f 6e20 4750 552c 206d 732e 6f70  O: On GPU, ms.op
+00029760: 732e 6d65 6469 616e 2074 6865 2072 6574  s.median the ret
+00029770: 7572 6e20 696e 6469 6365 7320 6d61 7920  urn indices may 
+00029780: 6265 2077 726f 6e67 2e0a 2020 2020 2020  be wrong..      
+00029790: 2020 2020 2020 6e61 6e6d 6564 6961 6e5f        nanmedian_
+000297a0: 203d 205f 6765 745f 6361 6368 655f 7072   = _get_cache_pr
+000297b0: 696d 286d 732e 6f70 732e 4d65 6469 616e  im(ms.ops.Median
+000297c0: 2928 676c 6f62 616c 5f6d 6564 6961 6e3d  )(global_median=
+000297d0: 4661 6c73 652c 2061 7869 733d 6469 6d2c  False, axis=dim,
+000297e0: 206b 6565 705f 6469 6d73 3d6b 6565 7064   keep_dims=keepd
+000297f0: 696d 2c0a 2020 2020 2020 2020 2020 2020  im,.            
+00029800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029810: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00029820: 2020 2020 2020 2020 2020 2020 6967 6e6f              igno
+00029830: 7265 5f6e 616e 3d54 7275 6529 0a20 2020  re_nan=True).   
+00029840: 2020 2020 2020 2020 2076 616c 7565 2c20           value, 
+00029850: 696e 6469 6365 7320 3d20 6e61 6e6d 6564  indices = nanmed
+00029860: 6961 6e5f 2869 6e70 7574 5f6d 7329 0a20  ian_(input_ms). 
+00029870: 2020 2020 2020 2020 2020 2069 6620 7079             if py
+00029880: 6e61 7469 7665 5f6d 6f64 655f 636f 6e64  native_mode_cond
+00029890: 6974 696f 6e28 293a 0a20 2020 2020 2020  ition():.       
+000298a0: 2020 2020 2020 2020 2070 6f69 6e74 203d           point =
+000298b0: 2073 6574 5f6e 616d 655f 7475 706c 6528   set_name_tuple(
+000298c0: 276e 616e 6d65 6469 616e 2729 0a20 2020  'nanmedian').   
+000298d0: 2020 2020 2020 2020 2020 2020 2072 6c74               rlt
+000298e0: 203d 2070 6f69 6e74 2863 6173 745f 746f   = point(cast_to
+000298f0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+00029900: 7661 6c75 6529 2c20 6361 7374 5f74 6f5f  value), cast_to_
+00029910: 6164 6170 7465 725f 7465 6e73 6f72 2869  adapter_tensor(i
+00029920: 6e64 6963 6573 2929 0a20 2020 2020 2020  ndices)).       
+00029930: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+00029940: 726c 740a 2020 2020 2020 2020 2020 2020  rlt.            
+00029950: 7265 7475 726e 2063 6173 745f 746f 5f61  return cast_to_a
+00029960: 6461 7074 6572 5f74 656e 736f 7228 7661  dapter_tensor(va
+00029970: 6c75 6529 2c20 6361 7374 5f74 6f5f 6164  lue), cast_to_ad
+00029980: 6170 7465 725f 7465 6e73 6f72 2869 6e64  apter_tensor(ind
+00029990: 6963 6573 290a 0a20 2020 2064 6566 2066  ices)..    def f
+000299a0: 7265 7870 2873 656c 6629 3a0a 2020 2020  rexp(self):.    
+000299b0: 2020 2020 2320 544f 444f 3a20 746f 2075      # TODO: to u
+000299c0: 7365 206d 732e 6f70 732e 6672 6578 700a  se ms.ops.frexp.
+000299d0: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+000299e0: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+000299f0: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00029a00: 2020 2069 6620 696e 7075 745f 6d73 2e64     if input_ms.d
+00029a10: 7479 7065 203d 3d20 6d73 2e66 6c6f 6174  type == ms.float
+00029a20: 3136 3a0a 2020 2020 2020 2020 2020 2020  16:.            
+00029a30: 696e 7075 745f 6d73 203d 2069 6e70 7574  input_ms = input
+00029a40: 5f6d 732e 6173 7479 7065 286d 732e 666c  _ms.astype(ms.fl
+00029a50: 6f61 7433 3229 0a20 2020 2020 2020 2020  oat32).         
+00029a60: 2020 2073 6967 6e20 3d20 6d73 2e6f 7073     sign = ms.ops
+00029a70: 2e73 6967 6e28 696e 7075 745f 6d73 290a  .sign(input_ms).
+00029a80: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
+00029a90: 745f 6d73 203d 206d 732e 6f70 732e 6162  t_ms = ms.ops.ab
+00029aa0: 7328 696e 7075 745f 6d73 290a 2020 2020  s(input_ms).    
+00029ab0: 2020 2020 2020 2020 6578 7020 3d20 6d73          exp = ms
+00029ac0: 2e6f 7073 2e66 6c6f 6f72 286d 732e 6f70  .ops.floor(ms.op
+00029ad0: 732e 6c6f 6732 2869 6e70 7574 5f6d 7329  s.log2(input_ms)
+00029ae0: 2920 2b20 310a 2020 2020 2020 2020 2020  ) + 1.          
+00029af0: 2020 6d61 6e74 6973 7361 203d 2028 696e    mantissa = (in
+00029b00: 7075 745f 6d73 202a 2073 6967 6e20 2f20  put_ms * sign / 
+00029b10: 2832 202a 2a20 6578 7029 292e 6173 7479  (2 ** exp)).asty
+00029b20: 7065 286d 732e 666c 6f61 7431 3629 0a20  pe(ms.float16). 
+00029b30: 2020 2020 2020 2065 6c73 653a 0a20 2020         else:.   
+00029b40: 2020 2020 2020 2020 2073 6967 6e20 3d20           sign = 
+00029b50: 6d73 2e6f 7073 2e73 6967 6e28 696e 7075  ms.ops.sign(inpu
+00029b60: 745f 6d73 290a 2020 2020 2020 2020 2020  t_ms).          
+00029b70: 2020 696e 7075 745f 6d73 203d 206d 732e    input_ms = ms.
+00029b80: 6f70 732e 6162 7328 696e 7075 745f 6d73  ops.abs(input_ms
+00029b90: 290a 2020 2020 2020 2020 2020 2020 6578  ).            ex
+00029ba0: 7020 3d20 6d73 2e6f 7073 2e66 6c6f 6f72  p = ms.ops.floor
+00029bb0: 286d 732e 6f70 732e 6c6f 6732 2869 6e70  (ms.ops.log2(inp
+00029bc0: 7574 5f6d 7329 2920 2b20 310a 2020 2020  ut_ms)) + 1.    
+00029bd0: 2020 2020 2020 2020 6d61 6e74 6973 7361          mantissa
+00029be0: 203d 2069 6e70 7574 5f6d 7320 2a20 7369   = input_ms * si
+00029bf0: 676e 202f 2028 3220 2a2a 2065 7870 290a  gn / (2 ** exp).
+00029c00: 2020 2020 2020 2020 6f75 7470 7574 203d          output =
+00029c10: 2028 6d61 6e74 6973 7361 2c20 6578 702e   (mantissa, exp.
+00029c20: 6173 7479 7065 286d 732e 696e 7433 3229  astype(ms.int32)
+00029c30: 290a 2020 2020 2020 2020 7265 7475 726e  ).        return
+00029c40: 2063 6173 745f 746f 5f61 6461 7074 6572   cast_to_adapter
+00029c50: 5f74 656e 736f 7228 6f75 7470 7574 290a  _tensor(output).
+00029c60: 0a20 2020 2064 6566 206f 726d 7172 2873  .    def ormqr(s
+00029c70: 656c 662c 2074 6175 2c20 6f74 6865 722c  elf, tau, other,
+00029c80: 206c 6566 743d 5472 7565 2c20 7472 616e   left=True, tran
+00029c90: 7370 6f73 653d 4661 6c73 6529 3a0a 2020  spose=False):.  
+00029ca0: 2020 2020 2020 6966 206e 6f74 2069 735f        if not is_
+00029cb0: 756e 6465 725f 6770 755f 636f 6e74 6578  under_gpu_contex
+00029cc0: 7428 293a 0a20 2020 2020 2020 2020 2020  t():.           
+00029cd0: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
+00029ce0: 656e 7465 6445 7272 6f72 2822 6f72 6d71  entedError("ormq
+00029cf0: 7220 6375 7272 656e 746c 7920 6e6f 7420  r currently not 
+00029d00: 7375 7070 6f72 7465 6420 6f6e 2043 5055  supported on CPU
+00029d10: 206e 6f72 2041 7363 656e 6422 290a 2020   nor Ascend").  
+00029d20: 2020 2020 2020 656c 7365 3a0a 2020 2020        else:.    
+00029d30: 2020 2020 2020 2020 696e 7075 745f 6d73          input_ms
+00029d40: 203d 2063 6173 745f 746f 5f6d 735f 7465   = cast_to_ms_te
+00029d50: 6e73 6f72 2873 656c 6629 0a20 2020 2020  nsor(self).     
+00029d60: 2020 2020 2020 2074 6175 203d 2063 6173         tau = cas
+00029d70: 745f 746f 5f6d 735f 7465 6e73 6f72 2874  t_to_ms_tensor(t
+00029d80: 6175 290a 2020 2020 2020 2020 2020 2020  au).            
+00029d90: 6f74 6865 7220 3d20 6361 7374 5f74 6f5f  other = cast_to_
+00029da0: 6d73 5f74 656e 736f 7228 6f74 6865 7229  ms_tensor(other)
+00029db0: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00029dc0: 7075 7420 3d20 6d73 2e6f 7073 2e6f 726d  put = ms.ops.orm
+00029dd0: 7172 2869 6e70 7574 5f6d 732c 2074 6175  qr(input_ms, tau
+00029de0: 2c20 6f74 6865 722c 206c 6566 742c 2074  , other, left, t
+00029df0: 7261 6e73 706f 7365 290a 2020 2020 2020  ranspose).      
+00029e00: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+00029e10: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+00029e20: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+00029e30: 2064 6566 2074 7269 616e 6775 6c61 725f   def triangular_
+00029e40: 736f 6c76 6528 7365 6c66 2c20 412c 2075  solve(self, A, u
+00029e50: 7070 6572 3d54 7275 652c 2074 7261 6e73  pper=True, trans
+00029e60: 706f 7365 3d46 616c 7365 2c20 756e 6974  pose=False, unit
+00029e70: 7269 616e 6775 6c61 723d 4661 6c73 6529  riangular=False)
+00029e80: 3a0a 2020 2020 2020 2020 6966 2069 735f  :.        if is_
+00029e90: 756e 6465 725f 6173 6365 6e64 5f63 6f6e  under_ascend_con
+00029ea0: 7465 7874 2829 3a0a 2020 2020 2020 2020  text():.        
+00029eb0: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
+00029ec0: 6c65 6d65 6e74 6564 4572 726f 7228 2274  lementedError("t
+00029ed0: 7269 616e 6775 6c61 725f 736f 6c76 6520  riangular_solve 
+00029ee0: 6375 7272 656e 746c 7920 6e6f 7420 7375  currently not su
+00029ef0: 7070 6f72 7465 6420 6f6e 2041 7363 656e  pported on Ascen
+00029f00: 6422 290a 2020 2020 2020 2020 4220 3d20  d").        B = 
+00029f10: 6361 7374 5f74 6f5f 6d73 5f74 656e 736f  cast_to_ms_tenso
+00029f20: 7228 7365 6c66 290a 2020 2020 2020 2020  r(self).        
+00029f30: 4120 3d20 6361 7374 5f74 6f5f 6d73 5f74  A = cast_to_ms_t
+00029f40: 656e 736f 7228 4129 0a20 2020 2020 2020  ensor(A).       
+00029f50: 2074 7261 6e73 203d 2027 5427 2069 6620   trans = 'T' if 
+00029f60: 7472 616e 7370 6f73 6520 656c 7365 2027  transpose else '
+00029f70: 4e27 0a20 2020 2020 2020 2073 6f6c 7665  N'.        solve
+00029f80: 5f6f 7020 3d20 536f 6c76 6554 7269 616e  _op = SolveTrian
+00029f90: 6775 6c61 7228 6c6f 7765 723d 286e 6f74  gular(lower=(not
+00029fa0: 2075 7070 6572 292c 2075 6e69 745f 6469   upper), unit_di
+00029fb0: 6167 6f6e 616c 3d75 6e69 7472 6961 6e67  agonal=unitriang
+00029fc0: 756c 6172 2c20 7472 616e 733d 7472 616e  ular, trans=tran
+00029fd0: 7329 0a20 2020 2020 2020 206f 7574 7075  s).        outpu
+00029fe0: 7420 3d20 736f 6c76 655f 6f70 2841 2c20  t = solve_op(A, 
+00029ff0: 4229 0a20 2020 2020 2020 2069 6620 7079  B).        if py
+0002a000: 6e61 7469 7665 5f6d 6f64 655f 636f 6e64  native_mode_cond
+0002a010: 6974 696f 6e28 293a 0a20 2020 2020 2020  ition():.       
+0002a020: 2020 2020 2074 7269 616e 6775 6c61 725f       triangular_
+0002a030: 736f 6c76 655f 6e61 6d65 6474 7570 6c65  solve_namedtuple
+0002a040: 203d 2073 6574 5f6d 756c 7469 706c 655f   = set_multiple_
+0002a050: 6e61 6d65 5f74 7570 6c65 2827 7472 6961  name_tuple('tria
+0002a060: 6e67 756c 6172 5f73 6f6c 7665 272c 2027  ngular_solve', '
+0002a070: 736f 6c75 7469 6f6e 2c20 636c 6f6e 6564  solution, cloned
+0002a080: 5f63 6f65 6666 6963 6965 6e74 2729 0a20  _coefficient'). 
+0002a090: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+0002a0a0: 7420 3d20 7472 6961 6e67 756c 6172 5f73  t = triangular_s
+0002a0b0: 6f6c 7665 5f6e 616d 6564 7475 706c 6528  olve_namedtuple(
+0002a0c0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+0002a0d0: 7465 6e73 6f72 286f 7574 7075 7429 2c20  tensor(output), 
+0002a0e0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+0002a0f0: 7465 6e73 6f72 2841 2929 0a20 2020 2020  tensor(A)).     
+0002a100: 2020 2020 2020 2072 6574 7572 6e20 6f75         return ou
+0002a110: 7470 7574 0a20 2020 2020 2020 2072 6574  tput.        ret
+0002a120: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+0002a130: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+0002a140: 7429 2c20 6361 7374 5f74 6f5f 6164 6170  t), cast_to_adap
+0002a150: 7465 725f 7465 6e73 6f72 2841 290a 0a20  ter_tensor(A).. 
+0002a160: 2020 2064 6566 2072 656c 7528 7365 6c66     def relu(self
+0002a170: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0002a180: 5f6d 7320 3d20 6361 7374 5f74 6f5f 6d73  _ms = cast_to_ms
+0002a190: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0002a1a0: 2020 2020 2020 6f75 7470 7574 203d 206d        output = m
+0002a1b0: 732e 6f70 732e 7265 6c75 2869 6e70 7574  s.ops.relu(input
+0002a1c0: 5f6d 7329 0a20 2020 2020 2020 2072 6574  _ms).        ret
+0002a1d0: 7572 6e20 6361 7374 5f74 6f5f 6164 6170  urn cast_to_adap
+0002a1e0: 7465 725f 7465 6e73 6f72 286f 7574 7075  ter_tensor(outpu
+0002a1f0: 7429 0a0a 2020 2020 6465 6620 6266 6c6f  t)..    def bflo
+0002a200: 6174 3136 2873 656c 662c 206d 656d 6f72  at16(self, memor
+0002a210: 795f 666f 726d 6174 3d4e 6f6e 6529 3a0a  y_format=None):.
+0002a220: 2020 2020 2020 2020 6966 206d 656d 6f72          if memor
+0002a230: 795f 666f 726d 6174 3a0a 2020 2020 2020  y_format:.      
+0002a240: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+0002a250: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+0002a260: 226d 656d 6f72 795f 666f 726d 6174 2069  "memory_format i
+0002a270: 7320 6e6f 7420 7375 7070 6f72 7465 642e  s not supported.
+0002a280: 2229 0a20 2020 2020 2020 2078 203d 2063  ").        x = c
+0002a290: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0002a2a0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+0002a2b0: 7574 7075 7420 3d20 782e 6173 7479 7065  utput = x.astype
+0002a2c0: 286d 732e 6266 6c6f 6174 3136 290a 2020  (ms.bfloat16).  
+0002a2d0: 2020 2020 2020 7265 7475 726e 2063 6173        return cas
+0002a2e0: 745f 746f 5f61 6461 7074 6572 5f74 656e  t_to_adapter_ten
+0002a2f0: 736f 7228 6f75 7470 7574 290a 0a20 2020  sor(output)..   
+0002a300: 2064 6566 2063 666c 6f61 7428 7365 6c66   def cfloat(self
+0002a310: 2c20 6d65 6d6f 7279 5f66 6f72 6d61 743d  , memory_format=
+0002a320: 4e6f 6e65 293a 0a20 2020 2020 2020 2069  None):.        i
+0002a330: 6620 6d65 6d6f 7279 5f66 6f72 6d61 743a  f memory_format:
+0002a340: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+0002a350: 7365 204e 6f74 496d 706c 656d 656e 7465  se NotImplemente
+0002a360: 6445 7272 6f72 2822 6d65 6d6f 7279 5f66  dError("memory_f
+0002a370: 6f72 6d61 7420 6973 206e 6f74 2073 7570  ormat is not sup
+0002a380: 706f 7274 6564 2e22 290a 2020 2020 2020  ported.").      
+0002a390: 2020 7820 3d20 6361 7374 5f74 6f5f 6d73    x = cast_to_ms
+0002a3a0: 5f74 656e 736f 7228 7365 6c66 290a 2020  _tensor(self).  
+0002a3b0: 2020 2020 2020 6f75 7470 7574 203d 2078        output = x
+0002a3c0: 2e61 7374 7970 6528 6d73 2e63 6f6d 706c  .astype(ms.compl
+0002a3d0: 6578 3634 290a 2020 2020 2020 2020 7265  ex64).        re
+0002a3e0: 7475 726e 2063 6173 745f 746f 5f61 6461  turn cast_to_ada
+0002a3f0: 7074 6572 5f74 656e 736f 7228 6f75 7470  pter_tensor(outp
+0002a400: 7574 290a 0a20 2020 2064 6566 2063 646f  ut)..    def cdo
+0002a410: 7562 6c65 2873 656c 662c 206d 656d 6f72  uble(self, memor
+0002a420: 795f 666f 726d 6174 3d4e 6f6e 6529 3a0a  y_format=None):.
+0002a430: 2020 2020 2020 2020 6966 206d 656d 6f72          if memor
+0002a440: 795f 666f 726d 6174 3a0a 2020 2020 2020  y_format:.      
+0002a450: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+0002a460: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+0002a470: 226d 656d 6f72 795f 666f 726d 6174 2069  "memory_format i
+0002a480: 7320 6e6f 7420 7375 7070 6f72 7465 642e  s not supported.
+0002a490: 2229 0a20 2020 2020 2020 2078 203d 2063  ").        x = c
+0002a4a0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0002a4b0: 2873 656c 6629 0a20 2020 2020 2020 206f  (self).        o
+0002a4c0: 7574 7075 7420 3d20 782e 6173 7479 7065  utput = x.astype
+0002a4d0: 286d 732e 636f 6d70 6c65 7831 3238 290a  (ms.complex128).
+0002a4e0: 2020 2020 2020 2020 7265 7475 726e 2063          return c
+0002a4f0: 6173 745f 746f 5f61 6461 7074 6572 5f74  ast_to_adapter_t
+0002a500: 656e 736f 7228 6f75 7470 7574 290a 0a0a  ensor(output)...
+0002a510: 636c 6173 7320 5f54 7970 6554 656e 736f  class _TypeTenso
+0002a520: 7228 5465 6e73 6f72 293a 0a20 2020 2064  r(Tensor):.    d
+0002a530: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
+0002a540: 2c20 2a69 6e70 7574 5f64 6174 612c 2064  , *input_data, d
+0002a550: 7479 7065 5f6e 616d 6529 3a0a 2020 2020  type_name):.    
+0002a560: 2020 2020 7375 7065 7228 5f54 7970 6554      super(_TypeT
+0002a570: 656e 736f 722c 2073 656c 6629 2e5f 5f69  ensor, self).__i
+0002a580: 6e69 745f 5f28 2a69 6e70 7574 5f64 6174  nit__(*input_dat
+0002a590: 612c 2064 7479 7065 3d64 7479 7065 5f6e  a, dtype=dtype_n
+0002a5a0: 616d 652c 2069 6e6e 6572 3d46 616c 7365  ame, inner=False
+0002a5b0: 290a 0a0a 636c 6173 7320 426f 6f6c 5465  )...class BoolTe
+0002a5c0: 6e73 6f72 285f 5479 7065 5465 6e73 6f72  nsor(_TypeTensor
+0002a5d0: 293a 0a20 2020 2064 6566 205f 5f69 6e69  ):.    def __ini
+0002a5e0: 745f 5f28 7365 6c66 2c20 2a69 6e70 7574  t__(self, *input
+0002a5f0: 5f64 6174 6129 3a0a 2020 2020 2020 2020  _data):.        
+0002a600: 7375 7065 7228 426f 6f6c 5465 6e73 6f72  super(BoolTensor
+0002a610: 2c20 7365 6c66 292e 5f5f 696e 6974 5f5f  , self).__init__
+0002a620: 282a 696e 7075 745f 6461 7461 2c20 6474  (*input_data, dt
+0002a630: 7970 655f 6e61 6d65 3d27 626f 6f6c 2729  ype_name='bool')
+0002a640: 0a0a 0a63 6c61 7373 2042 7974 6554 656e  ...class ByteTen
+0002a650: 736f 7228 5f54 7970 6554 656e 736f 7229  sor(_TypeTensor)
+0002a660: 3a0a 2020 2020 6465 6620 5f5f 696e 6974  :.    def __init
+0002a670: 5f5f 2873 656c 662c 202a 696e 7075 745f  __(self, *input_
+0002a680: 6461 7461 293a 0a20 2020 2020 2020 2073  data):.        s
+0002a690: 7570 6572 2842 7974 6554 656e 736f 722c  uper(ByteTensor,
+0002a6a0: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
+0002a6b0: 2a69 6e70 7574 5f64 6174 612c 2064 7479  *input_data, dty
+0002a6c0: 7065 5f6e 616d 653d 2775 696e 7438 2729  pe_name='uint8')
+0002a6d0: 0a0a 0a63 6c61 7373 2043 6861 7254 656e  ...class CharTen
+0002a6e0: 736f 7228 5f54 7970 6554 656e 736f 7229  sor(_TypeTensor)
+0002a6f0: 3a0a 2020 2020 6465 6620 5f5f 696e 6974  :.    def __init
+0002a700: 5f5f 2873 656c 662c 202a 696e 7075 745f  __(self, *input_
+0002a710: 6461 7461 293a 0a20 2020 2020 2020 2073  data):.        s
+0002a720: 7570 6572 2843 6861 7254 656e 736f 722c  uper(CharTensor,
+0002a730: 2073 656c 6629 2e5f 5f69 6e69 745f 5f28   self).__init__(
+0002a740: 2a69 6e70 7574 5f64 6174 612c 2064 7479  *input_data, dty
+0002a750: 7065 5f6e 616d 653d 2769 6e74 3827 290a  pe_name='int8').
+0002a760: 0a0a 636c 6173 7320 5368 6f72 7454 656e  ..class ShortTen
+0002a770: 736f 7228 5f54 7970 6554 656e 736f 7229  sor(_TypeTensor)
+0002a780: 3a0a 2020 2020 6465 6620 5f5f 696e 6974  :.    def __init
+0002a790: 5f5f 2873 656c 662c 202a 696e 7075 745f  __(self, *input_
+0002a7a0: 6461 7461 293a 0a20 2020 2020 2020 2073  data):.        s
+0002a7b0: 7570 6572 2853 686f 7274 5465 6e73 6f72  uper(ShortTensor
+0002a7c0: 2c20 7365 6c66 292e 5f5f 696e 6974 5f5f  , self).__init__
+0002a7d0: 282a 696e 7075 745f 6461 7461 2c20 6474  (*input_data, dt
+0002a7e0: 7970 655f 6e61 6d65 3d27 696e 7431 3627  ype_name='int16'
+0002a7f0: 290a 0a0a 636c 6173 7320 496e 7454 656e  )...class IntTen
+0002a800: 736f 7228 5f54 7970 6554 656e 736f 7229  sor(_TypeTensor)
+0002a810: 3a0a 2020 2020 6465 6620 5f5f 696e 6974  :.    def __init
+0002a820: 5f5f 2873 656c 662c 202a 696e 7075 745f  __(self, *input_
+0002a830: 6461 7461 293a 0a20 2020 2020 2020 2073  data):.        s
+0002a840: 7570 6572 2849 6e74 5465 6e73 6f72 2c20  uper(IntTensor, 
+0002a850: 7365 6c66 292e 5f5f 696e 6974 5f5f 282a  self).__init__(*
+0002a860: 696e 7075 745f 6461 7461 2c20 6474 7970  input_data, dtyp
+0002a870: 655f 6e61 6d65 3d27 696e 7433 3227 290a  e_name='int32').
+0002a880: 0a0a 636c 6173 7320 4861 6c66 5465 6e73  ..class HalfTens
+0002a890: 6f72 285f 5479 7065 5465 6e73 6f72 293a  or(_TypeTensor):
+0002a8a0: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+0002a8b0: 5f28 7365 6c66 2c20 2a69 6e70 7574 5f64  _(self, *input_d
+0002a8c0: 6174 6129 3a0a 2020 2020 2020 2020 7375  ata):.        su
+0002a8d0: 7065 7228 4861 6c66 5465 6e73 6f72 2c20  per(HalfTensor, 
+0002a8e0: 7365 6c66 292e 5f5f 696e 6974 5f5f 282a  self).__init__(*
+0002a8f0: 696e 7075 745f 6461 7461 2c20 6474 7970  input_data, dtyp
+0002a900: 655f 6e61 6d65 3d27 666c 6f61 7431 3627  e_name='float16'
+0002a910: 290a 0a0a 636c 6173 7320 466c 6f61 7454  )...class FloatT
+0002a920: 656e 736f 7228 5f54 7970 6554 656e 736f  ensor(_TypeTenso
+0002a930: 7229 3a0a 2020 2020 6465 6620 5f5f 696e  r):.    def __in
+0002a940: 6974 5f5f 2873 656c 662c 202a 696e 7075  it__(self, *inpu
+0002a950: 745f 6461 7461 293a 0a20 2020 2020 2020  t_data):.       
+0002a960: 2073 7570 6572 2846 6c6f 6174 5465 6e73   super(FloatTens
+0002a970: 6f72 2c20 7365 6c66 292e 5f5f 696e 6974  or, self).__init
+0002a980: 5f5f 282a 696e 7075 745f 6461 7461 2c20  __(*input_data, 
+0002a990: 6474 7970 655f 6e61 6d65 3d27 666c 6f61  dtype_name='floa
+0002a9a0: 7433 3227 290a 0a0a 636c 6173 7320 446f  t32')...class Do
+0002a9b0: 7562 6c65 5465 6e73 6f72 285f 5479 7065  ubleTensor(_Type
+0002a9c0: 5465 6e73 6f72 293a 0a20 2020 2064 6566  Tensor):.    def
+0002a9d0: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+0002a9e0: 2a69 6e70 7574 5f64 6174 6129 3a0a 2020  *input_data):.  
+0002a9f0: 2020 2020 2020 7375 7065 7228 446f 7562        super(Doub
+0002aa00: 6c65 5465 6e73 6f72 2c20 7365 6c66 292e  leTensor, self).
+0002aa10: 5f5f 696e 6974 5f5f 282a 696e 7075 745f  __init__(*input_
+0002aa20: 6461 7461 2c20 6474 7970 655f 6e61 6d65  data, dtype_name
+0002aa30: 3d27 666c 6f61 7436 3427 290a 0a0a 636c  ='float64')...cl
+0002aa40: 6173 7320 4c6f 6e67 5465 6e73 6f72 285f  ass LongTensor(_
+0002aa50: 5479 7065 5465 6e73 6f72 293a 0a20 2020  TypeTensor):.   
+0002aa60: 2064 6566 205f 5f69 6e69 745f 5f28 7365   def __init__(se
+0002aa70: 6c66 2c20 2a69 6e70 7574 5f64 6174 6129  lf, *input_data)
+0002aa80: 3a0a 2020 2020 2020 2020 7375 7065 7228  :.        super(
+0002aa90: 4c6f 6e67 5465 6e73 6f72 2c20 7365 6c66  LongTensor, self
+0002aaa0: 292e 5f5f 696e 6974 5f5f 282a 696e 7075  ).__init__(*inpu
+0002aab0: 745f 6461 7461 2c20 6474 7970 655f 6e61  t_data, dtype_na
+0002aac0: 6d65 3d27 696e 7436 3427 290a 0a63 6c61  me='int64')..cla
+0002aad0: 7373 2042 466c 6f61 7431 3654 656e 736f  ss BFloat16Tenso
+0002aae0: 7228 5f54 7970 6554 656e 736f 7229 3a0a  r(_TypeTensor):.
+0002aaf0: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+0002ab00: 2873 656c 662c 202a 696e 7075 745f 6461  (self, *input_da
+0002ab10: 7461 293a 0a20 2020 2020 2020 2073 7570  ta):.        sup
+0002ab20: 6572 2842 466c 6f61 7431 3654 656e 736f  er(BFloat16Tenso
+0002ab30: 722c 2073 656c 6629 2e5f 5f69 6e69 745f  r, self).__init_
+0002ab40: 5f28 2a69 6e70 7574 5f64 6174 612c 2064  _(*input_data, d
+0002ab50: 7479 7065 5f6e 616d 653d 2762 666c 6f61  type_name='bfloa
+0002ab60: 7431 3627 290a 0a0a 5f6e 705f 6670 5f74  t16')..._np_fp_t
+0002ab70: 7970 6573 203d 2028 6e70 2e66 6c6f 6174  ypes = (np.float
+0002ab80: 3136 2c20 6e70 2e66 6c6f 6174 3332 2c20  16, np.float32, 
+0002ab90: 6e70 2e66 6c6f 6174 3634 290a 0a64 6566  np.float64)..def
+0002aba0: 205f 6765 745f 6465 6661 756c 745f 6474   _get_default_dt
+0002abb0: 7970 655f 6279 5f64 6174 6128 6461 7461  ype_by_data(data
+0002abc0: 293a 0a20 2020 2069 6620 6973 696e 7374  ):.    if isinst
+0002abd0: 616e 6365 2864 6174 612c 206e 702e 6e64  ance(data, np.nd
+0002abe0: 6172 7261 7929 3a0a 2020 2020 2020 2020  array):.        
+0002abf0: 6f72 6967 696e 5f64 7479 7065 203d 2064  origin_dtype = d
+0002ac00: 6174 612e 6474 7970 650a 2020 2020 656c  ata.dtype.    el
+0002ac10: 6966 2069 7369 6e73 7461 6e63 6528 6461  if isinstance(da
+0002ac20: 7461 2c20 2874 7570 6c65 2c20 6c69 7374  ta, (tuple, list
+0002ac30: 2929 3a0a 2020 2020 2020 2020 6f72 6967  )):.        orig
+0002ac40: 696e 5f64 7479 7065 203d 206e 702e 6172  in_dtype = np.ar
+0002ac50: 7261 7928 6461 7461 292e 6474 7970 650a  ray(data).dtype.
+0002ac60: 2020 2020 656c 6966 2069 7369 6e73 7461      elif isinsta
+0002ac70: 6e63 6528 6461 7461 2c20 666c 6f61 7429  nce(data, float)
+0002ac80: 3a0a 2020 2020 2020 2020 696e 7075 745f  :.        input_
+0002ac90: 6461 7461 203d 206e 702e 6172 7261 7928  data = np.array(
+0002aca0: 6461 7461 290a 2020 2020 2020 2020 6f72  data).        or
+0002acb0: 6967 696e 5f64 7479 7065 203d 2069 6e70  igin_dtype = inp
+0002acc0: 7574 5f64 6174 612e 6474 7970 650a 2020  ut_data.dtype.  
+0002acd0: 2020 656c 7365 3a0a 2020 2020 2020 2020    else:.        
+0002ace0: 7265 7475 726e 204e 6f6e 650a 0a20 2020  return None..   
+0002acf0: 2069 6620 6f72 6967 696e 5f64 7479 7065   if origin_dtype
+0002ad00: 2069 6e20 5f6e 705f 6670 5f74 7970 6573   in _np_fp_types
+0002ad10: 3a0a 2020 2020 2020 2020 6465 6661 756c  :.        defaul
+0002ad20: 745f 6474 7970 6520 3d20 6765 745f 6465  t_dtype = get_de
+0002ad30: 6661 756c 745f 6474 7970 6528 290a 2020  fault_dtype().  
+0002ad40: 2020 2020 2020 7265 7475 726e 2064 6566        return def
+0002ad50: 6175 6c74 5f64 7479 7065 0a20 2020 2072  ault_dtype.    r
+0002ad60: 6574 7572 6e20 4e6f 6e65 0a0a 6465 6620  eturn None..def 
+0002ad70: 7465 6e73 6f72 2864 6174 612c 2064 7479  tensor(data, dty
+0002ad80: 7065 3d4e 6f6e 652c 2064 6576 6963 653d  pe=None, device=
+0002ad90: 4e6f 6e65 2c20 7265 7175 6972 6573 5f67  None, requires_g
+0002ada0: 7261 643d 4661 6c73 6529 3a0a 2020 2020  rad=False):.    
+0002adb0: 756e 7375 7070 6f72 7465 645f 6174 7472  unsupported_attr
+0002adc0: 2864 6576 6963 6529 0a20 2020 2069 6620  (device).    if 
+0002add0: 6474 7970 6520 6973 204e 6f6e 6520 616e  dtype is None an
+0002ade0: 6420 5f6e 6f74 5f64 6566 6175 6c74 5f66  d _not_default_f
+0002adf0: 7033 325f 6474 7970 6528 293a 0a20 2020  p32_dtype():.   
+0002ae00: 2020 2020 2064 7479 7065 203d 205f 6765       dtype = _ge
+0002ae10: 745f 6465 6661 756c 745f 6474 7970 655f  t_default_dtype_
+0002ae20: 6279 5f64 6174 6128 6461 7461 290a 0a20  by_data(data).. 
+0002ae30: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+0002ae40: 2864 6174 612c 2028 7475 706c 652c 206c  (data, (tuple, l
+0002ae50: 6973 7429 2920 616e 6420 6e6f 7420 6461  ist)) and not da
+0002ae60: 7461 3a0a 2020 2020 2020 2020 7265 7475  ta:.        retu
+0002ae70: 726e 2054 656e 736f 7228 2a64 6174 612c  rn Tensor(*data,
+0002ae80: 2072 6571 7569 7265 735f 6772 6164 3d72   requires_grad=r
+0002ae90: 6571 7569 7265 735f 6772 6164 2c20 6474  equires_grad, dt
+0002aea0: 7970 653d 6474 7970 652c 2069 6e6e 6572  ype=dtype, inner
+0002aeb0: 3d46 616c 7365 290a 0a20 2020 2072 6574  =False)..    ret
+0002aec0: 7572 6e20 5465 6e73 6f72 2864 6174 612c  urn Tensor(data,
+0002aed0: 2072 6571 7569 7265 735f 6772 6164 3d72   requires_grad=r
+0002aee0: 6571 7569 7265 735f 6772 6164 2c20 6474  equires_grad, dt
+0002aef0: 7970 653d 6474 7970 652c 2069 6e6e 6572  ype=dtype, inner
+0002af00: 3d54 7275 6529 0a0a 6465 6620 6361 7374  =True)..def cast
+0002af10: 5f74 6f5f 6d73 5f74 656e 736f 7228 696e  _to_ms_tensor(in
+0002af20: 7075 7473 293a 0a20 2020 2022 2222 0a20  puts):.    """. 
+0002af30: 2020 2043 6173 7420 4d69 6e64 546f 7263     Cast MindTorc
+0002af40: 682e 5465 6e73 6f72 2074 6f20 4d69 6e64  h.Tensor to Mind
+0002af50: 5370 6f72 652e 5465 6e73 6f72 2062 6566  Spore.Tensor bef
+0002af60: 6f72 6520 6361 6c6c 206d 696e 6473 706f  ore call mindspo
+0002af70: 7265 2041 5049 2e0a 2020 2020 2222 220a  re API..    """.
+0002af80: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+0002af90: 6528 696e 7075 7473 2c20 5465 6e73 6f72  e(inputs, Tensor
+0002afa0: 293a 0a20 2020 2020 2020 2069 6e70 7574  ):.        input
+0002afb0: 7320 3d20 696e 6e65 722e 636f 6e76 6572  s = inner.conver
+0002afc0: 745f 746f 5f6d 735f 7465 6e73 6f72 2869  t_to_ms_tensor(i
+0002afd0: 6e70 7574 7329 0a20 2020 2065 6c69 6620  nputs).    elif 
+0002afe0: 6973 696e 7374 616e 6365 2869 6e70 7574  isinstance(input
+0002aff0: 732c 2074 7570 6c65 293a 0a20 2020 2020  s, tuple):.     
+0002b000: 2020 2069 6e70 7574 735f 7475 706c 6520     inputs_tuple 
+0002b010: 3d20 2829 0a20 2020 2020 2020 2066 6f72  = ().        for
+0002b020: 2076 616c 7565 2069 6e20 696e 7075 7473   value in inputs
+0002b030: 3a0a 2020 2020 2020 2020 2020 2020 696e  :.            in
+0002b040: 7075 7473 5f74 7570 6c65 202b 3d20 2863  puts_tuple += (c
+0002b050: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0002b060: 2876 616c 7565 292c 2029 0a20 2020 2020  (value), ).     
+0002b070: 2020 2069 6e70 7574 7320 3d20 696e 7075     inputs = inpu
+0002b080: 7473 5f74 7570 6c65 0a20 2020 2065 6c69  ts_tuple.    eli
+0002b090: 6620 6973 696e 7374 616e 6365 2869 6e70  f isinstance(inp
+0002b0a0: 7574 732c 206c 6973 7429 3a0a 2020 2020  uts, list):.    
+0002b0b0: 2020 2020 696e 7075 7473 5f6c 6973 7420      inputs_list 
+0002b0c0: 3d20 5b5d 0a20 2020 2020 2020 2066 6f72  = [].        for
+0002b0d0: 2076 616c 7565 2069 6e20 696e 7075 7473   value in inputs
+0002b0e0: 3a0a 2020 2020 2020 2020 2020 2020 696e  :.            in
+0002b0f0: 7075 7473 5f6c 6973 742e 6170 7065 6e64  puts_list.append
+0002b100: 2863 6173 745f 746f 5f6d 735f 7465 6e73  (cast_to_ms_tens
+0002b110: 6f72 2876 616c 7565 2929 0a20 2020 2020  or(value)).     
+0002b120: 2020 2069 6e70 7574 7320 3d20 696e 7075     inputs = inpu
+0002b130: 7473 5f6c 6973 740a 2020 2020 656c 6966  ts_list.    elif
+0002b140: 2069 7369 6e73 7461 6e63 6528 696e 7075   isinstance(inpu
+0002b150: 7473 2c20 6469 6374 293a 0a20 2020 2020  ts, dict):.     
+0002b160: 2020 2066 6f72 206b 6579 2c20 7661 6c75     for key, valu
+0002b170: 6520 696e 2069 6e70 7574 732e 6974 656d  e in inputs.item
+0002b180: 7328 293a 0a20 2020 2020 2020 2020 2020  s():.           
+0002b190: 2069 6e70 7574 735b 6b65 795d 203d 2063   inputs[key] = c
+0002b1a0: 6173 745f 746f 5f6d 735f 7465 6e73 6f72  ast_to_ms_tensor
+0002b1b0: 2876 616c 7565 290a 2020 2020 7265 7475  (value).    retu
+0002b1c0: 726e 2069 6e70 7574 730a 0a0a 6465 6620  rn inputs...def 
+0002b1d0: 6361 7374 5f74 6f5f 6164 6170 7465 725f  cast_to_adapter_
+0002b1e0: 7465 6e73 6f72 286f 7574 7075 7473 293a  tensor(outputs):
+0002b1f0: 0a20 2020 2022 2222 0a20 2020 2043 6173  .    """.    Cas
+0002b200: 7420 4d69 6e64 5370 6f72 652e 5465 6e73  t MindSpore.Tens
+0002b210: 6f72 2074 6f20 4d69 6e64 546f 7263 682e  or to MindTorch.
+0002b220: 5465 6e73 6f72 2061 6674 6572 2063 616c  Tensor after cal
+0002b230: 6c20 6d69 6e64 7370 6f72 6520 4150 492e  l mindspore API.
+0002b240: 0a20 2020 2022 2222 0a20 2020 2069 6620  .    """.    if 
+0002b250: 6973 696e 7374 616e 6365 286f 7574 7075  isinstance(outpu
+0002b260: 7473 2c20 2853 7475 6254 656e 736f 722c  ts, (StubTensor,
+0002b270: 206d 732e 5465 6e73 6f72 2929 3a0a 2020   ms.Tensor)):.  
+0002b280: 2020 2020 2020 6f75 7470 7574 7320 3d20        outputs = 
+0002b290: 696e 6e65 722e 636f 6e76 6572 745f 746f  inner.convert_to
+0002b2a0: 5f61 6461 7074 6572 5f74 656e 736f 7228  _adapter_tensor(
+0002b2b0: 6f75 7470 7574 7329 0a20 2020 2065 6c69  outputs).    eli
+0002b2c0: 6620 6973 696e 7374 616e 6365 286f 7574  f isinstance(out
+0002b2d0: 7075 7473 2c20 7475 706c 6529 3a0a 2020  puts, tuple):.  
+0002b2e0: 2020 2020 2020 6f75 7470 7574 735f 7475        outputs_tu
+0002b2f0: 706c 6520 3d20 2829 0a20 2020 2020 2020  ple = ().       
+0002b300: 2066 6f72 2076 616c 7565 2069 6e20 6f75   for value in ou
+0002b310: 7470 7574 733a 0a20 2020 2020 2020 2020  tputs:.         
+0002b320: 2020 206f 7574 7075 7473 5f74 7570 6c65     outputs_tuple
+0002b330: 202b 3d20 2863 6173 745f 746f 5f61 6461   += (cast_to_ada
+0002b340: 7074 6572 5f74 656e 736f 7228 7661 6c75  pter_tensor(valu
+0002b350: 6529 2c20 290a 2020 2020 2020 2020 6f75  e), ).        ou
+0002b360: 7470 7574 7320 3d20 6f75 7470 7574 735f  tputs = outputs_
+0002b370: 7475 706c 650a 2020 2020 656c 6966 2069  tuple.    elif i
+0002b380: 7369 6e73 7461 6e63 6528 6f75 7470 7574  sinstance(output
+0002b390: 732c 206c 6973 7429 3a0a 2020 2020 2020  s, list):.      
+0002b3a0: 2020 6f75 7470 7574 735f 6c69 7374 203d    outputs_list =
+0002b3b0: 205b 5d0a 2020 2020 2020 2020 666f 7220   [].        for 
+0002b3c0: 7661 6c75 6520 696e 206f 7574 7075 7473  value in outputs
+0002b3d0: 3a0a 2020 2020 2020 2020 2020 2020 6f75  :.            ou
+0002b3e0: 7470 7574 735f 6c69 7374 2e61 7070 656e  tputs_list.appen
+0002b3f0: 6428 6361 7374 5f74 6f5f 6164 6170 7465  d(cast_to_adapte
+0002b400: 725f 7465 6e73 6f72 2876 616c 7565 2929  r_tensor(value))
+0002b410: 0a20 2020 2020 2020 206f 7574 7075 7473  .        outputs
+0002b420: 203d 206f 7574 7075 7473 5f6c 6973 740a   = outputs_list.
+0002b430: 2020 2020 656c 6966 2069 7369 6e73 7461      elif isinsta
+0002b440: 6e63 6528 6f75 7470 7574 732c 2064 6963  nce(outputs, dic
+0002b450: 7429 3a0a 2020 2020 2020 2020 666f 7220  t):.        for 
+0002b460: 6b65 792c 2076 616c 7565 2069 6e20 6f75  key, value in ou
+0002b470: 7470 7574 732e 6974 656d 7328 293a 0a20  tputs.items():. 
+0002b480: 2020 2020 2020 2020 2020 206f 7574 7075             outpu
+0002b490: 7473 5b6b 6579 5d20 3d20 6361 7374 5f74  ts[key] = cast_t
+0002b4a0: 6f5f 6164 6170 7465 725f 7465 6e73 6f72  o_adapter_tensor
+0002b4b0: 2876 616c 7565 290a 2020 2020 7265 7475  (value).    retu
+0002b4c0: 726e 206f 7574 7075 7473 0a0a 0a64 6566  rn outputs...def
+0002b4d0: 205f 7465 6e73 6f72 5f69 6e70 6c61 6365   _tensor_inplace
+0002b4e0: 5f61 7373 6967 6e28 696e 7075 742c 206f  _assign(input, o
+0002b4f0: 7574 7075 742c 206f 705f 6e61 6d65 2c20  utput, op_name, 
+0002b500: 7265 706c 6163 655f 6f70 293a 0a20 2020  replace_op):.   
+0002b510: 2023 2069 6620 7079 6e61 7469 7665 5f6d   # if pynative_m
+0002b520: 6f64 655f 636f 6e64 6974 696f 6e28 293a  ode_condition():
+0002b530: 2020 2320 544f 444f 3a20 6d73 5f66 756e    # TODO: ms_fun
+0002b540: 6374 696f 6e0a 2020 2020 2320 2020 2020  ction.    #     
+0002b550: 696e 7075 742e 6173 7369 676e 5f76 616c  input.assign_val
+0002b560: 7565 286f 7574 7075 7429 0a20 2020 2023  ue(output).    #
+0002b570: 2020 2020 2072 6574 7572 6e20 696e 7075       return inpu
+0002b580: 740a 0a20 2020 2023 2054 4f44 4f3a 2074  t..    # TODO: t
+0002b590: 656e 736f 7220 6170 6920 7769 6c6c 2062  ensor api will b
+0002b5a0: 6520 7573 6564 2069 6e20 696e 6974 2064  e used in init d
+0002b5b0: 6174 612c 2062 7574 2069 7420 6361 6e20  ata, but it can 
+0002b5c0: 6e6f 7420 6265 2075 7365 6420 696e 2067  not be used in g
+0002b5d0: 7261 7068 2e0a 2020 2020 6966 2067 7261  raph..    if gra
+0002b5e0: 7068 5f6d 6f64 655f 636f 6e64 6974 696f  ph_mode_conditio
+0002b5f0: 6e28 293a 0a20 2020 2020 2020 2072 6169  n():.        rai
+0002b600: 7365 2052 756e 7469 6d65 4572 726f 7228  se RuntimeError(
+0002b610: 2760 5465 6e73 6f72 2e7b 617d 6020 6973  '`Tensor.{a}` is
+0002b620: 2061 6e20 696e 2d70 6c61 6365 206f 7065   an in-place ope
+0002b630: 7261 7469 6f6e 2061 6e64 2022 782e 7b61  ration and "x.{a
+0002b640: 7d28 2922 2069 7320 6e6f 7420 7375 7070  }()" is not supp
+0002b650: 6f72 7465 6420 746f 2075 7365 2027 0a20  orted to use '. 
+0002b660: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002b670: 2020 2020 2020 2020 2020 2769 6e20 4d69            'in Mi
+0002b680: 6e64 5370 6f72 6520 7374 6174 6963 2067  ndSpore static g
+0002b690: 7261 7068 206d 6f64 652e 2050 6c65 6173  raph mode. Pleas
+0002b6a0: 6520 7573 6520 2278 203d 2078 2e7b 627d  e use "x = x.{b}
+0002b6b0: 2829 2220 6f72 206f 7468 6572 2041 5049  ()" or other API
+0002b6c0: 2027 0a20 2020 2020 2020 2020 2020 2020   '.             
+0002b6d0: 2020 2020 2020 2020 2020 2020 2020 2769                'i
+0002b6e0: 6e73 7465 6164 2e27 2e66 6f72 6d61 7428  nstead.'.format(
+0002b6f0: 613d 6f70 5f6e 616d 652c 2062 3d72 6570  a=op_name, b=rep
+0002b700: 6c61 6365 5f6f 7029 290a 0a20 2020 2069  lace_op))..    i
+0002b710: 6e66 6f28 2760 5465 6e73 6f72 2e7b 617d  nfo('`Tensor.{a}
+0002b720: 6020 6973 2061 6e20 696e 2d70 6c61 6365  ` is an in-place
+0002b730: 206f 7065 7261 7469 6f6e 2061 6e64 2022   operation and "
+0002b740: 782e 7b61 7d28 2922 2069 7320 6e6f 7420  x.{a}()" is not 
+0002b750: 656e 636f 7572 6167 6564 2074 6f20 7573  encouraged to us
+0002b760: 6520 696e 204d 696e 6453 706f 7265 2e20  e in MindSpore. 
+0002b770: 2720 5c0a 2020 2020 2020 2020 2027 506c  ' \.         'Pl
+0002b780: 6561 7365 2075 7365 2022 7820 3d20 782e  ease use "x = x.
+0002b790: 7b62 7d28 2922 206f 7220 6f74 6865 7220  {b}()" or other 
+0002b7a0: 4150 4920 696e 7374 6561 642e 272e 666f  API instead.'.fo
+0002b7b0: 726d 6174 2861 3d6f 705f 6e61 6d65 2c20  rmat(a=op_name, 
+0002b7c0: 623d 7265 706c 6163 655f 6f70 2929 0a20  b=replace_op)). 
+0002b7d0: 2020 2075 6e73 7570 706f 7274 6564 5f61     unsupported_a
+0002b7e0: 7474 7228 6f70 5f6e 616d 6529 0a20 2020  ttr(op_name).   
+0002b7f0: 2075 6e73 7570 706f 7274 6564 5f61 7474   unsupported_att
+0002b800: 7228 7265 706c 6163 655f 6f70 290a 2020  r(replace_op).  
+0002b810: 2020 2320 5061 7373 2060 6361 7374 5f74    # Pass `cast_t
+0002b820: 6f5f 6d73 5f74 656e 736f 7228 6f75 7470  o_ms_tensor(outp
+0002b830: 7574 2960 2066 6f72 2070 6572 666f 726d  ut)` for perform
+0002b840: 616e 6365 2c20 6164 6420 6974 2062 6163  ance, add it bac
+0002b850: 6b20 7768 656e 206e 6565 6465 642e 0a20  k when needed.. 
+0002b860: 2020 2069 6e70 7574 2e61 7373 6967 6e5f     input.assign_
+0002b870: 7661 6c75 6528 6f75 7470 7574 290a 2020  value(output).  
+0002b880: 2020 7265 7475 726e 2069 6e70 7574 0a0a    return input..
+0002b890: 6465 6620 5f67 616d 6d61 5f74 7970 6528  def _gamma_type(
+0002b8a0: 696e 7075 745f 6d73 2c20 6f74 6865 725f  input_ms, other_
+0002b8b0: 6d73 293a 0a20 2020 2069 6e70 7574 5f74  ms):.    input_t
+0002b8c0: 7970 6520 3d20 696e 7075 745f 6d73 2e64  ype = input_ms.d
+0002b8d0: 7479 7065 0a20 2020 206f 7468 6572 5f74  type.    other_t
+0002b8e0: 7970 6520 3d20 6f74 6865 725f 6d73 2e64  ype = other_ms.d
+0002b8f0: 7479 7065 0a20 2020 2066 6c6f 6174 5f66  type.    float_f
+0002b900: 6c61 6720 3d20 4661 6c73 650a 2020 2020  lag = False.    
+0002b910: 6966 2069 6e70 7574 5f74 7970 6520 3d3d  if input_type ==
+0002b920: 206d 732e 666c 6f61 7436 3420 6f72 206f   ms.float64 or o
+0002b930: 7468 6572 5f74 7970 6520 3d3d 206d 732e  ther_type == ms.
+0002b940: 666c 6f61 7436 343a 0a20 2020 2020 2020  float64:.       
+0002b950: 2069 6e70 7574 5f6d 7320 3d20 696e 7075   input_ms = inpu
+0002b960: 745f 6d73 2e61 7374 7970 6528 6d73 2e66  t_ms.astype(ms.f
+0002b970: 6c6f 6174 3634 290a 2020 2020 2020 2020  loat64).        
+0002b980: 6f74 6865 725f 6d73 203d 206f 7468 6572  other_ms = other
+0002b990: 5f6d 732e 6173 7479 7065 286d 732e 666c  _ms.astype(ms.fl
+0002b9a0: 6f61 7436 3429 0a20 2020 2065 6c73 653a  oat64).    else:
+0002b9b0: 0a20 2020 2020 2020 2069 6620 696e 7075  .        if inpu
+0002b9c0: 745f 7479 7065 203d 3d20 6d73 2e66 6c6f  t_type == ms.flo
+0002b9d0: 6174 3136 2061 6e64 206f 7468 6572 5f74  at16 and other_t
+0002b9e0: 7970 6520 3d3d 206d 732e 666c 6f61 7431  ype == ms.float1
+0002b9f0: 363a 0a20 2020 2020 2020 2020 2020 2066  6:.            f
+0002ba00: 6c6f 6174 5f66 6c61 6720 3d20 5472 7565  loat_flag = True
+0002ba10: 0a20 2020 2020 2020 2069 6e70 7574 5f6d  .        input_m
+0002ba20: 7320 3d20 696e 7075 745f 6d73 2e61 7374  s = input_ms.ast
+0002ba30: 7970 6528 6d73 2e66 6c6f 6174 3332 290a  ype(ms.float32).
+0002ba40: 2020 2020 2020 2020 6f74 6865 725f 6d73          other_ms
+0002ba50: 203d 206f 7468 6572 5f6d 732e 6173 7479   = other_ms.asty
+0002ba60: 7065 286d 732e 666c 6f61 7433 3229 0a20  pe(ms.float32). 
+0002ba70: 2020 2072 6574 7572 6e20 696e 7075 745f     return input_
+0002ba80: 6d73 2c20 6f74 6865 725f 6d73 2c20 666c  ms, other_ms, fl
+0002ba90: 6f61 745f 666c 6167 0a0a 6465 6620 5f6c  oat_flag..def _l
+0002baa0: 755f 6661 6374 6f72 2841 2c20 2a2c 2070  u_factor(A, *, p
+0002bab0: 6976 6f74 3d54 7275 6529 3a0a 2020 2020  ivot=True):.    
+0002bac0: 2354 4f44 4f3a 204d 696e 6473 706f 7265  #TODO: Mindspore
+0002bad0: 2064 6f65 7320 6e6f 7420 7375 7070 6f72   does not suppor
+0002bae0: 7420 7069 766f 743d 4661 6c73 6520 636f  t pivot=False co
+0002baf0: 6e64 6974 696f 6e0a 2020 2020 6966 206e  ndition.    if n
+0002bb00: 6f74 2070 6976 6f74 3a0a 2020 2020 2020  ot pivot:.      
+0002bb10: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
+0002bb20: 6d65 6e74 6564 4572 726f 7228 226c 7520  mentedError("lu 
+0002bb30: 6375 7272 656e 746c 7920 6e6f 7420 7375  currently not su
+0002bb40: 7070 6f72 7465 6420 7069 766f 743d 4661  pported pivot=Fa
+0002bb50: 6c73 6522 290a 2020 2020 696e 6e65 725f  lse").    inner_
+0002bb60: 6c75 5f66 6163 746f 725f 6f70 203d 206e  lu_factor_op = n
+0002bb70: 756d 7079 5f63 656c 6c2e 4e75 6d70 794c  umpy_cell.NumpyL
+0002bb80: 5546 6163 746f 7228 276c 7527 290a 2020  UFactor('lu').  
+0002bb90: 2020 6f75 7470 7574 203d 2069 6e6e 6572    output = inner
+0002bba0: 5f6c 755f 6661 6374 6f72 5f6f 7028 4129  _lu_factor_op(A)
+0002bbb0: 0a20 2020 2072 6574 7572 6e20 6f75 7470  .    return outp
+0002bbc0: 7574 0a0a 6465 6620 5f6c 755f 6661 6374  ut..def _lu_fact
+0002bbd0: 6f72 5f65 7828 412c 202a 2c20 7069 766f  or_ex(A, *, pivo
+0002bbe0: 743d 5472 7565 293a 0a20 2020 2023 544f  t=True):.    #TO
+0002bbf0: 444f 3a20 4d69 6e64 7370 6f72 6520 646f  DO: Mindspore do
+0002bc00: 6573 206e 6f74 2073 7570 706f 7274 2070  es not support p
+0002bc10: 6976 6f74 3d46 616c 7365 2063 6f6e 6469  ivot=False condi
+0002bc20: 7469 6f6e 0a20 2020 2069 6620 6e6f 7420  tion.    if not 
+0002bc30: 7069 766f 743a 0a20 2020 2020 2020 2072  pivot:.        r
+0002bc40: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
+0002bc50: 7465 6445 7272 6f72 2822 6c75 2063 7572  tedError("lu cur
+0002bc60: 7265 6e74 6c79 206e 6f74 2073 7570 706f  rently not suppo
+0002bc70: 7274 6564 2070 6976 6f74 3d46 616c 7365  rted pivot=False
+0002bc80: 2229 0a20 2020 2069 6e6e 6572 5f6c 755f  ").    inner_lu_
+0002bc90: 6661 6374 6f72 5f6f 7020 3d20 6e75 6d70  factor_op = nump
+0002bca0: 795f 6365 6c6c 2e4e 756d 7079 4c55 4661  y_cell.NumpyLUFa
+0002bcb0: 6374 6f72 2827 6c75 2729 0a20 2020 206f  ctor('lu').    o
+0002bcc0: 7574 7075 7420 3d20 696e 6e65 725f 6c75  utput = inner_lu
+0002bcd0: 5f66 6163 746f 725f 6f70 2841 290a 2020  _factor_op(A).  
+0002bce0: 2020 696e 666f 203d 2030 0a20 2020 2072    info = 0.    r
+0002bcf0: 6574 7572 6e20 6f75 7470 7574 2c20 696e  eturn output, in
+0002bd00: 666f 0a0a 6465 6620 5f63 6f6e 7665 7274  fo..def _convert
+0002bd10: 5f73 6861 7065 5f74 6f5f 696e 7428 7368  _shape_to_int(sh
+0002bd20: 6170 6529 3a0a 2020 2020 5f73 6861 7065  ape):.    _shape
+0002bd30: 203d 206c 6973 7428 7368 6170 6529 0a20   = list(shape). 
+0002bd40: 2020 2066 6f72 2069 2c20 7320 696e 2065     for i, s in e
+0002bd50: 6e75 6d65 7261 7465 2873 6861 7065 293a  numerate(shape):
+0002bd60: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
+0002bd70: 7374 616e 6365 2873 2c20 696e 7429 3a0a  stance(s, int):.
+0002bd80: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+0002bd90: 696e 7565 0a20 2020 2020 2020 2069 6620  inue.        if 
+0002bda0: 6973 696e 7374 616e 6365 2873 2c20 5465  isinstance(s, Te
+0002bdb0: 6e73 6f72 2920 616e 6420 732e 6474 7970  nsor) and s.dtyp
+0002bdc0: 6520 696e 2061 6c6c 5f69 6e74 5f74 7970  e in all_int_typ
+0002bdd0: 653a 0a20 2020 2020 2020 2020 2020 205f  e:.            _
+0002bde0: 7368 6170 655b 695d 203d 2073 2e69 7465  shape[i] = s.ite
+0002bdf0: 6d28 290a 2020 2020 2020 2020 656c 7365  m().        else
+0002be00: 3a0a 2020 2020 2020 2020 2020 2020 7261  :.            ra
+0002be10: 6973 6520 5479 7065 4572 726f 7228 2273  ise TypeError("s
+0002be20: 6861 7065 206d 7573 7420 6265 2074 7570  hape must be tup
+0002be30: 6c65 206f 6620 696e 7473 2c20 220a 2020  le of ints, ".  
+0002be40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0002be50: 2020 2020 2020 2020 2020 6622 6275 7420            f"but 
+0002be60: 666f 756e 6420 656c 656d 656e 7420 6f66  found element of
+0002be70: 2074 7970 6520 5465 6e73 6f72 2061 7420   type Tensor at 
+0002be80: 706f 7320 7b69 7d22 290a 2020 2020 7265  pos {i}").    re
+0002be90: 7475 726e 2074 7570 6c65 285f 7368 6170  turn tuple(_shap
+0002bea0: 6529 0a                                  e).
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/torch_version.py` & `mindtorch-0.3.0/mindtorch/torch/torch_version.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/types.py` & `mindtorch-0.3.0/mindtorch/torch/types.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 #!/usr/bin/env python
 import builtins
-from typing import Any,  Union
+from typing import Union
 import mindspore as ms
 from mindtorch.utils import unsupported_attr, get_backend
 
 @ms.jit_class
 class device():
     def __init__(self, type=None, index=None):
         if type is not None:
@@ -70,44 +70,11 @@
 
 @ms.jit_class
 class Storage():
     def _print(self):
         raise NotImplementedError("`Storage` is not currently supported, please delete it, "
                                   "and that will not affect the calculation results.")
 
-    def __deepcopy__(self, memo) -> 'Storage':
-        unsupported_attr(memo)
-        self._print()
-
-    def _new_shared(self, int) -> 'Storage':
-        unsupported_attr(int)
-        self._print()
-
-    def _write_file(self, f: Any, is_real_file: _bool, save_size: _bool, element_size: int) -> None:
-        unsupported_attr(f, is_real_file, save_size, element_size)
-        self._print()
-
-    def element_size(self) -> int:
-        self._print()
-
-    def is_shared(self) -> bool:
-        self._print()
-
-    def share_memory_(self) -> 'Storage':
-        self._print()
-
-    def nbytes(self) -> int:
-        self._print()
-
-    def cpu(self) -> 'Storage':
-        self._print()
-
-    def data_ptr(self) -> int:
-        self._print()
-
-    def from_file(self, filename: str, shared: bool = False, nbytes: int = 0) -> 'Storage':
-        unsupported_attr(filename, shared, nbytes)
-        self._print()
-
-    def _new_with_file(self, f: Any, element_size: int) -> 'Storage':
-        unsupported_attr(f, element_size)
+    def _new_with_file(self, f, element_size):
+        unsupported_attr(f)
+        unsupported_attr(element_size)
         self._print()
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/_pytree.py` & `mindtorch-0.3.0/mindtorch/torch/utils/_pytree.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/checkpoint.py` & `mindtorch-0.3.0/mindtorch/torch/utils/checkpoint.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,12 +1,13 @@
+from mindtorch.torch.tensor import Tensor
 from ..nn.modules.container import Sequential
 from .._utils import warning
 
 __all__ = [
-    "checkpoint", "checkpoint_sequential",
+    "checkpoint", "checkpoint_sequential", "detach_variable"
 ]
 
 
 def checkpoint(function, *args, use_reentrant: bool = True, **kwargs):
     #preserve = kwargs.pop('preserve_rng_state', True)
     if kwargs and use_reentrant:
         raise ValueError("Unexpected keyword arguments: " + ",".join(arg for arg in kwargs))
@@ -40,7 +41,23 @@
         input = checkpoint(
             run_function(start, end, functions),
             input,
             use_reentrant=use_reentrant,
             preserve_rng_state=preserve
         )
     return run_function(end + 1, len(functions) - 1, functions)(input)
+
+def detach_variable(inputs):
+    if isinstance(inputs, tuple):
+        out = []
+        for inp in inputs:
+            if not isinstance(inp, Tensor):
+                out.append(inp)
+                continue
+
+            x = inp.detach()
+            x.requires_grad = inp.requires_grad
+            out.append(x)
+        return tuple(out)
+    else:
+        raise RuntimeError(
+            "Only tuple of tensors is supported. Got Unsupported input type: ", type(inputs).__name__)
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/cpp_extension.py` & `mindtorch-0.3.0/mindtorch/torch/utils/cpp_extension.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/__init__.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/collate.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/collate.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/fetch.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/fetch.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/pin_memory.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/pin_memory.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,27 +3,24 @@
 """
 from __future__ import absolute_import
 
 import collections
 import queue
 
 import mindtorch.torch as torch
-import mindspore as ms
 from mindtorch.torch._six import string_classes
 from . import MP_STATUS_CHECK_INTERVAL
 from mindtorch.torch._utils import ExceptionWrapper
 
 
 def _pin_memory_loop(in_queue, out_queue, device_id, done_event, device):
     # This setting is thread local, and prevents the copy in pin_memory from
     # consuming all CPU cores.
     # torch.set_num_threads(1) TODO:
 
-    ms.set_context(device_id=device_id)
-
     # See NOTE [ Data Loader Multiprocessing Shutdown Logic ] for details on the
     # logic of this function.
     while not done_event.is_set():
         try:
             r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
         except queue.Empty:
             continue
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/queue.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/queue.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 import traceback
 from multiprocessing import context
 import multiprocessing.queues
 import multiprocessing
 import types
 import numpy as np
 import mindtorch.torch as torch
-from mindtorch.torch.logging import warning
+from mindtorch.torch.logging import info
 
 class KeyErrorParse(str):
     """re-implement repr method, which returns itself in repr"""
     def __repr__(self):
         return self
 
 class ExceptionHandler:
@@ -115,15 +115,15 @@
                         byte = 8 * ((byte + 7) // 8)
                         self.put_start_bytes += byte
                         bufferlist.append((self.data_shared, seg_pos, byte, r.dtype, r.shape))
                     else:
                         if isinstance(r, np.ndarray) and r.size > self.min_shared_mem:
                             # Only print out error the first time it happens
                             if self.count.value == 0 and self.print_error:
-                                warning(
+                                info(
                                     "Using shared memory queue, but rowsize is larger than allocated memory "
                                     + "max_rowsize: "
                                     + str(self.seg_size / 1024 / 1024)
                                     + "MB, current rowsize: "
                                     + str((self.put_start_bytes + r.nbytes) / 1024 / 1024)
                                     + "MB."
                                 )
@@ -180,8 +180,7 @@
     def __del__(self):
         shm_list_len = len(self.shm_list)
         for idx in range(shm_list_len):
             del self.shm_list[shm_list_len - idx - 1]
         del self.shm_list
 
         self.close()
-
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/signal_handling.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/signal_handling.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/_utils/worker.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/_utils/worker.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/dataloader.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/dataloader.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,21 +2,21 @@
 
 To support these two classes, in `./_utils` we define many utility methods and
 functions to be run in multiprocessing. E.g., the data loading worker loop is
 in `./_utils/worker.py`.
 """
 from __future__ import absolute_import
 
-import functools
+import sys
 import itertools
 import logging
 import os
 import queue
 import math
-import multiprocessing as multiprocessing
+import mindtorch.torch.multiprocessing as multiprocessing
 from typing import Any, Callable, Iterable, TypeVar, Generic, Sequence, List, Optional, Union
 import numpy as np
 import mindtorch.torch as torch
 # import mindtorch.torch.utils.data.graph_settings
 
 from mindtorch.torch._utils import ExceptionWrapper
 from mindtorch.torch._six import string_classes
@@ -43,17 +43,15 @@
     "get_worker_info",
     "default_collate",
     "default_convert",
 ]
 
 _MP_MODE_ENV = os.environ.get('ENABLE_FORK_UTILS')
 
-if _MP_MODE_ENV == "1":
-    os.environ['MS_ENABLE_FORK_UTILS'] = '1'
-else:
+if _MP_MODE_ENV == "0":
     multiprocessing.set_start_method('spawn', force=True)
 
 
 T_co = TypeVar('T_co', covariant=True)
 T = TypeVar('T')
 _worker_init_fn_t = Callable[[int], None]
 
@@ -216,22 +214,27 @@
     prefetch_factor: int
     _iterator : Optional['_BaseDataLoaderIter']
     __initialized = False
 
     def __init__(self, dataset: Dataset[T_co], batch_size: Optional[int] = 1,
                  shuffle: Optional[bool] = None, sampler: Union[Sampler, Iterable, None] = None,
                  batch_sampler: Union[Sampler[Sequence], Iterable[Sequence], None] = None,
-                 num_workers: int = 1, collate_fn: Optional[_collate_fn_t] = None,
+                 num_workers: int = None, collate_fn: Optional[_collate_fn_t] = None,
                  pin_memory: bool = False, drop_last: bool = False,
                  timeout: float = 0, worker_init_fn: Optional[_worker_init_fn_t] = None,
                  multiprocessing_context=None, generator=None,
                  *, prefetch_factor: int = 2,
                  persistent_workers: bool = False,
                  pin_memory_device: str = ""):
         # torch._C._log_api_usage_once("python.data_loader")
+        if num_workers is None:
+            if sys.platform == "win32":
+                num_workers = 0
+            else:
+                num_workers = 1
 
         if num_workers < 0:
             raise ValueError('num_workers option should be non-negative; '
                              'use num_workers=0 to disable multiprocessing.')
 
         if timeout < 0:
             raise ValueError('timeout option should be non-negative')
@@ -378,15 +381,15 @@
             if self._auto_collation:
                 collate_fn = _utils.collate.default_collate
             else:
                 collate_fn = _utils.collate.default_convert_numpy
 
         self.collate_fn = collate_fn
 
-        if _MP_MODE_ENV != "1":
+        if _MP_MODE_ENV == "0":
             self.persistent_workers = num_workers > 0
         else:
             self.persistent_workers = persistent_workers
 
         self.__initialized = True
         self._IterableDataset_len_called = None  # See NOTE [ IterableDataset and __len__ ]
 
@@ -415,15 +418,15 @@
                 nbytes = collate_nbytes(single_data)
                 del single_data
                 # This factor is used for share cache redundancy in multiprocessing Queue
                 relaxation_ratio = 1.2
                 nbytes = math.ceil(max(int(nbytes) >> 20, 1) * relaxation_ratio)
                 self.maxsize = MIN_POWER_TWO(nbytes)
 
-        if _MP_MODE_ENV != "1":
+        if _MP_MODE_ENV == "0":
             self._iterator = self._get_iterator()
             self.is_first_iter = True
 
     def _get_iterator(self) -> '_BaseDataLoaderIter':
         if self.num_workers == 0:
             return _SingleProcessDataLoaderIter(self)
         else:
```

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/dataloader_experimental.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/dataloader_experimental.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/dataset.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/dataset.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/distributed.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/distributed.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/graph.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/graph.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/graph_settings.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/graph_settings.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torch/utils/data/sampler.py` & `mindtorch-0.3.0/mindtorch/torch/utils/data/sampler.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/_extension.py` & `mindtorch-0.3.0/mindtorch/torchaudio/_extension.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/_internal/module_utils.py` & `mindtorch-0.3.0/mindtorch/torchaudio/_internal/module_utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/backend/common.py` & `mindtorch-0.3.0/mindtorch/torchaudio/backend/common.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/backend/no_backend.py` & `mindtorch-0.3.0/mindtorch/torchaudio/backend/no_backend.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/backend/soundfile_backend.py` & `mindtorch-0.3.0/mindtorch/torchaudio/backend/soundfile_backend.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/backend/sox_io_backend.py` & `mindtorch-0.3.0/mindtorch/torchaudio/backend/sox_io_backend.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/backend/utils.py` & `mindtorch-0.3.0/mindtorch/torchaudio/backend/utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/compliance/kaldi.py` & `mindtorch-0.3.0/mindtorch/torchaudio/compliance/kaldi.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/cmuarctic.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/cmuarctic.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/cmudict.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/cmudict.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/commonvoice.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/commonvoice.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/dr_vctk.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/dr_vctk.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/gtzan.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/gtzan.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/librilight_limited.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/librilight_limited.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/librimix.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/librimix.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/librispeech.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/librispeech.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/libritts.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/libritts.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/ljspeech.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/ljspeech.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/quesst14.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/quesst14.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/speechcommands.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/speechcommands.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/tedlium.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/tedlium.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/utils.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/vctk.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/vctk.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/datasets/yesno.py` & `mindtorch-0.3.0/mindtorch/torchaudio/datasets/yesno.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/functional/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/functional/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/functional/filtering.py` & `mindtorch-0.3.0/mindtorch/torchaudio/functional/filtering.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/functional/functional.py` & `mindtorch-0.3.0/mindtorch/torchaudio/functional/functional.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/io/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/io/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/io/_compat.py` & `mindtorch-0.3.0/mindtorch/torchaudio/io/_compat.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/io/_stream_reader.py` & `mindtorch-0.3.0/mindtorch/torchaudio/io/_stream_reader.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/kaldi_io.py` & `mindtorch-0.3.0/mindtorch/torchaudio/kaldi_io.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/conformer.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/conformer.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/conv_tasnet.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/conv_tasnet.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/decoder/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/decoder/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/decoder/_ctc_decoder.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/decoder/_ctc_decoder.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/deepspeech.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/deepspeech.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/emformer.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/emformer.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/rnnt.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/rnnt.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/rnnt_decoder.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/rnnt_decoder.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/tacotron2.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/tacotron2.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/wav2letter.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/wav2letter.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/components.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/components.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/model.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/model.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/utils/import_fairseq.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/utils/import_fairseq.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/wav2vec2/utils/import_huggingface.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/wav2vec2/utils/import_huggingface.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/models/wavernn.py` & `mindtorch-0.3.0/mindtorch/torchaudio/models/wavernn.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/pipelines/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/pipelines/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_tts/impl.py` & `mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_tts/impl.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_tts/interface.py` & `mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_tts/interface.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_tts/utils.py` & `mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_tts/utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_wav2vec2/impl.py` & `mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_wav2vec2/impl.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/pipelines/_wav2vec2/utils.py` & `mindtorch-0.3.0/mindtorch/torchaudio/pipelines/_wav2vec2/utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/pipelines/rnnt_pipeline.py` & `mindtorch-0.3.0/mindtorch/torchaudio/pipelines/rnnt_pipeline.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/sox_effects/sox_effects.py` & `mindtorch-0.3.0/mindtorch/torchaudio/sox_effects/sox_effects.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/transforms/__init__.py` & `mindtorch-0.3.0/mindtorch/torchaudio/transforms/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/transforms/_multi_channel.py` & `mindtorch-0.3.0/mindtorch/torchaudio/transforms/_multi_channel.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/transforms/_transforms.py` & `mindtorch-0.3.0/mindtorch/torchaudio/transforms/_transforms.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/utils/download.py` & `mindtorch-0.3.0/mindtorch/torchaudio/utils/download.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/utils/ffmpeg_utils.py` & `mindtorch-0.3.0/mindtorch/torchaudio/utils/ffmpeg_utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchaudio/utils/sox_utils.py` & `mindtorch-0.3.0/mindtorch/torchaudio/utils/sox_utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/__init__.py` & `mindtorch-0.3.0/mindtorch/torchvision/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/_internally_replaced_utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/_internally_replaced_utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/_utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/_utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/__init__.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/_optical_flow.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/_optical_flow.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/caltech.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/caltech.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/celeba.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/celeba.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/cifar.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/cifar.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/cityscapes.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/cityscapes.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/clevr.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/clevr.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/coco.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/coco.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/country211.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/country211.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/dtd.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/dtd.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/eurosat.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/eurosat.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/fakedata.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/fakedata.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/fer2013.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/fer2013.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/fgvc_aircraft.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/fgvc_aircraft.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/flickr.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/flickr.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/flowers102.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/flowers102.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/folder.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/folder.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/food101.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/food101.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/gtsrb.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/gtsrb.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/hmdb51.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/hmdb51.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/imagenet.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/imagenet.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/inaturalist.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/inaturalist.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/kinetics.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/kinetics.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/kitti.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/kitti.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/lfw.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/lfw.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/lsun.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/lsun.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/mnist.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/mnist.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/omniglot.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/omniglot.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/oxford_iiit_pet.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/oxford_iiit_pet.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/pcam.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/pcam.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/phototour.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/phototour.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/places365.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/places365.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/rendered_sst2.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/rendered_sst2.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/samplers/clip_sampler.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/samplers/clip_sampler.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/sbd.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/sbd.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/sbu.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/sbu.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/semeion.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/semeion.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/stanford_cars.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/stanford_cars.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/stl10.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/stl10.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/sun397.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/sun397.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/svhn.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/svhn.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/ucf101.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/ucf101.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/usps.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/usps.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/video_utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/video_utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/vision.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/vision.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/voc.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/voc.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/datasets/widerface.py` & `mindtorch-0.3.0/mindtorch/torchvision/datasets/widerface.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/extension.py` & `mindtorch-0.3.0/mindtorch/torchvision/extension.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/io/__init__.py` & `mindtorch-0.3.0/mindtorch/torchvision/io/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/io/_video_opt.py` & `mindtorch-0.3.0/mindtorch/torchvision/io/_video_opt.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/io/image.py` & `mindtorch-0.3.0/mindtorch/torchvision/io/image.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/io/video.py` & `mindtorch-0.3.0/mindtorch/torchvision/io/video.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/io/video_reader.py` & `mindtorch-0.3.0/mindtorch/torchvision/io/video_reader.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/_utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/_utils.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,34 +1,32 @@
 import math
-import mindtorch.torch as torch
-
 from collections import OrderedDict
-from mindtorch.torch import Tensor
-from typing import List, Tuple
+from typing import Dict, List, Optional, Tuple
 
-from mindtorch.torchvision.ops.misc import FrozenBatchNorm2d
+import mindtorch.torch as torch
+from mindtorch.torch import Tensor, nn
+from mindtorch.torch.nn import functional as F
+from mindtorch.torchvision.ops import FrozenBatchNorm2d, complete_box_iou_loss, distance_box_iou_loss, generalized_box_iou_loss
 
 
-class BalancedPositiveNegativeSampler(object):
+class BalancedPositiveNegativeSampler:
     """
     This class samples batches, ensuring that they contain a fixed proportion of positives
     """
 
-    def __init__(self, batch_size_per_image, positive_fraction):
-        # type: (int, float) -> None
+    def __init__(self, batch_size_per_image: int, positive_fraction: float) -> None:
         """
         Args:
             batch_size_per_image (int): number of elements to be selected per image
-            positive_fraction (float): percentace of positive elements per batch
+            positive_fraction (float): percentage of positive elements per batch
         """
         self.batch_size_per_image = batch_size_per_image
         self.positive_fraction = positive_fraction
 
-    def __call__(self, matched_idxs):
-        # type: (List[Tensor]) -> Tuple[List[Tensor], List[Tensor]]
+    def __call__(self, matched_idxs: List[Tensor]) -> Tuple[List[Tensor], List[Tensor]]:
         """
         Args:
             matched idxs: list of tensors containing -1, 0 or positive values.
                 Each tensor corresponds to a specific image.
                 -1 values are ignored, 0 are considered as negatives and > 0 as
                 positives.
 
@@ -57,33 +55,28 @@
             perm1 = torch.randperm(positive.numel(), device=positive.device)[:num_pos]
             perm2 = torch.randperm(negative.numel(), device=negative.device)[:num_neg]
 
             pos_idx_per_image = positive[perm1]
             neg_idx_per_image = negative[perm2]
 
             # create binary mask from indices
-            pos_idx_per_image_mask = torch.zeros_like(
-                matched_idxs_per_image, dtype=torch.uint8
-            )
-            neg_idx_per_image_mask = torch.zeros_like(
-                matched_idxs_per_image, dtype=torch.uint8
-            )
+            pos_idx_per_image_mask = torch.zeros_like(matched_idxs_per_image, dtype=torch.uint8)
+            neg_idx_per_image_mask = torch.zeros_like(matched_idxs_per_image, dtype=torch.uint8)
 
             pos_idx_per_image_mask[pos_idx_per_image] = 1
             neg_idx_per_image_mask[neg_idx_per_image] = 1
 
             pos_idx.append(pos_idx_per_image_mask)
             neg_idx.append(neg_idx_per_image_mask)
 
         return pos_idx, neg_idx
 
 
 # @torch.jit._script_if_tracing
-def encode_boxes(reference_boxes, proposals, weights):
-    # type: (torch.Tensor, torch.Tensor, torch.Tensor) -> torch.Tensor
+def encode_boxes(reference_boxes: Tensor, proposals: Tensor, weights: Tensor) -> Tensor:
     """
     Encode a set of proposals with respect to some
     reference boxes
 
     Args:
         reference_boxes (Tensor): reference boxes
         proposals (Tensor): boxes to be encoded
@@ -122,39 +115,39 @@
     targets_dw = ww * torch.log(gt_widths / ex_widths)
     targets_dh = wh * torch.log(gt_heights / ex_heights)
 
     targets = torch.cat((targets_dx, targets_dy, targets_dw, targets_dh), dim=1)
     return targets
 
 
-class BoxCoder(object):
+class BoxCoder:
     """
     This class encodes and decodes a set of bounding boxes into
     the representation used for training the regressors.
     """
 
-    def __init__(self, weights, bbox_xform_clip=math.log(1000. / 16)):
-        # type: (Tuple[float, float, float, float], float) -> None
+    def __init__(
+        self, weights: Tuple[float, float, float, float], bbox_xform_clip: float = math.log(1000.0 / 16)
+    ) -> None:
         """
         Args:
             weights (4-element tuple)
             bbox_xform_clip (float)
         """
         self.weights = weights
         self.bbox_xform_clip = bbox_xform_clip
 
-    def encode(self, reference_boxes, proposals):
-        # type: (List[Tensor], List[Tensor]) -> List[Tensor]
+    def encode(self, reference_boxes: List[Tensor], proposals: List[Tensor]) -> List[Tensor]:
         boxes_per_image = [len(b) for b in reference_boxes]
         reference_boxes = torch.cat(reference_boxes, dim=0)
         proposals = torch.cat(proposals, dim=0)
         targets = self.encode_single(reference_boxes, proposals)
         return targets.split(boxes_per_image, 0)
 
-    def encode_single(self, reference_boxes, proposals):
+    def encode_single(self, reference_boxes: Tensor, proposals: Tensor) -> Tensor:
         """
         Encode a set of proposals with respect to some
         reference boxes
 
         Args:
             reference_boxes (Tensor): reference boxes
             proposals (Tensor): boxes to be encoded
@@ -162,48 +155,47 @@
         dtype = reference_boxes.dtype
         device = reference_boxes.device
         weights = torch.as_tensor(self.weights, dtype=dtype, device=device)
         targets = encode_boxes(reference_boxes, proposals, weights)
 
         return targets
 
-    def decode(self, rel_codes, boxes):
-        # type: (Tensor, List[Tensor]) -> Tensor
-        assert isinstance(boxes, (list, tuple))
-        assert isinstance(rel_codes, torch.Tensor)
+    def decode(self, rel_codes: Tensor, boxes: List[Tensor]) -> Tensor:
+        torch._assert(
+            isinstance(boxes, (list, tuple)),
+            "This function expects boxes of type list or tuple.",
+        )
+        torch._assert(
+            isinstance(rel_codes, torch.Tensor),
+            "This function expects rel_codes of type torch.Tensor.",
+        )
         boxes_per_image = [b.size(0) for b in boxes]
         concat_boxes = torch.cat(boxes, dim=0)
         box_sum = 0
         for val in boxes_per_image:
             box_sum += val
         if box_sum > 0:
             rel_codes = rel_codes.reshape(box_sum, -1)
-        pred_boxes = self.decode_single(
-            rel_codes, concat_boxes
-        )
+        pred_boxes = self.decode_single(rel_codes, concat_boxes)
         if box_sum > 0:
             pred_boxes = pred_boxes.reshape(box_sum, -1, 4)
         return pred_boxes
 
-    def decode_single(self, rel_codes, boxes):
+    def decode_single(self, rel_codes: Tensor, boxes: Tensor) -> Tensor:
         """
         From a set of original boxes and encoded relative box offsets,
         get the decoded boxes.
 
         Args:
             rel_codes (Tensor): encoded boxes
             boxes (Tensor): reference boxes.
         """
 
         boxes = boxes.to(rel_codes.dtype)
 
-        #TODO: after mindspore support 0 shape Tensor computation on Ascend, remove the code below.
-        if boxes.shape[0] == 0:
-            return torch.zeros(0, rel_codes.shape[1]).to(rel_codes.dtype)
-
         widths = boxes[:, 2] - boxes[:, 0]
         heights = boxes[:, 3] - boxes[:, 1]
         ctr_x = boxes[:, 0] + 0.5 * widths
         ctr_y = boxes[:, 1] + 0.5 * heights
 
         wx, wy, ww, wh = self.weights
         dx = rel_codes[:, 0::4] / wx
@@ -216,23 +208,104 @@
         dh = torch.clamp(dh, max=self.bbox_xform_clip)
 
         pred_ctr_x = dx * widths[:, None] + ctr_x[:, None]
         pred_ctr_y = dy * heights[:, None] + ctr_y[:, None]
         pred_w = torch.exp(dw) * widths[:, None]
         pred_h = torch.exp(dh) * heights[:, None]
 
-        pred_boxes1 = pred_ctr_x - torch.tensor(0.5, dtype=pred_ctr_x.dtype, device=pred_w.device) * pred_w
-        pred_boxes2 = pred_ctr_y - torch.tensor(0.5, dtype=pred_ctr_y.dtype, device=pred_h.device) * pred_h
-        pred_boxes3 = pred_ctr_x + torch.tensor(0.5, dtype=pred_ctr_x.dtype, device=pred_w.device) * pred_w
-        pred_boxes4 = pred_ctr_y + torch.tensor(0.5, dtype=pred_ctr_y.dtype, device=pred_h.device) * pred_h
+        # Distance from center to box's corner.
+        c_to_c_h = torch.tensor(0.5, dtype=pred_ctr_y.dtype, device=pred_h.device) * pred_h
+        c_to_c_w = torch.tensor(0.5, dtype=pred_ctr_x.dtype, device=pred_w.device) * pred_w
+
+        pred_boxes1 = pred_ctr_x - c_to_c_w
+        pred_boxes2 = pred_ctr_y - c_to_c_h
+        pred_boxes3 = pred_ctr_x + c_to_c_w
+        pred_boxes4 = pred_ctr_y + c_to_c_h
         pred_boxes = torch.stack((pred_boxes1, pred_boxes2, pred_boxes3, pred_boxes4), dim=2).flatten(1)
         return pred_boxes
 
 
-class Matcher(object):
+class BoxLinearCoder:
+    """
+    The linear box-to-box transform defined in FCOS. The transformation is parameterized
+    by the distance from the center of (square) src box to 4 edges of the target box.
+    """
+
+    def __init__(self, normalize_by_size: bool = True) -> None:
+        """
+        Args:
+            normalize_by_size (bool): normalize deltas by the size of src (anchor) boxes.
+        """
+        self.normalize_by_size = normalize_by_size
+
+    def encode_single(self, reference_boxes: Tensor, proposals: Tensor) -> Tensor:
+        """
+        Encode a set of proposals with respect to some reference boxes
+
+        Args:
+            reference_boxes (Tensor): reference boxes
+            proposals (Tensor): boxes to be encoded
+
+        Returns:
+            Tensor: the encoded relative box offsets that can be used to
+            decode the boxes.
+        """
+        # get the center of reference_boxes
+        reference_boxes_ctr_x = 0.5 * (reference_boxes[:, 0] + reference_boxes[:, 2])
+        reference_boxes_ctr_y = 0.5 * (reference_boxes[:, 1] + reference_boxes[:, 3])
+
+        # get box regression transformation deltas
+        target_l = reference_boxes_ctr_x - proposals[:, 0]
+        target_t = reference_boxes_ctr_y - proposals[:, 1]
+        target_r = proposals[:, 2] - reference_boxes_ctr_x
+        target_b = proposals[:, 3] - reference_boxes_ctr_y
+
+        targets = torch.stack((target_l, target_t, target_r, target_b), dim=1)
+        if self.normalize_by_size:
+            reference_boxes_w = reference_boxes[:, 2] - reference_boxes[:, 0]
+            reference_boxes_h = reference_boxes[:, 3] - reference_boxes[:, 1]
+            reference_boxes_size = torch.stack(
+                (reference_boxes_w, reference_boxes_h, reference_boxes_w, reference_boxes_h), dim=1
+            )
+            targets = targets / reference_boxes_size
+
+        return targets
+
+    def decode_single(self, rel_codes: Tensor, boxes: Tensor) -> Tensor:
+        """
+        From a set of original boxes and encoded relative box offsets,
+        get the decoded boxes.
+
+        Args:
+            rel_codes (Tensor): encoded boxes
+            boxes (Tensor): reference boxes.
+
+        Returns:
+            Tensor: the predicted boxes with the encoded relative box offsets.
+        """
+
+        boxes = boxes.to(rel_codes.dtype)
+
+        ctr_x = 0.5 * (boxes[:, 0] + boxes[:, 2])
+        ctr_y = 0.5 * (boxes[:, 1] + boxes[:, 3])
+        if self.normalize_by_size:
+            boxes_w = boxes[:, 2] - boxes[:, 0]
+            boxes_h = boxes[:, 3] - boxes[:, 1]
+            boxes_size = torch.stack((boxes_w, boxes_h, boxes_w, boxes_h), dim=1)
+            rel_codes = rel_codes * boxes_size
+
+        pred_boxes1 = ctr_x - rel_codes[:, 0]
+        pred_boxes2 = ctr_y - rel_codes[:, 1]
+        pred_boxes3 = ctr_x + rel_codes[:, 2]
+        pred_boxes4 = ctr_y + rel_codes[:, 3]
+        pred_boxes = torch.stack((pred_boxes1, pred_boxes2, pred_boxes3, pred_boxes4), dim=1)
+        return pred_boxes
+
+
+class Matcher:
     """
     This class assigns to each predicted "element" (e.g., a box) a ground-truth
     element. Each predicted element will have exactly zero or one matches; each
     ground-truth element may be assigned to zero or more predicted elements.
 
     Matching is based on the MxN match_quality_matrix, that characterizes how well
     each (ground-truth, predicted)-pair match. For example, if the elements are
@@ -243,20 +316,19 @@
     is returned.
     """
 
     BELOW_LOW_THRESHOLD = -1
     BETWEEN_THRESHOLDS = -2
 
     __annotations__ = {
-        'BELOW_LOW_THRESHOLD': int,
-        'BETWEEN_THRESHOLDS': int,
+        "BELOW_LOW_THRESHOLD": int,
+        "BETWEEN_THRESHOLDS": int,
     }
 
-    def __init__(self, high_threshold, low_threshold, allow_low_quality_matches=False):
-        # type: (float, float, bool) -> None
+    def __init__(self, high_threshold: float, low_threshold: float, allow_low_quality_matches: bool = False) -> None:
         """
         Args:
             high_threshold (float): quality values greater than or equal to
                 this value are candidate matches.
             low_threshold (float): a lower quality threshold used to stratify
                 matches into three levels:
                 1) matches >= high_threshold
@@ -264,77 +336,71 @@
                 3) BELOW_LOW_THRESHOLD matches in [0, low_threshold)
             allow_low_quality_matches (bool): if True, produce additional matches
                 for predictions that have only low-quality match candidates. See
                 set_low_quality_matches_ for more details.
         """
         self.BELOW_LOW_THRESHOLD = -1
         self.BETWEEN_THRESHOLDS = -2
-        assert low_threshold <= high_threshold
+        torch._assert(low_threshold <= high_threshold, "low_threshold should be <= high_threshold")
         self.high_threshold = high_threshold
         self.low_threshold = low_threshold
         self.allow_low_quality_matches = allow_low_quality_matches
 
-    def __call__(self, match_quality_matrix):
+    def __call__(self, match_quality_matrix: Tensor) -> Tensor:
         """
         Args:
             match_quality_matrix (Tensor[float]): an MxN tensor, containing the
             pairwise quality between M ground-truth elements and N predicted elements.
 
         Returns:
             matches (Tensor[int64]): an N tensor where N[i] is a matched gt in
             [0, M - 1] or a negative value indicating that prediction i could not
             be matched.
         """
         if match_quality_matrix.numel() == 0:
             # empty targets or proposals not supported during training
             if match_quality_matrix.shape[0] == 0:
-                raise ValueError(
-                    "No ground-truth boxes available for one of the images "
-                    "during training")
+                raise ValueError("No ground-truth boxes available for one of the images during training")
             else:
-                raise ValueError(
-                    "No proposal boxes available for one of the images "
-                    "during training")
+                raise ValueError("No proposal boxes available for one of the images during training")
 
         # match_quality_matrix is M (gt) x N (predicted)
         # Max over gt elements (dim 0) to find best gt candidate for each prediction
         matched_vals, matches = match_quality_matrix.max(dim=0)
         if self.allow_low_quality_matches:
             all_matches = matches.clone()
         else:
-            all_matches = None
+            all_matches = None  # type: ignore[assignment]
 
         # Assign candidate matches with low quality to negative (unassigned) values
         below_low_threshold = matched_vals < self.low_threshold
-        between_thresholds = (matched_vals >= self.low_threshold) & (
-            matched_vals < self.high_threshold
-        )
+        between_thresholds = (matched_vals >= self.low_threshold) & (matched_vals < self.high_threshold)
         matches[below_low_threshold] = self.BELOW_LOW_THRESHOLD
         matches[between_thresholds] = self.BETWEEN_THRESHOLDS
 
         if self.allow_low_quality_matches:
-            assert all_matches is not None
-            self.set_low_quality_matches_(matches, all_matches, match_quality_matrix)
+            if all_matches is None:
+                torch._assert(False, "all_matches should not be None")
+            else:
+                self.set_low_quality_matches_(matches, all_matches, match_quality_matrix)
 
         return matches
 
-    def set_low_quality_matches_(self, matches, all_matches, match_quality_matrix):
+    def set_low_quality_matches_(self, matches: Tensor, all_matches: Tensor, match_quality_matrix: Tensor) -> None:
         """
         Produce additional matches for predictions that have only low-quality matches.
         Specifically, for each ground-truth find the set of predictions that have
         maximum overlap with it (including ties); for each prediction in that set, if
         it is unmatched, then match it to the ground-truth with which it has the highest
         quality value.
         """
         # For each gt, find the prediction with which it has highest quality
         highest_quality_foreach_gt, _ = match_quality_matrix.max(dim=1)
         # Find highest quality match available, even if it is low, including ties
-        gt_pred_pairs_of_highest_quality = torch.where(
-            match_quality_matrix == highest_quality_foreach_gt[:, None]
-        )
+        gt_pred_pairs_of_highest_quality = torch.where(match_quality_matrix == highest_quality_foreach_gt[:, None])
         # Example gt_pred_pairs_of_highest_quality:
         #   tensor([[    0, 39796],
         #           [    1, 32055],
         #           [    1, 32070],
         #           [    2, 39190],
         #           [    2, 40255],
         #           [    3, 40390],
@@ -346,31 +412,30 @@
         # Note how gt items 1, 2, 3, and 5 each have two ties
 
         pred_inds_to_update = gt_pred_pairs_of_highest_quality[1]
         matches[pred_inds_to_update] = all_matches[pred_inds_to_update]
 
 
 class SSDMatcher(Matcher):
-
-    def __init__(self, threshold):
+    def __init__(self, threshold: float) -> None:
         super().__init__(threshold, threshold, allow_low_quality_matches=False)
 
-    def __call__(self, match_quality_matrix):
+    def __call__(self, match_quality_matrix: Tensor) -> Tensor:
         matches = super().__call__(match_quality_matrix)
 
         # For each gt, find the prediction with which it has the highest quality
         _, highest_quality_pred_foreach_gt = match_quality_matrix.max(dim=1)
-        matches[highest_quality_pred_foreach_gt] = torch.arange(highest_quality_pred_foreach_gt.size(0),
-                                                                dtype=torch.int64,
-                                                                device=highest_quality_pred_foreach_gt.device)
+        matches[highest_quality_pred_foreach_gt] = torch.arange(
+            highest_quality_pred_foreach_gt.size(0), dtype=torch.int64, device=highest_quality_pred_foreach_gt.device
+        )
 
         return matches
 
 
-def overwrite_eps(model, eps):
+def overwrite_eps(model: nn.Module, eps: float) -> None:
     """
     This method overwrites the default eps values of all the
     FrozenBatchNorm2d layers of the model with the provided value.
     This is necessary to address the BC-breaking change introduced
     by the bug-fix at pytorch/vision#2933. The overwrite is applied
     only when the pretrained weights are loaded to maintain compatibility
     with previous versions.
@@ -380,35 +445,94 @@
         eps (float): The new value of eps.
     """
     for module in model.modules():
         if isinstance(module, FrozenBatchNorm2d):
             module.eps = eps
 
 
-def retrieve_out_channels(model, size):
+def retrieve_out_channels(model: nn.Module, size: Tuple[int, int]) -> List[int]:
     """
     This method retrieves the number of output channels of a specific model.
 
     Args:
         model (nn.Module): The model for which we estimate the out_channels.
             It should return a single Tensor or an OrderedDict[Tensor].
         size (Tuple[int, int]): The size (wxh) of the input.
 
     Returns:
         out_channels (List[int]): A list of the output channels of the model.
     """
     in_training = model.training
     model.eval()
 
-    # with torch.no_grad():
+    with torch.no_grad():
         # Use dummy data to retrieve the feature map sizes to avoid hard-coding their values
-    device = next(model.parameters()).device
-    tmp_img = torch.zeros((1, 3, size[1], size[0]), device=device)
-    features = model(tmp_img)
-    if isinstance(features, torch.Tensor):
-        features = OrderedDict([('0', features)])
-    out_channels = [x.size(1) for x in features.values()]
+        device = next(model.parameters()).device
+        tmp_img = torch.zeros((1, 3, size[1], size[0]), device=device)
+        features = model(tmp_img)
+        if isinstance(features, torch.Tensor):
+            features = OrderedDict([("0", features)])
+        out_channels = [x.size(1) for x in features.values()]
 
     if in_training:
         model.train()
 
     return out_channels
+
+
+# @torch.jit.unused
+def _fake_cast_onnx(v: Tensor) -> int:
+    return v
+
+
+def _topk_min(input: Tensor, orig_kval: int, axis: int) -> int:
+    """
+    ONNX spec requires the k-value to be less than or equal to the number of inputs along
+    provided dim. Certain models use the number of elements along a particular axis instead of K
+    if K exceeds the number of elements along that axis. Previously, python's min() function was
+    used to determine whether to use the provided k-value or the specified dim axis value.
+
+    However in cases where the model is being exported in tracing mode, python min() is
+    static causing the model to be traced incorrectly and eventually fail at the topk node.
+    In order to avoid this situation, in tracing mode, torch.min() is used instead.
+
+    Args:
+        input (Tensor): The orignal input tensor.
+        orig_kval (int): The provided k-value.
+        axis(int): Axis along which we retreive the input size.
+
+    Returns:
+        min_kval (int): Appropriately selected k-value.
+    """
+    if not torch.jit.is_tracing():
+        return min(orig_kval, input.size(axis))
+    axis_dim_val = torch._shape_as_tensor(input)[axis].unsqueeze(0)
+    min_kval = torch.min(torch.cat((torch.tensor([orig_kval], dtype=axis_dim_val.dtype), axis_dim_val), 0))
+    return _fake_cast_onnx(min_kval)
+
+
+def _box_loss(
+    type: str,
+    box_coder: BoxCoder,
+    anchors_per_image: Tensor,
+    matched_gt_boxes_per_image: Tensor,
+    bbox_regression_per_image: Tensor,
+    cnf: Optional[Dict[str, float]] = None,
+) -> Tensor:
+    torch._assert(type in ["l1", "smooth_l1", "ciou", "diou", "giou"], f"Unsupported loss: {type}")
+
+    if type == "l1":
+        target_regression = box_coder.encode_single(matched_gt_boxes_per_image, anchors_per_image)
+        return F.l1_loss(bbox_regression_per_image, target_regression, reduction="sum")
+    elif type == "smooth_l1":
+        target_regression = box_coder.encode_single(matched_gt_boxes_per_image, anchors_per_image)
+        beta = cnf["beta"] if cnf is not None and "beta" in cnf else 1.0
+        return F.smooth_l1_loss(bbox_regression_per_image, target_regression, reduction="sum", beta=beta)
+    else:
+        bbox_per_image = box_coder.decode_single(bbox_regression_per_image, anchors_per_image)
+        eps = cnf["eps"] if cnf is not None and "eps" in cnf else 1e-7
+        if type == "ciou":
+            return complete_box_iou_loss(bbox_per_image, matched_gt_boxes_per_image, reduction="sum", eps=eps)
+        if type == "diou":
+            return distance_box_iou_loss(bbox_per_image, matched_gt_boxes_per_image, reduction="sum", eps=eps)
+        # otherwise giou
+        return generalized_box_iou_loss(bbox_per_image, matched_gt_boxes_per_image, reduction="sum", eps=eps)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/anchor_utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/anchor_utils.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 import math
+from typing import List, Optional
+
 import mindtorch.torch as torch
 from mindtorch.torch import nn, Tensor
 
-from typing import List, Optional
 from .image_list import ImageList
 
 
 class AnchorGenerator(nn.Module):
     """
     Module that generates anchors for a set of feature maps and
     image sizes.
@@ -32,99 +33,100 @@
     }
 
     def __init__(
         self,
         sizes=((128, 256, 512),),
         aspect_ratios=((0.5, 1.0, 2.0),),
     ):
-        super(AnchorGenerator, self).__init__()
+        super().__init__()
 
         if not isinstance(sizes[0], (list, tuple)):
             # TODO change this
             sizes = tuple((s,) for s in sizes)
         if not isinstance(aspect_ratios[0], (list, tuple)):
             aspect_ratios = (aspect_ratios,) * len(sizes)
 
-        assert len(sizes) == len(aspect_ratios)
-
         self.sizes = sizes
         self.aspect_ratios = aspect_ratios
-        self.cell_anchors = [self.generate_anchors(size, aspect_ratio)
-                             for size, aspect_ratio in zip(sizes, aspect_ratios)]
+        self.cell_anchors = [
+            self.generate_anchors(size, aspect_ratio) for size, aspect_ratio in zip(sizes, aspect_ratios)
+        ]
 
     # TODO: https://github.com/pytorch/pytorch/issues/26792
     # For every (aspect_ratios, scales) combination, output a zero-centered anchor with those values.
     # (scales, aspect_ratios) are usually an element of zip(self.scales, self.aspect_ratios)
     # This method assumes aspect ratio = height / width for an anchor.
-    def generate_anchors(self, scales: List[int], aspect_ratios: List[float], dtype=torch.float32,
-                         device = torch.device("cpu")):
+    def generate_anchors(
+        self,
+        scales: List[int],
+        aspect_ratios: List[float],
+        dtype: torch.dtype = torch.float32,
+        device: torch.device = torch.device("cpu"),
+    ):
         scales = torch.as_tensor(scales, dtype=dtype, device=device)
         aspect_ratios = torch.as_tensor(aspect_ratios, dtype=dtype, device=device)
         h_ratios = torch.sqrt(aspect_ratios)
         w_ratios = 1 / h_ratios
 
         ws = (w_ratios[:, None] * scales[None, :]).view(-1)
         hs = (h_ratios[:, None] * scales[None, :]).view(-1)
 
         base_anchors = torch.stack([-ws, -hs, ws, hs], dim=1) / 2
         return base_anchors.round()
 
-    def set_cell_anchors(self, dtype, device: torch.device):
-        self.cell_anchors = [cell_anchor.to(dtype=dtype, device=device)
-                             for cell_anchor in self.cell_anchors]
+    def set_cell_anchors(self, dtype: torch.dtype, device: torch.device):
+        self.cell_anchors = [cell_anchor.to(dtype=dtype, device=device) for cell_anchor in self.cell_anchors]
 
     def num_anchors_per_location(self):
         return [len(s) * len(a) for s, a in zip(self.sizes, self.aspect_ratios)]
 
     # For every combination of (a, (g, s), i) in (self.cell_anchors, zip(grid_sizes, strides), 0:2),
     # output g[i] anchors that are s[i] distance apart in direction i, with the same dimensions as a.
     def grid_anchors(self, grid_sizes: List[List[int]], strides: List[List[Tensor]]) -> List[Tensor]:
         anchors = []
         cell_anchors = self.cell_anchors
-        assert cell_anchors is not None
+        torch._assert(cell_anchors is not None, "cell_anchors should not be None")
+        torch._assert(
+            len(grid_sizes) == len(strides) == len(cell_anchors),
+            "Anchors should be Tuple[Tuple[int]] because each feature "
+            "map could potentially have different sizes and aspect ratios. "
+            "There needs to be a match between the number of "
+            "feature maps passed and the number of sizes / aspect ratios specified.",
+        )
 
-        if not (len(grid_sizes) == len(strides) == len(cell_anchors)):
-            raise ValueError("Anchors should be Tuple[Tuple[int]] because each feature "
-                             "map could potentially have different sizes and aspect ratios. "
-                             "There needs to be a match between the number of "
-                             "feature maps passed and the number of sizes / aspect ratios specified.")
-
-        for size, stride, base_anchors in zip(
-            grid_sizes, strides, cell_anchors
-        ):
+        for size, stride, base_anchors in zip(grid_sizes, strides, cell_anchors):
             grid_height, grid_width = size
             stride_height, stride_width = stride
             device = base_anchors.device
 
             # For output anchor, compute [x_center, y_center, x_center, y_center]
-            shifts_x = torch.arange(
-                0, grid_width, dtype=torch.float32, device=device
-            ) * stride_width
-            shifts_y = torch.arange(
-                0, grid_height, dtype=torch.float32, device=device
-            ) * stride_height
-            shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)
+            shifts_x = torch.arange(0, grid_width, dtype=torch.int32, device=device) * stride_width
+            shifts_y = torch.arange(0, grid_height, dtype=torch.int32, device=device) * stride_height
+            shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x, indexing="ij")
             shift_x = shift_x.reshape(-1)
             shift_y = shift_y.reshape(-1)
             shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)
 
             # For every (base anchor, output anchor) pair,
             # offset each zero-centered base anchor by the center of the output anchor.
-            anchors.append(
-                (shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4)
-            )
+            anchors.append((shifts.view(-1, 1, 4) + base_anchors.view(1, -1, 4)).reshape(-1, 4))
 
         return anchors
 
     def forward(self, image_list: ImageList, feature_maps: List[Tensor]) -> List[Tensor]:
         grid_sizes = [feature_map.shape[-2:] for feature_map in feature_maps]
         image_size = image_list.tensors.shape[-2:]
         dtype, device = feature_maps[0].dtype, feature_maps[0].device
-        strides = [[torch.tensor(image_size[0] // g[0], dtype=torch.int64, device=device),
-                    torch.tensor(image_size[1] // g[1], dtype=torch.int64, device=device)] for g in grid_sizes]
+        strides = [
+            [
+                torch.empty((), dtype=torch.int64, device=device).fill_(image_size[0] // g[0]),
+                torch.empty((), dtype=torch.int64, device=device).fill_(image_size[1] // g[1]),
+            ]
+            for g in grid_sizes
+        ]
         self.set_cell_anchors(dtype, device)
         anchors_over_all_feature_maps = self.grid_anchors(grid_sizes, strides)
         anchors: List[List[torch.Tensor]] = []
         for _ in range(len(image_list.image_sizes)):
             anchors_in_image = [anchors_per_feature_map for anchors_per_feature_map in anchors_over_all_feature_maps]
             anchors.append(anchors_in_image)
         anchors = [torch.cat(anchors_per_image) for anchors_per_image in anchors]
@@ -145,19 +147,26 @@
             the ``min_ratio`` and ``max_ratio`` parameters.
         steps (List[int]], optional): It's a hyper-parameter that affects the tiling of defalt boxes. If not provided
             it will be estimated from the data.
         clip (bool): Whether the standardized values of default boxes should be clipped between 0 and 1. The clipping
             is applied while the boxes are encoded in format ``(cx, cy, w, h)``.
     """
 
-    def __init__(self, aspect_ratios: List[List[int]], min_ratio: float = 0.15, max_ratio: float = 0.9,
-                 scales: Optional[List[float]] = None, steps: Optional[List[int]] = None, clip: bool = True):
+    def __init__(
+        self,
+        aspect_ratios: List[List[int]],
+        min_ratio: float = 0.15,
+        max_ratio: float = 0.9,
+        scales: Optional[List[float]] = None,
+        steps: Optional[List[int]] = None,
+        clip: bool = True,
+    ):
         super().__init__()
-        if steps is not None:
-            assert len(aspect_ratios) == len(steps)
+        if steps is not None and len(aspect_ratios) != len(steps):
+            raise ValueError("aspect_ratios and steps should have the same length")
         self.aspect_ratios = aspect_ratios
         self.steps = steps
         self.clip = clip
         num_outputs = len(aspect_ratios)
 
         # Estimation of default boxes scales
         if scales is None:
@@ -168,16 +177,17 @@
             else:
                 self.scales = [min_ratio, max_ratio]
         else:
             self.scales = scales
 
         self._wh_pairs = self._generate_wh_pairs(num_outputs)
 
-    def _generate_wh_pairs(self, num_outputs: int, dtype=torch.float32,
-                           device=torch.device("cpu")) -> List[Tensor]:
+    def _generate_wh_pairs(
+        self, num_outputs: int, dtype: torch.dtype = torch.float32, device: torch.device = torch.device("cpu")
+    ) -> List[Tensor]:
         _wh_pairs: List[Tensor] = []
         for k in range(num_outputs):
             # Adding the 2 default width-height pairs for aspect ratio 1 and scale s'k
             s_k = self.scales[k]
             s_prime_k = math.sqrt(self.scales[k] * self.scales[k + 1])
             wh_pairs = [[s_k, s_k], [s_prime_k, s_prime_k]]
 
@@ -192,27 +202,29 @@
         return _wh_pairs
 
     def num_anchors_per_location(self):
         # Estimate num of anchors based on aspect ratios: 2 default boxes + 2 * ratios of feaure map.
         return [2 + 2 * len(r) for r in self.aspect_ratios]
 
     # Default Boxes calculation based on page 6 of SSD paper
-    def _grid_default_boxes(self, grid_sizes: List[List[int]], image_size: List[int],
-                            dtype) -> Tensor:
+    def _grid_default_boxes(
+        self, grid_sizes: List[List[int]], image_size: List[int], dtype: torch.dtype = torch.float32
+    ) -> Tensor:
         default_boxes = []
         for k, f_k in enumerate(grid_sizes):
             # Now add the default boxes for each width-height pair
             if self.steps is not None:
-                x_f_k, y_f_k = [img_shape / self.steps[k] for img_shape in image_size]
+                x_f_k = image_size[0] / self.steps[k]
+                y_f_k = image_size[1] / self.steps[k]
             else:
                 y_f_k, x_f_k = f_k
 
             shifts_x = ((torch.arange(0, f_k[1]) + 0.5) / x_f_k).to(dtype=dtype)
             shifts_y = ((torch.arange(0, f_k[0]) + 0.5) / y_f_k).to(dtype=dtype)
-            shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)
+            shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x, indexing="ij")
             shift_x = shift_x.reshape(-1)
             shift_y = shift_y.reshape(-1)
 
             shifts = torch.stack((shift_x, shift_y) * len(self._wh_pairs[k]), dim=-1).reshape(-1, 2)
             # Clipping the default boxes while the boxes are encoded in format (cx, cy, w, h)
             _wh_pair = self._wh_pairs[k].clamp(min=0, max=1) if self.clip else self._wh_pairs[k]
             wh_pairs = _wh_pair.repeat((f_k[0] * f_k[1]), 1)
@@ -220,31 +232,37 @@
             default_box = torch.cat((shifts, wh_pairs), dim=1)
 
             default_boxes.append(default_box)
 
         return torch.cat(default_boxes, dim=0)
 
     def __repr__(self) -> str:
-        s = self.__class__.__name__ + '('
-        s += 'aspect_ratios={aspect_ratios}'
-        s += ', clip={clip}'
-        s += ', scales={scales}'
-        s += ', steps={steps}'
-        s += ')'
-        return s.format(**self.__dict__)
+        s = (
+            f"{self.__class__.__name__}("
+            f"aspect_ratios={self.aspect_ratios}"
+            f", clip={self.clip}"
+            f", scales={self.scales}"
+            f", steps={self.steps}"
+            ")"
+        )
+        return s
 
     def forward(self, image_list: ImageList, feature_maps: List[Tensor]) -> List[Tensor]:
         grid_sizes = [feature_map.shape[-2:] for feature_map in feature_maps]
         image_size = image_list.tensors.shape[-2:]
         dtype, device = feature_maps[0].dtype, feature_maps[0].device
         default_boxes = self._grid_default_boxes(grid_sizes, image_size, dtype=dtype)
         default_boxes = default_boxes.to(device)
 
         dboxes = []
+        x_y_size = torch.tensor([image_size[1], image_size[0]], device=default_boxes.device)
         for _ in image_list.image_sizes:
             dboxes_in_image = default_boxes
-            dboxes_in_image = torch.cat([dboxes_in_image[:, :2] - 0.5 * dboxes_in_image[:, 2:],
-                                         dboxes_in_image[:, :2] + 0.5 * dboxes_in_image[:, 2:]], -1)
-            dboxes_in_image[:, 0::2] *= image_size[1]
-            dboxes_in_image[:, 1::2] *= image_size[0]
+            dboxes_in_image = torch.cat(
+                [
+                    (dboxes_in_image[:, :2] - 0.5 * dboxes_in_image[:, 2:]) * x_y_size,
+                    (dboxes_in_image[:, :2] + 0.5 * dboxes_in_image[:, 2:]) * x_y_size,
+                ],
+                -1,
+            )
             dboxes.append(dboxes_in_image)
         return dboxes
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/faster_rcnn.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/mask_rcnn.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,66 +1,62 @@
-from mindtorch.torch import nn
-import mindtorch.torch.nn.functional as F
-import mindtorch.torch as torch
+from collections import OrderedDict
+from typing import Any, Callable, Optional
 
+from mindtorch.torch import nn
 from mindtorch.torchvision.ops import MultiScaleRoIAlign
-from mindtorch import unsupported_attr
 
+from ...ops import misc as misc_nn_ops
+from ...transforms._presets import ObjectDetection
+from .._api import WeightsEnum, Weights
+from .._meta import _COCO_CATEGORIES
+from .._utils import handle_legacy_interface, _ovewrite_value_param
+from ..resnet import ResNet50_Weights, resnet50
 from ._utils import overwrite_eps
-from ..utils import check_ckpt_file, model_path_name
-
-from .anchor_utils import AnchorGenerator
-from .generalized_rcnn import GeneralizedRCNN
-from .rpn import RPNHead, RegionProposalNetwork
-from .roi_heads import RoIHeads
-from .transform import GeneralizedRCNNTransform
-from .backbone_utils import resnet_fpn_backbone, _validate_trainable_layers, mobilenet_backbone
-from mindtorch.torch.hub import load_state_dict_from_url
+from .backbone_utils import _resnet_fpn_extractor, _validate_trainable_layers
+from .faster_rcnn import FasterRCNN, FastRCNNConvFCHead, RPNHead, _default_anchorgen
 
 
 __all__ = [
-    "FasterRCNN", "fasterrcnn_resnet50_fpn", "fasterrcnn_mobilenet_v3_large_320_fpn",
-    "fasterrcnn_mobilenet_v3_large_fpn"
+    "MaskRCNN",
+    "MaskRCNN_ResNet50_FPN_Weights",
+    "MaskRCNN_ResNet50_FPN_V2_Weights",
+    "maskrcnn_resnet50_fpn",
+    "maskrcnn_resnet50_fpn_v2",
 ]
 
-model_urls = {
-    'fasterrcnn_resnet50_fpn_coco':
-        model_path_name + 'fasterrcnn_resnet50_fpn_coco-258fb6c6.pth',
-    'fasterrcnn_mobilenet_v3_large_320_fpn_coco':
-        model_path_name + 'fasterrcnn_mobilenet_v3_large_320_fpn-907ea3f9.pth',
-    'fasterrcnn_mobilenet_v3_large_fpn_coco':
-        model_path_name + 'fasterrcnn_mobilenet_v3_large_fpn-fb6a3cc7.pth'
-}
 
-
-class FasterRCNN(GeneralizedRCNN):
+class MaskRCNN(FasterRCNN):
     """
-    Implements Faster R-CNN.
+    Implements Mask R-CNN.
 
     The input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each
     image, and should be in 0-1 range. Different images can have different sizes.
 
     The behavior of the model changes depending if it is in training or evaluation mode.
 
     During training, the model expects both the input tensors, as well as a targets (list of dictionary),
     containing:
         - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with
           ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.
         - labels (Int64Tensor[N]): the class label for each ground-truth box
+        - masks (UInt8Tensor[N, H, W]): the segmentation binary masks for each instance
 
     The model returns a Dict[Tensor] during training, containing the classification and regression
-    losses for both the RPN and the R-CNN.
+    losses for both the RPN and the R-CNN, and the mask loss.
 
     During inference, the model requires only the input tensors, and returns the post-processed
     predictions as a List[Dict[Tensor]], one for each input image. The fields of the Dict are as
     follows:
         - boxes (``FloatTensor[N, 4]``): the predicted boxes in ``[x1, y1, x2, y2]`` format, with
           ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.
         - labels (Int64Tensor[N]): the predicted labels for each image
         - scores (Tensor[N]): the scores or each prediction
+        - masks (UInt8Tensor[N, 1, H, W]): the predicted masks for each instance, in 0-1 range. In order to
+          obtain the final segmentation masks, the soft masks can be thresholded, generally
+          with a value of 0.5 (mask >= 0.5)
 
     Args:
         backbone (nn.Module): the network used to compute the features for the model.
             It should contain a out_channels attribute, which indicates the number of output
             channels that each feature map has (and it should be the same for all feature maps).
             The backbone should return a single Tensor or and OrderedDict[Tensor].
         num_classes (int): number of output classes of the model (including the background).
@@ -105,25 +101,31 @@
             considered as negative during training of the classification head
         box_batch_size_per_image (int): number of proposals that are sampled during training of the
             classification head
         box_positive_fraction (float): proportion of positive proposals in a mini-batch during training
             of the classification head
         bbox_reg_weights (Tuple[float, float, float, float]): weights for the encoding/decoding of the
             bounding boxes
+        mask_roi_pool (MultiScaleRoIAlign): the module which crops and resizes the feature maps in
+             the locations indicated by the bounding boxes, which will be used for the mask head.
+        mask_head (nn.Module): module that takes the cropped feature maps as input
+        mask_predictor (nn.Module): module that takes the output of the mask_head and returns the
+            segmentation mask logits
 
     Example::
 
         >>> import torch
         >>> import torchvision
-        >>> from torchvision.models.detection import FasterRCNN
-        >>> from torchvision.models.detection.rpn import AnchorGenerator
+        >>> from torchvision.models.detection import MaskRCNN
+        >>> from torchvision.models.detection.anchor_utils import AnchorGenerator
+        >>>
         >>> # load a pre-trained model for classification and return
         >>> # only the features
-        >>> backbone = torchvision.models.mobilenet_v2(pretrained=True).features
-        >>> # FasterRCNN needs to know the number of
+        >>> backbone = torchvision.models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT).features
+        >>> # MaskRCNN needs to know the number of
         >>> # output channels in a backbone. For mobilenet_v2, it's 1280
         >>> # so we need to add it here
         >>> backbone.out_channels = 1280
         >>>
         >>> # let's make the RPN generate 5 x 3 anchors per spatial
         >>> # location, with 5 different sizes and 3 different aspect
         >>> # ratios. We have a Tuple[Tuple[int]] because each feature
@@ -139,344 +141,448 @@
         >>> # be ['0']. More generally, the backbone should return an
         >>> # OrderedDict[Tensor], and in featmap_names you can choose which
         >>> # feature maps to use.
         >>> roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],
         >>>                                                 output_size=7,
         >>>                                                 sampling_ratio=2)
         >>>
-        >>> # put the pieces together inside a FasterRCNN model
-        >>> model = FasterRCNN(backbone,
-        >>>                    num_classes=2,
-        >>>                    rpn_anchor_generator=anchor_generator,
-        >>>                    box_roi_pool=roi_pooler)
+        >>> mask_roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],
+        >>>                                                      output_size=14,
+        >>>                                                      sampling_ratio=2)
+        >>> # put the pieces together inside a MaskRCNN model
+        >>> model = MaskRCNN(backbone,
+        >>>                  num_classes=2,
+        >>>                  rpn_anchor_generator=anchor_generator,
+        >>>                  box_roi_pool=roi_pooler,
+        >>>                  mask_roi_pool=mask_roi_pooler)
         >>> model.eval()
         >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
         >>> predictions = model(x)
     """
 
-    def __init__(self, backbone, num_classes=None,
-                 # transform parameters
-                 min_size=800, max_size=1333,
-                 image_mean=None, image_std=None,
-                 # RPN parameters
-                 rpn_anchor_generator=None, rpn_head=None,
-                 rpn_pre_nms_top_n_train=2000, rpn_pre_nms_top_n_test=1000,
-                 rpn_post_nms_top_n_train=2000, rpn_post_nms_top_n_test=1000,
-                 rpn_nms_thresh=0.7,
-                 rpn_fg_iou_thresh=0.7, rpn_bg_iou_thresh=0.3,
-                 rpn_batch_size_per_image=256, rpn_positive_fraction=0.5,
-                 rpn_score_thresh=0.0,
-                 # Box parameters
-                 box_roi_pool=None, box_head=None, box_predictor=None,
-                 box_score_thresh=0.05, box_nms_thresh=0.5, box_detections_per_img=100,
-                 box_fg_iou_thresh=0.5, box_bg_iou_thresh=0.5,
-                 box_batch_size_per_image=512, box_positive_fraction=0.25,
-                 bbox_reg_weights=None):
-
-        if not hasattr(backbone, "out_channels"):
-            raise ValueError(
-                "backbone should contain an attribute out_channels "
-                "specifying the number of output channels (assumed to be the "
-                "same for all the levels)")
-
-        assert isinstance(rpn_anchor_generator, (AnchorGenerator, type(None)))
-        assert isinstance(box_roi_pool, (MultiScaleRoIAlign, type(None)))
+    def __init__(
+        self,
+        backbone,
+        num_classes=None,
+        # transform parameters
+        min_size=800,
+        max_size=1333,
+        image_mean=None,
+        image_std=None,
+        # RPN parameters
+        rpn_anchor_generator=None,
+        rpn_head=None,
+        rpn_pre_nms_top_n_train=2000,
+        rpn_pre_nms_top_n_test=1000,
+        rpn_post_nms_top_n_train=2000,
+        rpn_post_nms_top_n_test=1000,
+        rpn_nms_thresh=0.7,
+        rpn_fg_iou_thresh=0.7,
+        rpn_bg_iou_thresh=0.3,
+        rpn_batch_size_per_image=256,
+        rpn_positive_fraction=0.5,
+        rpn_score_thresh=0.0,
+        # Box parameters
+        box_roi_pool=None,
+        box_head=None,
+        box_predictor=None,
+        box_score_thresh=0.05,
+        box_nms_thresh=0.5,
+        box_detections_per_img=100,
+        box_fg_iou_thresh=0.5,
+        box_bg_iou_thresh=0.5,
+        box_batch_size_per_image=512,
+        box_positive_fraction=0.25,
+        bbox_reg_weights=None,
+        # Mask parameters
+        mask_roi_pool=None,
+        mask_head=None,
+        mask_predictor=None,
+        **kwargs,
+    ):
+
+        if not isinstance(mask_roi_pool, (MultiScaleRoIAlign, type(None))):
+            raise TypeError(
+                f"mask_roi_pool should be of type MultiScaleRoIAlign or None instead of {type(mask_roi_pool)}"
+            )
 
         if num_classes is not None:
-            if box_predictor is not None:
-                raise ValueError("num_classes should be None when box_predictor is specified")
-        else:
-            if box_predictor is None:
-                raise ValueError("num_classes should not be None when box_predictor "
-                                 "is not specified")
+            if mask_predictor is not None:
+                raise ValueError("num_classes should be None when mask_predictor is specified")
 
         out_channels = backbone.out_channels
 
-        if rpn_anchor_generator is None:
-            anchor_sizes = ((32,), (64,), (128,), (256,), (512,))
-            aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)
-            rpn_anchor_generator = AnchorGenerator(
-                anchor_sizes, aspect_ratios
-            )
-        if rpn_head is None:
-            rpn_head = RPNHead(
-                out_channels, rpn_anchor_generator.num_anchors_per_location()[0]
-            )
-
-        rpn_pre_nms_top_n = dict(training=rpn_pre_nms_top_n_train, testing=rpn_pre_nms_top_n_test)
-        rpn_post_nms_top_n = dict(training=rpn_post_nms_top_n_train, testing=rpn_post_nms_top_n_test)
+        if mask_roi_pool is None:
+            mask_roi_pool = MultiScaleRoIAlign(featmap_names=["0", "1", "2", "3"], output_size=14, sampling_ratio=2)
 
-        rpn = RegionProposalNetwork(
-            rpn_anchor_generator, rpn_head,
-            rpn_fg_iou_thresh, rpn_bg_iou_thresh,
-            rpn_batch_size_per_image, rpn_positive_fraction,
-            rpn_pre_nms_top_n, rpn_post_nms_top_n, rpn_nms_thresh,
-            score_thresh=rpn_score_thresh)
-
-        if box_roi_pool is None:
-            box_roi_pool = MultiScaleRoIAlign(
-                featmap_names=['0', '1', '2', '3'],
-                output_size=7,
-                sampling_ratio=2)
-
-        if box_head is None:
-            resolution = box_roi_pool.output_size[0]
-            representation_size = 1024
-            box_head = TwoMLPHead(
-                out_channels * resolution ** 2,
-                representation_size)
-
-        if box_predictor is None:
-            representation_size = 1024
-            box_predictor = FastRCNNPredictor(
-                representation_size,
-                num_classes)
-
-        roi_heads = RoIHeads(
-            # Box
-            box_roi_pool, box_head, box_predictor,
-            box_fg_iou_thresh, box_bg_iou_thresh,
-            box_batch_size_per_image, box_positive_fraction,
+        if mask_head is None:
+            mask_layers = (256, 256, 256, 256)
+            mask_dilation = 1
+            mask_head = MaskRCNNHeads(out_channels, mask_layers, mask_dilation)
+
+        if mask_predictor is None:
+            mask_predictor_in_channels = 256  # == mask_layers[-1]
+            mask_dim_reduced = 256
+            mask_predictor = MaskRCNNPredictor(mask_predictor_in_channels, mask_dim_reduced, num_classes)
+
+        super().__init__(
+            backbone,
+            num_classes,
+            # transform parameters
+            min_size,
+            max_size,
+            image_mean,
+            image_std,
+            # RPN-specific parameters
+            rpn_anchor_generator,
+            rpn_head,
+            rpn_pre_nms_top_n_train,
+            rpn_pre_nms_top_n_test,
+            rpn_post_nms_top_n_train,
+            rpn_post_nms_top_n_test,
+            rpn_nms_thresh,
+            rpn_fg_iou_thresh,
+            rpn_bg_iou_thresh,
+            rpn_batch_size_per_image,
+            rpn_positive_fraction,
+            rpn_score_thresh,
+            # Box parameters
+            box_roi_pool,
+            box_head,
+            box_predictor,
+            box_score_thresh,
+            box_nms_thresh,
+            box_detections_per_img,
+            box_fg_iou_thresh,
+            box_bg_iou_thresh,
+            box_batch_size_per_image,
+            box_positive_fraction,
             bbox_reg_weights,
-            box_score_thresh, box_nms_thresh, box_detections_per_img)
-
-        if image_mean is None:
-            image_mean = [0.485, 0.456, 0.406]
-        if image_std is None:
-            image_std = [0.229, 0.224, 0.225]
-        transform = GeneralizedRCNNTransform(min_size, max_size, image_mean, image_std)
-
-        super(FasterRCNN, self).__init__(backbone, rpn, roi_heads, transform)
+            **kwargs,
+        )
 
+        self.roi_heads.mask_roi_pool = mask_roi_pool
+        self.roi_heads.mask_head = mask_head
+        self.roi_heads.mask_predictor = mask_predictor
+
+
+class MaskRCNNHeads(nn.Sequential):
+    _version = 2
+
+    def __init__(self, in_channels, layers, dilation, norm_layer: Optional[Callable[..., nn.Module]] = None):
+        """
+        Args:
+            in_channels (int): number of input channels
+            layers (list): feature dimensions of each FCN layer
+            dilation (int): dilation rate of kernel
+            norm_layer (callable, optional): Module specifying the normalization layer to use. Default: None
+        """
+        blocks = []
+        next_feature = in_channels
+        for layer_features in layers:
+            blocks.append(
+                misc_nn_ops.Conv2dNormActivation(
+                    next_feature,
+                    layer_features,
+                    kernel_size=3,
+                    stride=1,
+                    padding=dilation,
+                    dilation=dilation,
+                    norm_layer=norm_layer,
+                )
+            )
+            next_feature = layer_features
 
-class TwoMLPHead(nn.Module):
-    """
-    Standard heads for FPN-based models
-
-    Args:
-        in_channels (int): number of input channels
-        representation_size (int): size of the intermediate representation
-    """
-
-    def __init__(self, in_channels, representation_size):
-        super(TwoMLPHead, self).__init__()
-
-        self.representation_size = representation_size
-        self.fc6 = nn.Linear(in_channels, representation_size)
-        self.fc7 = nn.Linear(representation_size, representation_size)
-
-    # TODO: Linear currently not support null input with shape (0, a, b, c),
-    # manually construct empty tensor as return value
-    def forward(self, x):
-        if x.numel() == 0:
-            return torch.empty(x.shape[0], self.representation_size)
-        x = x.flatten(start_dim=1)
-
-        x = F.relu(self.fc6(x))
-        x = F.relu(self.fc7(x))
-
-        return x
-
+        super().__init__(*blocks)
+        for layer in self.modules():
+            if isinstance(layer, nn.Conv2d):
+                nn.init.kaiming_normal_(layer.weight, mode="fan_out", nonlinearity="relu")
+                if layer.bias is not None:
+                    nn.init.zeros_(layer.bias)
+
+    def _load_from_state_dict(
+        self,
+        state_dict,
+        prefix,
+        local_metadata,
+        strict,
+        missing_keys,
+        unexpected_keys,
+        error_msgs,
+    ):
+        version = local_metadata.get("version", None)
+
+        if version is None or version < 2:
+            num_blocks = len(self)
+            for i in range(num_blocks):
+                for type in ["weight", "bias"]:
+                    old_key = f"{prefix}mask_fcn{i+1}.{type}"
+                    new_key = f"{prefix}{i}.0.{type}"
+                    if old_key in state_dict:
+                        state_dict[new_key] = state_dict.pop(old_key)
+
+        super()._load_from_state_dict(
+            state_dict,
+            prefix,
+            local_metadata,
+            strict,
+            missing_keys,
+            unexpected_keys,
+            error_msgs,
+        )
+
+
+class MaskRCNNPredictor(nn.Sequential):
+    def __init__(self, in_channels, dim_reduced, num_classes):
+        super().__init__(
+            OrderedDict(
+                [
+                    ("conv5_mask", nn.ConvTranspose2d(in_channels, dim_reduced, 2, 2, 0)),
+                    ("relu", nn.ReLU(inplace=False)),
+                    ("mask_fcn_logits", nn.Conv2d(dim_reduced, num_classes, 1, 1, 0)),
+                ]
+            )
+        )
 
-class FastRCNNPredictor(nn.Module):
-    """
-    Standard classification + bounding box regression layers
-    for Fast R-CNN.
+        for name, param in self.named_parameters():
+            if "weight" in name:
+                nn.init.kaiming_normal_(param, mode="fan_out", nonlinearity="relu")
+            # elif "bias" in name:
+            #     nn.init.constant_(param, 0)
 
-    Args:
-        in_channels (int): number of input channels
-        num_classes (int): number of output classes (including background)
-    """
 
-    def __init__(self, in_channels, num_classes):
-        super(FastRCNNPredictor, self).__init__()
-        self.num_classes = num_classes
-        self.cls_score = nn.Linear(in_channels, num_classes)
-        self.bbox_pred = nn.Linear(in_channels, num_classes * 4)
-
-    # TODO: Linear currently not support null input with shape (0, a, b, c),
-    # manually construct empty tensor as return value
-    def forward(self, x):
-        if x.numel() == 0:
-            return torch.empty(x.shape[0], self.num_classes), torch.empty(x.shape[0], self.num_classes * 4)
-        if x.dim() == 4:
-            assert list(x.shape[2:]) == [1, 1]
-        x = x.flatten(start_dim=1)
-        scores = self.cls_score(x)
-        bbox_deltas = self.bbox_pred(x)
+_COMMON_META = {
+    "categories": _COCO_CATEGORIES,
+    "min_size": (1, 1),
+}
 
-        return scores, bbox_deltas
 
+class MaskRCNN_ResNet50_FPN_Weights(WeightsEnum):
+    COCO_V1 = Weights(
+        url="https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth",
+        transforms=ObjectDetection,
+        meta={
+            **_COMMON_META,
+            "num_params": 44401393,
+            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#mask-r-cnn",
+            "_metrics": {
+                "COCO-val2017": {
+                    "box_map": 37.9,
+                    "mask_map": 34.6,
+                }
+            },
+            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
+        },
+    )
+    DEFAULT = COCO_V1
+
+
+class MaskRCNN_ResNet50_FPN_V2_Weights(WeightsEnum):
+    COCO_V1 = Weights(
+        url="https://download.pytorch.org/models/maskrcnn_resnet50_fpn_v2_coco-73cbd019.pth",
+        transforms=ObjectDetection,
+        meta={
+            **_COMMON_META,
+            "num_params": 46359409,
+            "recipe": "https://github.com/pytorch/vision/pull/5773",
+            "_metrics": {
+                "COCO-val2017": {
+                    "box_map": 47.4,
+                    "mask_map": 41.8,
+                }
+            },
+            "_docs": """These weights were produced using an enhanced training recipe to boost the model accuracy.""",
+        },
+    )
+    DEFAULT = COCO_V1
+
+
+@handle_legacy_interface(
+    weights=("pretrained", MaskRCNN_ResNet50_FPN_Weights.COCO_V1),
+    weights_backbone=("pretrained_backbone", ResNet50_Weights.IMAGENET1K_V1),
+)
+def maskrcnn_resnet50_fpn(
+    *,
+    weights: Optional[MaskRCNN_ResNet50_FPN_Weights] = None,
+    progress: bool = True,
+    num_classes: Optional[int] = None,
+    weights_backbone: Optional[ResNet50_Weights] = ResNet50_Weights.IMAGENET1K_V1,
+    trainable_backbone_layers: Optional[int] = None,
+    **kwargs: Any,
+) -> MaskRCNN:
+    """Mask R-CNN model with a ResNet-50-FPN backbone from the `Mask R-CNN
+    <https://arxiv.org/abs/1703.06870>`_ paper.
 
-def fasterrcnn_resnet50_fpn(pretrained=False, progress=True,
-                            num_classes=91, pretrained_backbone=True, trainable_backbone_layers=None, **kwargs):
-    """
-    Constructs a Faster R-CNN model with a ResNet-50-FPN backbone.
+    .. betastatus:: detection module
 
     The input to the model is expected to be a list of tensors, each of shape ``[C, H, W]``, one for each
     image, and should be in ``0-1`` range. Different images can have different sizes.
 
     The behavior of the model changes depending if it is in training or evaluation mode.
 
     During training, the model expects both the input tensors, as well as a targets (list of dictionary),
     containing:
 
         - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with
           ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.
         - labels (``Int64Tensor[N]``): the class label for each ground-truth box
+        - masks (``UInt8Tensor[N, H, W]``): the segmentation binary masks for each instance
 
     The model returns a ``Dict[Tensor]`` during training, containing the classification and regression
-    losses for both the RPN and the R-CNN.
+    losses for both the RPN and the R-CNN, and the mask loss.
 
     During inference, the model requires only the input tensors, and returns the post-processed
     predictions as a ``List[Dict[Tensor]]``, one for each input image. The fields of the ``Dict`` are as
-    follows, where ``N`` is the number of detections:
+    follows, where ``N`` is the number of detected instances:
 
         - boxes (``FloatTensor[N, 4]``): the predicted boxes in ``[x1, y1, x2, y2]`` format, with
           ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.
-        - labels (``Int64Tensor[N]``): the predicted labels for each detection
-        - scores (``Tensor[N]``): the scores of each detection
+        - labels (``Int64Tensor[N]``): the predicted labels for each instance
+        - scores (``Tensor[N]``): the scores or each instance
+        - masks (``UInt8Tensor[N, 1, H, W]``): the predicted masks for each instance, in ``0-1`` range. In order to
+          obtain the final segmentation masks, the soft masks can be thresholded, generally
+          with a value of 0.5 (``mask >= 0.5``)
 
-    For more details on the output, you may refer to :ref:`instance_seg_output`.
+    For more details on the output and on how to plot the masks, you may refer to :ref:`instance_seg_output`.
 
-    Faster R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.
+    Mask R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.
 
     Example::
 
-        >>> model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
-        >>> # For training
-        >>> images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)
-        >>> labels = torch.randint(1, 91, (4, 11))
-        >>> images = list(image for image in images)
-        >>> targets = []
-        >>> for i in range(len(images)):
-        >>>     d = {}
-        >>>     d['boxes'] = boxes[i]
-        >>>     d['labels'] = labels[i]
-        >>>     targets.append(d)
-        >>> output = model(images, targets)
-        >>> # For inference
+        >>> model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT)
         >>> model.eval()
         >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
         >>> predictions = model(x)
         >>>
         >>> # optionally, if you want to export the model to ONNX:
-        >>> torch.onnx.export(model, x, "faster_rcnn.onnx", opset_version = 11)
+        >>> torch.onnx.export(model, x, "mask_rcnn.onnx", opset_version = 11)
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on COCO train2017
-        progress (bool): If True, displays a progress bar of the download to stderr
-        num_classes (int): number of output classes of the model (including the background)
-        pretrained_backbone (bool): If True, returns a model with backbone pre-trained on Imagenet
-        trainable_backbone_layers (int): number of trainable (not frozen) resnet layers starting from final block.
-            Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.
-    """
-    trainable_backbone_layers = _validate_trainable_layers(
-        pretrained or pretrained_backbone, trainable_backbone_layers, 5, 3)
+        weights (:class:`~torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights` below for
+            more details, and possible values. By default, no pre-trained
+            weights are used.
+        progress (bool, optional): If True, displays a progress bar of the
+            download to stderr. Default is True.
+        num_classes (int, optional): number of output classes of the model (including the background)
+        weights_backbone (:class:`~torchvision.models.ResNet50_Weights`, optional): The
+            pretrained weights for the backbone.
+        trainable_backbone_layers (int, optional): number of trainable (not frozen) layers starting from
+            final block. Valid values are between 0 and 5, with 5 meaning all backbone layers are
+            trainable. If ``None`` is passed (the default) this value is set to 3.
+        **kwargs: parameters passed to the ``torchvision.models.detection.mask_rcnn.MaskRCNN``
+            base class. Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/detection/mask_rcnn.py>`_
+            for more details about this class.
+
+    .. autoclass:: torchvision.models.detection.MaskRCNN_ResNet50_FPN_Weights
+        :members:
+    """
+    weights = MaskRCNN_ResNet50_FPN_Weights.verify(weights)
+    weights_backbone = ResNet50_Weights.verify(weights_backbone)
+
+    if weights is not None:
+        weights_backbone = None
+        num_classes = _ovewrite_value_param(num_classes, len(weights.meta["categories"]))
+    elif num_classes is None:
+        num_classes = 91
+
+    is_trained = weights is not None or weights_backbone is not None
+    trainable_backbone_layers = _validate_trainable_layers(is_trained, trainable_backbone_layers, 5, 3)
+    norm_layer = misc_nn_ops.FrozenBatchNorm2d if is_trained else nn.BatchNorm2d
+
+    backbone = resnet50(weights=weights_backbone, progress=progress, norm_layer=norm_layer)
+    backbone = _resnet_fpn_extractor(backbone, trainable_backbone_layers)
+    model = MaskRCNN(backbone, num_classes=num_classes, **kwargs)
+
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
+        if weights == MaskRCNN_ResNet50_FPN_Weights.COCO_V1:
+            overwrite_eps(model, 0.0)
 
-    if pretrained:
-        # no need to download the backbone if pretrained is set
-        pretrained_backbone = False
-    backbone = resnet_fpn_backbone('resnet50', pretrained_backbone, trainable_layers=trainable_backbone_layers)
-    model = FasterRCNN(backbone, num_classes, **kwargs)
-    if pretrained:
-        state_dict = load_state_dict_from_url(model_urls['fasterrcnn_resnet50_fpn_coco'])
-        model.load_state_dict(state_dict)
-        overwrite_eps(model, 0.0)
     return model
 
 
-def _fasterrcnn_mobilenet_v3_large_fpn(weights_name, pretrained=False, progress=True, num_classes=91,
-                                       pretrained_backbone=True, trainable_backbone_layers=None, **kwargs):
-    unsupported_attr(progress)
-    trainable_backbone_layers = _validate_trainable_layers(
-        pretrained or pretrained_backbone, trainable_backbone_layers, 6, 3)
-
-    if pretrained:
-        pretrained_backbone = False
-    backbone = mobilenet_backbone("mobilenet_v3_large", pretrained_backbone, True,
-                                  trainable_layers=trainable_backbone_layers)
-
-    anchor_sizes = ((32, 64, 128, 256, 512, ), ) * 3
-    aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)
-
-    model = FasterRCNN(backbone, num_classes, rpn_anchor_generator=AnchorGenerator(anchor_sizes, aspect_ratios),
-                       **kwargs)
-    if pretrained:
-        if model_urls.get(weights_name, None) is None:
-            raise ValueError("No checkpoint is available for model {}".format(weights_name))
-        check_ckpt_file(model_urls[weights_name])
-        state_dict = load_state_dict_from_url(model_urls[weights_name])
-        model.load_state_dict(state_dict)
-    return model
+def maskrcnn_resnet50_fpn_v2(
+    *,
+    weights: Optional[MaskRCNN_ResNet50_FPN_V2_Weights] = None,
+    progress: bool = True,
+    num_classes: Optional[int] = None,
+    weights_backbone: Optional[ResNet50_Weights] = None,
+    trainable_backbone_layers: Optional[int] = None,
+    **kwargs: Any,
+) -> MaskRCNN:
+    """Improved Mask R-CNN model with a ResNet-50-FPN backbone from the `Benchmarking Detection Transfer
+    Learning with Vision Transformers <https://arxiv.org/abs/2111.11429>`_ paper.
 
+    .. betastatus:: detection module
 
-def fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=False, progress=True, num_classes=91, pretrained_backbone=True,
-                                          trainable_backbone_layers=None, **kwargs):
-    """
-    Constructs a low resolution Faster R-CNN model with a MobileNetV3-Large FPN backbone tunned for mobile use-cases.
-    It works similarly to Faster R-CNN with ResNet-50 FPN backbone. See
-    :func:`~torchvision.models.detection.fasterrcnn_resnet50_fpn` for more
-    details.
-
-    Example::
-
-        >>> model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_320_fpn(pretrained=True)
-        >>> model.eval()
-        >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
-        >>> predictions = model(x)
+    :func:`~torchvision.models.detection.maskrcnn_resnet50_fpn` for more details.
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on COCO train2017
-        progress (bool): If True, displays a progress bar of the download to stderr
-        num_classes (int): number of output classes of the model (including the background)
-        pretrained_backbone (bool): If True, returns a model with backbone pre-trained on Imagenet
-        trainable_backbone_layers (int): number of trainable (not frozen) resnet layers starting from final block.
-            Valid values are between 0 and 6, with 6 meaning all backbone layers are trainable.
-    """
-    weights_name = "fasterrcnn_mobilenet_v3_large_320_fpn_coco"
-    defaults = {
-        "min_size": 320,
-        "max_size": 640,
-        "rpn_pre_nms_top_n_test": 150,
-        "rpn_post_nms_top_n_test": 150,
-        "rpn_score_thresh": 0.05,
-    }
+        weights (:class:`~torchvision.models.detection.MaskRCNN_ResNet50_FPN_V2_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.detection.MaskRCNN_ResNet50_FPN_V2_Weights` below for
+            more details, and possible values. By default, no pre-trained
+            weights are used.
+        progress (bool, optional): If True, displays a progress bar of the
+            download to stderr. Default is True.
+        num_classes (int, optional): number of output classes of the model (including the background)
+        weights_backbone (:class:`~torchvision.models.ResNet50_Weights`, optional): The
+            pretrained weights for the backbone.
+        trainable_backbone_layers (int, optional): number of trainable (not frozen) layers starting from
+            final block. Valid values are between 0 and 5, with 5 meaning all backbone layers are
+            trainable. If ``None`` is passed (the default) this value is set to 3.
+        **kwargs: parameters passed to the ``torchvision.models.detection.mask_rcnn.MaskRCNN``
+            base class. Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/detection/mask_rcnn.py>`_
+            for more details about this class.
+
+    .. autoclass:: torchvision.models.detection.MaskRCNN_ResNet50_FPN_V2_Weights
+        :members:
+    """
+    weights = MaskRCNN_ResNet50_FPN_V2_Weights.verify(weights)
+    weights_backbone = ResNet50_Weights.verify(weights_backbone)
+
+    if weights is not None:
+        weights_backbone = None
+        num_classes = _ovewrite_value_param(num_classes, len(weights.meta["categories"]))
+    elif num_classes is None:
+        num_classes = 91
+
+    is_trained = weights is not None or weights_backbone is not None
+    trainable_backbone_layers = _validate_trainable_layers(is_trained, trainable_backbone_layers, 5, 3)
+
+    backbone = resnet50(weights=weights_backbone, progress=progress)
+    backbone = _resnet_fpn_extractor(backbone, trainable_backbone_layers, norm_layer=nn.BatchNorm2d)
+    rpn_anchor_generator = _default_anchorgen()
+    rpn_head = RPNHead(backbone.out_channels, rpn_anchor_generator.num_anchors_per_location()[0], conv_depth=2)
+    box_head = FastRCNNConvFCHead(
+        (backbone.out_channels, 7, 7), [256, 256, 256, 256], [1024], norm_layer=nn.BatchNorm2d
+    )
+    mask_head = MaskRCNNHeads(backbone.out_channels, [256, 256, 256, 256], 1, norm_layer=nn.BatchNorm2d)
+    model = MaskRCNN(
+        backbone,
+        num_classes=num_classes,
+        rpn_anchor_generator=rpn_anchor_generator,
+        rpn_head=rpn_head,
+        box_head=box_head,
+        mask_head=mask_head,
+        **kwargs,
+    )
 
-    kwargs = {**defaults, **kwargs}
-    return _fasterrcnn_mobilenet_v3_large_fpn(weights_name, pretrained=pretrained, progress=progress,
-                                              num_classes=num_classes, pretrained_backbone=pretrained_backbone,
-                                              trainable_backbone_layers=trainable_backbone_layers, **kwargs)
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
 
+    return model
 
-def fasterrcnn_mobilenet_v3_large_fpn(pretrained=False, progress=True, num_classes=91, pretrained_backbone=True,
-                                      trainable_backbone_layers=None, **kwargs):
-    """
-    Constructs a high resolution Faster R-CNN model with a MobileNetV3-Large FPN backbone.
-    It works similarly to Faster R-CNN with ResNet-50 FPN backbone. See
-    :func:`~torchvision.models.detection.fasterrcnn_resnet50_fpn` for more
-    details.
 
-    Example::
+# The dictionary below is internal implementation detail and will be removed in v0.15
+from .._utils import _ModelURLs
 
-        >>> model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)
-        >>> model.eval()
-        >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
-        >>> predictions = model(x)
 
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on COCO train2017
-        progress (bool): If True, displays a progress bar of the download to stderr
-        num_classes (int): number of output classes of the model (including the background)
-        pretrained_backbone (bool): If True, returns a model with backbone pre-trained on Imagenet
-        trainable_backbone_layers (int): number of trainable (not frozen) resnet layers starting from final block.
-            Valid values are between 0 and 6, with 6 meaning all backbone layers are trainable.
-    """
-    weights_name = "fasterrcnn_mobilenet_v3_large_fpn_coco"
-    defaults = {
-        "rpn_score_thresh": 0.05,
+model_urls = _ModelURLs(
+    {
+        "maskrcnn_resnet50_fpn_coco": MaskRCNN_ResNet50_FPN_Weights.COCO_V1.url,
     }
-
-    kwargs = {**defaults, **kwargs}
-    return _fasterrcnn_mobilenet_v3_large_fpn(weights_name, pretrained=pretrained, progress=progress,
-                                              num_classes=num_classes, pretrained_backbone=pretrained_backbone,
-                                              trainable_backbone_layers=trainable_backbone_layers, **kwargs)
+)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/generalized_rcnn.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/generalized_rcnn.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,16 +1,19 @@
 """
 Implements the Generalized R-CNN framework
 """
 
+import warnings
 from collections import OrderedDict
+from typing import Tuple, List, Dict, Optional, Union
+
 import mindtorch.torch as torch
 from mindtorch.torch import nn, Tensor
-import warnings
-from typing import Tuple, List, Dict, Optional, Union
+
+from ...utils import _log_api_usage_once
 
 
 class GeneralizedRCNN(nn.Module):
     """
     Main class for Generalized R-CNN.
 
     Args:
@@ -18,93 +21,98 @@
         rpn (nn.Module):
         roi_heads (nn.Module): takes the features + the proposals from the RPN and computes
             detections / masks from it.
         transform (nn.Module): performs the data transformation from the inputs to feed into
             the model
     """
 
-    def __init__(self, backbone, rpn, roi_heads, transform):
-        super(GeneralizedRCNN, self).__init__()
+    def __init__(self, backbone: nn.Module, rpn: nn.Module, roi_heads: nn.Module, transform: nn.Module) -> None:
+        super().__init__()
+        _log_api_usage_once(self)
         self.transform = transform
         self.backbone = backbone
         self.rpn = rpn
         self.roi_heads = roi_heads
         # used only on torchscript mode
         self._has_warned = False
 
-    # @torch.jit.unused
+    @torch.jit.unused
     def eager_outputs(self, losses, detections):
         # type: (Dict[str, Tensor], List[Dict[str, Tensor]]) -> Union[Dict[str, Tensor], List[Dict[str, Tensor]]]
         if self.training:
             return losses
 
         return detections
 
     def forward(self, images, targets=None):
         # type: (List[Tensor], Optional[List[Dict[str, Tensor]]]) -> Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]
         """
         Args:
             images (list[Tensor]): images to be processed
-            targets (list[Dict[Tensor]]): ground-truth boxes present in the image (optional)
+            targets (list[Dict[str, Tensor]]): ground-truth boxes present in the image (optional)
 
         Returns:
             result (list[BoxList] or dict[Tensor]): the output from the model.
                 During training, it returns a dict[Tensor] which contains the losses.
                 During testing, it returns list[BoxList] contains additional fields
                 like `scores`, `labels` and `mask` (for Mask R-CNN models).
 
         """
-        if self.training and targets is None:
-            raise ValueError("In training mode, targets should be passed")
         if self.training:
-            assert targets is not None
-            for target in targets:
-                boxes = target["boxes"]
-                if isinstance(boxes, torch.Tensor):
-                    if len(boxes.shape) != 2 or boxes.shape[-1] != 4:
-                        raise ValueError("Expected target boxes to be a tensor"
-                                         "of shape [N, 4], got {:}.".format(
-                                             boxes.shape))
-                else:
-                    raise ValueError("Expected target boxes to be of type "
-                                     "Tensor, got {:}.".format(type(boxes)))
+            if targets is None:
+                torch._assert(False, "targets should not be none when in training mode")
+            else:
+                for target in targets:
+                    boxes = target["boxes"]
+                    if isinstance(boxes, torch.Tensor):
+                        torch._assert(
+                            len(boxes.shape) == 2 and boxes.shape[-1] == 4,
+                            f"Expected target boxes to be a tensor of shape [N, 4], got {boxes.shape}.",
+                        )
+                    else:
+                        torch._assert(False, f"Expected target boxes to be of type Tensor, got {type(boxes)}.")
 
         original_image_sizes: List[Tuple[int, int]] = []
         for img in images:
             val = img.shape[-2:]
-            assert len(val) == 2
+            torch._assert(
+                len(val) == 2,
+                f"expecting the last two dimensions of the Tensor to be H and W instead got {img.shape[-2:]}",
+            )
             original_image_sizes.append((val[0], val[1]))
 
         images, targets = self.transform(images, targets)
 
         # Check for degenerate boxes
         # TODO: Move this to a function
         if targets is not None:
             for target_idx, target in enumerate(targets):
                 boxes = target["boxes"]
                 degenerate_boxes = boxes[:, 2:] <= boxes[:, :2]
                 if degenerate_boxes.any():
                     # print the first degenerate box
                     bb_idx = torch.where(degenerate_boxes.any(dim=1))[0][0]
                     degen_bb: List[float] = boxes[bb_idx].tolist()
-                    raise ValueError("All bounding boxes should have positive height and width."
-                                     " Found invalid box {} for target at index {}."
-                                     .format(degen_bb, target_idx))
+                    torch._assert(
+                        False,
+                        "All bounding boxes should have positive height and width."
+                        f" Found invalid box {degen_bb} for target at index {target_idx}.",
+                    )
 
         features = self.backbone(images.tensors)
         if isinstance(features, torch.Tensor):
-            features = OrderedDict([('0', features)])
+            features = OrderedDict([("0", features)])
         proposals, proposal_losses = self.rpn(images, features, targets)
         detections, detector_losses = self.roi_heads(features, proposals, images.image_sizes, targets)
-        detections = self.transform.postprocess(detections, images.image_sizes, original_image_sizes)
+        detections = self.transform.postprocess(detections, images.image_sizes, original_image_sizes)  # type: ignore[operator]
 
         losses = {}
         losses.update(detector_losses)
         losses.update(proposal_losses)
 
-        # if torch.jit.is_scripting():
-        #     if not self._has_warned:
-        #         warnings.warn("RCNN always returns a (Losses, Detections) tuple in scripting")
-        #         self._has_warned = True
-        #     return losses, detections
-        # else:
-        return self.eager_outputs(losses, detections)
+        if torch.jit.is_scripting():
+            if not self._has_warned:
+                warnings.warn("RCNN always returns a (Losses, Detections) tuple in scripting")
+                self._has_warned = True
+            return losses, detections
+        else:
+            return self.eager_outputs(losses, detections)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/image_list.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/image_list.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,25 +1,25 @@
+from typing import List, Tuple
+
 import mindtorch.torch as torch
 from mindtorch.torch import Tensor
-from typing import List, Tuple
 
 
-class ImageList(object):
+class ImageList:
     """
     Structure that holds a list of images (of possibly
     varying sizes) as a single tensor.
     This works by padding the images to the same size,
     and storing in a field the original sizes of each image
+
+    Args:
+        tensors (tensor): Tensor containing images.
+        image_sizes (list[tuple[int, int]]): List of Tuples each containing size of images.
     """
 
-    def __init__(self, tensors: Tensor, image_sizes: List[Tuple[int, int]]):
-        """
-        Args:
-            tensors (tensor)
-            image_sizes (list[tuple[int, int]])
-        """
+    def __init__(self, tensors: Tensor, image_sizes: List[Tuple[int, int]]) -> None:
         self.tensors = tensors
         self.image_sizes = image_sizes
 
-    def to(self, device: torch.device) -> 'ImageList':
+    def to(self, device: torch.device) -> "ImageList":
         cast_tensor = self.tensors.to(device)
         return ImageList(cast_tensor, self.image_sizes)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/keypoint_rcnn.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/keypoint_rcnn.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,31 +1,30 @@
+from typing import Any, Optional
+
 import mindtorch.torch as torch
 from mindtorch.torch import nn
-from mindtorch import unsupported_attr
 from mindtorch.torchvision.ops import MultiScaleRoIAlign
 
+from ...ops import misc as misc_nn_ops
+from ...transforms._presets import ObjectDetection
+from .._api import WeightsEnum, Weights
+from .._meta import _COCO_PERSON_CATEGORIES, _COCO_PERSON_KEYPOINT_NAMES
+from .._utils import handle_legacy_interface, _ovewrite_value_param
+from ..resnet import ResNet50_Weights, resnet50
 from ._utils import overwrite_eps
-from ..utils import check_ckpt_file, model_path_name
-
+from .backbone_utils import _resnet_fpn_extractor, _validate_trainable_layers
 from .faster_rcnn import FasterRCNN
-from .backbone_utils import resnet_fpn_backbone, _validate_trainable_layers
-from mindtorch.torch.hub import load_state_dict_from_url
 
 
 __all__ = [
-    "KeypointRCNN", "keypointrcnn_resnet50_fpn"
+    "KeypointRCNN",
+    "KeypointRCNN_ResNet50_FPN_Weights",
+    "keypointrcnn_resnet50_fpn",
 ]
 
-model_urls = {
-    # legacy model for BC reasons, see https://github.com/pytorch/vision/issues/1606
-    'keypointrcnn_resnet50_fpn_coco_legacy':
-        model_path_name + 'keypointrcnn_resnet50_fpn_coco-9f466800.pth',
-    'keypointrcnn_resnet50_fpn_coco':
-        model_path_name + 'keypointrcnn_resnet50_fpn_coco-fc266e95.pth',
-}
 
 class KeypointRCNN(FasterRCNN):
     """
     Implements Keypoint R-CNN.
 
     The input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each
     image, and should be in 0-1 range. Different images can have different sizes.
@@ -116,15 +115,15 @@
         >>> import torch
         >>> import torchvision
         >>> from torchvision.models.detection import KeypointRCNN
         >>> from torchvision.models.detection.anchor_utils import AnchorGenerator
         >>>
         >>> # load a pre-trained model for classification and return
         >>> # only the features
-        >>> backbone = torchvision.models.mobilenet_v2(pretrained=True).features
+        >>> backbone = torchvision.models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT).features
         >>> # KeypointRCNN needs to know the number of
         >>> # output channels in a backbone. For mobilenet_v2, it's 1280
         >>> # so we need to add it here
         >>> backbone.out_channels = 1280
         >>>
         >>> # let's make the RPN generate 5 x 3 anchors per spatial
         >>> # location, with 5 different sizes and 3 different aspect
@@ -155,151 +154,235 @@
         >>>                      box_roi_pool=roi_pooler,
         >>>                      keypoint_roi_pool=keypoint_roi_pooler)
         >>> model.eval()
         >>> model.eval()
         >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
         >>> predictions = model(x)
     """
-    def __init__(self, backbone, num_classes=None,
-                 # transform parameters
-                 min_size=None, max_size=1333,
-                 image_mean=None, image_std=None,
-                 # RPN parameters
-                 rpn_anchor_generator=None, rpn_head=None,
-                 rpn_pre_nms_top_n_train=2000, rpn_pre_nms_top_n_test=1000,
-                 rpn_post_nms_top_n_train=2000, rpn_post_nms_top_n_test=1000,
-                 rpn_nms_thresh=0.7,
-                 rpn_fg_iou_thresh=0.7, rpn_bg_iou_thresh=0.3,
-                 rpn_batch_size_per_image=256, rpn_positive_fraction=0.5,
-                 rpn_score_thresh=0.0,
-                 # Box parameters
-                 box_roi_pool=None, box_head=None, box_predictor=None,
-                 box_score_thresh=0.05, box_nms_thresh=0.5, box_detections_per_img=100,
-                 box_fg_iou_thresh=0.5, box_bg_iou_thresh=0.5,
-                 box_batch_size_per_image=512, box_positive_fraction=0.25,
-                 bbox_reg_weights=None,
-                 # keypoint parameters
-                 keypoint_roi_pool=None, keypoint_head=None, keypoint_predictor=None,
-                 num_keypoints=17):
 
-        assert isinstance(keypoint_roi_pool, (MultiScaleRoIAlign, type(None)))
+    def __init__(
+        self,
+        backbone,
+        num_classes=None,
+        # transform parameters
+        min_size=None,
+        max_size=1333,
+        image_mean=None,
+        image_std=None,
+        # RPN parameters
+        rpn_anchor_generator=None,
+        rpn_head=None,
+        rpn_pre_nms_top_n_train=2000,
+        rpn_pre_nms_top_n_test=1000,
+        rpn_post_nms_top_n_train=2000,
+        rpn_post_nms_top_n_test=1000,
+        rpn_nms_thresh=0.7,
+        rpn_fg_iou_thresh=0.7,
+        rpn_bg_iou_thresh=0.3,
+        rpn_batch_size_per_image=256,
+        rpn_positive_fraction=0.5,
+        rpn_score_thresh=0.0,
+        # Box parameters
+        box_roi_pool=None,
+        box_head=None,
+        box_predictor=None,
+        box_score_thresh=0.05,
+        box_nms_thresh=0.5,
+        box_detections_per_img=100,
+        box_fg_iou_thresh=0.5,
+        box_bg_iou_thresh=0.5,
+        box_batch_size_per_image=512,
+        box_positive_fraction=0.25,
+        bbox_reg_weights=None,
+        # keypoint parameters
+        keypoint_roi_pool=None,
+        keypoint_head=None,
+        keypoint_predictor=None,
+        num_keypoints=None,
+        **kwargs,
+    ):
+
+        if not isinstance(keypoint_roi_pool, (MultiScaleRoIAlign, type(None))):
+            raise TypeError(
+                "keypoint_roi_pool should be of type MultiScaleRoIAlign or None instead of {type(keypoint_roi_pool)}"
+            )
         if min_size is None:
             min_size = (640, 672, 704, 736, 768, 800)
 
-        if num_classes is not None:
+        if num_keypoints is not None:
             if keypoint_predictor is not None:
-                raise ValueError("num_classes should be None when keypoint_predictor is specified")
+                raise ValueError("num_keypoints should be None when keypoint_predictor is specified")
+        else:
+            num_keypoints = 17
 
         out_channels = backbone.out_channels
 
         if keypoint_roi_pool is None:
-            keypoint_roi_pool = MultiScaleRoIAlign(
-                featmap_names=['0', '1', '2', '3'],
-                output_size=14,
-                sampling_ratio=2)
+            keypoint_roi_pool = MultiScaleRoIAlign(featmap_names=["0", "1", "2", "3"], output_size=14, sampling_ratio=2)
 
         if keypoint_head is None:
             keypoint_layers = tuple(512 for _ in range(8))
             keypoint_head = KeypointRCNNHeads(out_channels, keypoint_layers)
 
         if keypoint_predictor is None:
             keypoint_dim_reduced = 512  # == keypoint_layers[-1]
             keypoint_predictor = KeypointRCNNPredictor(keypoint_dim_reduced, num_keypoints)
 
-        super(KeypointRCNN, self).__init__(
-            backbone, num_classes,
+        super().__init__(
+            backbone,
+            num_classes,
             # transform parameters
-            min_size, max_size,
-            image_mean, image_std,
+            min_size,
+            max_size,
+            image_mean,
+            image_std,
             # RPN-specific parameters
-            rpn_anchor_generator, rpn_head,
-            rpn_pre_nms_top_n_train, rpn_pre_nms_top_n_test,
-            rpn_post_nms_top_n_train, rpn_post_nms_top_n_test,
+            rpn_anchor_generator,
+            rpn_head,
+            rpn_pre_nms_top_n_train,
+            rpn_pre_nms_top_n_test,
+            rpn_post_nms_top_n_train,
+            rpn_post_nms_top_n_test,
             rpn_nms_thresh,
-            rpn_fg_iou_thresh, rpn_bg_iou_thresh,
-            rpn_batch_size_per_image, rpn_positive_fraction,
+            rpn_fg_iou_thresh,
+            rpn_bg_iou_thresh,
+            rpn_batch_size_per_image,
+            rpn_positive_fraction,
             rpn_score_thresh,
             # Box parameters
-            box_roi_pool, box_head, box_predictor,
-            box_score_thresh, box_nms_thresh, box_detections_per_img,
-            box_fg_iou_thresh, box_bg_iou_thresh,
-            box_batch_size_per_image, box_positive_fraction,
-            bbox_reg_weights)
+            box_roi_pool,
+            box_head,
+            box_predictor,
+            box_score_thresh,
+            box_nms_thresh,
+            box_detections_per_img,
+            box_fg_iou_thresh,
+            box_bg_iou_thresh,
+            box_batch_size_per_image,
+            box_positive_fraction,
+            bbox_reg_weights,
+            **kwargs,
+        )
 
         self.roi_heads.keypoint_roi_pool = keypoint_roi_pool
         self.roi_heads.keypoint_head = keypoint_head
         self.roi_heads.keypoint_predictor = keypoint_predictor
 
 
 class KeypointRCNNHeads(nn.Sequential):
     def __init__(self, in_channels, layers):
         d = []
         next_feature = in_channels
         for out_channels in layers:
             d.append(nn.Conv2d(next_feature, out_channels, 3, stride=1, padding=1))
             d.append(nn.ReLU(inplace=False))
             next_feature = out_channels
-        self.out_channels = out_channels
-        super(KeypointRCNNHeads, self).__init__(*d)
+        super().__init__(*d)
         for m in self.children():
             if isinstance(m, nn.Conv2d):
                 nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
                 nn.init.constant_(m.bias, 0)
 
-    # TODO: conv2d currently not support null input with shape (0, a, b, c),
-    # manually construct empty tensor as return value
-    def forward(self, x):
-        if x.numel() == 0:
-            Hout = (x.shape[2] + 2 * 1 - 1 * (3 - 1) - 1) / 1 + 1
-            Wout = (x.shape[3] + 2 * 1 - 1 * (3 - 1) - 1) / 1 + 1
-            x = torch.empty([x.shape[0], self.out_channels, Hout, Wout])
-        else:
-            x = super().forward(x)
-        return x
 
 class KeypointRCNNPredictor(nn.Module):
     def __init__(self, in_channels, num_keypoints):
-        super(KeypointRCNNPredictor, self).__init__()
+        super().__init__()
         input_features = in_channels
         deconv_kernel = 4
         self.kps_score_lowres = nn.ConvTranspose2d(
             input_features,
             num_keypoints,
             deconv_kernel,
             stride=2,
             padding=deconv_kernel // 2 - 1,
         )
-        nn.init.kaiming_normal_(
-            self.kps_score_lowres.weight, mode="fan_out", nonlinearity="relu"
-        )
+        nn.init.kaiming_normal_(self.kps_score_lowres.weight, mode="fan_out", nonlinearity="relu")
         nn.init.constant_(self.kps_score_lowres.bias, 0)
         self.up_scale = 2
         self.out_channels = num_keypoints
 
-    # TODO: conv2d currently not support null input with shape (0, a, b, c),
-    # manually construct empty tensor as return value
     def forward(self, x):
-        if x.numel() == 0:
-            weight = self.kps_score_lowres.weight
-            Hout = (x.shape[2] + 2 - 1 * (weight.shape[2] - 1) - 1) / 2 + 1
-            Wout = (x.shape[3] + 2 - 1 * (weight.shape[3] - 1) - 1) / 2 + 1
-            x = torch.empty([x.shape[0], weight.shape[0], Hout, Wout])
-        else:
-            x = self.kps_score_lowres(x)
+        x = self.kps_score_lowres(x)
         return torch.nn.functional.interpolate(
             x, scale_factor=float(self.up_scale), mode="bilinear", align_corners=False, recompute_scale_factor=False
         )
 
 
-def keypointrcnn_resnet50_fpn(pretrained=False, progress=True,
-                              num_classes=2, num_keypoints=17,
-                              pretrained_backbone=True, trainable_backbone_layers=None, **kwargs):
+_COMMON_META = {
+    "categories": _COCO_PERSON_CATEGORIES,
+    "keypoint_names": _COCO_PERSON_KEYPOINT_NAMES,
+    "min_size": (1, 1),
+}
+
+
+class KeypointRCNN_ResNet50_FPN_Weights(WeightsEnum):
+    COCO_LEGACY = Weights(
+        url="https://download.pytorch.org/models/keypointrcnn_resnet50_fpn_coco-9f466800.pth",
+        transforms=ObjectDetection,
+        meta={
+            **_COMMON_META,
+            "num_params": 59137258,
+            "recipe": "https://github.com/pytorch/vision/issues/1606",
+            "_metrics": {
+                "COCO-val2017": {
+                    "box_map": 50.6,
+                    "kp_map": 61.1,
+                }
+            },
+            "_docs": """
+                These weights were produced by following a similar training recipe as on the paper but use a checkpoint
+                from an early epoch.
+            """,
+        },
+    )
+    COCO_V1 = Weights(
+        url="https://download.pytorch.org/models/keypointrcnn_resnet50_fpn_coco-fc266e95.pth",
+        transforms=ObjectDetection,
+        meta={
+            **_COMMON_META,
+            "num_params": 59137258,
+            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#keypoint-r-cnn",
+            "_metrics": {
+                "COCO-val2017": {
+                    "box_map": 54.6,
+                    "kp_map": 65.0,
+                }
+            },
+            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
+        },
+    )
+    DEFAULT = COCO_V1
+
+
+@handle_legacy_interface(
+    weights=(
+        "pretrained",
+        lambda kwargs: KeypointRCNN_ResNet50_FPN_Weights.COCO_LEGACY
+        if kwargs["pretrained"] == "legacy"
+        else KeypointRCNN_ResNet50_FPN_Weights.COCO_V1,
+    ),
+    weights_backbone=("pretrained_backbone", ResNet50_Weights.IMAGENET1K_V1),
+)
+def keypointrcnn_resnet50_fpn(
+    *,
+    weights: Optional[KeypointRCNN_ResNet50_FPN_Weights] = None,
+    progress: bool = True,
+    num_classes: Optional[int] = None,
+    num_keypoints: Optional[int] = None,
+    weights_backbone: Optional[ResNet50_Weights] = ResNet50_Weights.IMAGENET1K_V1,
+    trainable_backbone_layers: Optional[int] = None,
+    **kwargs: Any,
+) -> KeypointRCNN:
     """
     Constructs a Keypoint R-CNN model with a ResNet-50-FPN backbone.
 
+    .. betastatus:: detection module
+
+    Reference: `Mask R-CNN <https://arxiv.org/abs/1703.06870>`__.
+
     The input to the model is expected to be a list of tensors, each of shape ``[C, H, W]``, one for each
     image, and should be in ``0-1`` range. Different images can have different sizes.
 
     The behavior of the model changes depending if it is in training or evaluation mode.
 
     During training, the model expects both the input tensors, as well as a targets (list of dictionary),
     containing:
@@ -325,42 +408,73 @@
 
     For more details on the output, you may refer to :ref:`instance_seg_output`.
 
     Keypoint R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.
 
     Example::
 
-        >>> model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)
+        >>> model = torchvision.models.detection.keypointrcnn_resnet50_fpn(weights=KeypointRCNN_ResNet50_FPN_Weights.DEFAULT)
         >>> model.eval()
         >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
         >>> predictions = model(x)
         >>>
         >>> # optionally, if you want to export the model to ONNX:
         >>> torch.onnx.export(model, x, "keypoint_rcnn.onnx", opset_version = 11)
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on COCO train2017
+        weights (:class:`~torchvision.models.detection.KeypointRCNN_ResNet50_FPN_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.detection.KeypointRCNN_ResNet50_FPN_Weights`
+            below for more details, and possible values. By default, no
+            pre-trained weights are used.
         progress (bool): If True, displays a progress bar of the download to stderr
-        num_classes (int): number of output classes of the model (including the background)
-        num_keypoints (int): number of keypoints, default 17
-        pretrained_backbone (bool): If True, returns a model with backbone pre-trained on Imagenet
-        trainable_backbone_layers (int): number of trainable (not frozen) resnet layers starting from final block.
-            Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.
+        num_classes (int, optional): number of output classes of the model (including the background)
+        num_keypoints (int, optional): number of keypoints
+        weights_backbone (:class:`~torchvision.models.ResNet50_Weights`, optional): The
+            pretrained weights for the backbone.
+        trainable_backbone_layers (int, optional): number of trainable (not frozen) layers starting from final block.
+            Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable. If ``None`` is
+            passed (the default) this value is set to 3.
+
+    .. autoclass:: torchvision.models.detection.KeypointRCNN_ResNet50_FPN_Weights
+        :members:
     """
-    unsupported_attr(progress)
-    trainable_backbone_layers = _validate_trainable_layers(
-        pretrained or pretrained_backbone, trainable_backbone_layers, 5, 3)
-
-    if pretrained:
-        # no need to download the backbone if pretrained is set
-        pretrained_backbone = False
-    backbone = resnet_fpn_backbone('resnet50', pretrained_backbone, trainable_layers=trainable_backbone_layers)
+    weights = KeypointRCNN_ResNet50_FPN_Weights.verify(weights)
+    weights_backbone = ResNet50_Weights.verify(weights_backbone)
+
+    if weights is not None:
+        weights_backbone = None
+        num_classes = _ovewrite_value_param(num_classes, len(weights.meta["categories"]))
+        num_keypoints = _ovewrite_value_param(num_keypoints, len(weights.meta["keypoint_names"]))
+    else:
+        if num_classes is None:
+            num_classes = 2
+        if num_keypoints is None:
+            num_keypoints = 17
+
+    is_trained = weights is not None or weights_backbone is not None
+    trainable_backbone_layers = _validate_trainable_layers(is_trained, trainable_backbone_layers, 5, 3)
+    norm_layer = misc_nn_ops.FrozenBatchNorm2d if is_trained else nn.BatchNorm2d
+
+    backbone = resnet50(weights=weights_backbone, progress=progress, norm_layer=norm_layer)
+    backbone = _resnet_fpn_extractor(backbone, trainable_backbone_layers)
     model = KeypointRCNN(backbone, num_classes, num_keypoints=num_keypoints, **kwargs)
-    if pretrained:
-        key = 'keypointrcnn_resnet50_fpn_coco'
-        if pretrained == 'legacy':
-            key += '_legacy'
-        check_ckpt_file(model_urls[key])
-        state_dict = load_state_dict_from_url(model_urls[key])
-        model.load_state_dict(state_dict)
-        overwrite_eps(model, 0.0)
+
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
+        if weights == KeypointRCNN_ResNet50_FPN_Weights.COCO_V1:
+            overwrite_eps(model, 0.0)
+
     return model
+
+
+# The dictionary below is internal implementation detail and will be removed in v0.15
+from .._utils import _ModelURLs
+
+
+model_urls = _ModelURLs(
+    {
+        # legacy model for BC reasons, see https://github.com/pytorch/vision/issues/1606
+        "keypointrcnn_resnet50_fpn_coco_legacy": KeypointRCNN_ResNet50_FPN_Weights.COCO_LEGACY.url,
+        "keypointrcnn_resnet50_fpn_coco": KeypointRCNN_ResNet50_FPN_Weights.COCO_V1.url,
+    }
+)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/retinanet.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/ssd.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,632 +1,699 @@
-import math
-from collections import OrderedDict
 import warnings
+from collections import OrderedDict
+from typing import Any, Dict, List, Optional, Tuple
 
 import mindtorch.torch as torch
+import mindtorch.torch.nn.functional as F
 from mindtorch.torch import nn, Tensor
-from typing import Dict, List, Tuple, Optional
-from mindtorch import unsupported_attr
-from ._utils import overwrite_eps
-from ..utils import check_ckpt_file, model_path_name
 
+from ...ops import boxes as box_ops
+from ...transforms._presets import ObjectDetection
+from .._api import WeightsEnum, Weights
+from .._meta import _COCO_CATEGORIES
+from .._utils import handle_legacy_interface, _ovewrite_value_param
+from ..vgg import VGG, VGG16_Weights, vgg16
 from . import _utils as det_utils
-from .anchor_utils import AnchorGenerator
+from .anchor_utils import DefaultBoxGenerator
+from .backbone_utils import _validate_trainable_layers
 from .transform import GeneralizedRCNNTransform
-from .backbone_utils import resnet_fpn_backbone, _validate_trainable_layers
-from ...ops.feature_pyramid_network import LastLevelP6P7
-from ...ops import sigmoid_focal_loss
-from ...ops import boxes as box_ops
-from mindtorch.torch.hub import load_state_dict_from_url
 
 
 __all__ = [
-    "RetinaNet", "retinanet_resnet50_fpn"
+    "SSD300_VGG16_Weights",
+    "ssd300_vgg16",
 ]
 
-model_urls = {
-    'retinanet_resnet50_fpn_coco':
-        model_path_name + 'retinanet_resnet50_fpn_coco-eeacb38b.pth',
-}
-
 
-def _sum(x: List[Tensor]) -> Tensor:
-    res = x[0]
-    for i in x[1:]:
-        res = res + i
-    return res
+class SSD300_VGG16_Weights(WeightsEnum):
+    COCO_V1 = Weights(
+        url="https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth",
+        transforms=ObjectDetection,
+        meta={
+            "num_params": 35641826,
+            "categories": _COCO_CATEGORIES,
+            "min_size": (1, 1),
+            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#ssd300-vgg16",
+            "_metrics": {
+                "COCO-val2017": {
+                    "box_map": 25.1,
+                }
+            },
+            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
+        },
+    )
+    DEFAULT = COCO_V1
+
+
+def _xavier_init(conv: nn.Module):
+    for layer in conv.modules():
+        if isinstance(layer, nn.Conv2d):
+            torch.nn.init.xavier_uniform_(layer.weight)
+            if layer.bias is not None:
+                torch.nn.init.constant_(layer.bias, 0.0)
 
 
-class RetinaNetHead(nn.Module):
-    """
-    A regression and classification head for use in RetinaNet.
-
-    Args:
-        in_channels (int): number of channels of the input feature
-        num_anchors (int): number of anchors to be predicted
-        num_classes (int): number of classes to be predicted
-    """
-
-    def __init__(self, in_channels, num_anchors, num_classes):
+class SSDHead(nn.Module):
+    def __init__(self, in_channels: List[int], num_anchors: List[int], num_classes: int):
         super().__init__()
-        self.classification_head = RetinaNetClassificationHead(in_channels, num_anchors, num_classes)
-        self.regression_head = RetinaNetRegressionHead(in_channels, num_anchors)
+        self.classification_head = SSDClassificationHead(in_channels, num_anchors, num_classes)
+        self.regression_head = SSDRegressionHead(in_channels, num_anchors)
 
-    def compute_loss(self, targets, head_outputs, anchors, matched_idxs):
-        # type: (List[Dict[str, Tensor]], Dict[str, Tensor], List[Tensor], List[Tensor]) -> Dict[str, Tensor]
+    def forward(self, x: List[Tensor]) -> Dict[str, Tensor]:
         return {
-            'classification': self.classification_head.compute_loss(targets, head_outputs, matched_idxs),
-            'bbox_regression': self.regression_head.compute_loss(targets, head_outputs, anchors, matched_idxs),
+            "bbox_regression": self.regression_head(x),
+            "cls_logits": self.classification_head(x),
         }
 
-    def forward(self, x):
-        # type: (List[Tensor]) -> Dict[str, Tensor]
-        return {
-            'cls_logits': self.classification_head(x),
-            'bbox_regression': self.regression_head(x)
-        }
-
-
-class RetinaNetClassificationHead(nn.Module):
-    """
-    A classification head for use in RetinaNet.
 
-    Args:
-        in_channels (int): number of channels of the input feature
-        num_anchors (int): number of anchors to be predicted
-        num_classes (int): number of classes to be predicted
-    """
-
-    def __init__(self, in_channels, num_anchors, num_classes, prior_probability=0.01):
+class SSDScoringHead(nn.Module):
+    def __init__(self, module_list: nn.ModuleList, num_columns: int):
         super().__init__()
+        self.module_list = module_list
+        self.num_columns = num_columns
 
-        conv = []
-        for _ in range(4):
-            conv.append(nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1))
-            conv.append(nn.ReLU())
-        self.conv = nn.Sequential(*conv)
-
-        for layer in self.conv.children():
-            if isinstance(layer, nn.Conv2d):
-                torch.nn.init.normal_(layer.weight, std=0.01)
-                torch.nn.init.constant_(layer.bias, 0)
-
-        self.cls_logits = nn.Conv2d(in_channels, num_anchors * num_classes, kernel_size=3, stride=1, padding=1)
-        torch.nn.init.normal_(self.cls_logits.weight, std=0.01)
-        torch.nn.init.constant_(self.cls_logits.bias, -math.log((1 - prior_probability) / prior_probability))
-
-        self.num_classes = num_classes
-        self.num_anchors = num_anchors
-
-        # This is to fix using det_utils.Matcher.BETWEEN_THRESHOLDS in TorchScript.
-        # TorchScript doesn't support class attributes.
-        # https://github.com/pytorch/vision/pull/1697#issuecomment-630255584
-        self.BETWEEN_THRESHOLDS = det_utils.Matcher.BETWEEN_THRESHOLDS
-
-    def compute_loss(self, targets, head_outputs, matched_idxs):
-        # type: (List[Dict[str, Tensor]], Dict[str, Tensor], List[Tensor]) -> Tensor
-        losses = []
-
-        cls_logits = head_outputs['cls_logits']
-
-        for targets_per_image, cls_logits_per_image, matched_idxs_per_image in zip(targets, cls_logits, matched_idxs):
-            # determine only the foreground
-            foreground_idxs_per_image = matched_idxs_per_image >= 0
-            num_foreground = foreground_idxs_per_image.sum()
-
-            # create the target classification
-            gt_classes_target = torch.zeros_like(cls_logits_per_image)
-            gt_classes_target[
-                foreground_idxs_per_image,
-                targets_per_image['labels'][matched_idxs_per_image[foreground_idxs_per_image]]
-            ] = 1.0
-
-            # find indices for which anchors should be ignored
-            valid_idxs_per_image = matched_idxs_per_image != self.BETWEEN_THRESHOLDS
-
-            # compute the classification loss
-            losses.append(sigmoid_focal_loss(
-                cls_logits_per_image[valid_idxs_per_image],
-                gt_classes_target[valid_idxs_per_image],
-                reduction='sum',
-            ) / max(1, num_foreground))
-
-        return _sum(losses) / len(targets)
-
-    def forward(self, x):
-        # type: (List[Tensor]) -> Tensor
-        all_cls_logits = []
-
-        for features in x:
-            cls_logits = self.conv(features)
-            cls_logits = self.cls_logits(cls_logits)
-
-            # Permute classification output from (N, A * K, H, W) to (N, HWA, K).
-            N, _, H, W = cls_logits.shape
-            cls_logits = cls_logits.view(N, -1, self.num_classes, H, W)
-            cls_logits = cls_logits.permute(0, 3, 4, 1, 2)
-            cls_logits = cls_logits.reshape(N, -1, self.num_classes)  # Size=(N, HWA, 4)
-
-            all_cls_logits.append(cls_logits)
-
-        return torch.cat(all_cls_logits, dim=1)
-
-
-class RetinaNetRegressionHead(nn.Module):
-    """
-    A regression head for use in RetinaNet.
-
-    Args:
-        in_channels (int): number of channels of the input feature
-        num_anchors (int): number of anchors to be predicted
-    """
-    __annotations__ = {
-        'box_coder': det_utils.BoxCoder,
-    }
-
-    def __init__(self, in_channels, num_anchors):
-        super().__init__()
-
-        conv = []
-        for _ in range(4):
-            conv.append(nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1))
-            conv.append(nn.ReLU())
-        self.conv = nn.Sequential(*conv)
-
-        self.bbox_reg = nn.Conv2d(in_channels, num_anchors * 4, kernel_size=3, stride=1, padding=1)
-        torch.nn.init.normal_(self.bbox_reg.weight, std=0.01)
-        torch.nn.init.zeros_(self.bbox_reg.bias)
-
-        for layer in self.conv.children():
-            if isinstance(layer, nn.Conv2d):
-                torch.nn.init.normal_(layer.weight, std=0.01)
-                torch.nn.init.zeros_(layer.bias)
-
-        self.box_coder = det_utils.BoxCoder(weights=(1.0, 1.0, 1.0, 1.0))
-
-    def compute_loss(self, targets, head_outputs, anchors, matched_idxs):
-        # type: (List[Dict[str, Tensor]], Dict[str, Tensor], List[Tensor], List[Tensor]) -> Tensor
-        losses = []
-
-        bbox_regression = head_outputs['bbox_regression']
-
-        for targets_per_image, bbox_regression_per_image, anchors_per_image, matched_idxs_per_image in \
-                zip(targets, bbox_regression, anchors, matched_idxs):
-            # determine only the foreground indices, ignore the rest
-            foreground_idxs_per_image = torch.where(matched_idxs_per_image >= 0)[0]
-            num_foreground = foreground_idxs_per_image.numel()
-
-            # select only the foreground boxes
-            matched_gt_boxes_per_image = targets_per_image['boxes'][matched_idxs_per_image[foreground_idxs_per_image]]
-            bbox_regression_per_image = bbox_regression_per_image[foreground_idxs_per_image, :]
-            anchors_per_image = anchors_per_image[foreground_idxs_per_image, :]
-
-            # compute the regression targets
-            target_regression = self.box_coder.encode_single(matched_gt_boxes_per_image, anchors_per_image)
-
-            # compute the loss
-            losses.append(torch.nn.functional.l1_loss(
-                bbox_regression_per_image,
-                target_regression,
-                reduction='sum'
-            ) / max(1, num_foreground))
-
-        return _sum(losses) / max(1, len(targets))
-
-    def forward(self, x):
-        # type: (List[Tensor]) -> Tensor
-        all_bbox_regression = []
-
-        for features in x:
-            bbox_regression = self.conv(features)
-            bbox_regression = self.bbox_reg(bbox_regression)
-
-            # Permute bbox regression output from (N, 4 * A, H, W) to (N, HWA, 4).
-            N, _, H, W = bbox_regression.shape
-            bbox_regression = bbox_regression.view(N, -1, 4, H, W)
-            bbox_regression = bbox_regression.permute(0, 3, 4, 1, 2)
-            bbox_regression = bbox_regression.reshape(N, -1, 4)  # Size=(N, HWA, 4)
-
-            all_bbox_regression.append(bbox_regression)
-
-        return torch.cat(all_bbox_regression, dim=1)
+    def _get_result_from_module_list(self, x: Tensor, idx: int) -> Tensor:
+        """
+        This is equivalent to self.module_list[idx](x),
+        but torchscript doesn't support this yet
+        """
+        num_blocks = len(self.module_list)
+        if idx < 0:
+            idx += num_blocks
+        out = x
+        for i, module in enumerate(self.module_list):
+            if i == idx:
+                out = module(x)
+        return out
+
+    def forward(self, x: List[Tensor]) -> Tensor:
+        all_results = []
+
+        for i, features in enumerate(x):
+            results = self._get_result_from_module_list(features, i)
+
+            # Permute output from (N, A * K, H, W) to (N, HWA, K).
+            N, _, H, W = results.shape
+            results = results.view(N, -1, self.num_columns, H, W)
+            results = results.permute(0, 3, 4, 1, 2)
+            results = results.reshape(N, -1, self.num_columns)  # Size=(N, HWA, K)
+
+            all_results.append(results)
+
+        return torch.cat(all_results, dim=1)
+
+
+class SSDClassificationHead(SSDScoringHead):
+    def __init__(self, in_channels: List[int], num_anchors: List[int], num_classes: int):
+        cls_logits = nn.ModuleList()
+        for channels, anchors in zip(in_channels, num_anchors):
+            cls_logits.append(nn.Conv2d(channels, num_classes * anchors, kernel_size=3, padding=1))
+        _xavier_init(cls_logits)
+        super().__init__(cls_logits, num_classes)
+
+
+class SSDRegressionHead(SSDScoringHead):
+    def __init__(self, in_channels: List[int], num_anchors: List[int]):
+        bbox_reg = nn.ModuleList()
+        for channels, anchors in zip(in_channels, num_anchors):
+            bbox_reg.append(nn.Conv2d(channels, 4 * anchors, kernel_size=3, padding=1))
+        _xavier_init(bbox_reg)
+        super().__init__(bbox_reg, 4)
 
 
-class RetinaNet(nn.Module):
+class SSD(nn.Module):
     """
-    Implements RetinaNet.
+    Implements SSD architecture from `"SSD: Single Shot MultiBox Detector" <https://arxiv.org/abs/1512.02325>`_.
 
     The input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each
-    image, and should be in 0-1 range. Different images can have different sizes.
+    image, and should be in 0-1 range. Different images can have different sizes but they will be resized
+    to a fixed size before passing it to the backbone.
 
     The behavior of the model changes depending if it is in training or evaluation mode.
 
     During training, the model expects both the input tensors, as well as a targets (list of dictionary),
     containing:
         - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with
           ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.
         - labels (Int64Tensor[N]): the class label for each ground-truth box
 
     The model returns a Dict[Tensor] during training, containing the classification and regression
     losses.
 
     During inference, the model requires only the input tensors, and returns the post-processed
     predictions as a List[Dict[Tensor]], one for each input image. The fields of the Dict are as
-    follows:
+    follows, where ``N`` is the number of detections:
+
         - boxes (``FloatTensor[N, 4]``): the predicted boxes in ``[x1, y1, x2, y2]`` format, with
           ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.
-        - labels (Int64Tensor[N]): the predicted labels for each image
-        - scores (Tensor[N]): the scores for each prediction
+        - labels (Int64Tensor[N]): the predicted labels for each detection
+        - scores (Tensor[N]): the scores for each detection
 
     Args:
         backbone (nn.Module): the network used to compute the features for the model.
-            It should contain an out_channels attribute, which indicates the number of output
-            channels that each feature map has (and it should be the same for all feature maps).
-            The backbone should return a single Tensor or an OrderedDict[Tensor].
-        num_classes (int): number of output classes of the model (excluding the background).
-        min_size (int): minimum size of the image to be rescaled before feeding it to the backbone
-        max_size (int): maximum size of the image to be rescaled before feeding it to the backbone
+            It should contain an out_channels attribute with the list of the output channels of
+            each feature map. The backbone should return a single Tensor or an OrderedDict[Tensor].
+        anchor_generator (DefaultBoxGenerator): module that generates the default boxes for a
+            set of feature maps.
+        size (Tuple[int, int]): the width and height to which images will be rescaled before feeding them
+            to the backbone.
+        num_classes (int): number of output classes of the model (including the background).
         image_mean (Tuple[float, float, float]): mean values used for input normalization.
             They are generally the mean values of the dataset on which the backbone has been trained
             on
         image_std (Tuple[float, float, float]): std values used for input normalization.
             They are generally the std values of the dataset on which the backbone has been trained on
-        anchor_generator (AnchorGenerator): module that generates the anchors for a set of feature
-            maps.
-        head (nn.Module): Module run on top of the feature pyramid.
-            Defaults to a module containing a classification and regression module.
+        head (nn.Module, optional): Module run on top of the backbone features. Defaults to a module containing
+            a classification and regression module.
         score_thresh (float): Score threshold used for postprocessing the detections.
         nms_thresh (float): NMS threshold used for postprocessing the detections.
         detections_per_img (int): Number of best detections to keep after NMS.
-        fg_iou_thresh (float): minimum IoU between the anchor and the GT box so that they can be
+        iou_thresh (float): minimum IoU between the anchor and the GT box so that they can be
             considered as positive during training.
-        bg_iou_thresh (float): maximum IoU between the anchor and the GT box so that they can be
-            considered as negative during training.
         topk_candidates (int): Number of best detections to keep before NMS.
-
-    Example:
-
-        >>> import torch
-        >>> import torchvision
-        >>> from torchvision.models.detection import RetinaNet
-        >>> from torchvision.models.detection.anchor_utils import AnchorGenerator
-        >>> # load a pre-trained model for classification and return
-        >>> # only the features
-        >>> backbone = torchvision.models.mobilenet_v2(pretrained=True).features
-        >>> # RetinaNet needs to know the number of
-        >>> # output channels in a backbone. For mobilenet_v2, it's 1280
-        >>> # so we need to add it here
-        >>> backbone.out_channels = 1280
-        >>>
-        >>> # let's make the network generate 5 x 3 anchors per spatial
-        >>> # location, with 5 different sizes and 3 different aspect
-        >>> # ratios. We have a Tuple[Tuple[int]] because each feature
-        >>> # map could potentially have different sizes and
-        >>> # aspect ratios
-        >>> anchor_generator = AnchorGenerator(
-        >>>     sizes=((32, 64, 128, 256, 512),),
-        >>>     aspect_ratios=((0.5, 1.0, 2.0),)
-        >>> )
-        >>>
-        >>> # put the pieces together inside a RetinaNet model
-        >>> model = RetinaNet(backbone,
-        >>>                   num_classes=2,
-        >>>                   anchor_generator=anchor_generator)
-        >>> model.eval()
-        >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
-        >>> predictions = model(x)
+        positive_fraction (float): a number between 0 and 1 which indicates the proportion of positive
+            proposals used during the training of the classification head. It is used to estimate the negative to
+            positive ratio.
     """
+
     __annotations__ = {
-        'box_coder': det_utils.BoxCoder,
-        'proposal_matcher': det_utils.Matcher,
+        "box_coder": det_utils.BoxCoder,
+        "proposal_matcher": det_utils.Matcher,
     }
 
-    def __init__(self, backbone, num_classes,
-                 # transform parameters
-                 min_size=800, max_size=1333,
-                 image_mean=None, image_std=None,
-                 # Anchor parameters
-                 anchor_generator=None, head=None,
-                 proposal_matcher=None,
-                 score_thresh=0.05,
-                 nms_thresh=0.5,
-                 detections_per_img=300,
-                 fg_iou_thresh=0.5, bg_iou_thresh=0.4,
-                 topk_candidates=1000):
+    def __init__(
+        self,
+        backbone: nn.Module,
+        anchor_generator: DefaultBoxGenerator,
+        size: Tuple[int, int],
+        num_classes: int,
+        image_mean: Optional[List[float]] = None,
+        image_std: Optional[List[float]] = None,
+        head: Optional[nn.Module] = None,
+        score_thresh: float = 0.01,
+        nms_thresh: float = 0.45,
+        detections_per_img: int = 200,
+        iou_thresh: float = 0.5,
+        topk_candidates: int = 400,
+        positive_fraction: float = 0.25,
+        **kwargs: Any,
+    ):
         super().__init__()
 
-        if not hasattr(backbone, "out_channels"):
-            raise ValueError(
-                "backbone should contain an attribute out_channels "
-                "specifying the number of output channels (assumed to be the "
-                "same for all the levels)")
         self.backbone = backbone
 
-        assert isinstance(anchor_generator, (AnchorGenerator, type(None)))
-
-        if anchor_generator is None:
-            anchor_sizes = tuple((x, int(x * 2 ** (1.0 / 3)), int(x * 2 ** (2.0 / 3))) for x in [32, 64, 128, 256, 512])
-            aspect_ratios = ((0.5, 1.0, 2.0),) * len(anchor_sizes)
-            anchor_generator = AnchorGenerator(
-                anchor_sizes, aspect_ratios
-            )
         self.anchor_generator = anchor_generator
 
+        self.box_coder = det_utils.BoxCoder(weights=(10.0, 10.0, 5.0, 5.0))
+
         if head is None:
-            head = RetinaNetHead(backbone.out_channels, anchor_generator.num_anchors_per_location()[0], num_classes)
-        self.head = head
+            if hasattr(backbone, "out_channels"):
+                out_channels = backbone.out_channels
+            else:
+                out_channels = det_utils.retrieve_out_channels(backbone, size)
+
+            if len(out_channels) != len(anchor_generator.aspect_ratios):
+                raise ValueError(
+                    f"The length of the output channels from the backbone ({len(out_channels)}) do not match the length of the anchor generator aspect ratios ({len(anchor_generator.aspect_ratios)})"
+                )
 
-        if proposal_matcher is None:
-            proposal_matcher = det_utils.Matcher(
-                fg_iou_thresh,
-                bg_iou_thresh,
-                allow_low_quality_matches=True,
-            )
-        self.proposal_matcher = proposal_matcher
+            num_anchors = self.anchor_generator.num_anchors_per_location()
+            head = SSDHead(out_channels, num_anchors, num_classes)
+        self.head = head
 
-        self.box_coder = det_utils.BoxCoder(weights=(1.0, 1.0, 1.0, 1.0))
+        self.proposal_matcher = det_utils.SSDMatcher(iou_thresh)
 
         if image_mean is None:
             image_mean = [0.485, 0.456, 0.406]
         if image_std is None:
             image_std = [0.229, 0.224, 0.225]
-        self.transform = GeneralizedRCNNTransform(min_size, max_size, image_mean, image_std)
+        self.transform = GeneralizedRCNNTransform(
+            min(size), max(size), image_mean, image_std, size_divisible=1, fixed_size=size, **kwargs
+        )
 
         self.score_thresh = score_thresh
         self.nms_thresh = nms_thresh
         self.detections_per_img = detections_per_img
         self.topk_candidates = topk_candidates
+        self.neg_to_pos_ratio = (1.0 - positive_fraction) / positive_fraction
 
         # used only on torchscript mode
         self._has_warned = False
 
     # @torch.jit.unused
-    def eager_outputs(self, losses, detections):
-        # type: (Dict[str, Tensor], List[Dict[str, Tensor]]) -> Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]
+    def eager_outputs(
+        self, losses: Dict[str, Tensor], detections: List[Dict[str, Tensor]]
+    ) -> Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]:
         if self.training:
             return losses
 
         return detections
 
-    def compute_loss(self, targets, head_outputs, anchors):
-        # type: (List[Dict[str, Tensor]], Dict[str, Tensor], List[Tensor]) -> Dict[str, Tensor]
-        matched_idxs = []
-        for anchors_per_image, targets_per_image in zip(anchors, targets):
-            if targets_per_image['boxes'].numel() == 0:
-                matched_idxs.append(torch.full((anchors_per_image.size(0),), -1, dtype=torch.int64,
-                                               device=anchors_per_image.device))
-                continue
-
-            match_quality_matrix = box_ops.box_iou(targets_per_image['boxes'], anchors_per_image)
-            matched_idxs.append(self.proposal_matcher(match_quality_matrix))
-
-        return self.head.compute_loss(targets, head_outputs, anchors, matched_idxs)
-
-    def postprocess_detections(self, head_outputs, anchors, image_shapes):
-        # type: (Dict[str, List[Tensor]], List[List[Tensor]], List[Tuple[int, int]]) -> List[Dict[str, Tensor]]
-        class_logits = head_outputs['cls_logits']
-        box_regression = head_outputs['bbox_regression']
-
-        num_images = len(image_shapes)
-
-        detections: List[Dict[str, Tensor]] = []
-
-        for index in range(num_images):
-            box_regression_per_image = [br[index] for br in box_regression]
-            logits_per_image = [cl[index] for cl in class_logits]
-            anchors_per_image, image_shape = anchors[index], image_shapes[index]
-
-            image_boxes = []
-            image_scores = []
-            image_labels = []
-
-            for box_regression_per_level, logits_per_level, anchors_per_level in \
-                    zip(box_regression_per_image, logits_per_image, anchors_per_image):
-                num_classes = logits_per_level.shape[-1]
-
-                # remove low scoring boxes
-                scores_per_level = torch.sigmoid(logits_per_level).flatten()
-                keep_idxs = scores_per_level > self.score_thresh
-                scores_per_level = scores_per_level[keep_idxs]
-                topk_idxs = torch.where(keep_idxs)[0]
-
-                # keep only topk scoring predictions
-                num_topk = min(self.topk_candidates, topk_idxs.size(0))
-                scores_per_level, idxs = scores_per_level.topk(num_topk)
-                topk_idxs = topk_idxs[idxs]
-
-                anchor_idxs = torch.div(topk_idxs, num_classes, rounding_mode='floor')
-                labels_per_level = topk_idxs % num_classes
-
-                if anchor_idxs.numel() == 0:
-                    boxes_per_level = self.box_coder.decode_single(box_regression_per_level, anchors_per_level)
-                else:
-                    boxes_per_level = self.box_coder.decode_single(box_regression_per_level[anchor_idxs],
-                        anchors_per_level[anchor_idxs])
-                boxes_per_level = box_ops.clip_boxes_to_image(boxes_per_level, image_shape)
-
-                image_boxes.append(boxes_per_level)
-                image_scores.append(scores_per_level)
-                image_labels.append(labels_per_level)
-
-            image_boxes = torch.cat(image_boxes, dim=0)
-            image_scores = torch.cat(image_scores, dim=0)
-            image_labels = torch.cat(image_labels, dim=0)
-
-            # non-maximum suppression
-            keep = box_ops.batched_nms(image_boxes, image_scores, image_labels, self.nms_thresh)
-            keep = keep[:self.detections_per_img]
-
-            detections.append({
-                'boxes': image_boxes[keep],
-                'scores': image_scores[keep],
-                'labels': image_labels[keep],
-            })
+    def compute_loss(
+        self,
+        targets: List[Dict[str, Tensor]],
+        head_outputs: Dict[str, Tensor],
+        anchors: List[Tensor],
+        matched_idxs: List[Tensor],
+    ) -> Dict[str, Tensor]:
+        bbox_regression = head_outputs["bbox_regression"]
+        cls_logits = head_outputs["cls_logits"]
+
+        # Match original targets with default boxes
+        num_foreground = 0
+        bbox_loss = []
+        cls_targets = []
+        for (
+            targets_per_image,
+            bbox_regression_per_image,
+            cls_logits_per_image,
+            anchors_per_image,
+            matched_idxs_per_image,
+        ) in zip(targets, bbox_regression, cls_logits, anchors, matched_idxs):
+            # produce the matching between boxes and targets
+            foreground_idxs_per_image = torch.where(matched_idxs_per_image >= 0)[0]
+            foreground_matched_idxs_per_image = matched_idxs_per_image[foreground_idxs_per_image]
+            num_foreground += foreground_matched_idxs_per_image.numel()
 
-        return detections
+            # Calculate regression loss
+            matched_gt_boxes_per_image = targets_per_image["boxes"][foreground_matched_idxs_per_image]
+            bbox_regression_per_image = bbox_regression_per_image[foreground_idxs_per_image, :]
+            anchors_per_image = anchors_per_image[foreground_idxs_per_image, :]
+            target_regression = self.box_coder.encode_single(matched_gt_boxes_per_image, anchors_per_image)
+            bbox_loss.append(
+                torch.nn.functional.smooth_l1_loss(bbox_regression_per_image, target_regression, reduction="sum")
+            )
 
-    def forward(self, images, targets=None):
-        # type: (List[Tensor], Optional[List[Dict[str, Tensor]]]) -> Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]
-        """
-        Args:
-            images (list[Tensor]): images to be processed
-            targets (list[Dict[Tensor]]): ground-truth boxes present in the image (optional)
-
-        Returns:
-            result (list[BoxList] or dict[Tensor]): the output from the model.
-                During training, it returns a dict[Tensor] which contains the losses.
-                During testing, it returns list[BoxList] contains additional fields
-                like `scores`, `labels` and `mask` (for Mask R-CNN models).
+            # Estimate ground truth for class targets
+            gt_classes_target = torch.zeros(
+                (cls_logits_per_image.size(0),),
+                dtype=targets_per_image["labels"].dtype,
+                device=targets_per_image["labels"].device,
+            )
+            gt_classes_target[foreground_idxs_per_image] = targets_per_image["labels"][
+                foreground_matched_idxs_per_image
+            ]
+            cls_targets.append(gt_classes_target)
+
+        bbox_loss = torch.stack(bbox_loss)
+        cls_targets = torch.stack(cls_targets)
+
+        # Calculate classification loss
+        num_classes = cls_logits.size(-1)
+        cls_loss = F.cross_entropy(cls_logits.view(-1, num_classes), cls_targets.view(-1), reduction="none").view(
+            cls_targets.size()
+        )
+
+        # Hard Negative Sampling
+        foreground_idxs = cls_targets > 0
+        num_negative = self.neg_to_pos_ratio * foreground_idxs.sum(1, keepdim=True)
+        # num_negative[num_negative < self.neg_to_pos_ratio] = self.neg_to_pos_ratio
+        negative_loss = cls_loss.clone()
+        negative_loss[foreground_idxs] = -float("inf")  # use -inf to detect positive values that creeped in the sample
+        values, idx = negative_loss.sort(1, descending=True)
+        # background_idxs = torch.logical_and(idx.sort(1)[1] < num_negative, torch.isfinite(values))
+        background_idxs = idx.sort(1)[1] < num_negative
 
-        """
-        if self.training and targets is None:
-            raise ValueError("In training mode, targets should be passed")
+        N = max(1, num_foreground)
+        return {
+            "bbox_regression": bbox_loss.sum() / N,
+            "classification": (cls_loss[foreground_idxs].sum() + cls_loss[background_idxs].sum()) / N,
+        }
 
+    def forward(
+        self, images: List[Tensor], targets: Optional[List[Dict[str, Tensor]]] = None
+    ) -> Tuple[Dict[str, Tensor], List[Dict[str, Tensor]]]:
         if self.training:
-            assert targets is not None
-            for target in targets:
-                boxes = target["boxes"]
-                if isinstance(boxes, torch.Tensor):
-                    if len(boxes.shape) != 2 or boxes.shape[-1] != 4:
-                        raise ValueError("Expected target boxes to be a tensor"
-                                         "of shape [N, 4], got {:}.".format(
-                                             boxes.shape))
-                else:
-                    raise ValueError("Expected target boxes to be of type "
-                                     "Tensor, got {:}.".format(type(boxes)))
+            if targets is None:
+                torch._assert(False, "targets should not be none when in training mode")
+            else:
+                for target in targets:
+                    boxes = target["boxes"]
+                    if isinstance(boxes, torch.Tensor):
+                        torch._assert(
+                            len(boxes.shape) == 2 and boxes.shape[-1] == 4,
+                            f"Expected target boxes to be a tensor of shape [N, 4], got {boxes.shape}.",
+                        )
+                    else:
+                        torch._assert(False, f"Expected target boxes to be of type Tensor, got {type(boxes)}.")
 
         # get the original image sizes
         original_image_sizes: List[Tuple[int, int]] = []
         for img in images:
             val = img.shape[-2:]
-            assert len(val) == 2
+            torch._assert(
+                len(val) == 2,
+                f"expecting the last two dimensions of the Tensor to be H and W instead got {img.shape[-2:]}",
+            )
             original_image_sizes.append((val[0], val[1]))
 
         # transform the input
         images, targets = self.transform(images, targets)
 
         # Check for degenerate boxes
-        # TODO: Move this to a function
         if targets is not None:
             for target_idx, target in enumerate(targets):
                 boxes = target["boxes"]
                 degenerate_boxes = boxes[:, 2:] <= boxes[:, :2]
                 if degenerate_boxes.any():
-                    # print the first degenerate box
                     bb_idx = torch.where(degenerate_boxes.any(dim=1))[0][0]
                     degen_bb: List[float] = boxes[bb_idx].tolist()
-                    raise ValueError("All bounding boxes should have positive height and width."
-                                     " Found invalid box {} for target at index {}."
-                                     .format(degen_bb, target_idx))
+                    torch._assert(
+                        False,
+                        "All bounding boxes should have positive height and width."
+                        f" Found invalid box {degen_bb} for target at index {target_idx}.",
+                    )
 
         # get the features from the backbone
         features = self.backbone(images.tensors)
         if isinstance(features, torch.Tensor):
-            features = OrderedDict([('0', features)])
+            features = OrderedDict([("0", features)])
 
-        # TODO: Do we want a list or a dict?
         features = list(features.values())
 
-        # compute the retinanet heads outputs using the features
+        # compute the ssd heads outputs using the features
         head_outputs = self.head(features)
 
         # create the set of anchors
         anchors = self.anchor_generator(images, features)
 
         losses = {}
         detections: List[Dict[str, Tensor]] = []
         if self.training:
-            assert targets is not None
+            matched_idxs = []
+            if targets is None:
+                torch._assert(False, "targets should not be none when in training mode")
+            else:
+                for anchors_per_image, targets_per_image in zip(anchors, targets):
+                    if targets_per_image["boxes"].numel() == 0:
+                        matched_idxs.append(
+                            torch.full(
+                                (anchors_per_image.size(0),), -1, dtype=torch.int64, device=anchors_per_image.device
+                            )
+                        )
+                        continue
 
-            # compute the losses
-            losses = self.compute_loss(targets, head_outputs, anchors)
-        else:
-            # recover level sizes
-            num_anchors_per_level = [x.size(2) * x.size(3) for x in features]
-            HW = 0
-            for v in num_anchors_per_level:
-                HW += v
-            HWA = head_outputs['cls_logits'].size(1)
-            A = HWA // HW
-            num_anchors_per_level = [hw * A for hw in num_anchors_per_level]
-
-            # split outputs per level
-            split_head_outputs: Dict[str, List[Tensor]] = {}
-            for k in head_outputs:
-                split_head_outputs[k] = list(head_outputs[k].split(num_anchors_per_level, dim=1))
-            split_anchors = [list(a.split(num_anchors_per_level)) for a in anchors]
+                    match_quality_matrix = box_ops.box_iou(targets_per_image["boxes"], anchors_per_image)
+                    matched_idxs.append(self.proposal_matcher(match_quality_matrix))
 
-            # compute the detections
-            detections = self.postprocess_detections(split_head_outputs, split_anchors, images.image_sizes)
+                losses = self.compute_loss(targets, head_outputs, anchors, matched_idxs)
+        else:
+            detections = self.postprocess_detections(head_outputs, anchors, images.image_sizes)
             detections = self.transform.postprocess(detections, images.image_sizes, original_image_sizes)
 
         # if torch.jit.is_scripting():
         #     if not self._has_warned:
-        #         warnings.warn("RetinaNet always returns a (Losses, Detections) tuple in scripting")
+        #         warnings.warn("SSD always returns a (Losses, Detections) tuple in scripting")
         #         self._has_warned = True
         #     return losses, detections
         return self.eager_outputs(losses, detections)
 
+    def postprocess_detections(
+        self, head_outputs: Dict[str, Tensor], image_anchors: List[Tensor], image_shapes: List[Tuple[int, int]]
+    ) -> List[Dict[str, Tensor]]:
+        bbox_regression = head_outputs["bbox_regression"]
+        pred_scores = F.softmax(head_outputs["cls_logits"], dim=-1)
 
-def retinanet_resnet50_fpn(pretrained=False, progress=True,
-                           num_classes=91, pretrained_backbone=True, trainable_backbone_layers=None, **kwargs):
-    """
-    Constructs a RetinaNet model with a ResNet-50-FPN backbone.
+        num_classes = pred_scores.size(-1)
+        device = pred_scores.device
+
+        detections: List[Dict[str, Tensor]] = []
+
+        for boxes, scores, anchors, image_shape in zip(bbox_regression, pred_scores, image_anchors, image_shapes):
+            boxes = self.box_coder.decode_single(boxes, anchors)
+            boxes = box_ops.clip_boxes_to_image(boxes, image_shape)
+
+            image_boxes = []
+            image_scores = []
+            image_labels = []
+            for label in range(1, num_classes):
+                score = scores[:, label]
+
+                keep_idxs = score > self.score_thresh
+                score = score[keep_idxs]
+                box = boxes[keep_idxs]
 
-    The input to the model is expected to be a list of tensors, each of shape ``[C, H, W]``, one for each
-    image, and should be in ``0-1`` range. Different images can have different sizes.
+                # keep only topk scoring predictions
+                num_topk = det_utils._topk_min(score, self.topk_candidates, 0)
+                score, idxs = score.topk(num_topk)
+                box = box[idxs]
+
+                image_boxes.append(box)
+                image_scores.append(score)
+                image_labels.append(torch.full_like(score, fill_value=label, dtype=torch.int64, device=device))
+
+            image_boxes = torch.cat(image_boxes, dim=0)
+            image_scores = torch.cat(image_scores, dim=0)
+            image_labels = torch.cat(image_labels, dim=0)
+
+            # non-maximum suppression
+            keep = box_ops.batched_nms(image_boxes, image_scores, image_labels, self.nms_thresh)
+            keep = keep[: self.detections_per_img]
+
+            detections.append(
+                {
+                    "boxes": image_boxes[keep],
+                    "scores": image_scores[keep],
+                    "labels": image_labels[keep],
+                }
+            )
+        return detections
+
+
+class SSDFeatureExtractorVGG(nn.Module):
+    def __init__(self, backbone: nn.Module, highres: bool):
+        super().__init__()
+
+        _, _, maxpool3_pos, maxpool4_pos, _ = (i for i, layer in enumerate(backbone) if isinstance(layer, nn.MaxPool2d))
+
+        # Patch ceil_mode for maxpool3 to get the same WxH output sizes as the paper
+        backbone[maxpool3_pos].ceil_mode = True
+
+        # parameters used for L2 regularization + rescaling
+        self.scale_weight = nn.Parameter(torch.ones(512) * 20)
+
+        # Multiple Feature maps - page 4, Fig 2 of SSD paper
+        self.features = nn.Sequential(*backbone[:maxpool4_pos])  # until conv4_3
+
+        # SSD300 case - page 4, Fig 2 of SSD paper
+        extra = nn.ModuleList(
+            [
+                nn.Sequential(
+                    nn.Conv2d(1024, 256, kernel_size=1),
+                    nn.ReLU(inplace=False),
+                    nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=2),  # conv8_2
+                    nn.ReLU(inplace=False),
+                ),
+                nn.Sequential(
+                    nn.Conv2d(512, 128, kernel_size=1),
+                    nn.ReLU(inplace=False),
+                    nn.Conv2d(128, 256, kernel_size=3, padding=1, stride=2),  # conv9_2
+                    nn.ReLU(inplace=False),
+                ),
+                nn.Sequential(
+                    nn.Conv2d(256, 128, kernel_size=1),
+                    nn.ReLU(inplace=False),
+                    nn.Conv2d(128, 256, kernel_size=3),  # conv10_2
+                    nn.ReLU(inplace=False),
+                ),
+                nn.Sequential(
+                    nn.Conv2d(256, 128, kernel_size=1),
+                    nn.ReLU(inplace=False),
+                    nn.Conv2d(128, 256, kernel_size=3),  # conv11_2
+                    nn.ReLU(inplace=False),
+                ),
+            ]
+        )
+        if highres:
+            # Additional layers for the SSD512 case. See page 11, footernote 5.
+            extra.append(
+                nn.Sequential(
+                    nn.Conv2d(256, 128, kernel_size=1),
+                    nn.ReLU(inplace=False),
+                    nn.Conv2d(128, 256, kernel_size=4),  # conv12_2
+                    nn.ReLU(inplace=False),
+                )
+            )
+        _xavier_init(extra)
+
+        fc = nn.Sequential(
+            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=False),  # add modified maxpool5
+            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=6, dilation=6),  # FC6 with atrous
+            nn.ReLU(inplace=False),
+            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=1),  # FC7
+            nn.ReLU(inplace=False),
+        )
+        _xavier_init(fc)
+        extra.insert(
+            0,
+            nn.Sequential(
+                *backbone[maxpool4_pos:-1],  # until conv5_3, skip maxpool5
+                fc,
+            ),
+        )
+        self.extra = extra
+
+    def forward(self, x: Tensor) -> Dict[str, Tensor]:
+        # L2 regularization + Rescaling of 1st block's feature map
+        x = self.features(x)
+        rescaled = self.scale_weight.view(1, -1, 1, 1) * F.normalize(x)
+        output = [rescaled]
+
+        # Calculating Feature maps for the rest blocks
+        for block in self.extra:
+            x = block(x)
+            output.append(x)
+
+        return OrderedDict([(str(i), v) for i, v in enumerate(output)])
+
+
+def _vgg_extractor(backbone: VGG, highres: bool, trainable_layers: int):
+    backbone = backbone.features
+    # Gather the indices of maxpools. These are the locations of output blocks.
+    stage_indices = [0] + [i for i, b in enumerate(backbone) if isinstance(b, nn.MaxPool2d)][:-1]
+    num_stages = len(stage_indices)
+
+    # find the index of the layer from which we wont freeze
+    torch._assert(
+        0 <= trainable_layers <= num_stages,
+        f"trainable_layers should be in the range [0, {num_stages}]. Instead got {trainable_layers}",
+    )
+    freeze_before = len(backbone) if trainable_layers == 0 else stage_indices[num_stages - trainable_layers]
+
+    for b in backbone[:freeze_before]:
+        for parameter in b.parameters():
+            parameter.requires_grad_(False)
+
+    return SSDFeatureExtractorVGG(backbone, highres)
+
+
+@handle_legacy_interface(
+    weights=("pretrained", SSD300_VGG16_Weights.COCO_V1),
+    weights_backbone=("pretrained_backbone", VGG16_Weights.IMAGENET1K_FEATURES),
+)
+def ssd300_vgg16(
+    *,
+    weights: Optional[SSD300_VGG16_Weights] = None,
+    progress: bool = True,
+    num_classes: Optional[int] = None,
+    weights_backbone: Optional[VGG16_Weights] = VGG16_Weights.IMAGENET1K_FEATURES,
+    trainable_backbone_layers: Optional[int] = None,
+    **kwargs: Any,
+) -> SSD:
+    """The SSD300 model is based on the `SSD: Single Shot MultiBox Detector
+    <https://arxiv.org/abs/1512.02325>`_ paper.
+
+    .. betastatus:: detection module
+
+    The input to the model is expected to be a list of tensors, each of shape [C, H, W], one for each
+    image, and should be in 0-1 range. Different images can have different sizes but they will be resized
+    to a fixed size before passing it to the backbone.
 
     The behavior of the model changes depending if it is in training or evaluation mode.
 
     During training, the model expects both the input tensors, as well as a targets (list of dictionary),
     containing:
 
         - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with
           ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.
-        - labels (``Int64Tensor[N]``): the class label for each ground-truth box
+        - labels (Int64Tensor[N]): the class label for each ground-truth box
 
-    The model returns a ``Dict[Tensor]`` during training, containing the classification and regression
+    The model returns a Dict[Tensor] during training, containing the classification and regression
     losses.
 
     During inference, the model requires only the input tensors, and returns the post-processed
-    predictions as a ``List[Dict[Tensor]]``, one for each input image. The fields of the ``Dict`` are as
+    predictions as a List[Dict[Tensor]], one for each input image. The fields of the Dict are as
     follows, where ``N`` is the number of detections:
 
         - boxes (``FloatTensor[N, 4]``): the predicted boxes in ``[x1, y1, x2, y2]`` format, with
           ``0 <= x1 < x2 <= W`` and ``0 <= y1 < y2 <= H``.
-        - labels (``Int64Tensor[N]``): the predicted labels for each detection
-        - scores (``Tensor[N]``): the scores of each detection
-
-    For more details on the output, you may refer to :ref:`instance_seg_output`.
+        - labels (Int64Tensor[N]): the predicted labels for each detection
+        - scores (Tensor[N]): the scores for each detection
 
-    Example::
+    Example:
 
-        >>> model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)
+        >>> model = torchvision.models.detection.ssd300_vgg16(weights=SSD300_VGG16_Weights.DEFAULT)
         >>> model.eval()
-        >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]
+        >>> x = [torch.rand(3, 300, 300), torch.rand(3, 500, 400)]
         >>> predictions = model(x)
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on COCO train2017
-        progress (bool): If True, displays a progress bar of the download to stderr
-        num_classes (int): number of output classes of the model (including the background)
-        pretrained_backbone (bool): If True, returns a model with backbone pre-trained on Imagenet
-        trainable_backbone_layers (int): number of trainable (not frozen) resnet layers starting from final block.
-            Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.
+        weights (:class:`~torchvision.models.detection.SSD300_VGG16_Weights`, optional): The pretrained
+                weights to use. See
+                :class:`~torchvision.models.detection.SSD300_VGG16_Weights`
+                below for more details, and possible values. By default, no
+                pre-trained weights are used.
+        progress (bool, optional): If True, displays a progress bar of the download to stderr
+            Default is True.
+        num_classes (int, optional): number of output classes of the model (including the background)
+        weights_backbone (:class:`~torchvision.models.VGG16_Weights`, optional): The pretrained weights for the
+            backbone
+        trainable_backbone_layers (int, optional): number of trainable (not frozen) layers starting from final block.
+            Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable. If ``None`` is
+            passed (the default) this value is set to 4.
+        **kwargs: parameters passed to the ``torchvision.models.detection.SSD``
+            base class. Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/detection/ssd.py>`_
+            for more details about this class.
+
+    .. autoclass:: torchvision.models.detection.SSD300_VGG16_Weights
+        :members:
     """
-    unsupported_attr(progress)
+    weights = SSD300_VGG16_Weights.verify(weights)
+    weights_backbone = VGG16_Weights.verify(weights_backbone)
+
+    if "size" in kwargs:
+        warnings.warn("The size of the model is already fixed; ignoring the parameter.")
+
+    if weights is not None:
+        weights_backbone = None
+        num_classes = _ovewrite_value_param(num_classes, len(weights.meta["categories"]))
+    elif num_classes is None:
+        num_classes = 91
+
     trainable_backbone_layers = _validate_trainable_layers(
-        pretrained or pretrained_backbone, trainable_backbone_layers, 5, 3)
+        weights is not None or weights_backbone is not None, trainable_backbone_layers, 5, 4
+    )
+
+    # Use custom backbones more appropriate for SSD
+    backbone = vgg16(weights=weights_backbone, progress=progress)
+    backbone = _vgg_extractor(backbone, False, trainable_backbone_layers)
+    anchor_generator = DefaultBoxGenerator(
+        [[2], [2, 3], [2, 3], [2, 3], [2], [2]],
+        scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05],
+        steps=[8, 16, 32, 64, 100, 300],
+    )
+
+    defaults = {
+        # Rescale the input in a way compatible to the backbone
+        "image_mean": [0.48235, 0.45882, 0.40784],
+        "image_std": [1.0 / 255.0, 1.0 / 255.0, 1.0 / 255.0],  # undo the 0-1 scaling of toTensor
+    }
+    kwargs: Any = {**defaults, **kwargs}
+    model = SSD(backbone, anchor_generator, (300, 300), num_classes, **kwargs)
+
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
 
-    if pretrained:
-        # no need to download the backbone if pretrained is set
-        pretrained_backbone = False
-    # skip P2 because it generates too many anchors (according to their paper)
-    backbone = resnet_fpn_backbone('resnet50', pretrained_backbone, returned_layers=[2, 3, 4],
-                                   extra_blocks=LastLevelP6P7(256, 256), trainable_layers=trainable_backbone_layers)
-    model = RetinaNet(backbone, num_classes, **kwargs)
-    if pretrained:
-        check_ckpt_file(model_urls['retinanet_resnet50_fpn_coco'])
-        state_dict = load_state_dict_from_url(model_urls['retinanet_resnet50_fpn_coco'])
-        model.load_state_dict(state_dict)
-        overwrite_eps(model, 0.0)
     return model
+
+
+# The dictionary below is internal implementation detail and will be removed in v0.15
+from .._utils import _ModelURLs
+
+
+model_urls = _ModelURLs(
+    {
+        "ssd300_vgg16_coco": SSD300_VGG16_Weights.COCO_V1.url,
+    }
+)
+
+
+backbone_urls = _ModelURLs(
+    {
+        # We port the features of a VGG16 backbone trained by amdegroot because unlike the one on TorchVision, it uses
+        # the same input standardization method as the paper.
+        # Ref: https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth
+        # Only the `features` weights have proper values, those on the `classifier` module are filled with nans.
+        "vgg16_features": VGG16_Weights.IMAGENET1K_FEATURES.url,
+    }
+)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/roi_heads.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/roi_heads.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,21 +1,17 @@
-import mindtorch.torch as torch
-import mindtorch.torchvision as torchvision
+from typing import Optional, List, Dict, Tuple
 
+import mindtorch.torch as torch
 import mindtorch.torch.nn.functional as F
+import mindtorch.torchvision as torchvision
 from mindtorch.torch import nn, Tensor
-
-from mindtorch.torchvision.ops import boxes as box_ops
-
-from mindtorch.torchvision.ops import roi_align
+from mindtorch.torchvision.ops import boxes as box_ops, roi_align
 
 from . import _utils as det_utils
 
-from typing import Optional, List, Dict, Tuple
-
 
 def fastrcnn_loss(class_logits, box_regression, labels, regression_targets):
     # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]
     """
     Computes the loss for Faster R-CNN.
 
     Args:
@@ -42,15 +38,15 @@
     N, num_classes = class_logits.shape
     box_regression = box_regression.reshape(N, box_regression.size(-1) // 4, 4)
 
     box_loss = F.smooth_l1_loss(
         box_regression[sampled_pos_inds_subset, labels_pos],
         regression_targets[sampled_pos_inds_subset],
         beta=1 / 9,
-        reduction='sum',
+        reduction="sum",
     )
     box_loss = box_loss / labels.numel()
 
     return classification_loss, box_loss
 
 
 def maskrcnn_inference(x, labels):
@@ -91,15 +87,15 @@
     crops and resizes the masks in the position defined by the
     boxes. This prepares the masks for them to be fed to the
     loss computation as the targets.
     """
     matched_idxs = matched_idxs.to(boxes)
     rois = torch.cat([matched_idxs[:, None], boxes], dim=1)
     gt_masks = gt_masks[:, None].to(rois)
-    return roi_align(gt_masks, rois, (M, M), 1.)[:, 0]
+    return roi_align(gt_masks, rois, (M, M), 1.0)[:, 0]
 
 
 def maskrcnn_loss(mask_logits, proposals, gt_masks, gt_labels, mask_matched_idxs):
     # type: (Tensor, List[Tensor], List[Tensor], List[Tensor], List[Tensor]) -> Tensor
     """
     Args:
         proposals (list[BoxList])
@@ -109,16 +105,15 @@
     Return:
         mask_loss (Tensor): scalar tensor containing the loss
     """
 
     discretization_size = mask_logits.shape[-1]
     labels = [gt_label[idxs] for gt_label, idxs in zip(gt_labels, mask_matched_idxs)]
     mask_targets = [
-        project_masks_on_boxes(m, p, i, discretization_size)
-        for m, p, i in zip(gt_masks, proposals, mask_matched_idxs)
+        project_masks_on_boxes(m, p, i, discretization_size) for m, p, i in zip(gt_masks, proposals, mask_matched_idxs)
     ]
 
     labels = torch.cat(labels, dim=0)
     mask_targets = torch.cat(mask_targets, dim=0)
 
     # torch.mean (in binary_cross_entropy_with_logits) doesn't
     # accept empty tensors, so handle it separately
@@ -163,151 +158,160 @@
 
     lin_ind = y * heatmap_size + x
     heatmaps = lin_ind * valid
 
     return heatmaps, valid
 
 
-def _onnx_heatmaps_to_keypoints(maps, maps_i, roi_map_width, roi_map_height,
-                                widths_i, heights_i, offset_x_i, offset_y_i):
+def _onnx_heatmaps_to_keypoints(
+    maps, maps_i, roi_map_width, roi_map_height, widths_i, heights_i, offset_x_i, offset_y_i
+):
     num_keypoints = torch.scalar_tensor(maps.size(1), dtype=torch.int64)
 
     width_correction = widths_i / roi_map_width
     height_correction = heights_i / roi_map_height
 
     roi_map = F.interpolate(
-        maps_i[:, None], size=(int(roi_map_height), int(roi_map_width)), mode='bicubic', align_corners=False)[:, 0]
+        maps_i[:, None], size=(int(roi_map_height), int(roi_map_width)), mode="bicubic", align_corners=False
+    )[:, 0]
 
     w = torch.scalar_tensor(roi_map.size(2), dtype=torch.int64)
     pos = roi_map.reshape(num_keypoints, -1).argmax(dim=1)
 
-    x_int = (pos % w)
-    y_int = ((pos - x_int) // w)
+    x_int = pos % w
+    y_int = (pos - x_int) // w
 
-    x = (torch.tensor(0.5, dtype=torch.float32) + x_int.to(dtype=torch.float32)) * \
-        width_correction.to(dtype=torch.float32)
-    y = (torch.tensor(0.5, dtype=torch.float32) + y_int.to(dtype=torch.float32)) * \
-        height_correction.to(dtype=torch.float32)
+    x = (torch.tensor(0.5, dtype=torch.float32) + x_int.to(dtype=torch.float32)) * width_correction.to(
+        dtype=torch.float32
+    )
+    y = (torch.tensor(0.5, dtype=torch.float32) + y_int.to(dtype=torch.float32)) * height_correction.to(
+        dtype=torch.float32
+    )
 
     xy_preds_i_0 = x + offset_x_i.to(dtype=torch.float32)
     xy_preds_i_1 = y + offset_y_i.to(dtype=torch.float32)
     xy_preds_i_2 = torch.ones(xy_preds_i_1.shape, dtype=torch.float32)
-    xy_preds_i = torch.stack([xy_preds_i_0.to(dtype=torch.float32),
-                              xy_preds_i_1.to(dtype=torch.float32),
-                              xy_preds_i_2.to(dtype=torch.float32)], 0)
+    xy_preds_i = torch.stack(
+        [
+            xy_preds_i_0.to(dtype=torch.float32),
+            xy_preds_i_1.to(dtype=torch.float32),
+            xy_preds_i_2.to(dtype=torch.float32),
+        ],
+        0,
+    )
 
     # TODO: simplify when indexing without rank will be supported by ONNX
     base = num_keypoints * num_keypoints + num_keypoints + 1
     ind = torch.arange(num_keypoints)
     ind = ind.to(dtype=torch.int64) * base
-    end_scores_i = roi_map.index_select(1, y_int.to(dtype=torch.int64)) \
-        .index_select(2, x_int.to(dtype=torch.int64)).view(-1).index_select(0, ind.to(dtype=torch.int64))
+    end_scores_i = (
+        roi_map.index_select(1, y_int.to(dtype=torch.int64))
+        .index_select(2, x_int.to(dtype=torch.int64))
+        .view(-1)
+        .index_select(0, ind.to(dtype=torch.int64))
+    )
 
     return xy_preds_i, end_scores_i
 
 
 # @torch.jit._script_if_tracing
-def _onnx_heatmaps_to_keypoints_loop(maps, rois, widths_ceil, heights_ceil,
-                                     widths, heights, offset_x, offset_y, num_keypoints):
+def _onnx_heatmaps_to_keypoints_loop(
+    maps, rois, widths_ceil, heights_ceil, widths, heights, offset_x, offset_y, num_keypoints
+):
     xy_preds = torch.zeros((0, 3, int(num_keypoints)), dtype=torch.float32, device=maps.device)
     end_scores = torch.zeros((0, int(num_keypoints)), dtype=torch.float32, device=maps.device)
 
     for i in range(int(rois.size(0))):
-        xy_preds_i, end_scores_i = _onnx_heatmaps_to_keypoints(maps, maps[i],
-                                                               widths_ceil[i], heights_ceil[i],
-                                                               widths[i], heights[i],
-                                                               offset_x[i], offset_y[i])
-        xy_preds = torch.cat((xy_preds.to(dtype=torch.float32),
-                              xy_preds_i.unsqueeze(0).to(dtype=torch.float32)), 0)
-        end_scores = torch.cat((end_scores.to(dtype=torch.float32),
-                                end_scores_i.to(dtype=torch.float32).unsqueeze(0)), 0)
+        xy_preds_i, end_scores_i = _onnx_heatmaps_to_keypoints(
+            maps, maps[i], widths_ceil[i], heights_ceil[i], widths[i], heights[i], offset_x[i], offset_y[i]
+        )
+        xy_preds = torch.cat((xy_preds.to(dtype=torch.float32), xy_preds_i.unsqueeze(0).to(dtype=torch.float32)), 0)
+        end_scores = torch.cat(
+            (end_scores.to(dtype=torch.float32), end_scores_i.to(dtype=torch.float32).unsqueeze(0)), 0
+        )
     return xy_preds, end_scores
 
 
 def heatmaps_to_keypoints(maps, rois):
     """Extract predicted keypoint locations from heatmaps. Output has shape
     (#rois, 4, #keypoints) with the 4 rows corresponding to (x, y, logit, prob)
     for each keypoint.
     """
     # This function converts a discrete image coordinate in a HEATMAP_SIZE x
     # HEATMAP_SIZE image to a continuous keypoint coordinate. We maintain
     # consistency with keypoints_to_heatmap_labels by using the conversion from
     # Heckbert 1990: c = d + 0.5, where d is a discrete coordinate and c is a
     # continuous coordinate.
-    #TODO: after mindspore support 0 shape Tensor computation on Ascend, remove the code below.
-    if maps.shape[0] == 0 or rois.shape[0] == 0:
-        num_keypoints = maps.shape[1]
-        return torch.zeros(0, num_keypoints, 3).to(torch.float32), \
-               torch.zeros(0, num_keypoints).to(torch.float32)
-
     offset_x = rois[:, 0]
     offset_y = rois[:, 1]
 
     widths = rois[:, 2] - rois[:, 0]
     heights = rois[:, 3] - rois[:, 1]
     widths = widths.clamp(min=1)
     heights = heights.clamp(min=1)
-    if widths.numel() == 0:
-        widths_ceil = widths
-    else:
-        widths_ceil = widths.ceil()
-    if heights.numel() == 0:
-        heights_ceil = heights
-    else:
-        heights_ceil = heights.ceil()
+    widths_ceil = widths.ceil()
+    heights_ceil = heights.ceil()
 
     num_keypoints = maps.shape[1]
 
-    if torchvision._is_tracing():
-        xy_preds, end_scores = _onnx_heatmaps_to_keypoints_loop(maps, rois,
-                                                                widths_ceil, heights_ceil, widths, heights,
-                                                                offset_x, offset_y,
-                                                                torch.scalar_tensor(num_keypoints, dtype=torch.int64))
-        return xy_preds.permute(0, 2, 1), end_scores
+    # if torchvision._is_tracing():
+    #     xy_preds, end_scores = _onnx_heatmaps_to_keypoints_loop(
+    #         maps,
+    #         rois,
+    #         widths_ceil,
+    #         heights_ceil,
+    #         widths,
+    #         heights,
+    #         offset_x,
+    #         offset_y,
+    #         torch.scalar_tensor(num_keypoints, dtype=torch.int64),
+    #     )
+    #     return xy_preds.permute(0, 2, 1), end_scores
 
     xy_preds = torch.zeros((len(rois), 3, num_keypoints), dtype=torch.float32, device=maps.device)
     end_scores = torch.zeros((len(rois), num_keypoints), dtype=torch.float32, device=maps.device)
     for i in range(len(rois)):
         roi_map_width = int(widths_ceil[i].item())
         roi_map_height = int(heights_ceil[i].item())
         width_correction = widths[i] / roi_map_width
         height_correction = heights[i] / roi_map_height
         roi_map = F.interpolate(
-            maps[i][:, None], size=(roi_map_height, roi_map_width), mode='bicubic', align_corners=False)[:, 0]
+            maps[i][:, None], size=(roi_map_height, roi_map_width), mode="bicubic", align_corners=False
+        )[:, 0]
         # roi_map_probs = scores_to_probs(roi_map.copy())
         w = roi_map.shape[2]
         pos = roi_map.reshape(num_keypoints, -1).argmax(dim=1)
 
         x_int = pos % w
-        y_int = torch.div(pos - x_int, w, rounding_mode='floor')
+        y_int = torch.div(pos - x_int, w, rounding_mode="floor")
         # assert (roi_map_probs[k, y_int, x_int] ==
         #         roi_map_probs[k, :, :].max())
         x = (x_int.float() + 0.5) * width_correction
         y = (y_int.float() + 0.5) * height_correction
         xy_preds[i, 0, :] = x + offset_x[i]
         xy_preds[i, 1, :] = y + offset_y[i]
         xy_preds[i, 2, :] = 1
         end_scores[i, :] = roi_map[torch.arange(num_keypoints, device=roi_map.device), y_int, x_int]
-    if xy_preds.numel() == 0:
-        return torch.empty(xy_preds.shape[0], xy_preds.shape[2], xy_preds.shape[1]), end_scores
+
     return xy_preds.permute(0, 2, 1), end_scores
 
 
 def keypointrcnn_loss(keypoint_logits, proposals, gt_keypoints, keypoint_matched_idxs):
     # type: (Tensor, List[Tensor], List[Tensor], List[Tensor]) -> Tensor
     N, K, H, W = keypoint_logits.shape
-    assert H == W
+    if H != W:
+        raise ValueError(
+            f"keypoint_logits height and width (last two elements of shape) should be equal. Instead got H = {H} and W = {W}"
+        )
     discretization_size = H
     heatmaps = []
     valid = []
     for proposals_per_image, gt_kp_in_image, midx in zip(proposals, gt_keypoints, keypoint_matched_idxs):
         kp = gt_kp_in_image[midx]
-        heatmaps_per_image, valid_per_image = keypoints_to_heatmap(
-            kp, proposals_per_image, discretization_size
-        )
+        heatmaps_per_image, valid_per_image = keypoints_to_heatmap(kp, proposals_per_image, discretization_size)
         heatmaps.append(heatmaps_per_image.view(-1))
         valid.append(valid_per_image.view(-1))
 
     keypoint_targets = torch.cat(heatmaps, dim=0)
     valid = torch.cat(valid, dim=0).to(dtype=torch.uint8)
     valid = torch.where(valid)[0]
 
@@ -336,18 +340,18 @@
         kp_scores.append(scores)
 
     return kp_probs, kp_scores
 
 
 def _onnx_expand_boxes(boxes, scale):
     # type: (Tensor, float) -> Tensor
-    w_half = (boxes[:, 2] - boxes[:, 0]) * .5
-    h_half = (boxes[:, 3] - boxes[:, 1]) * .5
-    x_c = (boxes[:, 2] + boxes[:, 0]) * .5
-    y_c = (boxes[:, 3] + boxes[:, 1]) * .5
+    w_half = (boxes[:, 2] - boxes[:, 0]) * 0.5
+    h_half = (boxes[:, 3] - boxes[:, 1]) * 0.5
+    x_c = (boxes[:, 2] + boxes[:, 0]) * 0.5
+    y_c = (boxes[:, 3] + boxes[:, 1]) * 0.5
 
     w_half = w_half.to(dtype=torch.float32) * scale
     h_half = h_half.to(dtype=torch.float32) * scale
 
     boxes_exp0 = x_c - w_half
     boxes_exp1 = y_c - h_half
     boxes_exp2 = x_c + w_half
@@ -357,24 +361,20 @@
 
 
 # the next two functions should be merged inside Masker
 # but are kept here for the moment while we need them
 # temporarily for paste_mask_in_image
 def expand_boxes(boxes, scale):
     # type: (Tensor, float) -> Tensor
-    if torchvision._is_tracing():
-        return _onnx_expand_boxes(boxes, scale)
-    #TODO: after mindspore support 0 shape Tensor computation on Ascend, remove the code below.
-    if boxes.shape[0] == 0:
-        return torch.zeros_like(boxes)
-
-    w_half = (boxes[:, 2] - boxes[:, 0]) * .5
-    h_half = (boxes[:, 3] - boxes[:, 1]) * .5
-    x_c = (boxes[:, 2] + boxes[:, 0]) * .5
-    y_c = (boxes[:, 3] + boxes[:, 1]) * .5
+    # if torchvision._is_tracing():
+    #     return _onnx_expand_boxes(boxes, scale)
+    w_half = (boxes[:, 2] - boxes[:, 0]) * 0.5
+    h_half = (boxes[:, 3] - boxes[:, 1]) * 0.5
+    x_c = (boxes[:, 2] + boxes[:, 0]) * 0.5
+    y_c = (boxes[:, 3] + boxes[:, 1]) * 0.5
 
     w_half *= scale
     h_half *= scale
 
     boxes_exp = torch.zeros_like(boxes)
     boxes_exp[:, 0] = x_c - w_half
     boxes_exp[:, 2] = x_c + w_half
@@ -388,23 +388,19 @@
     # type: (int, int) -> float
     return torch.tensor(M + 2 * padding).to(torch.float32) / torch.tensor(M).to(torch.float32)
 
 
 def expand_masks(mask, padding):
     # type: (Tensor, int) -> Tuple[Tensor, float]
     M = mask.shape[-1]
-    if torch._C._get_tracing_state():  # could not import is_tracing(), not sure why
-        scale = expand_masks_tracing_scale(M, padding)
-    else:
-        scale = float(M + 2 * padding) / M
-    if mask.numel() == 0:
-        padded_mask = torch.empty(mask.shape[0], mask.shape[1], mask.shape[2] + 2, mask.shape[3] + 2)
-    else:
-        padded_mask = F.pad(mask, (padding,) * 4)
-
+    # if torch._C._get_tracing_state():  # could not import is_tracing(), not sure why
+    #        scale = expand_masks_tracing_scale(M, padding)
+    # else:
+    scale = float(M + 2 * padding) / M
+    padded_mask = F.pad(mask, (padding,) * 4)
     return padded_mask, scale
 
 
 def paste_mask_in_image(mask, box, im_h, im_w):
     # type: (Tensor, Tensor, int, int) -> Tensor
     TO_REMOVE = 1
     w = int(box[2] - box[0] + TO_REMOVE)
@@ -412,67 +408,60 @@
     w = max(w, 1)
     h = max(h, 1)
 
     # Set shape to [batchxCxHxW]
     mask = mask.expand((1, 1, -1, -1))
 
     # Resize mask
-    mask = F.interpolate(mask, size=(h, w), mode='bilinear', align_corners=False)
+    mask = F.interpolate(mask, size=(h, w), mode="bilinear", align_corners=False)
     mask = mask[0][0]
 
     im_mask = torch.zeros((im_h, im_w), dtype=mask.dtype, device=mask.device)
     x_0 = max(box[0], 0)
     x_1 = min(box[2] + 1, im_w)
     y_0 = max(box[1], 0)
     y_1 = min(box[3] + 1, im_h)
 
-    im_mask[y_0:y_1, x_0:x_1] = mask[
-        (y_0 - box[1]):(y_1 - box[1]), (x_0 - box[0]):(x_1 - box[0])
-    ]
+    im_mask[y_0:y_1, x_0:x_1] = mask[(y_0 - box[1]) : (y_1 - box[1]), (x_0 - box[0]) : (x_1 - box[0])]
     return im_mask
 
 
 def _onnx_paste_mask_in_image(mask, box, im_h, im_w):
     one = torch.ones(1, dtype=torch.int64)
     zero = torch.zeros(1, dtype=torch.int64)
 
-    w = (box[2] - box[0] + one)
-    h = (box[3] - box[1] + one)
+    w = box[2] - box[0] + one
+    h = box[3] - box[1] + one
     w = torch.max(torch.cat((w, one)))
     h = torch.max(torch.cat((h, one)))
 
     # Set shape to [batchxCxHxW]
     mask = mask.expand((1, 1, mask.size(0), mask.size(1)))
 
     # Resize mask
-    mask = F.interpolate(mask, size=(int(h), int(w)), mode='bilinear', align_corners=False)
+    mask = F.interpolate(mask, size=(int(h), int(w)), mode="bilinear", align_corners=False)
     mask = mask[0][0]
 
     x_0 = torch.max(torch.cat((box[0].unsqueeze(0), zero)))
     x_1 = torch.min(torch.cat((box[2].unsqueeze(0) + one, im_w.unsqueeze(0))))
     y_0 = torch.max(torch.cat((box[1].unsqueeze(0), zero)))
     y_1 = torch.min(torch.cat((box[3].unsqueeze(0) + one, im_h.unsqueeze(0))))
 
-    unpaded_im_mask = mask[(y_0 - box[1]):(y_1 - box[1]),
-                           (x_0 - box[0]):(x_1 - box[0])]
+    unpaded_im_mask = mask[(y_0 - box[1]) : (y_1 - box[1]), (x_0 - box[0]) : (x_1 - box[0])]
 
     # TODO : replace below with a dynamic padding when support is added in ONNX
 
     # pad y
     zeros_y0 = torch.zeros(y_0, unpaded_im_mask.size(1))
     zeros_y1 = torch.zeros(im_h - y_1, unpaded_im_mask.size(1))
-    concat_0 = torch.cat((zeros_y0,
-                          unpaded_im_mask.to(dtype=torch.float32),
-                          zeros_y1), 0)[0:im_h, :]
+    concat_0 = torch.cat((zeros_y0, unpaded_im_mask.to(dtype=torch.float32), zeros_y1), 0)[0:im_h, :]
     # pad x
     zeros_x0 = torch.zeros(concat_0.size(0), x_0)
     zeros_x1 = torch.zeros(concat_0.size(0), im_w - x_1)
-    im_mask = torch.cat((zeros_x0,
-                         concat_0,
-                         zeros_x1), 1)[:, :im_w]
+    im_mask = torch.cat((zeros_x0, concat_0, zeros_x1), 1)[:, :im_w]
     return im_mask
 
 
 # @torch.jit._script_if_tracing
 def _onnx_paste_masks_in_image_loop(masks, boxes, im_h, im_w):
     res_append = torch.zeros(0, im_h, im_w)
     for i in range(masks.size(0)):
@@ -484,71 +473,66 @@
 
 def paste_masks_in_image(masks, boxes, img_shape, padding=1):
     # type: (Tensor, Tensor, Tuple[int, int], int) -> Tensor
     masks, scale = expand_masks(masks, padding=padding)
     boxes = expand_boxes(boxes, scale).to(dtype=torch.int64)
     im_h, im_w = img_shape
 
-    if torchvision._is_tracing():
-        return _onnx_paste_masks_in_image_loop(masks, boxes,
-                                               torch.scalar_tensor(im_h, dtype=torch.int64),
-                                               torch.scalar_tensor(im_w, dtype=torch.int64))[:, None]
-    res = [
-        paste_mask_in_image(m[0], b, im_h, im_w)
-        for m, b in zip(masks, boxes)
-    ]
+    # if torchvision._is_tracing():
+    #     return _onnx_paste_masks_in_image_loop(
+    #         masks, boxes, torch.scalar_tensor(im_h, dtype=torch.int64), torch.scalar_tensor(im_w, dtype=torch.int64)
+    #     )[:, None]
+    res = [paste_mask_in_image(m[0], b, im_h, im_w) for m, b in zip(masks, boxes)]
     if len(res) > 0:
         ret = torch.stack(res, dim=0)[:, None]
     else:
         ret = masks.new_empty((0, 1, im_h, im_w))
     return ret
 
 
 class RoIHeads(nn.Module):
     __annotations__ = {
-        'box_coder': det_utils.BoxCoder,
-        'proposal_matcher': det_utils.Matcher,
-        'fg_bg_sampler': det_utils.BalancedPositiveNegativeSampler,
+        "box_coder": det_utils.BoxCoder,
+        "proposal_matcher": det_utils.Matcher,
+        "fg_bg_sampler": det_utils.BalancedPositiveNegativeSampler,
     }
 
-    def __init__(self,
-                 box_roi_pool,
-                 box_head,
-                 box_predictor,
-                 # Faster R-CNN training
-                 fg_iou_thresh, bg_iou_thresh,
-                 batch_size_per_image, positive_fraction,
-                 bbox_reg_weights,
-                 # Faster R-CNN inference
-                 score_thresh,
-                 nms_thresh,
-                 detections_per_img,
-                 # Mask
-                 mask_roi_pool=None,
-                 mask_head=None,
-                 mask_predictor=None,
-                 keypoint_roi_pool=None,
-                 keypoint_head=None,
-                 keypoint_predictor=None,
-                 ):
-        super(RoIHeads, self).__init__()
+    def __init__(
+        self,
+        box_roi_pool,
+        box_head,
+        box_predictor,
+        # Faster R-CNN training
+        fg_iou_thresh,
+        bg_iou_thresh,
+        batch_size_per_image,
+        positive_fraction,
+        bbox_reg_weights,
+        # Faster R-CNN inference
+        score_thresh,
+        nms_thresh,
+        detections_per_img,
+        # Mask
+        mask_roi_pool=None,
+        mask_head=None,
+        mask_predictor=None,
+        keypoint_roi_pool=None,
+        keypoint_head=None,
+        keypoint_predictor=None,
+    ):
+        super().__init__()
 
         self.box_similarity = box_ops.box_iou
         # assign ground-truth boxes for each proposal
-        self.proposal_matcher = det_utils.Matcher(
-            fg_iou_thresh,
-            bg_iou_thresh,
-            allow_low_quality_matches=False)
-
-        self.fg_bg_sampler = det_utils.BalancedPositiveNegativeSampler(
-            batch_size_per_image,
-            positive_fraction)
+        self.proposal_matcher = det_utils.Matcher(fg_iou_thresh, bg_iou_thresh, allow_low_quality_matches=False)
+
+        self.fg_bg_sampler = det_utils.BalancedPositiveNegativeSampler(batch_size_per_image, positive_fraction)
 
         if bbox_reg_weights is None:
-            bbox_reg_weights = (10., 10., 5., 5.)
+            bbox_reg_weights = (10.0, 10.0, 5.0, 5.0)
         self.box_coder = det_utils.BoxCoder(bbox_reg_weights)
 
         self.box_roi_pool = box_roi_pool
         self.box_head = box_head
         self.box_predictor = box_predictor
 
         self.score_thresh = score_thresh
@@ -589,17 +573,15 @@
 
             if gt_boxes_in_image.numel() == 0:
                 # Background image
                 device = proposals_in_image.device
                 clamped_matched_idxs_in_image = torch.zeros(
                     (proposals_in_image.shape[0],), dtype=torch.int64, device=device
                 )
-                labels_in_image = torch.zeros(
-                    (proposals_in_image.shape[0],), dtype=torch.int64, device=device
-                )
+                labels_in_image = torch.zeros((proposals_in_image.shape[0],), dtype=torch.int64, device=device)
             else:
                 #  set to self.box_similarity when https://github.com/pytorch/pytorch/issues/27495 lands
                 match_quality_matrix = box_ops.box_iou(gt_boxes_in_image, proposals_in_image)
                 matched_idxs_in_image = self.proposal_matcher(match_quality_matrix)
 
                 clamped_matched_idxs_in_image = matched_idxs_in_image.clamp(min=0)
 
@@ -618,45 +600,46 @@
             labels.append(labels_in_image)
         return matched_idxs, labels
 
     def subsample(self, labels):
         # type: (List[Tensor]) -> List[Tensor]
         sampled_pos_inds, sampled_neg_inds = self.fg_bg_sampler(labels)
         sampled_inds = []
-        for img_idx, (pos_inds_img, neg_inds_img) in enumerate(
-            zip(sampled_pos_inds, sampled_neg_inds)
-        ):
+        for img_idx, (pos_inds_img, neg_inds_img) in enumerate(zip(sampled_pos_inds, sampled_neg_inds)):
             img_sampled_inds = torch.where(pos_inds_img | neg_inds_img)[0]
             sampled_inds.append(img_sampled_inds)
         return sampled_inds
 
     def add_gt_proposals(self, proposals, gt_boxes):
         # type: (List[Tensor], List[Tensor]) -> List[Tensor]
-        proposals = [
-            torch.cat((proposal, gt_box))
-            for proposal, gt_box in zip(proposals, gt_boxes)
-        ]
+        proposals = [torch.cat((proposal, gt_box)) for proposal, gt_box in zip(proposals, gt_boxes)]
 
         return proposals
 
     def check_targets(self, targets):
         # type: (Optional[List[Dict[str, Tensor]]]) -> None
-        assert targets is not None
-        assert all(["boxes" in t for t in targets])
-        assert all(["labels" in t for t in targets])
+        if targets is None:
+            raise ValueError("targets should not be None")
+        if not all(["boxes" in t for t in targets]):
+            raise ValueError("Every element of targets should have a boxes key")
+        if not all(["labels" in t for t in targets]):
+            raise ValueError("Every element of targets should have a labels key")
         if self.has_mask():
-            assert all(["masks" in t for t in targets])
+            if not all(["masks" in t for t in targets]):
+                raise ValueError("Every element of targets should have a masks key")
 
-    def select_training_samples(self,
-                                proposals,  # type: List[Tensor]
-                                targets     # type: Optional[List[Dict[str, Tensor]]]
-                                ):
+    def select_training_samples(
+        self,
+        proposals,  # type: List[Tensor]
+        targets,  # type: Optional[List[Dict[str, Tensor]]]
+    ):
         # type: (...) -> Tuple[List[Tensor], List[Tensor], List[Tensor], List[Tensor]]
         self.check_targets(targets)
-        assert targets is not None
+        if targets is None:
+            raise ValueError("targets should not be None")
         dtype = proposals[0].dtype
         device = proposals[0].device
 
         gt_boxes = [t["boxes"].to(dtype) for t in targets]
         gt_labels = [t["labels"] for t in targets]
 
         # append ground-truth bboxes to propos
@@ -678,20 +661,21 @@
             if gt_boxes_in_image.numel() == 0:
                 gt_boxes_in_image = torch.zeros((1, 4), dtype=dtype, device=device)
             matched_gt_boxes.append(gt_boxes_in_image[matched_idxs[img_id]])
 
         regression_targets = self.box_coder.encode(matched_gt_boxes, proposals)
         return proposals, matched_idxs, labels, regression_targets
 
-    def postprocess_detections(self,
-                               class_logits,    # type: Tensor
-                               box_regression,  # type: Tensor
-                               proposals,       # type: List[Tensor]
-                               image_shapes     # type: List[Tuple[int, int]]
-                               ):
+    def postprocess_detections(
+        self,
+        class_logits,  # type: Tensor
+        box_regression,  # type: Tensor
+        proposals,  # type: List[Tensor]
+        image_shapes,  # type: List[Tuple[int, int]]
+    ):
         # type: (...) -> Tuple[List[Tensor], List[Tensor], List[Tensor]]
         device = class_logits.device
         num_classes = class_logits.shape[-1]
 
         boxes_per_image = [boxes_in_image.shape[0] for boxes_in_image in proposals]
         pred_boxes = self.box_coder.decode(box_regression, proposals)
 
@@ -716,61 +700,60 @@
             labels = labels[:, 1:]
 
             # batch everything, by making every class prediction be a separate instance
             boxes = boxes.reshape(-1, 4)
             scores = scores.reshape(-1)
             labels = labels.reshape(-1)
 
-            #TODO: after mindspore support 0 shape Tensor computation on Ascend, remove the code below.
-            if boxes.shape[0] != 0:
-                # remove low scoring boxes
-                if scores.numel() != 0:
-                    inds = torch.where(scores > self.score_thresh)[0]
-                    boxes, scores, labels = boxes[inds], scores[inds], labels[inds]
-
-                #TODO: after mindspore support 0 shape Tensor computation on Ascend, remove the code below.
-                if boxes.shape[0] != 0:
-                    # remove empty boxes
-                    keep = box_ops.remove_small_boxes(boxes, min_size=1e-2)
-                    boxes, scores, labels = boxes[keep], scores[keep], labels[keep]
-
-                    # non-maximum suppression, independently done per class
-                    keep = box_ops.batched_nms(boxes, scores, labels, self.nms_thresh)
-                    # keep only topk scoring predictions
-                    keep = keep[:self.detections_per_img]
-                    boxes, scores, labels = boxes[keep], scores[keep], labels[keep]
+            # remove low scoring boxes
+            inds = torch.where(scores > self.score_thresh)[0]
+            boxes, scores, labels = boxes[inds], scores[inds], labels[inds]
+
+            # remove empty boxes
+            keep = box_ops.remove_small_boxes(boxes, min_size=1e-2)
+            boxes, scores, labels = boxes[keep], scores[keep], labels[keep]
+
+            # non-maximum suppression, independently done per class
+            keep = box_ops.batched_nms(boxes, scores, labels, self.nms_thresh)
+            # keep only topk scoring predictions
+            keep = keep[: self.detections_per_img]
+            boxes, scores, labels = boxes[keep], scores[keep], labels[keep]
 
             all_boxes.append(boxes)
             all_scores.append(scores)
             all_labels.append(labels)
 
         return all_boxes, all_scores, all_labels
 
-    def forward(self,
-                features,      # type: Dict[str, Tensor]
-                proposals,     # type: List[Tensor]
-                image_shapes,  # type: List[Tuple[int, int]]
-                targets=None   # type: Optional[List[Dict[str, Tensor]]]
-                ):
+    def forward(
+        self,
+        features,  # type: Dict[str, Tensor]
+        proposals,  # type: List[Tensor]
+        image_shapes,  # type: List[Tuple[int, int]]
+        targets=None,  # type: Optional[List[Dict[str, Tensor]]]
+    ):
         # type: (...) -> Tuple[List[Dict[str, Tensor]], Dict[str, Tensor]]
         """
         Args:
             features (List[Tensor])
             proposals (List[Tensor[N, 4]])
             image_shapes (List[Tuple[H, W]])
             targets (List[Dict])
         """
         if targets is not None:
             for t in targets:
                 # TODO: https://github.com/pytorch/pytorch/issues/26731
                 floating_point_types = (torch.float, torch.double, torch.half)
-                assert t["boxes"].dtype in floating_point_types, 'target boxes must of float type'
-                assert t["labels"].dtype == torch.int64, 'target labels must of int64 type'
+                if not t["boxes"].dtype in floating_point_types:
+                    raise TypeError(f"target boxes must of float type, instead got {t['boxes'].dtype}")
+                if not t["labels"].dtype == torch.int64:
+                    raise TypeError("target labels must of int64 type, instead got {t['labels'].dtype}")
                 if self.has_keypoint():
-                    assert t["keypoints"].dtype == torch.float32, 'target keypoints must of float type'
+                    if not t["keypoints"].dtype == torch.float32:
+                        raise TypeError(f"target keypoints must of float type, instead got {t['keypoints'].dtype}")
 
         if self.training:
             proposals, matched_idxs, labels, regression_targets = self.select_training_samples(proposals, targets)
         else:
             labels = None
             regression_targets = None
             matched_idxs = None
@@ -778,21 +761,20 @@
         box_features = self.box_roi_pool(features, proposals, image_shapes)
         box_features = self.box_head(box_features)
         class_logits, box_regression = self.box_predictor(box_features)
 
         result: List[Dict[str, torch.Tensor]] = []
         losses = {}
         if self.training:
-            assert labels is not None and regression_targets is not None
-            loss_classifier, loss_box_reg = fastrcnn_loss(
-                class_logits, box_regression, labels, regression_targets)
-            losses = {
-                "loss_classifier": loss_classifier,
-                "loss_box_reg": loss_box_reg
-            }
+            if labels is None:
+                raise ValueError("labels cannot be None")
+            if regression_targets is None:
+                raise ValueError("regression_targets cannot be None")
+            loss_classifier, loss_box_reg = fastrcnn_loss(class_logits, box_regression, labels, regression_targets)
+            losses = {"loss_classifier": loss_classifier, "loss_box_reg": loss_box_reg}
         else:
             boxes, scores, labels = self.postprocess_detections(class_logits, box_regression, proposals, image_shapes)
             num_images = len(boxes)
             for i in range(num_images):
                 result.append(
                     {
                         "boxes": boxes[i],
@@ -800,15 +782,17 @@
                         "scores": scores[i],
                     }
                 )
 
         if self.has_mask():
             mask_proposals = [p["boxes"] for p in result]
             if self.training:
-                assert matched_idxs is not None
+                if matched_idxs is None:
+                    raise ValueError("if in trainning, matched_idxs should not be None")
+
                 # during training, only focus on positive boxes
                 num_images = len(proposals)
                 mask_proposals = []
                 pos_matched_idxs = []
                 for img_id in range(num_images):
                     pos = torch.where(labels[img_id] > 0)[0]
                     mask_proposals.append(proposals[img_id][pos])
@@ -821,73 +805,72 @@
                 mask_features = self.mask_head(mask_features)
                 mask_logits = self.mask_predictor(mask_features)
             else:
                 raise Exception("Expected mask_roi_pool to be not None")
 
             loss_mask = {}
             if self.training:
-                assert targets is not None
-                assert pos_matched_idxs is not None
-                assert mask_logits is not None
+                if targets is None or pos_matched_idxs is None or mask_logits is None:
+                    raise ValueError("targets, pos_matched_idxs, mask_logits cannot be None when training")
 
                 gt_masks = [t["masks"] for t in targets]
                 gt_labels = [t["labels"] for t in targets]
-                rcnn_loss_mask = maskrcnn_loss(
-                    mask_logits, mask_proposals,
-                    gt_masks, gt_labels, pos_matched_idxs)
-                loss_mask = {
-                    "loss_mask": rcnn_loss_mask
-                }
+                rcnn_loss_mask = maskrcnn_loss(mask_logits, mask_proposals, gt_masks, gt_labels, pos_matched_idxs)
+                loss_mask = {"loss_mask": rcnn_loss_mask}
             else:
                 labels = [r["labels"] for r in result]
                 masks_probs = maskrcnn_inference(mask_logits, labels)
                 for mask_prob, r in zip(masks_probs, result):
                     r["masks"] = mask_prob
 
             losses.update(loss_mask)
 
         # keep none checks in if conditional so torchscript will conditionally
         # compile each branch
-        if self.keypoint_roi_pool is not None and self.keypoint_head is not None \
-                and self.keypoint_predictor is not None:
+        if (
+            self.keypoint_roi_pool is not None
+            and self.keypoint_head is not None
+            and self.keypoint_predictor is not None
+        ):
             keypoint_proposals = [p["boxes"] for p in result]
             if self.training:
                 # during training, only focus on positive boxes
                 num_images = len(proposals)
                 keypoint_proposals = []
                 pos_matched_idxs = []
-                assert matched_idxs is not None
+                if matched_idxs is None:
+                    raise ValueError("if in trainning, matched_idxs should not be None")
+
                 for img_id in range(num_images):
                     pos = torch.where(labels[img_id] > 0)[0]
                     keypoint_proposals.append(proposals[img_id][pos])
                     pos_matched_idxs.append(matched_idxs[img_id][pos])
             else:
                 pos_matched_idxs = None
 
             keypoint_features = self.keypoint_roi_pool(features, keypoint_proposals, image_shapes)
             keypoint_features = self.keypoint_head(keypoint_features)
             keypoint_logits = self.keypoint_predictor(keypoint_features)
 
             loss_keypoint = {}
             if self.training:
-                assert targets is not None
-                assert pos_matched_idxs is not None
+                if targets is None or pos_matched_idxs is None:
+                    raise ValueError("both targets and pos_matched_idxs should not be None when in training mode")
 
                 gt_keypoints = [t["keypoints"] for t in targets]
                 rcnn_loss_keypoint = keypointrcnn_loss(
-                    keypoint_logits, keypoint_proposals,
-                    gt_keypoints, pos_matched_idxs)
-                loss_keypoint = {
-                    "loss_keypoint": rcnn_loss_keypoint
-                }
+                    keypoint_logits, keypoint_proposals, gt_keypoints, pos_matched_idxs
+                )
+                loss_keypoint = {"loss_keypoint": rcnn_loss_keypoint}
             else:
-                assert keypoint_logits is not None
-                assert keypoint_proposals is not None
+                if keypoint_logits is None or keypoint_proposals is None:
+                    raise ValueError(
+                        "both keypoint_logits and keypoint_proposals should not be None when not in training mode"
+                    )
 
                 keypoints_probs, kp_scores = keypointrcnn_inference(keypoint_logits, keypoint_proposals)
                 for keypoint_prob, kps, r in zip(keypoints_probs, kp_scores, result):
                     r["keypoints"] = keypoint_prob
                     r["keypoints_scores"] = kps
-
             losses.update(loss_keypoint)
 
         return result, losses
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/rpn.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/rpn.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,100 +1,111 @@
+from typing import List, Optional, Dict, Tuple
+
 import mindtorch.torch as torch
-from mindtorch.torch.nn import functional as F
 from mindtorch.torch import nn, Tensor
-
-import mindtorch.torchvision as torchvision
+from mindtorch.torch.nn import functional as F
+from mindtorch.torchvision.ops import Conv2dNormActivation
 from mindtorch.torchvision.ops import boxes as box_ops
 
 from . import _utils as det_utils
-from .image_list import ImageList
-
-from typing import List, Optional, Dict, Tuple
 
 # Import AnchorGenerator to keep compatibility.
-from .anchor_utils import AnchorGenerator
-
-
-# @torch.jit.unused
-def _onnx_get_num_anchors_and_pre_nms_top_n(ob, orig_pre_nms_top_n):
-    # type: (Tensor, int) -> Tuple[int, int]
-    from torch.onnx import operators
-    num_anchors = operators.shape_as_tensor(ob)[1].unsqueeze(0)
-    pre_nms_top_n = torch.min(torch.cat(
-        (torch.tensor([orig_pre_nms_top_n], dtype=num_anchors.dtype),
-         num_anchors), 0))
-
-    return num_anchors, pre_nms_top_n
+from .anchor_utils import AnchorGenerator  # noqa: 401
+from .image_list import ImageList
 
 
 class RPNHead(nn.Module):
     """
     Adds a simple RPN Head with classification and regression heads
 
     Args:
         in_channels (int): number of channels of the input feature
         num_anchors (int): number of anchors to be predicted
+        conv_depth (int, optional): number of convolutions
     """
 
-    def __init__(self, in_channels, num_anchors):
-        super(RPNHead, self).__init__()
-        self.conv = nn.Conv2d(
-            in_channels, in_channels, kernel_size=3, stride=1, padding=1
-        )
+    _version = 2
+
+    def __init__(self, in_channels: int, num_anchors: int, conv_depth=1) -> None:
+        super().__init__()
+        convs = []
+        for _ in range(conv_depth):
+            convs.append(Conv2dNormActivation(in_channels, in_channels, kernel_size=3, norm_layer=None))
+        self.conv = nn.Sequential(*convs)
         self.cls_logits = nn.Conv2d(in_channels, num_anchors, kernel_size=1, stride=1)
-        self.bbox_pred = nn.Conv2d(
-            in_channels, num_anchors * 4, kernel_size=1, stride=1
-        )
+        self.bbox_pred = nn.Conv2d(in_channels, num_anchors * 4, kernel_size=1, stride=1)
 
-        for layer in self.children():
-            torch.nn.init.normal_(layer.weight, std=0.01)
-            torch.nn.init.constant_(layer.bias, 0)
+        for layer in self.modules():
+            if isinstance(layer, nn.Conv2d):
+                torch.nn.init.normal_(layer.weight, std=0.01)  # type: ignore[arg-type]
+                if layer.bias is not None:
+                    torch.nn.init.constant_(layer.bias, 0)  # type: ignore[arg-type]
+
+    def _load_from_state_dict(
+        self,
+        state_dict,
+        prefix,
+        local_metadata,
+        strict,
+        missing_keys,
+        unexpected_keys,
+        error_msgs,
+    ):
+        version = local_metadata.get("version", None)
+
+        if version is None or version < 2:
+            for type in ["weight", "bias"]:
+                old_key = f"{prefix}conv.{type}"
+                new_key = f"{prefix}conv.0.0.{type}"
+                if old_key in state_dict:
+                    state_dict[new_key] = state_dict.pop(old_key)
+
+        super()._load_from_state_dict(
+            state_dict,
+            prefix,
+            local_metadata,
+            strict,
+            missing_keys,
+            unexpected_keys,
+            error_msgs,
+        )
 
-    def forward(self, x):
-        # type: (List[Tensor]) -> Tuple[List[Tensor], List[Tensor]]
+    def forward(self, x: List[Tensor]) -> Tuple[List[Tensor], List[Tensor]]:
         logits = []
         bbox_reg = []
         for feature in x:
-            t = F.relu(self.conv(feature))
+            t = self.conv(feature)
             logits.append(self.cls_logits(t))
             bbox_reg.append(self.bbox_pred(t))
         return logits, bbox_reg
 
 
-def permute_and_flatten(layer, N, A, C, H, W):
-    # type: (Tensor, int, int, int, int, int) -> Tensor
+def permute_and_flatten(layer: Tensor, N: int, A: int, C: int, H: int, W: int) -> Tensor:
     layer = layer.view(N, -1, C, H, W)
     layer = layer.permute(0, 3, 4, 1, 2)
     layer = layer.reshape(N, -1, C)
     return layer
 
 
-def concat_box_prediction_layers(box_cls, box_regression):
-    # type: (List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]
+def concat_box_prediction_layers(box_cls: List[Tensor], box_regression: List[Tensor]) -> Tuple[Tensor, Tensor]:
     box_cls_flattened = []
     box_regression_flattened = []
     # for each feature level, permute the outputs to make them be in the
     # same format as the labels. Note that the labels are computed for
     # all feature levels concatenated, so we keep the same representation
     # for the objectness and the box_regression
-    for box_cls_per_level, box_regression_per_level in zip(
-        box_cls, box_regression
-    ):
+    for box_cls_per_level, box_regression_per_level in zip(box_cls, box_regression):
         N, AxC, H, W = box_cls_per_level.shape
         Ax4 = box_regression_per_level.shape[1]
         A = Ax4 // 4
         C = AxC // A
-        box_cls_per_level = permute_and_flatten(
-            box_cls_per_level, N, A, C, H, W
-        )
+        box_cls_per_level = permute_and_flatten(box_cls_per_level, N, A, C, H, W)
         box_cls_flattened.append(box_cls_per_level)
 
-        box_regression_per_level = permute_and_flatten(
-            box_regression_per_level, N, A, 4, H, W
-        )
+        box_regression_per_level = permute_and_flatten(box_regression_per_level, N, A, 4, H, W)
         box_regression_flattened.append(box_regression_per_level)
     # concatenate on the first dimension (representing the feature levels), to
     # take into account the way the labels were generated (with all feature maps
     # being concatenated as well)
     box_cls = torch.cat(box_cls_flattened, dim=1).flatten(0, -2)
     box_regression = torch.cat(box_regression_flattened, dim=1).reshape(-1, 4)
     return box_cls, box_regression
@@ -112,75 +123,81 @@
             considered as positive during training of the RPN.
         bg_iou_thresh (float): maximum IoU between the anchor and the GT box so that they can be
             considered as negative during training of the RPN.
         batch_size_per_image (int): number of anchors that are sampled during training of the RPN
             for computing the loss
         positive_fraction (float): proportion of positive anchors in a mini-batch during training
             of the RPN
-        pre_nms_top_n (Dict[int]): number of proposals to keep before applying NMS. It should
+        pre_nms_top_n (Dict[str, int]): number of proposals to keep before applying NMS. It should
             contain two fields: training and testing, to allow for different values depending
             on training or evaluation
-        post_nms_top_n (Dict[int]): number of proposals to keep after applying NMS. It should
+        post_nms_top_n (Dict[str, int]): number of proposals to keep after applying NMS. It should
             contain two fields: training and testing, to allow for different values depending
             on training or evaluation
         nms_thresh (float): NMS threshold used for postprocessing the RPN proposals
 
     """
+
     __annotations__ = {
-        'box_coder': det_utils.BoxCoder,
-        'proposal_matcher': det_utils.Matcher,
-        'fg_bg_sampler': det_utils.BalancedPositiveNegativeSampler,
-        'pre_nms_top_n': Dict[str, int],
-        'post_nms_top_n': Dict[str, int],
+        "box_coder": det_utils.BoxCoder,
+        "proposal_matcher": det_utils.Matcher,
+        "fg_bg_sampler": det_utils.BalancedPositiveNegativeSampler,
     }
 
-    def __init__(self,
-                 anchor_generator,
-                 head,
-                 #
-                 fg_iou_thresh, bg_iou_thresh,
-                 batch_size_per_image, positive_fraction,
-                 #
-                 pre_nms_top_n, post_nms_top_n, nms_thresh, score_thresh=0.0):
-        super(RegionProposalNetwork, self).__init__()
+    def __init__(
+        self,
+        anchor_generator: AnchorGenerator,
+        head: nn.Module,
+        # Faster-RCNN Training
+        fg_iou_thresh: float,
+        bg_iou_thresh: float,
+        batch_size_per_image: int,
+        positive_fraction: float,
+        # Faster-RCNN Inference
+        pre_nms_top_n: Dict[str, int],
+        post_nms_top_n: Dict[str, int],
+        nms_thresh: float,
+        score_thresh: float = 0.0,
+    ) -> None:
+        super().__init__()
         self.anchor_generator = anchor_generator
         self.head = head
         self.box_coder = det_utils.BoxCoder(weights=(1.0, 1.0, 1.0, 1.0))
 
         # used during training
         self.box_similarity = box_ops.box_iou
 
         self.proposal_matcher = det_utils.Matcher(
             fg_iou_thresh,
             bg_iou_thresh,
             allow_low_quality_matches=True,
         )
 
-        self.fg_bg_sampler = det_utils.BalancedPositiveNegativeSampler(
-            batch_size_per_image, positive_fraction
-        )
+        self.fg_bg_sampler = det_utils.BalancedPositiveNegativeSampler(batch_size_per_image, positive_fraction)
         # used during testing
         self._pre_nms_top_n = pre_nms_top_n
         self._post_nms_top_n = post_nms_top_n
         self.nms_thresh = nms_thresh
         self.score_thresh = score_thresh
         self.min_size = 1e-3
 
-    def pre_nms_top_n(self):
+    def pre_nms_top_n(self) -> int:
         if self.training:
-            return self._pre_nms_top_n['training']
-        return self._pre_nms_top_n['testing']
+            return self._pre_nms_top_n["training"]
+        return self._pre_nms_top_n["testing"]
 
-    def post_nms_top_n(self):
+    def post_nms_top_n(self) -> int:
         if self.training:
-            return self._post_nms_top_n['training']
-        return self._post_nms_top_n['testing']
+            return self._post_nms_top_n["training"]
+        return self._post_nms_top_n["testing"]
+
+    def assign_targets_to_anchors(
+        self, anchors: List[Tensor], targets: List[Dict[str, Tensor]]
+    ) -> Tuple[List[Tensor], List[Tensor]]:
 
-    def assign_targets_to_anchors(self, anchors, targets):
-        # type: (List[Tensor], List[Dict[str, Tensor]]) -> Tuple[List[Tensor], List[Tensor]]
         labels = []
         matched_gt_boxes = []
         for anchors_per_image, targets_per_image in zip(anchors, targets):
             gt_boxes = targets_per_image["boxes"]
 
             if gt_boxes.numel() == 0:
                 # Background image (negative example)
@@ -207,40 +224,41 @@
                 inds_to_discard = matched_idxs == self.proposal_matcher.BETWEEN_THRESHOLDS
                 labels_per_image[inds_to_discard] = -1.0
 
             labels.append(labels_per_image)
             matched_gt_boxes.append(matched_gt_boxes_per_image)
         return labels, matched_gt_boxes
 
-    def _get_top_n_idx(self, objectness, num_anchors_per_level):
-        # type: (Tensor, List[int]) -> Tensor
+    def _get_top_n_idx(self, objectness: Tensor, num_anchors_per_level: List[int]) -> Tensor:
         r = []
         offset = 0
         for ob in objectness.split(num_anchors_per_level, 1):
-            if torchvision._is_tracing():
-                num_anchors, pre_nms_top_n = _onnx_get_num_anchors_and_pre_nms_top_n(ob, self.pre_nms_top_n())
-            else:
-                num_anchors = ob.shape[1]
-                pre_nms_top_n = min(self.pre_nms_top_n(), num_anchors)
+            num_anchors = ob.shape[1]
+            pre_nms_top_n = det_utils._topk_min(ob, self.pre_nms_top_n(), 1)
             _, top_n_idx = ob.topk(pre_nms_top_n, dim=1)
             r.append(top_n_idx + offset)
             offset += num_anchors
         return torch.cat(r, dim=1)
 
-    def filter_proposals(self, proposals, objectness, image_shapes, num_anchors_per_level):
-        # type: (Tensor, Tensor, List[Tuple[int, int]], List[int]) -> Tuple[List[Tensor], List[Tensor]]
+    def filter_proposals(
+        self,
+        proposals: Tensor,
+        objectness: Tensor,
+        image_shapes: List[Tuple[int, int]],
+        num_anchors_per_level: List[int],
+    ) -> Tuple[List[Tensor], List[Tensor]]:
+
         num_images = proposals.shape[0]
         device = proposals.device
-        # do not backprop throught objectness
+        # do not backprop through objectness
         objectness = objectness.detach()
         objectness = objectness.reshape(num_images, -1)
 
         levels = [
-            torch.full((n,), idx, dtype=torch.int64, device=device)
-            for idx, n in enumerate(num_anchors_per_level)
+            torch.full((n,), idx, dtype=torch.int64, device=device) for idx, n in enumerate(num_anchors_per_level)
         ]
         levels = torch.cat(levels, 0)
         levels = levels.reshape(1, -1).expand_as(objectness)
 
         # select top_n boxes independently per level before applying nms
         top_n_idx = self._get_top_n_idx(objectness, num_anchors_per_level)
 
@@ -267,23 +285,24 @@
             keep = torch.where(scores >= self.score_thresh)[0]
             boxes, scores, lvl = boxes[keep], scores[keep], lvl[keep]
 
             # non-maximum suppression, independently done per level
             keep = box_ops.batched_nms(boxes, scores, lvl, self.nms_thresh)
 
             # keep only topk scoring predictions
-            keep = keep[:self.post_nms_top_n()]
+            keep = keep[: self.post_nms_top_n()]
             boxes, scores = boxes[keep], scores[keep]
 
             final_boxes.append(boxes)
             final_scores.append(scores)
         return final_boxes, final_scores
 
-    def compute_loss(self, objectness, pred_bbox_deltas, labels, regression_targets):
-        # type: (Tensor, Tensor, List[Tensor], List[Tensor]) -> Tuple[Tensor, Tensor]
+    def compute_loss(
+        self, objectness: Tensor, pred_bbox_deltas: Tensor, labels: List[Tensor], regression_targets: List[Tensor]
+    ) -> Tuple[Tensor, Tensor]:
         """
         Args:
             objectness (Tensor)
             pred_bbox_deltas (Tensor)
             labels (List[Tensor])
             regression_targets (List[Tensor])
 
@@ -299,71 +318,74 @@
         sampled_inds = torch.cat([sampled_pos_inds, sampled_neg_inds], dim=0)
 
         objectness = objectness.flatten()
 
         labels = torch.cat(labels, dim=0)
         regression_targets = torch.cat(regression_targets, dim=0)
 
-        box_loss = F.smooth_l1_loss(
-            pred_bbox_deltas[sampled_pos_inds],
-            regression_targets[sampled_pos_inds],
-            beta=1 / 9,
-            reduction='sum',
-        ) / (sampled_inds.numel())
-
-        objectness_loss = F.binary_cross_entropy_with_logits(
-            objectness[sampled_inds], labels[sampled_inds]
+        box_loss = (
+            F.smooth_l1_loss(
+                pred_bbox_deltas[sampled_pos_inds],
+                regression_targets[sampled_pos_inds],
+                beta=1 / 9,
+                reduction="sum",
+            )
+            / (sampled_inds.numel())
         )
 
+        objectness_loss = F.binary_cross_entropy_with_logits(objectness[sampled_inds], labels[sampled_inds])
+
         return objectness_loss, box_loss
 
-    def forward(self,
-                images,       # type: ImageList
-                features,     # type: Dict[str, Tensor]
-                targets=None  # type: Optional[List[Dict[str, Tensor]]]
-                ):
-        # type: (...) -> Tuple[List[Tensor], Dict[str, Tensor]]
+    def forward(
+        self,
+        images: ImageList,
+        features: Dict[str, Tensor],
+        targets: Optional[List[Dict[str, Tensor]]] = None,
+    ) -> Tuple[List[Tensor], Dict[str, Tensor]]:
+
         """
         Args:
             images (ImageList): images for which we want to compute the predictions
-            features (OrderedDict[Tensor]): features computed from the images that are
+            features (Dict[str, Tensor]): features computed from the images that are
                 used for computing the predictions. Each tensor in the list
                 correspond to different feature levels
-            targets (List[Dict[Tensor]]): ground-truth boxes present in the image (optional).
+            targets (List[Dict[str, Tensor]]): ground-truth boxes present in the image (optional).
                 If provided, each element in the dict should contain a field `boxes`,
                 with the locations of the ground-truth boxes.
 
         Returns:
             boxes (List[Tensor]): the predicted boxes from the RPN, one Tensor per
                 image.
-            losses (Dict[Tensor]): the losses for the model during training. During
+            losses (Dict[str, Tensor]): the losses for the model during training. During
                 testing, it is an empty dict.
         """
         # RPN uses all feature maps that are available
         features = list(features.values())
         objectness, pred_bbox_deltas = self.head(features)
         anchors = self.anchor_generator(images, features)
 
         num_images = len(anchors)
         num_anchors_per_level_shape_tensors = [o[0].shape for o in objectness]
         num_anchors_per_level = [s[0] * s[1] * s[2] for s in num_anchors_per_level_shape_tensors]
-        objectness, pred_bbox_deltas = \
-            concat_box_prediction_layers(objectness, pred_bbox_deltas)
+        objectness, pred_bbox_deltas = concat_box_prediction_layers(objectness, pred_bbox_deltas)
         # apply pred_bbox_deltas to anchors to obtain the decoded proposals
         # note that we detach the deltas because Faster R-CNN do not backprop through
         # the proposals
         proposals = self.box_coder.decode(pred_bbox_deltas.detach(), anchors)
         proposals = proposals.view(num_images, -1, 4)
         boxes, scores = self.filter_proposals(proposals, objectness, images.image_sizes, num_anchors_per_level)
 
         losses = {}
         if self.training:
-            assert targets is not None
+            if targets is None:
+                raise ValueError("targets should not be None")
             labels, matched_gt_boxes = self.assign_targets_to_anchors(anchors, targets)
             regression_targets = self.box_coder.encode(matched_gt_boxes, anchors)
             loss_objectness, loss_rpn_box_reg = self.compute_loss(
-                objectness, pred_bbox_deltas, labels, regression_targets)
+                objectness, pred_bbox_deltas, labels, regression_targets
+            )
             losses = {
                 "loss_objectness": loss_objectness,
                 "loss_rpn_box_reg": loss_rpn_box_reg,
             }
         return boxes, losses
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/ssdlite.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/ssdlite.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,90 +1,105 @@
-import mindtorch.torch as torch
 import warnings
-
 from collections import OrderedDict
 from functools import partial
+from typing import Any, Callable, Dict, List, Optional, Union
+
+import mindtorch.torch as torch
 from mindtorch.torch import nn, Tensor
-from typing import Any, Callable, Dict, List, Optional, Tuple
 
+from ...ops.misc import Conv2dNormActivation
+from ...transforms._presets import ObjectDetection
+from .. import mobilenet
+from .._api import WeightsEnum, Weights
+from .._meta import _COCO_CATEGORIES
+from .._utils import handle_legacy_interface, _ovewrite_value_param
+from ..mobilenetv3 import MobileNet_V3_Large_Weights, mobilenet_v3_large
 from . import _utils as det_utils
-from .ssd import SSD, SSDScoringHead
 from .anchor_utils import DefaultBoxGenerator
 from .backbone_utils import _validate_trainable_layers
-from .. import mobilenet
-from ..mobilenetv3 import ConvBNActivation
-from ..utils import check_ckpt_file, model_path_name
-from mindtorch.torch.hub import load_state_dict_from_url
-
-
-__all__ = ['ssdlite320_mobilenet_v3_large']
+from .ssd import SSD, SSDScoringHead
 
-model_urls = {
-    'ssdlite320_mobilenet_v3_large_coco':
-        model_path_name + 'ssdlite320_mobilenet_v3_large_coco-a79551df.pth'
-}
 
+__all__ = [
+    "SSDLite320_MobileNet_V3_Large_Weights",
+    "ssdlite320_mobilenet_v3_large",
+]
 
 
 # Building blocks of SSDlite as described in section 6.2 of MobileNetV2 paper
-def _prediction_block(in_channels: int, out_channels: int, kernel_size: int,
-                      norm_layer: Callable[..., nn.Module]) -> nn.Sequential:
+def _prediction_block(
+    in_channels: int, out_channels: int, kernel_size: int, norm_layer: Callable[..., nn.Module]
+) -> nn.Sequential:
     return nn.Sequential(
         # 3x3 depthwise with stride 1 and padding 1
-        ConvBNActivation(in_channels, in_channels, kernel_size=kernel_size, groups=in_channels,
-                         norm_layer=norm_layer, activation_layer=nn.ReLU6),
-
+        Conv2dNormActivation(
+            in_channels,
+            in_channels,
+            kernel_size=kernel_size,
+            groups=in_channels,
+            norm_layer=norm_layer,
+            activation_layer=nn.ReLU6,
+        ),
         # 1x1 projetion to output channels
-        nn.Conv2d(in_channels, out_channels, 1)
+        nn.Conv2d(in_channels, out_channels, 1),
     )
 
 
 def _extra_block(in_channels: int, out_channels: int, norm_layer: Callable[..., nn.Module]) -> nn.Sequential:
     activation = nn.ReLU6
     intermediate_channels = out_channels // 2
     return nn.Sequential(
         # 1x1 projection to half output channels
-        ConvBNActivation(in_channels, intermediate_channels, kernel_size=1,
-                         norm_layer=norm_layer, activation_layer=activation),
-
+        Conv2dNormActivation(
+            in_channels, intermediate_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=activation
+        ),
         # 3x3 depthwise with stride 2 and padding 1
-        ConvBNActivation(intermediate_channels, intermediate_channels, kernel_size=3, stride=2,
-                         groups=intermediate_channels, norm_layer=norm_layer, activation_layer=activation),
-
+        Conv2dNormActivation(
+            intermediate_channels,
+            intermediate_channels,
+            kernel_size=3,
+            stride=2,
+            groups=intermediate_channels,
+            norm_layer=norm_layer,
+            activation_layer=activation,
+        ),
         # 1x1 projetion to output channels
-        ConvBNActivation(intermediate_channels, out_channels, kernel_size=1,
-                         norm_layer=norm_layer, activation_layer=activation),
+        Conv2dNormActivation(
+            intermediate_channels, out_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=activation
+        ),
     )
 
 
 def _normal_init(conv: nn.Module):
     for layer in conv.modules():
         if isinstance(layer, nn.Conv2d):
             torch.nn.init.normal_(layer.weight, mean=0.0, std=0.03)
             if layer.bias is not None:
                 torch.nn.init.constant_(layer.bias, 0.0)
 
 
 class SSDLiteHead(nn.Module):
-    def __init__(self, in_channels: List[int], num_anchors: List[int], num_classes: int,
-                 norm_layer: Callable[..., nn.Module]):
+    def __init__(
+        self, in_channels: List[int], num_anchors: List[int], num_classes: int, norm_layer: Callable[..., nn.Module]
+    ):
         super().__init__()
         self.classification_head = SSDLiteClassificationHead(in_channels, num_anchors, num_classes, norm_layer)
         self.regression_head = SSDLiteRegressionHead(in_channels, num_anchors, norm_layer)
 
     def forward(self, x: List[Tensor]) -> Dict[str, Tensor]:
         return {
-            'bbox_regression': self.regression_head(x),
-            'cls_logits': self.classification_head(x),
+            "bbox_regression": self.regression_head(x),
+            "cls_logits": self.classification_head(x),
         }
 
 
 class SSDLiteClassificationHead(SSDScoringHead):
-    def __init__(self, in_channels: List[int], num_anchors: List[int], num_classes: int,
-                 norm_layer: Callable[..., nn.Module]):
+    def __init__(
+        self, in_channels: List[int], num_anchors: List[int], num_classes: int, norm_layer: Callable[..., nn.Module]
+    ):
         cls_logits = nn.ModuleList()
         for channels, anchors in zip(in_channels, num_anchors):
             cls_logits.append(_prediction_block(channels, num_classes * anchors, 3, norm_layer))
         _normal_init(cls_logits)
         super().__init__(cls_logits, num_classes)
 
 
@@ -94,32 +109,42 @@
         for channels, anchors in zip(in_channels, num_anchors):
             bbox_reg.append(_prediction_block(channels, 4 * anchors, 3, norm_layer))
         _normal_init(bbox_reg)
         super().__init__(bbox_reg, 4)
 
 
 class SSDLiteFeatureExtractorMobileNet(nn.Module):
-    def __init__(self, backbone: nn.Module, c4_pos: int, norm_layer: Callable[..., nn.Module], width_mult: float = 1.0,
-                 min_depth: int = 16, **kwargs: Any):
+    def __init__(
+        self,
+        backbone: nn.Module,
+        c4_pos: int,
+        norm_layer: Callable[..., nn.Module],
+        width_mult: float = 1.0,
+        min_depth: int = 16,
+    ):
         super().__init__()
 
-        assert not backbone[c4_pos].use_res_connect
+        if backbone[c4_pos].use_res_connect:
+            raise ValueError("backbone[c4_pos].use_res_connect should be False")
+
         self.features = nn.Sequential(
             # As described in section 6.3 of MobileNetV3 paper
             nn.Sequential(*backbone[:c4_pos], backbone[c4_pos].block[0]),  # from start until C4 expansion layer
-            nn.Sequential(backbone[c4_pos].block[1:], *backbone[c4_pos + 1:]),  # from C4 depthwise until end
+            nn.Sequential(backbone[c4_pos].block[1:], *backbone[c4_pos + 1 :]),  # from C4 depthwise until end
         )
 
         get_depth = lambda d: max(min_depth, int(d * width_mult))  # noqa: E731
-        extra = nn.ModuleList([
-            _extra_block(backbone[-1].out_channels, get_depth(512), norm_layer),
-            _extra_block(get_depth(512), get_depth(256), norm_layer),
-            _extra_block(get_depth(256), get_depth(256), norm_layer),
-            _extra_block(get_depth(256), get_depth(128), norm_layer),
-        ])
+        extra = nn.ModuleList(
+            [
+                _extra_block(backbone[-1].out_channels, get_depth(512), norm_layer),
+                _extra_block(get_depth(512), get_depth(256), norm_layer),
+                _extra_block(get_depth(256), get_depth(256), norm_layer),
+                _extra_block(get_depth(256), get_depth(128), norm_layer),
+            ]
+        )
         _normal_init(extra)
 
         self.extra = extra
 
     def forward(self, x: Tensor) -> Dict[str, Tensor]:
         # Get feature maps from backbone and extra. Can't be refactored due to JIT limitations.
         output = []
@@ -130,106 +155,183 @@
         for block in self.extra:
             x = block(x)
             output.append(x)
 
         return OrderedDict([(str(i), v) for i, v in enumerate(output)])
 
 
-def _mobilenet_extractor(backbone_name: str, progress: bool, pretrained: bool, trainable_layers: int,
-                         norm_layer: Callable[..., nn.Module], **kwargs: Any):
-    backbone = mobilenet.__dict__[backbone_name](pretrained=pretrained, progress=progress,
-                                                 norm_layer=norm_layer, **kwargs).features
-    if not pretrained:
-        # Change the default initialization scheme if not pretrained
-        _normal_init(backbone)
-
+def _mobilenet_extractor(
+    backbone: Union[mobilenet.MobileNetV2, mobilenet.MobileNetV3],
+    trainable_layers: int,
+    norm_layer: Callable[..., nn.Module],
+):
+    backbone = backbone.features
     # Gather the indices of blocks which are strided. These are the locations of C1, ..., Cn-1 blocks.
     # The first and last blocks are always included because they are the C0 (conv1) and Cn.
     stage_indices = [0] + [i for i, b in enumerate(backbone) if getattr(b, "_is_cn", False)] + [len(backbone) - 1]
     num_stages = len(stage_indices)
 
     # find the index of the layer from which we wont freeze
-    assert 0 <= trainable_layers <= num_stages
+    if not 0 <= trainable_layers <= num_stages:
+        raise ValueError("trainable_layers should be in the range [0, {num_stages}], instead got {trainable_layers}")
     freeze_before = len(backbone) if trainable_layers == 0 else stage_indices[num_stages - trainable_layers]
 
     for b in backbone[:freeze_before]:
         for parameter in b.parameters():
             parameter.requires_grad_(False)
 
-    return SSDLiteFeatureExtractorMobileNet(backbone, stage_indices[-2], norm_layer, **kwargs)
+    return SSDLiteFeatureExtractorMobileNet(backbone, stage_indices[-2], norm_layer)
+
+
+class SSDLite320_MobileNet_V3_Large_Weights(WeightsEnum):
+    COCO_V1 = Weights(
+        url="https://download.pytorch.org/models/ssdlite320_mobilenet_v3_large_coco-a79551df.pth",
+        transforms=ObjectDetection,
+        meta={
+            "num_params": 3440060,
+            "categories": _COCO_CATEGORIES,
+            "min_size": (1, 1),
+            "recipe": "https://github.com/pytorch/vision/tree/main/references/detection#ssdlite320-mobilenetv3-large",
+            "_metrics": {
+                "COCO-val2017": {
+                    "box_map": 21.3,
+                }
+            },
+            "_docs": """These weights were produced by following a similar training recipe as on the paper.""",
+        },
+    )
+    DEFAULT = COCO_V1
 
 
-def ssdlite320_mobilenet_v3_large(pretrained: bool = False, progress: bool = True, num_classes: int = 91,
-                                  pretrained_backbone: bool = False, trainable_backbone_layers: Optional[int] = None,
-                                  norm_layer: Optional[Callable[..., nn.Module]] = None,
-                                  **kwargs: Any):
-    """Constructs an SSDlite model with input size 320x320 and a MobileNetV3 Large backbone, as described at
-    `"Searching for MobileNetV3"
-    <https://arxiv.org/abs/1905.02244>`_ and
-    `"MobileNetV2: Inverted Residuals and Linear Bottlenecks"
-    <https://arxiv.org/abs/1801.04381>`_.
+@handle_legacy_interface(
+    weights=("pretrained", SSDLite320_MobileNet_V3_Large_Weights.COCO_V1),
+    weights_backbone=("pretrained_backbone", MobileNet_V3_Large_Weights.IMAGENET1K_V1),
+)
+def ssdlite320_mobilenet_v3_large(
+    *,
+    weights: Optional[SSDLite320_MobileNet_V3_Large_Weights] = None,
+    progress: bool = True,
+    num_classes: Optional[int] = None,
+    weights_backbone: Optional[MobileNet_V3_Large_Weights] = MobileNet_V3_Large_Weights.IMAGENET1K_V1,
+    trainable_backbone_layers: Optional[int] = None,
+    norm_layer: Optional[Callable[..., nn.Module]] = None,
+    **kwargs: Any,
+) -> SSD:
+    """SSDlite model architecture with input size 320x320 and a MobileNetV3 Large backbone, as
+    described at `Searching for MobileNetV3 <https://arxiv.org/abs/1905.02244>`__ and
+    `MobileNetV2: Inverted Residuals and Linear Bottlenecks <https://arxiv.org/abs/1801.04381>`__.
+
+    .. betastatus:: detection module
 
     See :func:`~torchvision.models.detection.ssd300_vgg16` for more details.
 
     Example:
 
-        >>> model = torchvision.models.detection.ssdlite320_mobilenet_v3_large(pretrained=True)
+        >>> model = torchvision.models.detection.ssdlite320_mobilenet_v3_large(weights=SSDLite320_MobileNet_V3_Large_Weights.DEFAULT)
         >>> model.eval()
         >>> x = [torch.rand(3, 320, 320), torch.rand(3, 500, 400)]
         >>> predictions = model(x)
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on COCO train2017
-        progress (bool): If True, displays a progress bar of the download to stderr
-        num_classes (int): number of output classes of the model (including the background)
-        pretrained_backbone (bool): If True, returns a model with backbone pre-trained on Imagenet
-        trainable_backbone_layers (int): number of trainable (not frozen) resnet layers starting from final block.
-            Valid values are between 0 and 6, with 6 meaning all backbone layers are trainable.
+        weights (:class:`~torchvision.models.detection.SSDLite320_MobileNet_V3_Large_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.detection.SSDLite320_MobileNet_V3_Large_Weights` below for
+            more details, and possible values. By default, no pre-trained
+            weights are used.
+        progress (bool, optional): If True, displays a progress bar of the
+            download to stderr. Default is True.
+        num_classes (int, optional): number of output classes of the model
+            (including the background).
+        weights_backbone (:class:`~torchvision.models.MobileNet_V3_Large_Weights`, optional): The pretrained
+            weights for the backbone.
+        trainable_backbone_layers (int, optional): number of trainable (not frozen) layers
+            starting from final block. Valid values are between 0 and 6, with 6 meaning all
+            backbone layers are trainable. If ``None`` is passed (the default) this value is
+            set to 6.
         norm_layer (callable, optional): Module specifying the normalization layer to use.
+        **kwargs: parameters passed to the ``torchvision.models.detection.ssd.SSD``
+            base class. Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/detection/ssd.py>`_
+            for more details about this class.
+
+    .. autoclass:: torchvision.models.detection.SSDLite320_MobileNet_V3_Large_Weights
+        :members:
     """
+
+    weights = SSDLite320_MobileNet_V3_Large_Weights.verify(weights)
+    weights_backbone = MobileNet_V3_Large_Weights.verify(weights_backbone)
+
     if "size" in kwargs:
-        warnings.warn("The size of the model is already fixed; ignoring the argument.")
+        warnings.warn("The size of the model is already fixed; ignoring the parameter.")
 
-    trainable_backbone_layers = _validate_trainable_layers(
-        pretrained or pretrained_backbone, trainable_backbone_layers, 6, 6)
+    if weights is not None:
+        weights_backbone = None
+        num_classes = _ovewrite_value_param(num_classes, len(weights.meta["categories"]))
+    elif num_classes is None:
+        num_classes = 91
 
-    if pretrained:
-        pretrained_backbone = False
+    trainable_backbone_layers = _validate_trainable_layers(
+        weights is not None or weights_backbone is not None, trainable_backbone_layers, 6, 6
+    )
 
     # Enable reduced tail if no pretrained backbone is selected. See Table 6 of MobileNetV3 paper.
-    reduce_tail = not pretrained_backbone
+    reduce_tail = weights_backbone is None
 
     if norm_layer is None:
         norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.03)
 
-    backbone = _mobilenet_extractor("mobilenet_v3_large", progress, pretrained_backbone, trainable_backbone_layers,
-                                    norm_layer, reduced_tail=reduce_tail, **kwargs)
+    backbone = mobilenet_v3_large(
+        weights=weights_backbone, progress=progress, norm_layer=norm_layer, reduced_tail=reduce_tail, **kwargs
+    )
+    if weights_backbone is None:
+        # Change the default initialization scheme if not pretrained
+        _normal_init(backbone)
+    backbone = _mobilenet_extractor(
+        backbone,
+        trainable_backbone_layers,
+        norm_layer,
+    )
 
     size = (320, 320)
     anchor_generator = DefaultBoxGenerator([[2, 3] for _ in range(6)], min_ratio=0.2, max_ratio=0.95)
     out_channels = det_utils.retrieve_out_channels(backbone, size)
     num_anchors = anchor_generator.num_anchors_per_location()
-    assert len(out_channels) == len(anchor_generator.aspect_ratios)
+    if len(out_channels) != len(anchor_generator.aspect_ratios):
+        raise ValueError(
+            f"The length of the output channels from the backbone {len(out_channels)} do not match the length of the anchor generator aspect ratios {len(anchor_generator.aspect_ratios)}"
+        )
 
     defaults = {
         "score_thresh": 0.001,
         "nms_thresh": 0.55,
         "detections_per_img": 300,
         "topk_candidates": 300,
         # Rescale the input in a way compatible to the backbone:
-        # The following mean/std rescale the data from [0, 1] to [-1, -1]
+        # The following mean/std rescale the data from [0, 1] to [-1, 1]
         "image_mean": [0.5, 0.5, 0.5],
         "image_std": [0.5, 0.5, 0.5],
     }
-    kwargs = {**defaults, **kwargs}
-    model = SSD(backbone, anchor_generator, size, num_classes,
-                head=SSDLiteHead(out_channels, num_anchors, num_classes, norm_layer), **kwargs)
-
-    if pretrained:
-        weights_name = 'ssdlite320_mobilenet_v3_large_coco'
-        if model_urls.get(weights_name, None) is None:
-            raise ValueError("No checkpoint is available for model {}".format(weights_name))
-
-        check_ckpt_file(model_urls[weights_name])
-        state_dict = load_state_dict_from_url(model_urls[weights_name])
-        model.load_state_dict(state_dict)
+    kwargs: Any = {**defaults, **kwargs}
+    model = SSD(
+        backbone,
+        anchor_generator,
+        size,
+        num_classes,
+        head=SSDLiteHead(out_channels, num_anchors, num_classes, norm_layer),
+        **kwargs,
+    )
+
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
+
     return model
+
+
+# The dictionary below is internal implementation detail and will be removed in v0.15
+from .._utils import _ModelURLs
+
+
+model_urls = _ModelURLs(
+    {
+        "ssdlite320_mobilenet_v3_large_coco": SSDLite320_MobileNet_V3_Large_Weights.COCO_V1.url,
+    }
+)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/detection/transform.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/detection/transform.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,67 +1,76 @@
 import math
+from typing import List, Tuple, Dict, Optional, Any
+
 import mindtorch.torch as torch
 import mindtorch.torchvision as torchvision
-
 from mindtorch.torch import nn, Tensor
-from typing import List, Tuple, Dict, Optional
 
 from .image_list import ImageList
 from .roi_heads import paste_masks_in_image
 
 
 # @torch.jit.unused
-# def _get_shape_onnx(image):
-#     # type: (Tensor) -> Tensor
-#     from torch.onnx import operators
-#     return operators.shape_as_tensor(image)[-2:]
+def _get_shape_onnx(image: Tensor) -> Tensor:
+    from torch.onnx import operators
+
+    return operators.shape_as_tensor(image)[-2:]
 
 
 # @torch.jit.unused
-# def _fake_cast_onnx(v):
-#     # type: (Tensor) -> float
-#     # ONNX requires a tensor but here we fake its type for JIT.
-#     return v
+def _fake_cast_onnx(v: Tensor) -> float:
+    # ONNX requires a tensor but here we fake its type for JIT.
+    return v
 
 
-def _resize_image_and_masks(image: Tensor, self_min_size: float, self_max_size: float,
-                            target: Optional[Dict[str, Tensor]] = None,
-                            fixed_size: Optional[Tuple[int, int]] = None,
-                            ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:
-    # if torchvision._is_tracing():
-    # im_shape = _get_shape_onnx(image)
-    # else:
-    im_shape = torch.tensor(image.shape[-2:])
+def _resize_image_and_masks(
+    image: Tensor,
+    self_min_size: float,
+    self_max_size: float,
+    target: Optional[Dict[str, Tensor]] = None,
+    fixed_size: Optional[Tuple[int, int]] = None,
+) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:
+    if torchvision._is_tracing():
+        im_shape = _get_shape_onnx(image)
+    else:
+        im_shape = torch.tensor(image.shape[-2:])
 
     size: Optional[List[int]] = None
     scale_factor: Optional[float] = None
     recompute_scale_factor: Optional[bool] = None
     if fixed_size is not None:
         size = [fixed_size[1], fixed_size[0]]
     else:
         min_size = torch.min(im_shape).to(dtype=torch.float32)
         max_size = torch.max(im_shape).to(dtype=torch.float32)
         scale = torch.min(self_min_size / min_size, self_max_size / max_size)
 
-        # if torchvision._is_tracing():
-        # scale_factor = _fake_cast_onnx(scale)
-        # else:
-        scale_factor = scale.item()
+        if torchvision._is_tracing():
+            scale_factor = _fake_cast_onnx(scale)
+        else:
+            scale_factor = scale.item()
         recompute_scale_factor = True
 
-    image = torch.nn.functional.interpolate(image[None], size=size, scale_factor=scale_factor, mode='bilinear',
-                                            recompute_scale_factor=recompute_scale_factor, align_corners=False)[0]
+    image = torch.nn.functional.interpolate(
+        image[None],
+        size=size,
+        scale_factor=scale_factor,
+        mode="bilinear",
+        recompute_scale_factor=recompute_scale_factor,
+        align_corners=False,
+    )[0]
 
     if target is None:
         return image, target
 
     if "masks" in target:
         mask = target["masks"]
-        mask = torch.nn.functional.interpolate(mask[:, None].float(), size=size, scale_factor=scale_factor,
-                                               recompute_scale_factor=recompute_scale_factor)[:, 0].byte()
+        mask = torch.nn.functional.interpolate(
+            mask[:, None].float(), size=size, scale_factor=scale_factor, recompute_scale_factor=recompute_scale_factor
+        )[:, 0].byte()
         target["masks"] = mask
     return image, target
 
 
 class GeneralizedRCNNTransform(nn.Module):
     """
     Performs input / target transformation before feeding the data to a GeneralizedRCNN
@@ -70,30 +79,38 @@
     The transformations it perform are:
         - input normalization (mean subtraction and std division)
         - input / target resizing to match min_size / max_size
 
     It returns a ImageList for the inputs, and a List[Dict[Tensor]] for the targets
     """
 
-    def __init__(self, min_size, max_size, image_mean, image_std, size_divisible=32, fixed_size=None):
-        super(GeneralizedRCNNTransform, self).__init__()
+    def __init__(
+        self,
+        min_size: int,
+        max_size: int,
+        image_mean: List[float],
+        image_std: List[float],
+        size_divisible: int = 32,
+        fixed_size: Optional[Tuple[int, int]] = None,
+        **kwargs: Any,
+    ):
+        super().__init__()
         if not isinstance(min_size, (list, tuple)):
             min_size = (min_size,)
         self.min_size = min_size
         self.max_size = max_size
         self.image_mean = image_mean
         self.image_std = image_std
         self.size_divisible = size_divisible
         self.fixed_size = fixed_size
+        self._skip_resize = kwargs.pop("_skip_resize", False)
 
-    def forward(self,
-                images,       # type: List[Tensor]
-                targets=None  # type: Optional[List[Dict[str, Tensor]]]
-                ):
-        # type: (...) -> Tuple[ImageList, Optional[List[Dict[str, Tensor]]]]
+    def forward(
+        self, images: List[Tensor], targets: Optional[List[Dict[str, Tensor]]] = None
+    ) -> Tuple[ImageList, Optional[List[Dict[str, Tensor]]]]:
         images = [img for img in images]
         if targets is not None:
             # make a copy of targets to avoid modifying it in-place
             # once torchscript supports dict comprehension
             # this can be simplified as follows
             # targets = [{k: v for k,v in t.items()} for t in targets]
             targets_copy: List[Dict[str, Tensor]] = []
@@ -104,59 +121,63 @@
                 targets_copy.append(data)
             targets = targets_copy
         for i in range(len(images)):
             image = images[i]
             target_index = targets[i] if targets is not None else None
 
             if image.dim() != 3:
-                raise ValueError("images is expected to be a list of 3d tensors "
-                                 "of shape [C, H, W], got {}".format(image.shape))
+                raise ValueError(f"images is expected to be a list of 3d tensors of shape [C, H, W], got {image.shape}")
             image = self.normalize(image)
             image, target_index = self.resize(image, target_index)
             images[i] = image
             if targets is not None and target_index is not None:
                 targets[i] = target_index
 
         image_sizes = [img.shape[-2:] for img in images]
         images = self.batch_images(images, size_divisible=self.size_divisible)
         image_sizes_list: List[Tuple[int, int]] = []
         for image_size in image_sizes:
-            assert len(image_size) == 2
+            torch._assert(
+                len(image_size) == 2,
+                f"Input tensors expected to have in the last two elements H and W, instead got {image_size}",
+            )
             image_sizes_list.append((image_size[0], image_size[1]))
 
         image_list = ImageList(images, image_sizes_list)
         return image_list, targets
 
-    def normalize(self, image):
+    def normalize(self, image: Tensor) -> Tensor:
         if not image.is_floating_point():
             raise TypeError(
                 f"Expected input images to be of floating type (in range [0, 1]), "
                 f"but found type {image.dtype} instead"
             )
         dtype, device = image.dtype, image.device
         mean = torch.as_tensor(self.image_mean, dtype=dtype, device=device)
         std = torch.as_tensor(self.image_std, dtype=dtype, device=device)
         return (image - mean[:, None, None]) / std[:, None, None]
 
-    def torch_choice(self, k):
-        # type: (List[int]) -> int
+    def torch_choice(self, k: List[int]) -> int:
         """
         Implements `random.choice` via torch ops so it can be compiled with
         TorchScript. Remove if https://github.com/pytorch/pytorch/issues/25803
         is fixed.
         """
-        index = int(torch.empty(1).uniform_adapter(0., float(len(k))).item())
+        index = int(torch.empty(1).uniform_(0.0, float(len(k))).item())
         return k[index]
 
-    def resize(self,
-               image: Tensor,
-               target: Optional[Dict[str, Tensor]] = None,
-               ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:
+    def resize(
+        self,
+        image: Tensor,
+        target: Optional[Dict[str, Tensor]] = None,
+    ) -> Tuple[Tensor, Optional[Dict[str, Tensor]]]:
         h, w = image.shape[-2:]
         if self.training:
+            if self._skip_resize:
+                return image, target
             size = float(self.torch_choice(self.min_size))
         else:
             # FIXME assume for now that testing uses the largest scale
             size = float(self.min_size[-1])
         image, target = _resize_image_and_masks(image, size, float(self.max_size), target, self.fixed_size)
 
         if target is None:
@@ -171,16 +192,15 @@
             keypoints = resize_keypoints(keypoints, (h, w), image.shape[-2:])
             target["keypoints"] = keypoints
         return image, target
 
     # _onnx_batch_images() is an implementation of
     # batch_images() that is supported by ONNX tracing.
     # @torch.jit.unused
-    def _onnx_batch_images(self, images, size_divisible=32):
-        # type: (List[Tensor], int) -> Tensor
+    def _onnx_batch_images(self, images: List[Tensor], size_divisible: int = 32) -> Tensor:
         max_size = []
         for i in range(images[0].dim()):
             max_size_i = torch.max(torch.stack([img.shape[i] for img in images]).to(torch.float32)).to(torch.int64)
             max_size.append(max_size_i)
         stride = size_divisible
         max_size[1] = (torch.ceil((max_size[1].to(torch.float32)) / stride) * stride).to(torch.int64)
         max_size[2] = (torch.ceil((max_size[2].to(torch.float32)) / stride) * stride).to(torch.int64)
@@ -193,112 +213,98 @@
         for img in images:
             padding = [(s1 - s2) for s1, s2 in zip(max_size, tuple(img.shape))]
             padded_img = torch.nn.functional.pad(img, (0, padding[2], 0, padding[1], 0, padding[0]))
             padded_imgs.append(padded_img)
 
         return torch.stack(padded_imgs)
 
-    def max_by_axis(self, the_list):
-        # type: (List[List[int]]) -> List[int]
+    def max_by_axis(self, the_list: List[List[int]]) -> List[int]:
         maxes = the_list[0]
         for sublist in the_list[1:]:
             for index, item in enumerate(sublist):
                 maxes[index] = max(maxes[index], item)
         return maxes
 
-    def batch_images(self, images, size_divisible=32):
-        # type: (List[Tensor], int) -> Tensor
+    def batch_images(self, images: List[Tensor], size_divisible: int = 32) -> Tensor:
         if torchvision._is_tracing():
             # batch_images() does not export well to ONNX
             # call _onnx_batch_images() instead
             return self._onnx_batch_images(images, size_divisible)
 
         max_size = self.max_by_axis([list(img.shape) for img in images])
         stride = float(size_divisible)
         max_size = list(max_size)
         max_size[1] = int(math.ceil(float(max_size[1]) / stride) * stride)
         max_size[2] = int(math.ceil(float(max_size[2]) / stride) * stride)
 
         batch_shape = [len(images)] + max_size
         batched_imgs = images[0].new_full(batch_shape, 0)
-        for img, pad_img in zip(images, batched_imgs):
-            pad_img[: img.shape[0], : img.shape[1], : img.shape[2]] = img
+        for i in range(batched_imgs.shape[0]):
+            img = images[i]
+            batched_imgs[i, : img.shape[0], : img.shape[1], : img.shape[2]].copy_(img)
 
         return batched_imgs
 
-    def postprocess(self,
-                    result,               # type: List[Dict[str, Tensor]]
-                    image_shapes,         # type: List[Tuple[int, int]]
-                    original_image_sizes  # type: List[Tuple[int, int]]
-                    ):
-        # type: (...) -> List[Dict[str, Tensor]]
+    def postprocess(
+        self,
+        result: List[Dict[str, Tensor]],
+        image_shapes: List[Tuple[int, int]],
+        original_image_sizes: List[Tuple[int, int]],
+    ) -> List[Dict[str, Tensor]]:
         if self.training:
             return result
         for i, (pred, im_s, o_im_s) in enumerate(zip(result, image_shapes, original_image_sizes)):
             boxes = pred["boxes"]
             boxes = resize_boxes(boxes, im_s, o_im_s)
             result[i]["boxes"] = boxes
             if "masks" in pred:
                 masks = pred["masks"]
+                # TODO Because pad cannot pad empty tensors. If the output data is empty, post-processing will not be possible.
                 masks = paste_masks_in_image(masks, boxes, o_im_s)
                 result[i]["masks"] = masks
             if "keypoints" in pred:
                 keypoints = pred["keypoints"]
                 keypoints = resize_keypoints(keypoints, im_s, o_im_s)
                 result[i]["keypoints"] = keypoints
         return result
 
-    def __repr__(self):
-        format_string = self.__class__.__name__ + '('
-        _indent = '\n    '
-        format_string += "{0}Normalize(mean={1}, std={2})".format(_indent, self.image_mean, self.image_std)
-        format_string += "{0}Resize(min_size={1}, max_size={2}, mode='bilinear')".format(_indent, self.min_size,
-                                                                                         self.max_size)
-        format_string += '\n)'
+    def __repr__(self) -> str:
+        format_string = f"{self.__class__.__name__}("
+        _indent = "\n    "
+        format_string += f"{_indent}Normalize(mean={self.image_mean}, std={self.image_std})"
+        format_string += f"{_indent}Resize(min_size={self.min_size}, max_size={self.max_size}, mode='bilinear')"
+        format_string += "\n)"
         return format_string
 
 
-def resize_keypoints(keypoints, original_size, new_size):
-    # type: (Tensor, List[int], List[int]) -> Tensor
+def resize_keypoints(keypoints: Tensor, original_size: List[int], new_size: List[int]) -> Tensor:
     ratios = [
-        torch.tensor(s, dtype=torch.float32, device=keypoints.device) /
-        torch.tensor(s_orig, dtype=torch.float32, device=keypoints.device)
+        torch.tensor(s, dtype=torch.float32, device=keypoints.device)
+        / torch.tensor(s_orig, dtype=torch.float32, device=keypoints.device)
         for s, s_orig in zip(new_size, original_size)
     ]
     ratio_h, ratio_w = ratios
     resized_data = keypoints.clone()
-
-    #TODO: after mindspore support 0 shape Tensor computation on Ascend, remove the code below.
-    if resized_data.shape[0] == 0:
-        if torch._C._get_tracing_state():
-            return torch.zeros(resized_data.shape + (1,)).to(resized_data.dtype)
-        else:
-            return resized_data
-
-    if torch._C._get_tracing_state():
-        resized_data_0 = resized_data[:, :, 0] * ratio_w
-        resized_data_1 = resized_data[:, :, 1] * ratio_h
-        resized_data = torch.stack((resized_data_0, resized_data_1, resized_data[:, :, 2]), dim=2)
-    else:
-        resized_data[..., 0] *= ratio_w
-        resized_data[..., 1] *= ratio_h
+    # if torch._C._get_tracing_state():
+    #     resized_data_0 = resized_data[:, :, 0] * ratio_w
+    #     resized_data_1 = resized_data[:, :, 1] * ratio_h
+    #     resized_data = torch.stack((resized_data_0, resized_data_1, resized_data[:, :, 2]), dim=2)
+    # else:
+    resized_data[..., 0] *= ratio_w
+    resized_data[..., 1] *= ratio_h
     return resized_data
 
 
-def resize_boxes(boxes, original_size, new_size):
-    # type: (Tensor, List[int], List[int]) -> Tensor
+def resize_boxes(boxes: Tensor, original_size: List[int], new_size: List[int]) -> Tensor:
     ratios = [
-        torch.tensor(s, dtype=torch.float32, device=boxes.device) /
-        torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)
+        torch.tensor(s, dtype=torch.float32, device=boxes.device)
+        / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)
         for s, s_orig in zip(new_size, original_size)
     ]
     ratio_height, ratio_width = ratios
-    if boxes.numel() == 0:
-        xmin, ymin, xmax, ymax = boxes.split(1, 1)
-    else:
-        xmin, ymin, xmax, ymax = boxes.unbind(1)
+    xmin, ymin, xmax, ymax = boxes.unbind(1)
 
     xmin = xmin * ratio_width
     xmax = xmax * ratio_width
     ymin = ymin * ratio_height
     ymax = ymax * ratio_height
     return torch.stack((xmin, ymin, xmax, ymax), dim=1)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/googlenet.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/googlenet.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,91 +1,60 @@
 import warnings
 from collections import namedtuple
+from functools import partial
+from typing import Optional, Tuple, List, Callable, Any
+
 import mindtorch.torch as torch
 import mindtorch.torch.nn as nn
 import mindtorch.torch.nn.functional as F
 from mindtorch.torch import Tensor
-from mindtorch import unsupported_attr
-from .utils import check_ckpt_file
-from typing import Optional, Tuple, List, Callable, Any
 
-__all__ = ['GoogLeNet', 'googlenet', "GoogLeNetOutputs", "_GoogLeNetOutputs"]
+from ..transforms._presets import ImageClassification
+from ._api import WeightsEnum, Weights
+from ._meta import _IMAGENET_CATEGORIES
+from ._utils import handle_legacy_interface, _ovewrite_named_param
 
 
-f = {
-    'googlenet': 'googlenet-1378be20.ckpt',
-}
+__all__ = ["GoogLeNet", "GoogLeNetOutputs", "_GoogLeNetOutputs", "GoogLeNet_Weights", "googlenet"]
 
-GoogLeNetOutputs = namedtuple('GoogLeNetOutputs', ['logits', 'aux_logits2', 'aux_logits1'])
-GoogLeNetOutputs.__annotations__ = {'logits': Tensor, 'aux_logits2': Optional[Tensor],
-                                    'aux_logits1': Optional[Tensor]}
+
+GoogLeNetOutputs = namedtuple("GoogLeNetOutputs", ["logits", "aux_logits2", "aux_logits1"])
+GoogLeNetOutputs.__annotations__ = {"logits": Tensor, "aux_logits2": Optional[Tensor], "aux_logits1": Optional[Tensor]}
 
 # Script annotations failed with _GoogleNetOutputs = namedtuple ...
 # _GoogLeNetOutputs set here for backwards compat
 _GoogLeNetOutputs = GoogLeNetOutputs
 
 
-def googlenet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> "GoogLeNet":
-    r"""GoogLeNet (Inception v1) model architecture from
-    `"Going Deeper with Convolutions" <http://arxiv.org/abs/1409.4842>`_.
-
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
-        aux_logits (bool): If True, adds two auxiliary branches that can improve training.
-            Default: *False* when pretrained is True otherwise *True*
-        transform_input (bool): If True, preprocesses the input according to the method with which it
-            was trained on ImageNet. Default: *False*
-    """
-    unsupported_attr(progress)
-    model = GoogLeNet(**kwargs)
-    if pretrained:
-        # if 'transform_input' not in kwargs:
-        #     kwargs['transform_input'] = True
-        # if 'aux_logits' not in kwargs:
-        #     kwargs['aux_logits'] = False
-        # if kwargs['aux_logits']:
-        #     warnings.warn('auxiliary heads in the pretrained googlenet model are NOT pretrained, '
-        #                   'so make sure to train them')
-        # original_aux_logits = kwargs['aux_logits']
-        # kwargs['aux_logits'] = True
-        # kwargs['init_weights'] = False
-        check_ckpt_file(f)
-        state_dict = torch.load(f)
-        model.load_state_dict(state_dict)
-        # state_dict = load_state_dict_from_url(model_urls['googlenet'],
-        #                                       progress=progress)
-        # model.load_state_dict(state_dict)
-        # if not original_aux_logits:
-        #     model.aux_logits = False
-        #     model.aux1 = None  # type: ignore[assignment]
-        #     model.aux2 = None  # type: ignore[assignment]
-    return model
-
-
 class GoogLeNet(nn.Module):
-    __constants__ = ['aux_logits', 'transform_input']
+    __constants__ = ["aux_logits", "transform_input"]
 
     def __init__(
         self,
         num_classes: int = 1000,
         aux_logits: bool = True,
         transform_input: bool = False,
         init_weights: Optional[bool] = None,
-        blocks: Optional[List[Callable[..., nn.Module]]] = None
+        blocks: Optional[List[Callable[..., nn.Module]]] = None,
+        dropout: float = 0.2,
+        dropout_aux: float = 0.7,
     ) -> None:
-        super(GoogLeNet, self).__init__()
+        super().__init__()
         if blocks is None:
             blocks = [BasicConv2d, Inception, InceptionAux]
         if init_weights is None:
-            warnings.warn('The default weight initialization of GoogleNet will be changed in future releases of '
-                          'torchvision. If you wish to keep the old behavior (which leads to long initialization times'
-                          ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)
+            warnings.warn(
+                "The default weight initialization of GoogleNet will be changed in future releases of "
+                "torchvision. If you wish to keep the old behavior (which leads to long initialization times"
+                " due to scipy/scipy#11299), please set init_weights=True.",
+                FutureWarning,
+            )
             init_weights = True
-        assert len(blocks) == 3
+        if len(blocks) != 3:
+            raise ValueError(f"blocks length should be 3 instead of {len(blocks)}")
         conv_block = blocks[0]
         inception_block = blocks[1]
         inception_aux_block = blocks[2]
 
         self.aux_logits = aux_logits
         self.transform_input = transform_input
 
@@ -106,39 +75,31 @@
         self.inception4e = inception_block(528, 256, 160, 320, 32, 128, 128)
         self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)
 
         self.inception5a = inception_block(832, 256, 160, 320, 32, 128, 128)
         self.inception5b = inception_block(832, 384, 192, 384, 48, 128, 128)
 
         if aux_logits:
-            self.aux1 = inception_aux_block(512, num_classes)
-            self.aux2 = inception_aux_block(528, num_classes)
+            self.aux1 = inception_aux_block(512, num_classes, dropout=dropout_aux)
+            self.aux2 = inception_aux_block(528, num_classes, dropout=dropout_aux)
         else:
             self.aux1 = None  # type: ignore[assignment]
             self.aux2 = None  # type: ignore[assignment]
 
         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
-        self.dropout = nn.Dropout(0.2)
+        self.dropout = nn.Dropout(p=dropout)
         self.fc = nn.Linear(1024, num_classes)
 
         if init_weights:
-            self._initialize_weights()
-
-    def _initialize_weights(self) -> None:
-        for m in self.modules():
-            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
-                import scipy.stats as stats
-                X = stats.truncnorm(-2, 2, scale=0.01)
-                values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype)
-                values = values.view(m.weight.size())
-                with torch.no_grad():
-                    m.weight.copy_(values)
-            elif isinstance(m, nn.BatchNorm2d):
-                nn.init.constant_(m.weight, 1)
-                nn.init.constant_(m.bias, 0)
+            for m in self.modules():
+                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
+                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=0.01, a=-2, b=2)
+                elif isinstance(m, nn.BatchNorm2d):
+                    nn.init.constant_(m.weight, 1)
+                    nn.init.constant_(m.bias, 0)
 
     def _transform_input(self, x: Tensor) -> Tensor:
         if self.transform_input:
             x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5
             x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5
             x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5
             x = torch.cat((x_ch0, x_ch1, x_ch2), 1)
@@ -200,61 +161,59 @@
         return x, aux2, aux1
 
     # @torch.jit.unused
     def eager_outputs(self, x: Tensor, aux2: Tensor, aux1: Optional[Tensor]) -> GoogLeNetOutputs:
         if self.training and self.aux_logits:
             return _GoogLeNetOutputs(x, aux2, aux1)
         else:
-            return x   # type: ignore[return-value]
+            return x
 
     def forward(self, x: Tensor) -> GoogLeNetOutputs:
         x = self._transform_input(x)
         x, aux1, aux2 = self._forward(x)
         aux_defined = self.training and self.aux_logits
         if torch.jit.is_scripting():
             if not aux_defined:
                 warnings.warn("Scripted GoogleNet always returns GoogleNetOutputs Tuple")
             return GoogLeNetOutputs(x, aux2, aux1)
         else:
             return self.eager_outputs(x, aux2, aux1)
 
 
 class Inception(nn.Module):
-
     def __init__(
         self,
         in_channels: int,
         ch1x1: int,
         ch3x3red: int,
         ch3x3: int,
         ch5x5red: int,
         ch5x5: int,
         pool_proj: int,
-        conv_block: Optional[Callable[..., nn.Module]] = None
+        conv_block: Optional[Callable[..., nn.Module]] = None,
     ) -> None:
-        super(Inception, self).__init__()
+        super().__init__()
         if conv_block is None:
             conv_block = BasicConv2d
         self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)
 
         self.branch2 = nn.Sequential(
-            conv_block(in_channels, ch3x3red, kernel_size=1),
-            conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)
+            conv_block(in_channels, ch3x3red, kernel_size=1), conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)
         )
 
         self.branch3 = nn.Sequential(
             conv_block(in_channels, ch5x5red, kernel_size=1),
             # Here, kernel_size=3 instead of kernel_size=5 is a known bug.
             # Please see https://github.com/pytorch/vision/issues/906 for details.
-            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1)
+            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1),
         )
 
         self.branch4 = nn.Sequential(
             nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),
-            conv_block(in_channels, pool_proj, kernel_size=1)
+            conv_block(in_channels, pool_proj, kernel_size=1),
         )
 
     def _forward(self, x: Tensor) -> List[Tensor]:
         branch1 = self.branch1(x)
         branch2 = self.branch2(x)
         branch3 = self.branch3(x)
         branch4 = self.branch4(x)
@@ -264,56 +223,130 @@
 
     def forward(self, x: Tensor) -> Tensor:
         outputs = self._forward(x)
         return torch.cat(outputs, 1)
 
 
 class InceptionAux(nn.Module):
-
     def __init__(
         self,
         in_channels: int,
         num_classes: int,
-        conv_block: Optional[Callable[..., nn.Module]] = None
+        conv_block: Optional[Callable[..., nn.Module]] = None,
+        dropout: float = 0.7,
     ) -> None:
-        super(InceptionAux, self).__init__()
+        super().__init__()
         if conv_block is None:
             conv_block = BasicConv2d
         self.conv = conv_block(in_channels, 128, kernel_size=1)
 
         self.fc1 = nn.Linear(2048, 1024)
         self.fc2 = nn.Linear(1024, num_classes)
+        self.dropout = nn.Dropout(p=dropout)
 
     def forward(self, x: Tensor) -> Tensor:
         # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14
         x = F.adaptive_avg_pool2d(x, (4, 4))
         # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4
         x = self.conv(x)
         # N x 128 x 4 x 4
         x = torch.flatten(x, 1)
         # N x 2048
         x = F.relu(self.fc1(x), inplace=False)
         # N x 1024
-        x = F.dropout(x, 0.7, training=self.training)
+        x = self.dropout(x)
         # N x 1024
         x = self.fc2(x)
         # N x 1000 (num_classes)
 
         return x
 
 
 class BasicConv2d(nn.Module):
-
-    def __init__(
-        self,
-        in_channels: int,
-        out_channels: int,
-        **kwargs: Any
-    ) -> None:
-        super(BasicConv2d, self).__init__()
+    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:
+        super().__init__()
         self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)
         self.bn = nn.BatchNorm2d(out_channels, eps=0.001)
 
     def forward(self, x: Tensor) -> Tensor:
         x = self.conv(x)
         x = self.bn(x)
         return F.relu(x, inplace=False)
+
+
+class GoogLeNet_Weights(WeightsEnum):
+    IMAGENET1K_V1 = Weights(
+        url="https://download.pytorch.org/models/googlenet-1378be20.pth",
+        transforms=partial(ImageClassification, crop_size=224),
+        meta={
+            "num_params": 6624904,
+            "min_size": (15, 15),
+            "categories": _IMAGENET_CATEGORIES,
+            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#googlenet",
+            "_metrics": {
+                "ImageNet-1K": {
+                    "acc@1": 69.778,
+                    "acc@5": 89.530,
+                }
+            },
+            "_docs": """These weights are ported from the original paper.""",
+        },
+    )
+    DEFAULT = IMAGENET1K_V1
+
+
+@handle_legacy_interface(weights=("pretrained", GoogLeNet_Weights.IMAGENET1K_V1))
+def googlenet(*, weights: Optional[GoogLeNet_Weights] = None, progress: bool = True, **kwargs: Any) -> GoogLeNet:
+    """GoogLeNet (Inception v1) model architecture from
+    `Going Deeper with Convolutions <http://arxiv.org/abs/1409.4842>`_.
+
+    Args:
+        weights (:class:`~torchvision.models.GoogLeNet_Weights`, optional): The
+            pretrained weights for the model. See
+            :class:`~torchvision.models.GoogLeNet_Weights` below for
+            more details, and possible values. By default, no pre-trained
+            weights are used.
+        progress (bool, optional): If True, displays a progress bar of the
+            download to stderr. Default is True.
+        **kwargs: parameters passed to the ``torchvision.models.GoogLeNet``
+            base class. Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/googlenet.py>`_
+            for more details about this class.
+    .. autoclass:: torchvision.models.GoogLeNet_Weights
+        :members:
+    """
+    weights = GoogLeNet_Weights.verify(weights)
+
+    original_aux_logits = kwargs.get("aux_logits", False)
+    if weights is not None:
+        if "transform_input" not in kwargs:
+            _ovewrite_named_param(kwargs, "transform_input", True)
+        _ovewrite_named_param(kwargs, "aux_logits", True)
+        _ovewrite_named_param(kwargs, "init_weights", False)
+        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))
+
+    model = GoogLeNet(**kwargs)
+
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
+        if not original_aux_logits:
+            model.aux_logits = False
+            model.aux1 = None  # type: ignore[assignment]
+            model.aux2 = None  # type: ignore[assignment]
+        else:
+            warnings.warn(
+                "auxiliary heads in the pretrained googlenet model are NOT pretrained, so make sure to train them"
+            )
+
+    return model
+
+
+# The dictionary below is internal implementation detail and will be removed in v0.15
+from ._utils import _ModelURLs
+
+
+model_urls = _ModelURLs(
+    {
+        # GoogLeNet ported from TensorFlow
+        "googlenet": GoogLeNet_Weights.IMAGENET1K_V1.url,
+    }
+)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/inception.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/inception.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,83 +1,56 @@
-from collections import namedtuple
 import warnings
+from collections import namedtuple
+from functools import partial
+from typing import Callable, Any, Optional, Tuple, List
+
 import mindtorch.torch as torch
-from mindtorch.torch import nn, Tensor
 import mindtorch.torch.nn.functional as F
-from mindtorch import unsupported_attr
-from .utils import check_ckpt_file, model_path_name
-from typing import Callable, Any, Optional, Tuple, List
-from mindtorch.torch.hub import load_state_dict_from_url
-from ._utils import _ovewrite_named_param
+from mindtorch.torch import nn, Tensor
 
-__all__ = ['Inception3', 'inception_v3', 'InceptionOutputs', '_InceptionOutputs']
+from ..transforms._presets import ImageClassification
+from ._api import WeightsEnum, Weights
+from ._meta import _IMAGENET_CATEGORIES
+from ._utils import handle_legacy_interface, _ovewrite_named_param
 
 
-f = {
-    # Inception v3 ported from TensorFlow
-    'inception_v3_google': model_path_name + 'inception_v3_google-0cc3c7bd.pth',
-}
+__all__ = ["Inception3", "InceptionOutputs", "_InceptionOutputs", "Inception_V3_Weights", "inception_v3"]
 
-InceptionOutputs = namedtuple('InceptionOutputs', ['logits', 'aux_logits'])
-InceptionOutputs.__annotations__ = {'logits': Tensor, 'aux_logits': Optional[Tensor]}
+
+InceptionOutputs = namedtuple("InceptionOutputs", ["logits", "aux_logits"])
+InceptionOutputs.__annotations__ = {"logits": Tensor, "aux_logits": Optional[Tensor]}
 
 # Script annotations failed with _GoogleNetOutputs = namedtuple ...
 # _InceptionOutputs set here for backwards compat
 _InceptionOutputs = InceptionOutputs
 
 
-def inception_v3(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> "Inception3":
-    r"""Inception v3 model architecture from
-    `"Rethinking the Inception Architecture for Computer Vision" <http://arxiv.org/abs/1512.00567>`_.
-
-    .. note::
-        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of
-        N x 3 x 299 x 299, so ensure your images are sized accordingly.
-
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
-        aux_logits (bool): If True, add an auxiliary branch that can improve training.
-            Default: *True*
-        transform_input (bool): If True, preprocesses the input according to the method with which it
-            was trained on ImageNet. Default: *False*
-    """
-    unsupported_attr(progress)
-    if "transform_input" not in kwargs:
-        _ovewrite_named_param(kwargs, "transform_input", True)
-    model = Inception3(**kwargs)
-    if pretrained:
-        check_ckpt_file(f['inception_v3_google'])
-        state_dict = load_state_dict_from_url(f['inception_v3_google'])
-        model.load_state_dict(state_dict)
-    return model
-
-
 class Inception3(nn.Module):
-
     def __init__(
         self,
         num_classes: int = 1000,
         aux_logits: bool = True,
         transform_input: bool = False,
         inception_blocks: Optional[List[Callable[..., nn.Module]]] = None,
-        init_weights: Optional[bool] = False
+        init_weights: Optional[bool] = None,
+        dropout: float = 0.5,
     ) -> None:
-        super(Inception3, self).__init__()
+        super().__init__()
         if inception_blocks is None:
-            inception_blocks = [
-                BasicConv2d, InceptionA, InceptionB, InceptionC,
-                InceptionD, InceptionE, InceptionAux
-            ]
+            inception_blocks = [BasicConv2d, InceptionA, InceptionB, InceptionC, InceptionD, InceptionE, InceptionAux]
         if init_weights is None:
-            warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '
-                          'torchvision. If you wish to keep the old behavior (which leads to long initialization times'
-                          ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)
+            warnings.warn(
+                "The default weight initialization of inception_v3 will be changed in future releases of "
+                "torchvision. If you wish to keep the old behavior (which leads to long initialization times"
+                " due to scipy/scipy#11299), please set init_weights=True.",
+                FutureWarning,
+            )
             init_weights = True
-        assert len(inception_blocks) == 7
+        if len(inception_blocks) != 7:
+            raise ValueError(f"lenght of inception_blocks should be 7 instead of {len(inception_blocks)}")
         conv_block = inception_blocks[0]
         inception_a = inception_blocks[1]
         inception_b = inception_blocks[2]
         inception_c = inception_blocks[3]
         inception_d = inception_blocks[4]
         inception_e = inception_blocks[5]
         inception_aux = inception_blocks[6]
@@ -102,15 +75,15 @@
         self.AuxLogits: Optional[nn.Module] = None
         if aux_logits:
             self.AuxLogits = inception_aux(768, num_classes)
         self.Mixed_7a = inception_d(768)
         self.Mixed_7b = inception_e(1280)
         self.Mixed_7c = inception_e(2048)
         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
-        self.dropout = nn.Dropout()
+        self.dropout = nn.Dropout(p=dropout)
         self.fc = nn.Linear(2048, num_classes)
         if init_weights:
             for m in self.modules():
                 if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
                     stddev = float(m.stddev) if hasattr(m, "stddev") else 0.1  # type: ignore
                     torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=stddev, a=-2, b=2)
                 elif isinstance(m, nn.BatchNorm2d):
@@ -185,30 +158,27 @@
         else:
             return x
 
     def forward(self, x: Tensor) -> InceptionOutputs:
         x = self._transform_input(x)
         x, aux = self._forward(x)
         aux_defined = self.training and self.aux_logits
-        # if torch.jit.is_scripting():
-        if not aux_defined:
-            warnings.warn("Scripted Inception3 always returns Inception3 Tuple")
-        # else:
-        return self.eager_outputs(x, aux)
+        if torch.jit.is_scripting():
+            if not aux_defined:
+                warnings.warn("Scripted Inception3 always returns Inception3 Tuple")
+            return InceptionOutputs(x, aux)
+        else:
+            return self.eager_outputs(x, aux)
 
 
 class InceptionA(nn.Module):
-
     def __init__(
-        self,
-        in_channels: int,
-        pool_features: int,
-        conv_block: Optional[Callable[..., nn.Module]] = None
+        self, in_channels: int, pool_features: int, conv_block: Optional[Callable[..., nn.Module]] = None
     ) -> None:
-        super(InceptionA, self).__init__()
+        super().__init__()
         if conv_block is None:
             conv_block = BasicConv2d
         self.branch1x1 = conv_block(in_channels, 64, kernel_size=1)
 
         self.branch5x5_1 = conv_block(in_channels, 48, kernel_size=1)
         self.branch5x5_2 = conv_block(48, 64, kernel_size=5, padding=2)
 
@@ -224,33 +194,29 @@
         branch5x5 = self.branch5x5_1(x)
         branch5x5 = self.branch5x5_2(branch5x5)
 
         branch3x3dbl = self.branch3x3dbl_1(x)
         branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)
         branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)
 
-        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)
+        # branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)
+        branch_pool = x
         branch_pool = self.branch_pool(branch_pool)
 
         outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]
         return outputs
 
     def forward(self, x: Tensor) -> Tensor:
         outputs = self._forward(x)
         return torch.cat(outputs, 1)
 
 
 class InceptionB(nn.Module):
-
-    def __init__(
-        self,
-        in_channels: int,
-        conv_block: Optional[Callable[..., nn.Module]] = None
-    ) -> None:
-        super(InceptionB, self).__init__()
+    def __init__(self, in_channels: int, conv_block: Optional[Callable[..., nn.Module]] = None) -> None:
+        super().__init__()
         if conv_block is None:
             conv_block = BasicConv2d
         self.branch3x3 = conv_block(in_channels, 384, kernel_size=3, stride=2)
 
         self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)
         self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)
         self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, stride=2)
@@ -269,22 +235,18 @@
 
     def forward(self, x: Tensor) -> Tensor:
         outputs = self._forward(x)
         return torch.cat(outputs, 1)
 
 
 class InceptionC(nn.Module):
-
     def __init__(
-        self,
-        in_channels: int,
-        channels_7x7: int,
-        conv_block: Optional[Callable[..., nn.Module]] = None
+        self, in_channels: int, channels_7x7: int, conv_block: Optional[Callable[..., nn.Module]] = None
     ) -> None:
-        super(InceptionC, self).__init__()
+        super().__init__()
         if conv_block is None:
             conv_block = BasicConv2d
         self.branch1x1 = conv_block(in_channels, 192, kernel_size=1)
 
         c7 = channels_7x7
         self.branch7x7_1 = conv_block(in_channels, c7, kernel_size=1)
         self.branch7x7_2 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))
@@ -307,33 +269,29 @@
 
         branch7x7dbl = self.branch7x7dbl_1(x)
         branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)
         branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)
         branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)
         branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)
 
-        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)
+        # branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)
+        branch_pool = x
         branch_pool = self.branch_pool(branch_pool)
 
         outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]
         return outputs
 
     def forward(self, x: Tensor) -> Tensor:
         outputs = self._forward(x)
         return torch.cat(outputs, 1)
 
 
 class InceptionD(nn.Module):
-
-    def __init__(
-        self,
-        in_channels: int,
-        conv_block: Optional[Callable[..., nn.Module]] = None
-    ) -> None:
-        super(InceptionD, self).__init__()
+    def __init__(self, in_channels: int, conv_block: Optional[Callable[..., nn.Module]] = None) -> None:
+        super().__init__()
         if conv_block is None:
             conv_block = BasicConv2d
         self.branch3x3_1 = conv_block(in_channels, 192, kernel_size=1)
         self.branch3x3_2 = conv_block(192, 320, kernel_size=3, stride=2)
 
         self.branch7x7x3_1 = conv_block(in_channels, 192, kernel_size=1)
         self.branch7x7x3_2 = conv_block(192, 192, kernel_size=(1, 7), padding=(0, 3))
@@ -355,21 +313,16 @@
 
     def forward(self, x: Tensor) -> Tensor:
         outputs = self._forward(x)
         return torch.cat(outputs, 1)
 
 
 class InceptionE(nn.Module):
-
-    def __init__(
-        self,
-        in_channels: int,
-        conv_block: Optional[Callable[..., nn.Module]] = None
-    ) -> None:
-        super(InceptionE, self).__init__()
+    def __init__(self, in_channels: int, conv_block: Optional[Callable[..., nn.Module]] = None) -> None:
+        super().__init__()
         if conv_block is None:
             conv_block = BasicConv2d
         self.branch1x1 = conv_block(in_channels, 320, kernel_size=1)
 
         self.branch3x3_1 = conv_block(in_channels, 384, kernel_size=1)
         self.branch3x3_2a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))
         self.branch3x3_2b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))
@@ -395,34 +348,31 @@
         branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)
         branch3x3dbl = [
             self.branch3x3dbl_3a(branch3x3dbl),
             self.branch3x3dbl_3b(branch3x3dbl),
         ]
         branch3x3dbl = torch.cat(branch3x3dbl, 1)
 
-        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)
+        # branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)
+        branch_pool = x
         branch_pool = self.branch_pool(branch_pool)
 
         outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]
         return outputs
 
     def forward(self, x: Tensor) -> Tensor:
         outputs = self._forward(x)
         return torch.cat(outputs, 1)
 
 
 class InceptionAux(nn.Module):
-
     def __init__(
-        self,
-        in_channels: int,
-        num_classes: int,
-        conv_block: Optional[Callable[..., nn.Module]] = None
+        self, in_channels: int, num_classes: int, conv_block: Optional[Callable[..., nn.Module]] = None
     ) -> None:
-        super(InceptionAux, self).__init__()
+        super().__init__()
         if conv_block is None:
             conv_block = BasicConv2d
         self.conv0 = conv_block(in_channels, 128, kernel_size=1)
         self.conv1 = conv_block(128, 768, kernel_size=5)
         self.conv1.stddev = 0.01
         self.fc = nn.Linear(768, num_classes)
         self.fc.stddev = 0.001
@@ -442,22 +392,96 @@
         # N x 768
         x = self.fc(x)
         # N x 1000
         return x
 
 
 class BasicConv2d(nn.Module):
-
-    def __init__(
-        self,
-        in_channels: int,
-        out_channels: int,
-        **kwargs: Any
-    ) -> None:
-        super(BasicConv2d, self).__init__()
+    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:
+        super().__init__()
         self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)
         self.bn = nn.BatchNorm2d(out_channels, eps=0.001)
 
     def forward(self, x: Tensor) -> Tensor:
         x = self.conv(x)
         x = self.bn(x)
         return F.relu(x, inplace=False)
+
+
+class Inception_V3_Weights(WeightsEnum):
+    IMAGENET1K_V1 = Weights(
+        url="https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth",
+        transforms=partial(ImageClassification, crop_size=299, resize_size=342),
+        meta={
+            "num_params": 27161264,
+            "min_size": (75, 75),
+            "categories": _IMAGENET_CATEGORIES,
+            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#inception-v3",
+            "_metrics": {
+                "ImageNet-1K": {
+                    "acc@1": 77.294,
+                    "acc@5": 93.450,
+                }
+            },
+            "_docs": """These weights are ported from the original paper.""",
+        },
+    )
+    DEFAULT = IMAGENET1K_V1
+
+
+@handle_legacy_interface(weights=("pretrained", Inception_V3_Weights.IMAGENET1K_V1))
+def inception_v3(*, weights: Optional[Inception_V3_Weights] = None, progress: bool = True, **kwargs: Any) -> Inception3:
+    """
+    Inception v3 model architecture from
+    `Rethinking the Inception Architecture for Computer Vision <http://arxiv.org/abs/1512.00567>`_.
+
+    .. note::
+        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of
+        N x 3 x 299 x 299, so ensure your images are sized accordingly.
+
+    Args:
+        weights (:class:`~torchvision.models.Inception_V3_Weights`, optional): The
+            pretrained weights for the model. See
+            :class:`~torchvision.models.Inception_V3_Weights` below for
+            more details, and possible values. By default, no pre-trained
+            weights are used.
+        progress (bool, optional): If True, displays a progress bar of the
+            download to stderr. Default is True.
+        **kwargs: parameters passed to the ``torchvision.models.Inception3``
+            base class. Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/inception.py>`_
+            for more details about this class.
+
+    .. autoclass:: torchvision.models.Inception_V3_Weights
+        :members:
+    """
+    weights = Inception_V3_Weights.verify(weights)
+
+    original_aux_logits = kwargs.get("aux_logits", True)
+    if weights is not None:
+        if "transform_input" not in kwargs:
+            _ovewrite_named_param(kwargs, "transform_input", True)
+        _ovewrite_named_param(kwargs, "aux_logits", True)
+        _ovewrite_named_param(kwargs, "init_weights", False)
+        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))
+
+    model = Inception3(**kwargs)
+
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
+        if not original_aux_logits:
+            model.aux_logits = False
+            model.AuxLogits = None
+
+    return model
+
+
+# The dictionary below is internal implementation detail and will be removed in v0.15
+from ._utils import _ModelURLs
+
+
+model_urls = _ModelURLs(
+    {
+        # Inception v3 ported from TensorFlow
+        "inception_v3_google": Inception_V3_Weights.IMAGENET1K_V1.url,
+    }
+)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/mobilenetv3.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/mobilenetv3.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,53 +1,59 @@
-import mindtorch.torch as torch
-
+import warnings
 from functools import partial
-from mindtorch.torch import nn, Tensor
-from mindtorch.torch.nn import functional as F
-from typing import Any, Callable, Dict, List, Optional, Sequence
-
-from mindtorch import unsupported_attr
-from .utils import check_ckpt_file, model_path_name
-from .mobilenetv2 import _make_divisible, ConvBNActivation
-from mindtorch.torch.hub import load_state_dict_from_url
+from typing import Any, Callable, List, Optional, Sequence
 
+import mindtorch.torch as torch
+from mindtorch.torch import nn, Tensor
 
-__all__ = ["MobileNetV3", "mobilenet_v3_large", "mobilenet_v3_small"]
+from ..ops.misc import Conv2dNormActivation, SqueezeExcitation as SElayer
+from ..transforms._presets import ImageClassification
+from ._api import WeightsEnum, Weights
+from ._meta import _IMAGENET_CATEGORIES
+from ._utils import handle_legacy_interface, _ovewrite_named_param, _make_divisible
+
+
+__all__ = [
+    "MobileNetV3",
+    "MobileNet_V3_Large_Weights",
+    "MobileNet_V3_Small_Weights",
+    "mobilenet_v3_large",
+    "mobilenet_v3_small",
+]
 
-f = {
-    "mobilenet_v3_large": model_path_name + "mobilenet_v3_large-8738ca79.pth",
-    "mobilenet_v3_small": model_path_name + "mobilenet_v3_small-047dcff4.pth",
-}
 
+class SqueezeExcitation(SElayer):
+    """DEPRECATED"""
 
-class SqueezeExcitation(nn.Module):
-    # Implemented as described at Figure 4 of the MobileNetV3 paper
     def __init__(self, input_channels: int, squeeze_factor: int = 4):
-        super().__init__()
         squeeze_channels = _make_divisible(input_channels // squeeze_factor, 8)
-        self.fc1 = nn.Conv2d(input_channels, squeeze_channels, 1)
-        self.relu = nn.ReLU(inplace=False)
-        self.fc2 = nn.Conv2d(squeeze_channels, input_channels, 1)
-
-    def _scale(self, input: Tensor, inplace: bool) -> Tensor:
-        scale = F.adaptive_avg_pool2d(input, 1)
-        scale = self.fc1(scale)
-        scale = self.relu(scale)
-        scale = self.fc2(scale)
-        return F.hardsigmoid(scale, inplace=inplace)
-
-    def forward(self, input: Tensor) -> Tensor:
-        scale = self._scale(input, True)
-        return scale * input
+        super().__init__(input_channels, squeeze_channels, scale_activation=nn.Hardsigmoid)
+        self.relu = self.activation
+        delattr(self, "activation")
+        warnings.warn(
+            "This SqueezeExcitation class is deprecated since 0.12 and will be removed in 0.14. "
+            "Use torchvision.ops.SqueezeExcitation instead.",
+            FutureWarning,
+        )
 
 
 class InvertedResidualConfig:
     # Stores information listed at Tables 1 and 2 of the MobileNetV3 paper
-    def __init__(self, input_channels: int, kernel: int, expanded_channels: int, out_channels: int, use_se: bool,
-                 activation: str, stride: int, dilation: int, width_mult: float):
+    def __init__(
+        self,
+        input_channels: int,
+        kernel: int,
+        expanded_channels: int,
+        out_channels: int,
+        use_se: bool,
+        activation: str,
+        stride: int,
+        dilation: int,
+        width_mult: float,
+    ):
         self.input_channels = self.adjust_channels(input_channels, width_mult)
         self.kernel = kernel
         self.expanded_channels = self.adjust_channels(expanded_channels, width_mult)
         self.out_channels = self.adjust_channels(out_channels, width_mult)
         self.use_se = use_se
         self.use_hs = activation == "HS"
         self.stride = stride
@@ -56,117 +62,159 @@
     @staticmethod
     def adjust_channels(channels: int, width_mult: float):
         return _make_divisible(channels * width_mult, 8)
 
 
 class InvertedResidual(nn.Module):
     # Implemented as described at section 5 of MobileNetV3 paper
-    def __init__(self, cnf: InvertedResidualConfig, norm_layer: Callable[..., nn.Module],
-                 se_layer: Callable[..., nn.Module] = SqueezeExcitation):
+    def __init__(
+        self,
+        cnf: InvertedResidualConfig,
+        norm_layer: Callable[..., nn.Module],
+        se_layer: Callable[..., nn.Module] = partial(SElayer, scale_activation=nn.Hardsigmoid),
+    ):
         super().__init__()
         if not (1 <= cnf.stride <= 2):
-            raise ValueError('illegal stride value')
+            raise ValueError("illegal stride value")
 
         self.use_res_connect = cnf.stride == 1 and cnf.input_channels == cnf.out_channels
 
         layers: List[nn.Module] = []
         activation_layer = nn.Hardswish if cnf.use_hs else nn.ReLU
 
         # expand
         if cnf.expanded_channels != cnf.input_channels:
-            layers.append(ConvBNActivation(cnf.input_channels, cnf.expanded_channels, kernel_size=1,
-                                           norm_layer=norm_layer, activation_layer=activation_layer))
+            layers.append(
+                Conv2dNormActivation(
+                    cnf.input_channels,
+                    cnf.expanded_channels,
+                    kernel_size=1,
+                    norm_layer=norm_layer,
+                    activation_layer=activation_layer,
+                )
+            )
 
         # depthwise
         stride = 1 if cnf.dilation > 1 else cnf.stride
-        layers.append(ConvBNActivation(cnf.expanded_channels, cnf.expanded_channels, kernel_size=cnf.kernel,
-                                       stride=stride, dilation=cnf.dilation, groups=cnf.expanded_channels,
-                                       norm_layer=norm_layer, activation_layer=activation_layer))
+        layers.append(
+            Conv2dNormActivation(
+                cnf.expanded_channels,
+                cnf.expanded_channels,
+                kernel_size=cnf.kernel,
+                stride=stride,
+                dilation=cnf.dilation,
+                groups=cnf.expanded_channels,
+                norm_layer=norm_layer,
+                activation_layer=activation_layer,
+            )
+        )
         if cnf.use_se:
-            layers.append(se_layer(cnf.expanded_channels))
+            squeeze_channels = _make_divisible(cnf.expanded_channels // 4, 8)
+            layers.append(se_layer(cnf.expanded_channels, squeeze_channels))
 
         # project
-        layers.append(ConvBNActivation(cnf.expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer,
-                                       activation_layer=nn.Identity))
+        layers.append(
+            Conv2dNormActivation(
+                cnf.expanded_channels, cnf.out_channels, kernel_size=1, norm_layer=norm_layer, activation_layer=None
+            )
+        )
 
         self.block = nn.Sequential(*layers)
         self.out_channels = cnf.out_channels
         self._is_cn = cnf.stride > 1
 
     def forward(self, input: Tensor) -> Tensor:
         result = self.block(input)
         if self.use_res_connect:
             result += input
         return result
 
 
 class MobileNetV3(nn.Module):
-
     def __init__(
-            self,
-            inverted_residual_setting: List[InvertedResidualConfig],
-            last_channel: int,
-            num_classes: int = 1000,
-            block: Optional[Callable[..., nn.Module]] = None,
-            norm_layer: Optional[Callable[..., nn.Module]] = None,
-            **kwargs: Any
+        self,
+        inverted_residual_setting: List[InvertedResidualConfig],
+        last_channel: int,
+        num_classes: int = 1000,
+        block: Optional[Callable[..., nn.Module]] = None,
+        norm_layer: Optional[Callable[..., nn.Module]] = None,
+        dropout: float = 0.2,
+        **kwargs: Any,
     ) -> None:
         """
         MobileNet V3 main class
 
         Args:
             inverted_residual_setting (List[InvertedResidualConfig]): Network structure
             last_channel (int): The number of channels on the penultimate layer
             num_classes (int): Number of classes
             block (Optional[Callable[..., nn.Module]]): Module specifying inverted residual building block for mobilenet
             norm_layer (Optional[Callable[..., nn.Module]]): Module specifying the normalization layer to use
+            dropout (float): The droupout probability
         """
         super().__init__()
 
         if not inverted_residual_setting:
             raise ValueError("The inverted_residual_setting should not be empty")
-        elif not (isinstance(inverted_residual_setting, Sequence) and
-                  all([isinstance(s, InvertedResidualConfig) for s in inverted_residual_setting])):
+        elif not (
+            isinstance(inverted_residual_setting, Sequence)
+            and all([isinstance(s, InvertedResidualConfig) for s in inverted_residual_setting])
+        ):
             raise TypeError("The inverted_residual_setting should be List[InvertedResidualConfig]")
 
         if block is None:
             block = InvertedResidual
 
         if norm_layer is None:
             norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.01)
 
         layers: List[nn.Module] = []
 
         # building first layer
         firstconv_output_channels = inverted_residual_setting[0].input_channels
-        layers.append(ConvBNActivation(3, firstconv_output_channels, kernel_size=3, stride=2, norm_layer=norm_layer,
-                                       activation_layer=nn.Hardswish))
+        layers.append(
+            Conv2dNormActivation(
+                3,
+                firstconv_output_channels,
+                kernel_size=3,
+                stride=2,
+                norm_layer=norm_layer,
+                activation_layer=nn.Hardswish,
+            )
+        )
 
         # building inverted residual blocks
         for cnf in inverted_residual_setting:
             layers.append(block(cnf, norm_layer))
 
         # building last several layers
         lastconv_input_channels = inverted_residual_setting[-1].out_channels
         lastconv_output_channels = 6 * lastconv_input_channels
-        layers.append(ConvBNActivation(lastconv_input_channels, lastconv_output_channels, kernel_size=1,
-                                       norm_layer=norm_layer, activation_layer=nn.Hardswish))
+        layers.append(
+            Conv2dNormActivation(
+                lastconv_input_channels,
+                lastconv_output_channels,
+                kernel_size=1,
+                norm_layer=norm_layer,
+                activation_layer=nn.Hardswish,
+            )
+        )
 
         self.features = nn.Sequential(*layers)
         self.avgpool = nn.AdaptiveAvgPool2d(1)
         self.classifier = nn.Sequential(
             nn.Linear(lastconv_output_channels, last_channel),
             nn.Hardswish(inplace=False),
-            nn.Dropout(p=0.2, inplace=False),
+            nn.Dropout(p=dropout, inplace=False),
             nn.Linear(last_channel, num_classes),
         )
 
         for m in self.modules():
             if isinstance(m, nn.Conv2d):
-                nn.init.kaiming_normal_(m.weight, mode='fan_out')
+                nn.init.kaiming_normal_(m.weight, mode="fan_out")
                 if m.bias is not None:
                     nn.init.zeros_(m.bias)
             elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                 nn.init.ones_(m.weight)
                 nn.init.zeros_(m.bias)
             elif isinstance(m, nn.Linear):
                 nn.init.normal_(m.weight, 0, 0.01)
@@ -182,16 +230,17 @@
 
         return x
 
     def forward(self, x: Tensor) -> Tensor:
         return self._forward_impl(x)
 
 
-def _mobilenet_v3_conf(arch: str, width_mult: float = 1.0, reduced_tail: bool = False, dilated: bool = False,
-                       **kwargs: Any):
+def _mobilenet_v3_conf(
+    arch: str, width_mult: float = 1.0, reduced_tail: bool = False, dilated: bool = False, **kwargs: Any
+):
     reduce_divider = 2 if reduced_tail else 1
     dilation = 2 if dilated else 1
 
     bneck_conf = partial(InvertedResidualConfig, width_mult=width_mult)
     adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_mult=width_mult)
 
     if arch == "mobilenet_v3_large":
@@ -225,55 +274,168 @@
             bneck_conf(48, 5, 144, 48, True, "HS", 1, 1),
             bneck_conf(48, 5, 288, 96 // reduce_divider, True, "HS", 2, dilation),  # C4
             bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, "HS", 1, dilation),
             bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, "HS", 1, dilation),
         ]
         last_channel = adjust_channels(1024 // reduce_divider)  # C5
     else:
-        raise ValueError("Unsupported model type {}".format(arch))
+        raise ValueError(f"Unsupported model type {arch}")
 
     return inverted_residual_setting, last_channel
 
 
-def _mobilenet_v3_model(
-    arch: str,
+def _mobilenet_v3(
     inverted_residual_setting: List[InvertedResidualConfig],
     last_channel: int,
-    pretrained: bool,
+    weights: Optional[WeightsEnum],
     progress: bool,
-    **kwargs: Any
-):
-    unsupported_attr(progress)
+    **kwargs: Any,
+) -> MobileNetV3:
+    if weights is not None:
+        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))
+
     model = MobileNetV3(inverted_residual_setting, last_channel, **kwargs)
-    if pretrained:
-        check_ckpt_file(f[arch])
-        state_dict = load_state_dict_from_url(f[arch])
-        model.load_state_dict(state_dict)
+
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
+
     return model
 
 
-def mobilenet_v3_large(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> MobileNetV3:
+_COMMON_META = {
+    "min_size": (1, 1),
+    "categories": _IMAGENET_CATEGORIES,
+}
+
+
+class MobileNet_V3_Large_Weights(WeightsEnum):
+    IMAGENET1K_V1 = Weights(
+        url="https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth",
+        transforms=partial(ImageClassification, crop_size=224),
+        meta={
+            **_COMMON_META,
+            "num_params": 5483032,
+            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#mobilenetv3-large--small",
+            "_metrics": {
+                "ImageNet-1K": {
+                    "acc@1": 74.042,
+                    "acc@5": 91.340,
+                }
+            },
+            "_docs": """These weights were trained from scratch by using a simple training recipe.""",
+        },
+    )
+    IMAGENET1K_V2 = Weights(
+        url="https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth",
+        transforms=partial(ImageClassification, crop_size=224, resize_size=232),
+        meta={
+            **_COMMON_META,
+            "num_params": 5483032,
+            "recipe": "https://github.com/pytorch/vision/issues/3995#new-recipe-with-reg-tuning",
+            "_metrics": {
+                "ImageNet-1K": {
+                    "acc@1": 75.274,
+                    "acc@5": 92.566,
+                }
+            },
+            "_docs": """
+                These weights improve marginally upon the results of the original paper by using a modified version of
+                TorchVision's `new training recipe
+                <https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/>`_.
+            """,
+        },
+    )
+    DEFAULT = IMAGENET1K_V2
+
+
+class MobileNet_V3_Small_Weights(WeightsEnum):
+    IMAGENET1K_V1 = Weights(
+        url="https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth",
+        transforms=partial(ImageClassification, crop_size=224),
+        meta={
+            **_COMMON_META,
+            "num_params": 2542856,
+            "recipe": "https://github.com/pytorch/vision/tree/main/references/classification#mobilenetv3-large--small",
+            "_metrics": {
+                "ImageNet-1K": {
+                    "acc@1": 67.668,
+                    "acc@5": 87.402,
+                }
+            },
+            "_docs": """
+                These weights improve upon the results of the original paper by using a simple training recipe.
+            """,
+        },
+    )
+    DEFAULT = IMAGENET1K_V1
+
+
+@handle_legacy_interface(weights=("pretrained", MobileNet_V3_Large_Weights.IMAGENET1K_V1))
+def mobilenet_v3_large(
+    *, weights: Optional[MobileNet_V3_Large_Weights] = None, progress: bool = True, **kwargs: Any
+) -> MobileNetV3:
     """
     Constructs a large MobileNetV3 architecture from
-    `"Searching for MobileNetV3" <https://arxiv.org/abs/1905.02244>`_.
+    `Searching for MobileNetV3 <https://arxiv.org/abs/1905.02244>`__.
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
+        weights (:class:`~torchvision.models.MobileNet_V3_Large_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.MobileNet_V3_Large_Weights` below for
+            more details, and possible values. By default, no pre-trained
+            weights are used.
+        progress (bool, optional): If True, displays a progress bar of the
+            download to stderr. Default is True.
+        **kwargs: parameters passed to the ``torchvision.models.resnet.MobileNetV3``
+            base class. Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv3.py>`_
+            for more details about this class.
+
+    .. autoclass:: torchvision.models.MobileNet_V3_Large_Weights
+        :members:
     """
-    arch = "mobilenet_v3_large"
-    inverted_residual_setting, last_channel = _mobilenet_v3_conf(arch, **kwargs)
-    return _mobilenet_v3_model(arch, inverted_residual_setting, last_channel, pretrained, progress, **kwargs)
+    weights = MobileNet_V3_Large_Weights.verify(weights)
+
+    inverted_residual_setting, last_channel = _mobilenet_v3_conf("mobilenet_v3_large", **kwargs)
+    return _mobilenet_v3(inverted_residual_setting, last_channel, weights, progress, **kwargs)
 
 
-def mobilenet_v3_small(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> MobileNetV3:
+@handle_legacy_interface(weights=("pretrained", MobileNet_V3_Small_Weights.IMAGENET1K_V1))
+def mobilenet_v3_small(
+    *, weights: Optional[MobileNet_V3_Small_Weights] = None, progress: bool = True, **kwargs: Any
+) -> MobileNetV3:
     """
     Constructs a small MobileNetV3 architecture from
-    `"Searching for MobileNetV3" <https://arxiv.org/abs/1905.02244>`_.
+    `Searching for MobileNetV3 <https://arxiv.org/abs/1905.02244>`__.
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
+        weights (:class:`~torchvision.models.MobileNet_V3_Small_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.MobileNet_V3_Small_Weights` below for
+            more details, and possible values. By default, no pre-trained
+            weights are used.
+        progress (bool, optional): If True, displays a progress bar of the
+            download to stderr. Default is True.
+        **kwargs: parameters passed to the ``torchvision.models.resnet.MobileNetV3``
+            base class. Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/mobilenetv3.py>`_
+            for more details about this class.
+
+    .. autoclass:: torchvision.models.MobileNet_V3_Small_Weights
+        :members:
     """
-    arch = "mobilenet_v3_small"
-    inverted_residual_setting, last_channel = _mobilenet_v3_conf(arch, **kwargs)
-    return _mobilenet_v3_model(arch, inverted_residual_setting, last_channel, pretrained, progress, **kwargs)
+    weights = MobileNet_V3_Small_Weights.verify(weights)
+
+    inverted_residual_setting, last_channel = _mobilenet_v3_conf("mobilenet_v3_small", **kwargs)
+    return _mobilenet_v3(inverted_residual_setting, last_channel, weights, progress, **kwargs)
+
+
+# The dictionary below is internal implementation detail and will be removed in v0.15
+from ._utils import _ModelURLs
+
+
+model_urls = _ModelURLs(
+    {
+        "mobilenet_v3_large": MobileNet_V3_Large_Weights.IMAGENET1K_V1.url,
+        "mobilenet_v3_small": MobileNet_V3_Small_Weights.IMAGENET1K_V1.url,
+    }
+)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/resnet.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/video/resnet.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,390 +1,491 @@
-import mindtorch.torch as torch
-from mindtorch.torch import Tensor
+from functools import partial
+from typing import Tuple, Optional, Callable, List, Sequence, Type, Any, Union
+
 import mindtorch.torch.nn as nn
-from mindtorch import unsupported_attr
-from .utils import check_ckpt_file, model_path_name
-from typing import Type, Any, Callable, Union, List, Optional
-from mindtorch.torch.hub import load_state_dict_from_url
-
-
-__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',
-           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',
-           'wide_resnet50_2', 'wide_resnet101_2']
-
-f = {
-    'resnet18': model_path_name + 'resnet18-f37072fd.pth',
-    'resnet34': model_path_name + 'resnet34-b627a593.pth',
-    'resnet50': model_path_name + 'resnet50-0676ba61.pth',
-    'resnet101': model_path_name + 'resnet101-63fe2227.pth',
-    'resnet152': model_path_name + 'resnet152-394f9c45.pth',
-    'resnext50_32x4d': model_path_name + 'resnext50_32x4d-7cdf4587.pth',
-    'resnext101_32x8d': model_path_name + 'resnext101_32x8d-8ba56ff5.pth',
-    'wide_resnet50_2': model_path_name + 'wide_resnet50_2-95faca4d.pth',
-    'wide_resnet101_2': model_path_name + 'wide_resnet101_2-32ee1156.pth',
-}
+from mindtorch.torch import Tensor
 
-def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:
-    """3x3 convolution with padding"""
-    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
-                     padding=dilation, groups=groups, bias=False, dilation=dilation)
+from ...transforms._presets import VideoClassification
+from ...utils import _log_api_usage_once
+from .._api import WeightsEnum, Weights
+from .._meta import _KINETICS400_CATEGORIES
+from .._utils import handle_legacy_interface, _ovewrite_named_param
+
+
+__all__ = [
+    "VideoResNet",
+    "R3D_18_Weights",
+    "MC3_18_Weights",
+    "R2Plus1D_18_Weights",
+    "r3d_18",
+    "mc3_18",
+    "r2plus1d_18",
+]
 
 
-def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:
-    """1x1 convolution"""
-    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)
+class Conv3DSimple(nn.Conv3d):
+    def __init__(
+        self, in_planes: int, out_planes: int, midplanes: Optional[int] = None, stride: int = 1, padding: int = 1
+    ) -> None:
+
+        super().__init__(
+            in_channels=in_planes,
+            out_channels=out_planes,
+            kernel_size=(3, 3, 3),
+            stride=stride,
+            padding=padding,
+            bias=False,
+        )
+
+    @staticmethod
+    def get_downsample_stride(stride: int) -> Tuple[int, int, int]:
+        return stride, stride, stride
+
+
+class Conv2Plus1D(nn.Sequential):
+    def __init__(self, in_planes: int, out_planes: int, midplanes: int, stride: int = 1, padding: int = 1) -> None:
+        super().__init__(
+            nn.Conv3d(
+                in_planes,
+                midplanes,
+                kernel_size=(1, 3, 3),
+                stride=(1, stride, stride),
+                padding=(0, padding, padding),
+                bias=False,
+            ),
+            nn.BatchNorm3d(midplanes),
+            nn.ReLU(inplace=False),
+            nn.Conv3d(
+                midplanes, out_planes, kernel_size=(3, 1, 1), stride=(stride, 1, 1), padding=(padding, 0, 0), bias=False
+            ),
+        )
+
+    @staticmethod
+    def get_downsample_stride(stride: int) -> Tuple[int, int, int]:
+        return stride, stride, stride
+
+
+class Conv3DNoTemporal(nn.Conv3d):
+    def __init__(
+        self, in_planes: int, out_planes: int, midplanes: Optional[int] = None, stride: int = 1, padding: int = 1
+    ) -> None:
+
+        super().__init__(
+            in_channels=in_planes,
+            out_channels=out_planes,
+            kernel_size=(1, 3, 3),
+            stride=(1, stride, stride),
+            padding=(0, padding, padding),
+            bias=False,
+        )
+
+    @staticmethod
+    def get_downsample_stride(stride: int) -> Tuple[int, int, int]:
+        return 1, stride, stride
 
 
 class BasicBlock(nn.Module):
-    expansion: int = 1
+
+    expansion = 1
 
     def __init__(
         self,
         inplanes: int,
         planes: int,
+        conv_builder: Callable[..., nn.Module],
         stride: int = 1,
         downsample: Optional[nn.Module] = None,
-        groups: int = 1,
-        base_width: int = 64,
-        dilation: int = 1,
-        norm_layer: Optional[Callable[..., nn.Module]] = None
     ) -> None:
-        super(BasicBlock, self).__init__()
-        if norm_layer is None:
-            norm_layer = nn.BatchNorm2d
-        if groups != 1 or base_width != 64:
-            raise ValueError('BasicBlock only supports groups=1 and base_width=64')
-        if dilation > 1:
-            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
-        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
-        self.conv1 = conv3x3(inplanes, planes, stride)
-        self.bn1 = norm_layer(planes)
+        midplanes = (inplanes * planes * 3 * 3 * 3) // (inplanes * 3 * 3 + 3 * planes)
+
+        super().__init__()
+        self.conv1 = nn.Sequential(
+            conv_builder(inplanes, planes, midplanes, stride), nn.BatchNorm3d(planes), nn.ReLU(inplace=False)
+        )
+        self.conv2 = nn.Sequential(conv_builder(planes, planes, midplanes), nn.BatchNorm3d(planes))
         self.relu = nn.ReLU(inplace=False)
-        self.conv2 = conv3x3(planes, planes)
-        self.bn2 = norm_layer(planes)
         self.downsample = downsample
         self.stride = stride
 
     def forward(self, x: Tensor) -> Tensor:
-        identity = x
+        residual = x
 
         out = self.conv1(x)
-        out = self.bn1(out)
-        out = self.relu(out)
-
         out = self.conv2(out)
-        out = self.bn2(out)
-
         if self.downsample is not None:
-            identity = self.downsample(x)
+            residual = self.downsample(x)
 
-        out += identity
+        out += residual
         out = self.relu(out)
 
         return out
 
 
 class Bottleneck(nn.Module):
-    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
-    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
-    # according to "Deep residual learning for image recognition"https://arxiv.org/abs/1512.03385.
-    # This variant is also known as ResNet V1.5 and improves accuracy according to
-    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.
-
-    expansion: int = 4
+    expansion = 4
 
     def __init__(
         self,
         inplanes: int,
         planes: int,
+        conv_builder: Callable[..., nn.Module],
         stride: int = 1,
         downsample: Optional[nn.Module] = None,
-        groups: int = 1,
-        base_width: int = 64,
-        dilation: int = 1,
-        norm_layer: Optional[Callable[..., nn.Module]] = None
     ) -> None:
-        super(Bottleneck, self).__init__()
-        if norm_layer is None:
-            norm_layer = nn.BatchNorm2d
-        width = int(planes * (base_width / 64.)) * groups
-        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
-        self.conv1 = conv1x1(inplanes, width)
-        self.bn1 = norm_layer(width)
-        self.conv2 = conv3x3(width, width, stride, groups, dilation)
-        self.bn2 = norm_layer(width)
-        self.conv3 = conv1x1(width, planes * self.expansion)
-        self.bn3 = norm_layer(planes * self.expansion)
+
+        super().__init__()
+        midplanes = (inplanes * planes * 3 * 3 * 3) // (inplanes * 3 * 3 + 3 * planes)
+
+        # 1x1x1
+        self.conv1 = nn.Sequential(
+            nn.Conv3d(inplanes, planes, kernel_size=1, bias=False), nn.BatchNorm3d(planes), nn.ReLU(inplace=False)
+        )
+        # Second kernel
+        self.conv2 = nn.Sequential(
+            conv_builder(planes, planes, midplanes, stride), nn.BatchNorm3d(planes), nn.ReLU(inplace=False)
+        )
+
+        # 1x1x1
+        self.conv3 = nn.Sequential(
+            nn.Conv3d(planes, planes * self.expansion, kernel_size=1, bias=False),
+            nn.BatchNorm3d(planes * self.expansion),
+        )
         self.relu = nn.ReLU(inplace=False)
         self.downsample = downsample
         self.stride = stride
 
     def forward(self, x: Tensor) -> Tensor:
-        identity = x
+        residual = x
 
         out = self.conv1(x)
-        out = self.bn1(out)
-        out = self.relu(out)
-
         out = self.conv2(out)
-        out = self.bn2(out)
-        out = self.relu(out)
-
         out = self.conv3(out)
-        out = self.bn3(out)
 
         if self.downsample is not None:
-            identity = self.downsample(x)
+            residual = self.downsample(x)
 
-        out += identity
+        out += residual
         out = self.relu(out)
 
         return out
 
 
-class ResNet(nn.Module):
+class BasicStem(nn.Sequential):
+    """The default conv-batchnorm-relu stem"""
+
+    def __init__(self) -> None:
+        super().__init__(
+            nn.Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False),
+            nn.BatchNorm3d(64),
+            nn.ReLU(inplace=False),
+        )
+
+
+class R2Plus1dStem(nn.Sequential):
+    """R(2+1)D stem is different than the default one as it uses separated 3D convolution"""
+
+    def __init__(self) -> None:
+        super().__init__(
+            nn.Conv3d(3, 45, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False),
+            nn.BatchNorm3d(45),
+            nn.ReLU(inplace=False),
+            nn.Conv3d(45, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False),
+            nn.BatchNorm3d(64),
+            nn.ReLU(inplace=False),
+        )
+
 
+class VideoResNet(nn.Module):
     def __init__(
         self,
         block: Type[Union[BasicBlock, Bottleneck]],
+        conv_makers: Sequence[Type[Union[Conv3DSimple, Conv3DNoTemporal, Conv2Plus1D]]],
         layers: List[int],
-        num_classes: int = 1000,
+        stem: Callable[..., nn.Module],
+        num_classes: int = 400,
         zero_init_residual: bool = False,
-        groups: int = 1,
-        width_per_group: int = 64,
-        replace_stride_with_dilation: Optional[List[bool]] = None,
-        norm_layer: Optional[Callable[..., nn.Module]] = None
     ) -> None:
-        super(ResNet, self).__init__()
-        if norm_layer is None:
-            norm_layer = nn.BatchNorm2d
-        self._norm_layer = norm_layer
+        """Generic resnet video generator.
 
+        Args:
+            block (Type[Union[BasicBlock, Bottleneck]]): resnet building block
+            conv_makers (List[Type[Union[Conv3DSimple, Conv3DNoTemporal, Conv2Plus1D]]]): generator
+                function for each layer
+            layers (List[int]): number of blocks per layer
+            stem (Callable[..., nn.Module]): module specifying the ResNet stem.
+            num_classes (int, optional): Dimension of the final FC layer. Defaults to 400.
+            zero_init_residual (bool, optional): Zero init bottleneck residual BN. Defaults to False.
+        """
+        super().__init__()
+        _log_api_usage_once(self)
         self.inplanes = 64
-        self.dilation = 1
-        if replace_stride_with_dilation is None:
-            # each element in the tuple indicates if we should replace
-            # the 2x2 stride with a dilated convolution instead
-            replace_stride_with_dilation = [False, False, False]
-        if len(replace_stride_with_dilation) != 3:
-            raise ValueError("replace_stride_with_dilation should be None "
-                             "or a 3-element tuple, got {}".format(replace_stride_with_dilation))
-        self.groups = groups
-        self.base_width = width_per_group
-        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,
-                               bias=False)
-        self.bn1 = norm_layer(self.inplanes)
-        self.relu = nn.ReLU(inplace=False)
-        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
-        self.layer1 = self._make_layer(block, 64, layers[0])
-        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,
-                                       dilate=replace_stride_with_dilation[0])
-        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,
-                                       dilate=replace_stride_with_dilation[1])
-        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,
-                                       dilate=replace_stride_with_dilation[2])
-        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
+
+        self.stem = stem()
+
+        self.layer1 = self._make_layer(block, conv_makers[0], 64, layers[0], stride=1)
+        self.layer2 = self._make_layer(block, conv_makers[1], 128, layers[1], stride=2)
+        self.layer3 = self._make_layer(block, conv_makers[2], 256, layers[2], stride=2)
+        self.layer4 = self._make_layer(block, conv_makers[3], 512, layers[3], stride=2)
+
+        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))
         self.fc = nn.Linear(512 * block.expansion, num_classes)
 
+        # init weights
         for m in self.modules():
-            if isinstance(m, nn.Conv2d):
-                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
-            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
+            if isinstance(m, nn.Conv3d):
+                nn.init.kaiming_normal_(m.weight, mode="fan_out", nonlinearity="relu")
+                if m.bias is not None:
+                    nn.init.constant_(m.bias, 0)
+            elif isinstance(m, nn.BatchNorm3d):
                 nn.init.constant_(m.weight, 1)
                 nn.init.constant_(m.bias, 0)
+            elif isinstance(m, nn.Linear):
+                nn.init.normal_(m.weight, 0, 0.01)
+                nn.init.constant_(m.bias, 0)
 
-        # Zero-initialize the last BN in each residual branch,
-        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
-        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
         if zero_init_residual:
             for m in self.modules():
                 if isinstance(m, Bottleneck):
-                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
-                elif isinstance(m, BasicBlock):
-                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]
-
-    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,
-                    stride: int = 1, dilate: bool = False) -> nn.Sequential:
-        norm_layer = self._norm_layer
-        downsample = None
-        previous_dilation = self.dilation
-        if dilate:
-            self.dilation *= stride
-            stride = 1
-        if stride != 1 or self.inplanes != planes * block.expansion:
-            downsample = nn.Sequential(
-                conv1x1(self.inplanes, planes * block.expansion, stride),
-                norm_layer(planes * block.expansion),
-            )
-
-        layers = []
-        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,
-                            self.base_width, previous_dilation, norm_layer))
-        self.inplanes = planes * block.expansion
-        for _ in range(1, blocks):
-            layers.append(block(self.inplanes, planes, groups=self.groups,
-                                base_width=self.base_width, dilation=self.dilation,
-                                norm_layer=norm_layer))
+                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[union-attr, arg-type]
 
-        return nn.Sequential(*layers)
-
-    def _forward_impl(self, x: Tensor) -> Tensor:
-        # See note [TorchScript super()]
-        x = self.conv1(x)
-        x = self.bn1(x)
-        x = self.relu(x)
-        x = self.maxpool(x)
+    def forward(self, x: Tensor) -> Tensor:
+        x = self.stem(x)
 
         x = self.layer1(x)
         x = self.layer2(x)
         x = self.layer3(x)
         x = self.layer4(x)
 
         x = self.avgpool(x)
-        x = torch.flatten(x, 1)
+        # Flatten the layer to fc
+        x = x.flatten(1)
         x = self.fc(x)
 
         return x
 
-    def forward(self, x: Tensor) -> Tensor:
-        return self._forward_impl(x)
+    def _make_layer(
+        self,
+        block: Type[Union[BasicBlock, Bottleneck]],
+        conv_builder: Type[Union[Conv3DSimple, Conv3DNoTemporal, Conv2Plus1D]],
+        planes: int,
+        blocks: int,
+        stride: int = 1,
+    ) -> nn.Sequential:
+        downsample = None
 
+        if stride != 1 or self.inplanes != planes * block.expansion:
+            ds_stride = conv_builder.get_downsample_stride(stride)
+            downsample = nn.Sequential(
+                nn.Conv3d(self.inplanes, planes * block.expansion, kernel_size=1, stride=ds_stride, bias=False),
+                nn.BatchNorm3d(planes * block.expansion),
+            )
+        layers = []
+        layers.append(block(self.inplanes, planes, conv_builder, stride, downsample))
 
-def _resnet(
-    arch: str,
+        self.inplanes = planes * block.expansion
+        for i in range(1, blocks):
+            layers.append(block(self.inplanes, planes, conv_builder))
+
+        return nn.Sequential(*layers)
+
+
+def _video_resnet(
     block: Type[Union[BasicBlock, Bottleneck]],
+    conv_makers: Sequence[Type[Union[Conv3DSimple, Conv3DNoTemporal, Conv2Plus1D]]],
     layers: List[int],
-    pretrained: bool,
+    stem: Callable[..., nn.Module],
+    weights: Optional[WeightsEnum],
     progress: bool,
-    **kwargs: Any
-) -> ResNet:
-    unsupported_attr(progress)
-    model = ResNet(block, layers, **kwargs)
-    if pretrained:
-        check_ckpt_file(f[arch])
-        state_dict = load_state_dict_from_url(f[arch])
-        model.load_state_dict(state_dict)
-    return model
+    **kwargs: Any,
+) -> VideoResNet:
+    if weights is not None:
+        _ovewrite_named_param(kwargs, "num_classes", len(weights.meta["categories"]))
 
+    model = VideoResNet(block, conv_makers, layers, stem, **kwargs)
 
-def resnet18(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""ResNet-18 model from
-    `"Deep Residual Learning for Image Recognition" <https://arxiv.org/pdf/1512.03385.pdf>`_.
-
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
-    """
-    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,
-                   **kwargs)
+    if weights is not None:
+        model.load_state_dict(weights.get_state_dict(progress=progress))
 
+    return model
 
-def resnet34(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""ResNet-34 model from
-    `"Deep Residual Learning for Image Recognition" <https://arxiv.org/pdf/1512.03385.pdf>`_.
-
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
-    """
-    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,
-                   **kwargs)
 
+_COMMON_META = {
+    "min_size": (1, 1),
+    "categories": _KINETICS400_CATEGORIES,
+    "recipe": "https://github.com/pytorch/vision/tree/main/references/video_classification",
+    "_docs": """These weights reproduce closely the accuracy of the paper for 16-frame clip inputs.""",
+}
 
-def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""ResNet-50 model from
-    `"Deep Residual Learning for Image Recognition" <https://arxiv.org/pdf/1512.03385.pdf>`_.
 
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
-    """
-    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,
-                   **kwargs)
+class R3D_18_Weights(WeightsEnum):
+    KINETICS400_V1 = Weights(
+        url="https://download.pytorch.org/models/r3d_18-b3b3357e.pth",
+        transforms=partial(VideoClassification, crop_size=(112, 112), resize_size=(128, 171)),
+        meta={
+            **_COMMON_META,
+            "num_params": 33371472,
+            "_metrics": {
+                "Kinetics-400": {
+                    "acc@1": 52.75,
+                    "acc@5": 75.45,
+                }
+            },
+        },
+    )
+    DEFAULT = KINETICS400_V1
+
+
+class MC3_18_Weights(WeightsEnum):
+    KINETICS400_V1 = Weights(
+        url="https://download.pytorch.org/models/mc3_18-a90a0ba3.pth",
+        transforms=partial(VideoClassification, crop_size=(112, 112), resize_size=(128, 171)),
+        meta={
+            **_COMMON_META,
+            "num_params": 11695440,
+            "_metrics": {
+                "Kinetics-400": {
+                    "acc@1": 53.90,
+                    "acc@5": 76.29,
+                }
+            },
+        },
+    )
+    DEFAULT = KINETICS400_V1
+
+
+class R2Plus1D_18_Weights(WeightsEnum):
+    KINETICS400_V1 = Weights(
+        url="https://download.pytorch.org/models/r2plus1d_18-91a641e6.pth",
+        transforms=partial(VideoClassification, crop_size=(112, 112), resize_size=(128, 171)),
+        meta={
+            **_COMMON_META,
+            "num_params": 31505325,
+            "_metrics": {
+                "Kinetics-400": {
+                    "acc@1": 57.50,
+                    "acc@5": 78.81,
+                }
+            },
+        },
+    )
+    DEFAULT = KINETICS400_V1
+
+
+@handle_legacy_interface(weights=("pretrained", R3D_18_Weights.KINETICS400_V1))
+def r3d_18(*, weights: Optional[R3D_18_Weights] = None, progress: bool = True, **kwargs: Any) -> VideoResNet:
+    """Construct 18 layer Resnet3D model.
 
+    .. betastatus:: video module
 
-def resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""ResNet-101 model from
-    `"Deep Residual Learning for Image Recognition" <https://arxiv.org/pdf/1512.03385.pdf>`_.
+    Reference: `A Closer Look at Spatiotemporal Convolutions for Action Recognition <https://arxiv.org/abs/1711.11248>`__.
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
-    """
-    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,
-                   **kwargs)
-
-
-def resnet152(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""ResNet-152 model from
-    `"Deep Residual Learning for Image Recognition" <https://arxiv.org/pdf/1512.03385.pdf>`_.
+        weights (:class:`~torchvision.models.video.R3D_18_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.video.R3D_18_Weights`
+            below for more details, and possible values. By default, no
+            pre-trained weights are used.
+        progress (bool): If True, displays a progress bar of the download to stderr. Default is True.
+        **kwargs: parameters passed to the ``torchvision.models.video.resnet.VideoResNet`` base class.
+            Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/video/resnet.py>`_
+            for more details about this class.
 
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
+    .. autoclass:: torchvision.models.video.R3D_18_Weights
+        :members:
     """
-    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,
-                   **kwargs)
-
+    weights = R3D_18_Weights.verify(weights)
 
-def resnext50_32x4d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""ResNeXt-50 32x4d model from
-    `"Aggregated Residual Transformation for Deep Neural Networks" <https://arxiv.org/pdf/1611.05431.pdf>`_.
-
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
-    """
-    kwargs['groups'] = 32
-    kwargs['width_per_group'] = 4
-    return _resnet('resnext50_32x4d', Bottleneck, [3, 4, 6, 3],
-                   pretrained, progress, **kwargs)
+    return _video_resnet(
+        BasicBlock,
+        [Conv3DSimple] * 4,
+        [2, 2, 2, 2],
+        BasicStem,
+        weights,
+        progress,
+        **kwargs,
+    )
+
+
+@handle_legacy_interface(weights=("pretrained", MC3_18_Weights.KINETICS400_V1))
+def mc3_18(*, weights: Optional[MC3_18_Weights] = None, progress: bool = True, **kwargs: Any) -> VideoResNet:
+    """Construct 18 layer Mixed Convolution network as in
 
+    .. betastatus:: video module
 
-def resnext101_32x8d(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""ResNeXt-101 32x8d model from
-    `"Aggregated Residual Transformation for Deep Neural Networks" <https://arxiv.org/pdf/1611.05431.pdf>`_.
+    Reference: `A Closer Look at Spatiotemporal Convolutions for Action Recognition <https://arxiv.org/abs/1711.11248>`__.
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
-    """
-    kwargs['groups'] = 32
-    kwargs['width_per_group'] = 8
-    return _resnet('resnext101_32x8d', Bottleneck, [3, 4, 23, 3],
-                   pretrained, progress, **kwargs)
-
+        weights (:class:`~torchvision.models.video.MC3_18_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.video.MC3_18_Weights`
+            below for more details, and possible values. By default, no
+            pre-trained weights are used.
+        progress (bool): If True, displays a progress bar of the download to stderr. Default is True.
+        **kwargs: parameters passed to the ``torchvision.models.video.resnet.VideoResNet`` base class.
+            Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/video/resnet.py>`_
+            for more details about this class.
 
-def wide_resnet50_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""Wide ResNet-50-2 model from
-    `"Wide Residual Networks" <https://arxiv.org/pdf/1605.07146.pdf>`_.
-
-    The model is the same as ResNet except for the bottleneck number of channels
-    which is twice larger in every block. The number of channels in outer 1x1
-    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048
-    channels, and in Wide ResNet-50-2 has 2048-1024-2048.
-
-    Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
+    .. autoclass:: torchvision.models.video.MC3_18_Weights
+        :members:
     """
-    kwargs['width_per_group'] = 64 * 2
-    return _resnet('wide_resnet50_2', Bottleneck, [3, 4, 6, 3],
-                   pretrained, progress, **kwargs)
+    weights = MC3_18_Weights.verify(weights)
+
+    return _video_resnet(
+        BasicBlock,
+        [Conv3DSimple] + [Conv3DNoTemporal] * 3,  # type: ignore[list-item]
+        [2, 2, 2, 2],
+        BasicStem,
+        weights,
+        progress,
+        **kwargs,
+    )
+
+
+@handle_legacy_interface(weights=("pretrained", R2Plus1D_18_Weights.KINETICS400_V1))
+def r2plus1d_18(*, weights: Optional[R2Plus1D_18_Weights] = None, progress: bool = True, **kwargs: Any) -> VideoResNet:
+    """Construct 18 layer deep R(2+1)D network as in
 
+    .. betastatus:: video module
 
-def wide_resnet101_2(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
-    r"""Wide ResNet-101-2 model from
-    `"Wide Residual Networks" <https://arxiv.org/pdf/1605.07146.pdf>`_.
-
-    The model is the same as ResNet except for the bottleneck number of channels
-    which is twice larger in every block. The number of channels in outer 1x1
-    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048
-    channels, and in Wide ResNet-50-2 has 2048-1024-2048.
+    Reference: `A Closer Look at Spatiotemporal Convolutions for Action Recognition <https://arxiv.org/abs/1711.11248>`__.
 
     Args:
-        pretrained (bool): If True, returns a model pre-trained on ImageNet
-        progress (bool): If True, displays a progress bar of the download to stderr
+        weights (:class:`~torchvision.models.video.R2Plus1D_18_Weights`, optional): The
+            pretrained weights to use. See
+            :class:`~torchvision.models.video.R2Plus1D_18_Weights`
+            below for more details, and possible values. By default, no
+            pre-trained weights are used.
+        progress (bool): If True, displays a progress bar of the download to stderr. Default is True.
+        **kwargs: parameters passed to the ``torchvision.models.video.resnet.VideoResNet`` base class.
+            Please refer to the `source code
+            <https://github.com/pytorch/vision/blob/main/torchvision/models/video/resnet.py>`_
+            for more details about this class.
+
+    .. autoclass:: torchvision.models.video.R2Plus1D_18_Weights
+        :members:
     """
-    kwargs['width_per_group'] = 64 * 2
-    return _resnet('wide_resnet101_2', Bottleneck, [3, 4, 23, 3],
-                   pretrained, progress, **kwargs)
+    weights = R2Plus1D_18_Weights.verify(weights)
+
+    return _video_resnet(
+        BasicBlock,
+        [Conv2Plus1D] * 4,
+        [2, 2, 2, 2],
+        R2Plus1dStem,
+        weights,
+        progress,
+        **kwargs,
+    )
+
+
+# The dictionary below is internal implementation detail and will be removed in v0.15
+from .._utils import _ModelURLs
+
+
+model_urls = _ModelURLs(
+    {
+        "r3d_18": R3D_18_Weights.KINETICS400_V1.url,
+        "mc3_18": MC3_18_Weights.KINETICS400_V1.url,
+        "r2plus1d_18": R2Plus1D_18_Weights.KINETICS400_V1.url,
+    }
+)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/models/segmentation/_utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/models/segmentation/_utils.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,33 +1,34 @@
 from collections import OrderedDict
+from typing import Optional, Dict
 
-from mindtorch.torch import nn
+from mindtorch.torch import nn, Tensor
 from mindtorch.torch.nn import functional as F
 
 
 class _SimpleSegmentationModel(nn.Module):
-    __constants__ = ['aux_classifier']
+    __constants__ = ["aux_classifier"]
 
-    def __init__(self, backbone, classifier, aux_classifier=None):
-        super(_SimpleSegmentationModel, self).__init__()
+    def __init__(self, backbone: nn.Module, classifier: nn.Module, aux_classifier: Optional[nn.Module] = None) -> None:
+        super().__init__()
         self.backbone = backbone
         self.classifier = classifier
         self.aux_classifier = aux_classifier
 
-    def forward(self, x):
+    def forward(self, x: Tensor) -> Dict[str, Tensor]:
         input_shape = x.shape[-2:]
         # contract: features is a dict of tensors
         features = self.backbone(x)
 
         result = OrderedDict()
         x = features["out"]
         x = self.classifier(x)
-        x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)
+        x = F.interpolate(x, size=input_shape, mode="bilinear", align_corners=False)
         result["out"] = x
 
         if self.aux_classifier is not None:
             x = features["aux"]
             x = self.aux_classifier(x)
-            x = F.interpolate(x, size=input_shape, mode='bilinear', align_corners=False)
+            x = F.interpolate(x, size=input_shape, mode="bilinear", align_corners=False)
             result["aux"] = x
 
         return result
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/__init__.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/__init__.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/_box_convert.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/_box_convert.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/_utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/_utils.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/boxes.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/boxes.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/ciou_loss.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/ciou_loss.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/deform_conv.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/deform_conv.py`

 * *Files 3% similar despite different names*

```diff
@@ -62,18 +62,14 @@
     # if not torch.jit.is_scripting() and not torch.jit.is_tracing():
     #     _log_api_usage_once(deform_conv2d)
     # _assert_has_ops()
     out_channels = weight.shape[0]
 
     # use_mask = mask is not None
 
-    if mask is None:
-        # mask = torch.zeros((input.shape[0], 0), device=input.device, dtype=input.dtype)
-        raise NotImplementedError("Only Deformable ConvNets v2 supported.")
-
     # if bias is None:
     #     bias = torch.zeros(out_channels, device=input.device, dtype=input.dtype)
 
     stride_h, stride_w = _pair(stride)
     pad_h, pad_w = _pair(padding)
     dil_h, dil_w = _pair(dilation)
     weights_h, weights_w = weight.shape[-2:]
@@ -97,16 +93,19 @@
     input = cast_to_ms_tensor(input)
     offset = cast_to_ms_tensor(offset)
     weight = cast_to_ms_tensor(weight)
     mask = cast_to_ms_tensor(mask)
     offset = offset.reshape((batch, n_offset_grps, weights_h, weights_w, 
             2, out_height, out_width)).transpose((0, 4, 1, 2, 3, 5, 6))
     offset_x, offset_y = ms.ops.split(offset, offset.shape[1] // 2, axis=1)
-    mask = mask.reshape((batch, n_offset_grps, weights_h, weights_w, 
-            1, out_height, out_width)).transpose((0, 4, 1, 2, 3, 5, 6))
+    if mask is None:
+        mask = ms.ops.ones((batch, 1, n_offset_grps, weights_h, weights_w, out_height, out_width))
+    else:
+        mask = mask.reshape((batch, n_offset_grps, weights_h, weights_w,
+                             1, out_height, out_width)).transpose((0, 4, 1, 2, 3, 5, 6))
     offset = ms.ops.cat((offset_y, offset_x, mask), axis=1).reshape((batch, 3 * n_offset_grps *
             weights_h * weights_w, out_height, out_width))
     if bias is not None:
         bias = cast_to_ms_tensor(bias)
 
     output = ms.ops.deformable_conv2d(input, weight, offset, (weights_h, weights_w), (1, 1, stride_h, stride_w),
                                       (pad_h, pad_h, pad_w, pad_w), bias, (1, 1, dil_h, dil_w), n_weight_grps, n_offset_grps)
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/diou_loss.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/diou_loss.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/drop_block.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/drop_block.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/feature_pyramid_network.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/feature_pyramid_network.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/focal_loss.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/focal_loss.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/giou_loss.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/giou_loss.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/misc.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/misc.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/poolers.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/poolers.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/ps_roi_align.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/ps_roi_align.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/ps_roi_pool.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/ps_roi_pool.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/roi_align.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/roi_align.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/roi_pool.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/roi_pool.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/ops/stochastic_depth.py` & `mindtorch-0.3.0/mindtorch/torchvision/ops/stochastic_depth.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/_functional_video.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/_functional_video.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/_pil_constants.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/_pil_constants.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/_presets.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/_presets.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/_transforms_video.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/_transforms_video.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/autoaugment.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/autoaugment.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/functional.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/functional.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/functional_pil.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/functional_pil.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/functional_tensor.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/functional_tensor.py`

 * *Files identical despite different names*

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/transforms/transforms.py` & `mindtorch-0.3.0/mindtorch/torchvision/transforms/transforms.py`

 * *Files 0% similar despite different names*

```diff
@@ -116,15 +116,15 @@
             else:
                 img = t(img)
 
         if _is_numpy(img) and _is_numpy_image(img):
             img = img.transpose((2, 0, 1))
 
         if return_tensor:
-            img = torch.tensor(img)
+            img = torch.from_numpy(img)
         return img
 
     def __repr__(self) -> str:
         format_string = self.__class__.__name__ + "("
         for t in self.transforms:
             format_string += "\n"
             format_string += f"    {t}"
```

### Comparing `mindtorch-0.2.1/mindtorch/torchvision/utils.py` & `mindtorch-0.3.0/mindtorch/torchvision/utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 import math
 import pathlib
 import warnings
-from typing import BinaryIO, List, Optional, Tuple, Union
+from typing import Any, BinaryIO, List, Optional, Tuple, Union
 
 import numpy as np
 import mindtorch.torch as torch
 from PIL import Image, ImageColor, ImageDraw, ImageFont
 
 __all__ = [
     "make_grid",
@@ -518,7 +518,35 @@
 #     return [(i * palette) % 255 for i in range(num_objects)]
 
 def _generate_color_palette(num_objects: int):
     a = 2 ** 25 - 1
     b = 2 ** 15 - 1
     c = 2 ** 21 - 1
     return [((i * a) % 255, (i * b) % 255, (i * c) % 255) for i in range(num_objects)]
+
+
+def _log_api_usage_once(obj: Any) -> None:
+
+    """
+    Logs API usage(module and name) within an organization.
+    In a large ecosystem, it's often useful to track the PyTorch and
+    TorchVision APIs usage. This API provides the similar functionality to the
+    logging module in the Python stdlib. It can be used for debugging purpose
+    to log which methods are used and by default it is inactive, unless the user
+    manually subscribes a logger via the `SetAPIUsageLogger method <https://github.com/pytorch/pytorch/blob/eb3b9fe719b21fae13c7a7cf3253f970290a573e/c10/util/Logging.cpp#L114>`_.
+    Please note it is triggered only once for the same API call within a process.
+    It does not collect any data from open-source users since it is no-op by default.
+    For more information, please refer to
+    * PyTorch note: https://pytorch.org/docs/stable/notes/large_scale_deployments.html#api-usage-logging;
+    * Logging policy: https://github.com/pytorch/vision/issues/5052;
+
+    Args:
+        obj (class instance or method): an object to extract info from.
+    """
+    if not obj.__module__.startswith("torchvision"):
+        return
+    # name = obj.__class__.__name__
+    # if isinstance(obj, FunctionType):
+    #     name = obj.__name__
+    # torch._C._log_api_usage_once(f"{obj.__module__}.{name}")
+    else:
+        raise NotImplementedError
```

### Comparing `mindtorch-0.2.1/mindtorch/utils.py` & `mindtorch-0.3.0/mindtorch/utils.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 #!/usr/bin/env python
 # -*- coding: utf-8 -*-
 import collections
+import importlib
 # from functools import lru_cache
 import mindspore as ms
 from mindspore import context
 from mindspore.ops.primitive import _primexpr
 
 
 _GLOBAL_LRU_CACHE_SIZE = 4
@@ -200,7 +201,31 @@
         type1 = _numpy_type_dict.get(type1)
     if type2 in numpy_dtype:
         type2 = _numpy_type_dict.get(type2)
 
     type1_index = _promoteTypesLookup[0].index(type1)
     type2_index = _promoteTypesLookup[0].index(type2)
     return _promoteTypesLookup[type1_index][type2_index]
+
+
+def get_empty_tensor(shape=(-1,), dtype=ms.float32):
+    x = ms.Tensor([1], dtype)
+    output = ms.ops.slice(x, (0,), (0,))
+    return output.reshape(shape)
+
+def try_import(module_name):
+    """Try importing a module, with an informative error message on failure."""
+    install_name = module_name
+
+    if module_name.find('.') > -1:
+        install_name = module_name.split('.')[0]
+
+    try:
+        mod = importlib.import_module(module_name)
+        return mod
+    except (Exception,) as error:
+        err_msg = (
+            "Failed importing {}. This likely means that some torch modules "
+            "require additional dependencies that have to be "
+            "manually installed (usually with `pip install {}`). ").format(
+                module_name, install_name)
+        raise ImportError(err_msg) from error
```

### Comparing `mindtorch-0.2.1/mindtorch.egg-info/PKG-INFO` & `mindtorch-0.3.0/mindtorch.egg-info/PKG-INFO`

 * *Files 23% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: mindtorch
-Version: 0.2.1
+Version: 0.3.0
 Summary: MindTorch is a toolkit for support the PyTorch model running on Ascend.
 Home-page: https://openi.pcl.ac.cn/OpenI/MSAdapter 
 Author: Peng Cheng Lab, HUAWEI
 Author-email: pcl.openi@pcl.ac.cn
 License: Apache 2.0
 Classifier: Development Status :: 3 - Alpha
 Classifier: Programming Language :: Python :: 3 :: Only
@@ -16,14 +16,20 @@
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Software Development :: Libraries
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: Operating System :: OS Independent
 Description-Content-Type: text/plain
 License-File: LICENSE
+Requires-Dist: ml_dtypes==0.2.0
+Requires-Dist: numpy<1.24.0,>=1.21.0
+Requires-Dist: numba==0.56.4
+Requires-Dist: scikit-learn==1.0.2
+Requires-Dist: librosa==0.10.1
+Requires-Dist: tqdm==4.65.0
 
 Introduction
 =============
 MindTorch is MindSpore tool for adapting the PyTorch interface, which is designed to make PyTorch code perform efficiently on Ascend without changing the habits of the original PyTorch users.
 
 |MindTorch-architecture|
 
@@ -44,76 +50,60 @@
 
 .. code:: bash
 
     pip3 install git+https://openi.pcl.ac.cn/OpenI/MSAdapter.git
 
 User guide
 ===========
-For data processing and model building, MindTorch can be used in the same way as PyTorch, while the model training part of the code needs to be customized, as shown in the following example.
+You can start using it straight away, for example:
 
-1. Data processing (only modify the import package)
+Import mstorch_enable in the main program of the code file to adapt PyTorch code to MindTorch
 
 .. code:: python
 
-    from mindtorch.torch.utils.data import DataLoader
-    from mindtorch.torchvision import datasets, transforms
+    from mindtorch.tools import mstorch_enable   # It needs to be used before importing torch related modules in the main program
 
-    transform = transforms.Compose([transforms.Resize((224, 224), interpolation=InterpolationMode.BICUBIC),
-                                    transforms.ToTensor(),
-                                    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.2435, 0.2616])
-                                   ])
-    train_images = datasets.CIFAR10('./', train=True, download=True, transform=transform)
-    train_data = DataLoader(train_images, batch_size=128, shuffle=True, num_workers=2, drop_last=True)
+    import torch
+    import torch.nn as nn
+    import torch.nn.functional as F
+    from torchvision import datasets, transforms
 
-2. Model construction (modify import package only)
-
-.. code:: python
-
-    from mindtorch.torch.nn import Module, Linear, Flatten
-
-    class MLP(Module):
+    class LeNet(nn.Module):
         def __init__(self):
-            super(MLP, self).__init__()
-            self.flatten = Flatten()
-            self.line1 = Linear(in_features=1024, out_features=64)
-            self.line2 = Linear(in_features=64, out_features=128, bias=False)
-            self.line3 = Linear(in_features=128, out_features=10)
-
-        def forward(self, inputs):
-            x = self.flatten(inputs)
-            x = self.line1(x)
-            x = self.line2(x)
-            x = self.line3(x)
+            super(LeNet, self).__init__()
+            self.conv1 = nn.Conv2d(3, 16, 5)
+            self.pool1 = nn.MaxPool2d(2, 2)
+            self.conv2 = nn.Conv2d(16, 32, 5)
+            self.pool2 = nn.MaxPool2d(2, 2)
+            self.fc1 = nn.Linear(32*5*5, 120)
+            self.fc2 = nn.Linear(120, 84)
+            self.fc3 = nn.Linear(84, 10)
+
+        def forward(self, x):
+            x = F.relu(self.conv1(x))
+            x = self.pool1(x)
+            x = F.relu(self.conv2(x))
+            x = self.pool2(x)
+            x = x.view(-1, 32*5*5)
+            x = F.relu(self.fc1(x))
+            x = F.relu(self.fc2(x))
+            x = self.fc3(x)
             return x
 
-3.Model training (custom training)
+    criterion = nn.CrossEntropyLoss()
 
-.. code:: python
+    transform = transforms.Compose(
+        [transforms.ToTensor(),
+         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
 
-    import mindtorch.torch as torch
-    import mindtorch.torch.nn as nn
-    import mindspore as ms
-
-    net = MLP()
-    net.train()
-    epochs = 500
-    criterion = nn.CrossEntropyLoss()
-    optimizer = ms.nn.SGD(net.trainable_params(), learning_rate=0.01, momentum=0.9, weight_decay=0.0005)
+    train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
+    train_data = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2, drop_last=True)
 
-    # Define the training process
-    loss_net = ms.nn.WithLossCell(net, criterion)
-    train_net = ms.nn.TrainOneStepCell(loss_net, optimizer)
-
-    for i in range(epochs):
-        for X, y in train_data:
-            res = train_net(X, y)
-            print("epoch:{}, loss:{:.6f}".format(i, res.asnumpy()))
-    # Save model
-    ms.save_checkpoint(net, "save_path.ckpt")
+After importing mstorch_enable, the imported module with the same name of torch will be automatically converted to the corresponding module of mindtorch when the code is executed (currently supports automatic conversion of torch, torchvision, torchaudio related modules), and then execute the .py file of the main program. For more information on how to use it, please refer to User's Guide.
 
 
 License
 =======
 
 MindTorch is released under the Apache 2.0 license.
 
-.. |MindTorch-architecture| image:: https://openi.pcl.ac.cn/laich/pose_data/raw/branch/master/MSA_F.png
+.. |MindTorch-architecture| image:: https://openi.pcl.ac.cn/OpenI/MSAdapter/raw/branch/master/doc/readthedocs/source_zh/docs/pic/MSA_F.png
```

### Comparing `mindtorch-0.2.1/setup.py` & `mindtorch-0.3.0/setup.py`

 * *Files 0% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 # -*- coding: utf-8 -*-
 
 from __future__ import absolute_import
 from setuptools import setup, find_packages
 import os, codecs, subprocess
 
 MAJOR = 0
-MINOR = 2
-PATCH = 1
+MINOR = 3
+PATCH = 0
 PRE_RELEASE = ''
 # Use the following formatting: (major, minor, patch, prerelease)
 VERSION = (MAJOR, MINOR, PATCH, PRE_RELEASE)
 
 old_pack_name = "msadapter"
 result = subprocess.run(["pip", "show", old_pack_name], capture_output=True)
 if result.returncode == 0:
```

