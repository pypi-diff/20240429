# Comparing `tmp/honeyhive-0.1.92-py2.py3-none-any.whl.zip` & `tmp/honeyhive-0.1.93-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 137210 bytes, number of entries: 156
+Zip file size: 138374 bytes, number of entries: 156
 -rw-r--r--  2.0 unx      127 b- defN 23-Nov-16 16:25 honeyhive/__init__.py
 -rw-r--r--  2.0 unx    11706 b- defN 24-Mar-07 22:14 honeyhive/configurations.py
 -rw-r--r--  2.0 unx    15200 b- defN 24-Mar-07 22:14 honeyhive/datapoints.py
 -rw-r--r--  2.0 unx    11897 b- defN 24-Mar-07 22:14 honeyhive/datasets.py
 -rw-r--r--  2.0 unx     9081 b- defN 24-Mar-07 22:14 honeyhive/events.py
 -rw-r--r--  2.0 unx    11381 b- defN 24-Mar-07 22:14 honeyhive/metrics.py
 -rw-r--r--  2.0 unx    12178 b- defN 24-Mar-07 22:14 honeyhive/projects.py
@@ -140,19 +140,19 @@
 -rw-r--r--  2.0 unx      794 b- defN 23-Nov-16 16:25 honeyhive/models/operations/put_tasks.py
 -rw-r--r--  2.0 unx     1531 b- defN 24-Mar-07 22:14 honeyhive/models/operations/startsession.py
 -rw-r--r--  2.0 unx      983 b- defN 24-Mar-07 22:14 honeyhive/models/operations/updateconfiguration.py
 -rw-r--r--  2.0 unx     1049 b- defN 24-Mar-07 22:14 honeyhive/models/operations/updatedatapoint.py
 -rw-r--r--  2.0 unx      755 b- defN 24-Mar-07 22:14 honeyhive/models/operations/updateproject.py
 -rw-r--r--  2.0 unx      760 b- defN 24-Mar-07 22:14 honeyhive/models/operations/updatetool.py
 -rw-r--r--  2.0 unx      120 b- defN 23-Nov-16 16:25 honeyhive/utils/__init__.py
--rw-r--r--  2.0 unx    36037 b- defN 24-Apr-12 16:06 honeyhive/utils/langchain_tracer.py
--rw-r--r--  2.0 unx    26678 b- defN 24-Apr-12 16:06 honeyhive/utils/llamaindex_tracer.py
+-rw-r--r--  2.0 unx    37534 b- defN 24-Apr-22 17:51 honeyhive/utils/langchain_tracer.py
+-rw-r--r--  2.0 unx    29985 b- defN 24-Apr-29 20:37 honeyhive/utils/llamaindex_tracer.py
 -rw-r--r--  2.0 unx     3778 b- defN 24-Mar-07 22:14 honeyhive/utils/retries.py
--rw-r--r--  2.0 unx    24449 b- defN 24-Apr-12 16:06 honeyhive/utils/tracer.py
+-rw-r--r--  2.0 unx    25540 b- defN 24-Apr-22 20:04 honeyhive/utils/tracer.py
 -rw-r--r--  2.0 unx    29904 b- defN 24-Mar-07 22:14 honeyhive/utils/utils.py
--rw-r--r--  2.0 unx     1067 b- defN 24-Apr-12 16:07 honeyhive-0.1.92.dist-info/LICENSE.md
--rw-r--r--  2.0 unx    10104 b- defN 24-Apr-12 16:07 honeyhive-0.1.92.dist-info/METADATA
--rw-r--r--  2.0 unx      110 b- defN 24-Apr-12 16:07 honeyhive-0.1.92.dist-info/WHEEL
--rw-r--r--  2.0 unx       54 b- defN 24-Apr-12 16:07 honeyhive-0.1.92.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 24-Apr-12 16:07 honeyhive-0.1.92.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    15540 b- defN 24-Apr-12 16:07 honeyhive-0.1.92.dist-info/RECORD
-156 files, 460982 bytes uncompressed, 111810 bytes compressed:  75.7%
+-rw-r--r--  2.0 unx     1067 b- defN 24-Apr-29 20:38 honeyhive-0.1.93.dist-info/LICENSE.md
+-rw-r--r--  2.0 unx    10104 b- defN 24-Apr-29 20:38 honeyhive-0.1.93.dist-info/METADATA
+-rw-r--r--  2.0 unx      110 b- defN 24-Apr-29 20:38 honeyhive-0.1.93.dist-info/WHEEL
+-rw-r--r--  2.0 unx       54 b- defN 24-Apr-29 20:38 honeyhive-0.1.93.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       10 b- defN 24-Apr-29 20:38 honeyhive-0.1.93.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    15540 b- defN 24-Apr-29 20:38 honeyhive-0.1.93.dist-info/RECORD
+156 files, 466877 bytes uncompressed, 112974 bytes compressed:  75.8%
```

## zipnote {}

```diff
@@ -444,26 +444,26 @@
 
 Filename: honeyhive/utils/tracer.py
 Comment: 
 
 Filename: honeyhive/utils/utils.py
 Comment: 
 
-Filename: honeyhive-0.1.92.dist-info/LICENSE.md
+Filename: honeyhive-0.1.93.dist-info/LICENSE.md
 Comment: 
 
-Filename: honeyhive-0.1.92.dist-info/METADATA
+Filename: honeyhive-0.1.93.dist-info/METADATA
 Comment: 
 
-Filename: honeyhive-0.1.92.dist-info/WHEEL
+Filename: honeyhive-0.1.93.dist-info/WHEEL
 Comment: 
 
-Filename: honeyhive-0.1.92.dist-info/entry_points.txt
+Filename: honeyhive-0.1.93.dist-info/entry_points.txt
 Comment: 
 
-Filename: honeyhive-0.1.92.dist-info/top_level.txt
+Filename: honeyhive-0.1.93.dist-info/top_level.txt
 Comment: 
 
-Filename: honeyhive-0.1.92.dist-info/RECORD
+Filename: honeyhive-0.1.93.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## honeyhive/utils/langchain_tracer.py

```diff
@@ -65,18 +65,23 @@
 
         self.project = project
         self.source = source if source is not None else "langchain"
         self.name = name
         self.user_properties = user_properties
         self.metadata = metadata
         self.eval_info = None
+        self.last_event_id = None
+        self.last_event_metrics = None
+        self.last_event_metadata = None
         if self.source == "evaluation":
             try:
                 if self.metadata and "run_id" in self.metadata:
                     self.eval_info = {"run_id": self.metadata["run_id"]}
+                    if "datapoint_id" in self.metadata:
+                        self.eval_info["datapoint_id"] = self.metadata["datapoint_id"]
                 elif self.metadata and "dataset_name" in self.metadata:
                     project_res = requests_retry_session().get(
                         url=f"{self._base_url}/projects",
                         headers=self._headers,
                         params={"name": self.project},
                     )
                     if project_res.status_code == 200:
@@ -104,14 +109,40 @@
                                 "run_name": run_name,
                             }
             except:
                 pass
         if api_key is not None:
             self._headers["Authorization"] = "Bearer " + api_key
 
+    def set_metric(
+        self,
+        metric_name,
+        metric_value,
+        threshold,
+    ):
+        if not self.last_event_id:
+            raise Exception("No events defined on session to set metric on")
+        metrics = self.last_event_metrics.copy()
+        metadata = self.last_event_metadata.copy()
+        metrics[metric_name] = metric_value
+        metadata[f"threshold_{metric_name}"] = threshold
+        body = {
+            "event_id": self.last_event_id,
+            "metadata": metadata,
+            "metrics": metrics,
+        }
+        res = requests_retry_session().put(
+            url=f"{self._base_url}/events",
+            headers=self._headers,
+            json=body,
+        )
+        if res.status_code == 200:
+            self.last_event_metrics = metrics
+            self.last_event_metadata = metadata
+
     def _start_new_session(self, inputs):
         session_body = {
             "project": self.project,
             "source": self.source,
             "session_id": self.session_id,
             "session_name": self.name,
             "user_properties": self.user_properties,
@@ -227,15 +258,15 @@
         return logs
 
     def _post_trace(self, logs: List[Log]) -> None:
         """Post a trace to the HoneyHive API"""
         root_log = logs[0].dict()
         self.final_outputs = root_log["outputs"]
         self.session_id = str(uuid.uuid4())
-        self._set_parent_ids(root_log, self.session_id)
+        self._crawl(root_log, self.session_id)
         self._start_new_session(root_log["inputs"])
         trace_response = requests_retry_session().post(
             url=f"{self._base_url}/session/{self.session_id}/traces",
             json={"logs": [root_log]},
             headers=self._headers,
         )
         if trace_response.status_code != 200:
@@ -252,17 +283,20 @@
                 if "run_id" in self.eval_info:
                     run_res = requests_retry_session().get(
                         url=f"{self._base_url}/runs/{self.eval_info['run_id']}",
                         headers=self._headers,
                     )
                     event_ids = run_res.json()["evaluation"]["event_ids"]
                     event_ids.append(self.session_id)
+                    datapoint_ids = run_res.json()["evaluation"]["event_ids"]
+                    if "datapoint_id" in self.eval_info:
+                        datapoint_ids.append(self.eval_info["datapoint_id"])
                     requests_retry_session().put(
                         url=f"{self._base_url}/runs/{self.eval_info['run_id']}",
-                        json={"event_ids": event_ids},
+                        json={"event_ids": event_ids, "datapoint_ids": datapoint_ids},
                         headers=self._headers,
                     )
                 else:
                     body = {
                         "event_ids": [self.session_id],
                         "dataset_id": self.eval_info["dataset_id"],
                         "datapoint_ids": self.eval_info["datapoint_ids"],
@@ -278,19 +312,22 @@
                         json=body,
                     )
                     run_id = run_res.json()["run_id"]
                     self.eval_info["run_id"] = run_id
             except:
                 pass
 
-    def _set_parent_ids(self, trace, session_id) -> None:
+    def _crawl(self, trace, session_id) -> None:
         def crawl(node):
             if node is None:
                 return
             node["session_id"] = session_id
+            self.last_event_id = node["event_id"]
+            self.last_event_metrics = node.get("metrics", {})
+            self.last_event_metadata = node.get("metadata", {})
             self.final_outputs = node["outputs"]
             if node["children"]:
                 for child in node["children"]:
                     child["parent_id"] = node["event_id"]
                     crawl(child)
 
         crawl(trace)
```

## honeyhive/utils/llamaindex_tracer.py

```diff
@@ -1,12 +1,12 @@
 # pylint: skip-file
 import json
 import os
 import uuid
-from collections import defaultdict
+from collections import defaultdict, deque
 from datetime import datetime
 from enum import Enum
 from typing import Any, Callable, Dict, List, Optional, Tuple
 
 import requests
 from llama_index.core.callbacks.base import BaseCallbackHandler
 from llama_index.core.callbacks.schema import (
@@ -22,15 +22,14 @@
     Config,
     LLMConfig,
     Log,
     log_to_dict,
     requests_retry_session,
 )
 
-
 class HHEventType(str, Enum):
     MODEL = "model"
     CHAIN = "chain"
     TOOL = "tool"
 
 
 class HoneyHiveLlamaIndexTracer(BaseCallbackHandler):
@@ -42,49 +41,52 @@
     def __init__(
         self,
         project: str,
         name: Optional[str] = None,
         source: Optional[str] = None,
         user_properties: Optional[Dict[str, Any]] = None,
         tokenizer: Optional[TokenCounter] = None,
-        event_starts_to_ignore: Optional[List[CBEventType]] = None,
-        event_ends_to_ignore: Optional[List[CBEventType]] = None,
+        event_types_to_ignore: Optional[List[CBEventType]] = None,
         api_key: Optional[str] = None,
         metadata: Optional[Dict[str, Any]] = None,
     ) -> None:
         if self._env_api_key:
             api_key = self._env_api_key
         elif not api_key:
             raise ValueError(
                 "HoneyHive API key is not set! Please set the HONEYHIVE_API_KEY environment variable or pass in the api_key value."
             )
 
         if api_key:
             self._headers["Authorization"] = f"Bearer {api_key}"
 
-        self.event_starts_to_ignore = event_starts_to_ignore or []
-        self.event_ends_to_ignore = event_ends_to_ignore or []
+        self.event_starts_to_ignore = event_types_to_ignore or []
+        self.event_ends_to_ignore = event_types_to_ignore or []
         self._event_pairs_by_id: Dict[str, List[CBEvent]] = defaultdict(list)
         self._cur_trace_id: Optional[str] = None
         self._trace_map: Dict[str, List[str]] = defaultdict(list)
         self.tokenizer = (
             TokenCounter(tokenizer=tokenizer) if tokenizer else TokenCounter()
         )
 
         self.name = name
         self.project = project
         self.source = source
         self.user_properties = user_properties
         self.metadata = metadata
         self.eval_info = None
-        self.root_event_ids = []
+        self.last_event_id = None
+        self.last_event_metrics = None
+        self.last_event_metadata = None
         if self.source == "evaluation":
             try:
                 if self.metadata and "run_id" in self.metadata:
                     self.eval_info = {"run_id": self.metadata["run_id"]}
+                    if "datapoint_id" in self.metadata:
+                        self.eval_info["datapoint_id"] = self.metadata["datapoint_id"]
                 elif self.metadata and "dataset_name" in self.metadata:
                     project_res = requests_retry_session().get(
                         url=f"{self._base_url}/projects",
                         headers=self._headers,
                         params={"name": self.project},
                     )
                     if project_res.status_code == 200:
@@ -111,14 +113,40 @@
                                 "project_id": project_id,
                                 "run_name": run_name,
                             }
             except:
                 pass
         self.session_id = None
 
+    def set_metric(
+        self,
+        metric_name,
+        metric_value,
+        threshold,
+    ):
+        if not self.last_event_id:
+            raise Exception("No events defined on session to set metric on")
+        metrics = self.last_event_metrics.copy()
+        metadata = self.last_event_metadata.copy()
+        metrics[metric_name] = metric_value
+        metadata[f"threshold_{metric_name}"] = threshold
+        body = {
+            "event_id": self.last_event_id,
+            "metadata": metadata,
+            "metrics": metrics,
+        }
+        res = requests_retry_session().put(
+            url=f"{self._base_url}/events",
+            headers=self._headers,
+            json=body,
+        )
+        if res.status_code == 200:
+            self.last_event_metrics = metrics
+            self.last_event_metadata = metadata
+
     def _start_new_session(self, inputs):
         body = {
             "project": self.project,
             "source": self.source,
             "session_name": self.name,
             "session_id": self.session_id,
             "user_properties": self.user_properties,
@@ -181,54 +209,98 @@
         trace_id: Optional[str] = None,
         trace_map: Optional[Dict[str, List[str]]] = None,
     ) -> None:
         self._trace_map = trace_map or defaultdict(list)
         self._end_time = datetime.now()
         self.log_trace()
 
+    def _percolate_up_blacklisted(self, trace_map, event_map):
+        new_trace_map = defaultdict(list)
+
+        # Create a reverse map to find parents of each event
+        parent_map = {}
+        for parent, children in trace_map.items():
+            for child in children:
+                parent_map[child] = parent
+
+        # Helper function to find the nearest non-blacklisted ancestor
+        def find_valid_parent(event_id):
+            while event_id in parent_map:
+                if event_map.get(parent_map[event_id]) is not None:
+                    return parent_map[event_id]
+                event_id = parent_map[event_id]
+            return 'root'  # Default to root if no valid parents found
+
+        # Recursively handle all children of each node
+        def handle_children(event_id, valid_parent):
+            for child in trace_map[event_id]:
+                if event_map.get(child) is not None:  # If child is not blacklisted
+                    new_trace_map[valid_parent].append(child)
+                    handle_children(child, child)  # Child becomes a new valid parent
+                else:
+                    handle_children(child, valid_parent)  # Continue with the current valid parent
+
+        # Start processing from root
+        for child in trace_map['root']:
+            if event_map.get(child) is None:  # Root's direct child is blacklisted
+                handle_children(child, 'root')  # Handle all descendants under root
+            else:
+                new_trace_map['root'].append(child)
+                handle_children(child, child)
+
+        return new_trace_map
+
+
     def log_trace(self) -> None:
         try:
             events = []
             for event_list in self._trace_map.values():
                 events.extend(event_list)
             events = set(events)
             event_map = {}
             for event in events:
                 event_pair = self._event_pairs_by_id[event]
                 event_log = self._convert_event_pair_to_log(event_pair)
                 event_map[event] = event_log
+            self._trace_map = self._percolate_up_blacklisted(self._trace_map, event_map)
             for event_id, child_event_ids in self._trace_map.items():
                 if event_id == "root":
                     continue
-                parent_log = event_map[event_id]
+                parent_log = event_map.get(event_id)
                 for child_event_id in child_event_ids:
-                    child_log = event_map[child_event_id]
-                    child_log.parent_id = parent_log.event_id
-                    if parent_log.children is None:
-                        parent_log.children = [child_log]
-                    else:
-                        parent_log.children += [child_log]
+                    child_log = event_map.get(child_event_id)
+                    if child_log:
+                        child_log.parent_id = None if parent_log is None else parent_log.event_id
+                        if parent_log:
+                            if parent_log.children is None:
+                                parent_log.children = [child_log]
+                            else:
+                                parent_log.children += [child_log]
             root_events = []
             for event_id in self._trace_map["root"]:
-                root_events.append(event_map[event_id])
+                event = event_map.get(event_id)
+                if event:
+                    root_events.append(event_map[event_id])
             root_events.sort(key=lambda event: event.start_time)
             for event in root_events:
                 self._post_trace(event)
 
         except Exception:
             # Silently ignore errors to not break user code
             pass
 
     def _convert_event_pair_to_log(
         self,
         event_pair: List[CBEvent],
         parent_id: Optional[str] = None,
         trace_id: Optional[str] = None,
-    ) -> Log:
+    ) -> Optional[Log]:
         """Convert a pair of events to a HoneyHive log."""
+        if len(event_pair) < 2:
+            return None
         start_time_us, end_time_us = self._get_time_in_us(event_pair)
 
         event_type = event_pair[0].event_type
         span_kind = self._map_event_type(event_type)
 
         root_log = Log(
             project=self.project,
@@ -506,15 +578,14 @@
         end_time_in_ms = int(
             (end_time - datetime(1970, 1, 1)).total_seconds() * 1000000
         )
 
         return start_time_in_ms, end_time_in_ms
 
     def _post_trace(self, root_log: Log) -> None:
-        self.root_event_ids.append(root_log.event_id)
         root_log = log_to_dict(root_log)
         self.final_outputs = root_log["outputs"]
         first_trace = False
         if self.session_id is None:
             first_trace = True
             self.session_id = str(uuid.uuid4())
             self._start_new_session(root_log["inputs"])
@@ -530,30 +601,32 @@
                 f"Failed to post trace to HoneyHive with status code {trace_response.status_code}"
             )
         requests_retry_session().put(
             url=f"{self._base_url}/events",
             json={
                 "event_id": self.session_id,
                 "outputs": self.final_outputs,
-                "children_ids": self.root_event_ids,
             },
             headers=self._headers,
         )
         if self.eval_info and first_trace:
             try:
                 if "run_id" in self.eval_info:
                     run_res = requests_retry_session().get(
                         url=f"{self._base_url}/runs/{self.eval_info['run_id']}",
                         headers=self._headers,
                     )
                     event_ids = run_res.json()["evaluation"]["event_ids"]
                     event_ids.append(self.session_id)
+                    datapoint_ids = run_res.json()["evaluation"]["event_ids"]
+                    if "datapoint_id" in self.eval_info:
+                        datapoint_ids.append(self.eval_info["datapoint_id"])
                     requests_retry_session().put(
                         url=f"{self._base_url}/runs/{self.eval_info['run_id']}",
-                        json={"event_ids": event_ids},
+                        json={"event_ids": event_ids, "datapoint_ids": datapoint_ids},
                         headers=self._headers,
                     )
                 else:
                     body = {
                         "event_ids": [self.session_id],
                         "dataset_id": self.eval_info["dataset_id"],
                         "datapoint_ids": self.eval_info["datapoint_ids"],
@@ -613,14 +686,17 @@
         return chat_history
 
     def _crawl(self, trace, session_id) -> None:
         def crawl(node):
             if node is None:
                 return
             node["session_id"] = session_id
+            self.last_event_id = node["event_id"]
+            self.last_event_metrics = node.get("metrics", {})
+            self.last_event_metadata = node.get("metadata", {})
             self.final_outputs = node["outputs"]
             if node["children"]:
                 """
                 We do a pattern-match for the following pattern in the event tree:
                 synthesize
                   llm
                   templating
```

## honeyhive/utils/tracer.py

```diff
@@ -180,16 +180,45 @@
         self.context_set_properly = False
         self.context_function_name = ""
         self.context_file_name = ""
         self.start_time = 0
         self.end_time = 0
         self.call_value = None
         self.return_value = None
+        self.last_event_id = None
+        self.last_event_metrics = None
+        self.last_event_metadata = None
         self.show_trace = show_trace
 
+    def set_metric(
+        self,
+        metric_name,
+        metric_value,
+        threshold,
+    ):
+        if not self.last_event_id:
+            raise Exception("No events defined on session to set metric on")
+        metrics = self.last_event_metrics.copy()
+        metadata = self.last_event_metadata.copy()
+        metrics[metric_name] = metric_value
+        metadata[f"threshold_{metric_name}"] = threshold
+        body = {
+            "event_id": self.last_event_id,
+            "metadata": metadata,
+            "metrics": metrics,
+        }
+        res = requests_retry_session().put(
+            url=f"{self._base_url}/events",
+            headers=self._headers,
+            json=body,
+        )
+        if res.status_code == 200:
+            self.last_event_metrics = metrics
+            self.last_event_metadata = metadata
+
     def trace_calls(self, frame, event, arg):
         function_name = frame.f_code.co_name
         file_name = frame.f_code.co_filename
         if event == "call":
             if function_name == "create" and file_name == inspect.getfile(
                 openai.Completion
             ):
@@ -399,14 +428,18 @@
 
         res = requests_retry_session().post(
             url=f"{self._base_url}/events",
             json={"event": event},
             headers=self._headers,
         )
 
+        self.last_event_id = res.json()["event_id"]
+        self.last_event_metadata = self.metadata
+        self.last_event_metrics = {}
+
         # reset the event
         self.event_id = None
         self.event_type = "model"
         self.event_name = ""
         self.config = {}
         self.children = []
         self.input = {}
```

## Comparing `honeyhive-0.1.92.dist-info/LICENSE.md` & `honeyhive-0.1.93.dist-info/LICENSE.md`

 * *Files identical despite different names*

## Comparing `honeyhive-0.1.92.dist-info/METADATA` & `honeyhive-0.1.93.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: honeyhive
-Version: 0.1.92
+Version: 0.1.93
 Summary: The HoneyHive SDK for Python
 Author: HoneyHive
 Author-email: support@honeyhive.ai
 License: Apache License 2.0
 Project-URL: Documentation, https://docs.honeyhive.ai/
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
```

## Comparing `honeyhive-0.1.92.dist-info/RECORD` & `honeyhive-0.1.93.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -139,18 +139,18 @@
 honeyhive/models/operations/put_tasks.py,sha256=8AZW9plEY58xv_CAx-cWIwNnAcoupTJznGFucIOSLXY,794
 honeyhive/models/operations/startsession.py,sha256=cZb05TV8-lGesc4LbpQa7hL_bKzPpITPFl0BOkTdo_A,1531
 honeyhive/models/operations/updateconfiguration.py,sha256=3oKQgie-xezDYBwY72gZTMnGgfYxBlNXOP8wT-NenpE,983
 honeyhive/models/operations/updatedatapoint.py,sha256=rTaObde977UzsRInK05T5KSr7Lg6xdvN4YUWKqffzb0,1049
 honeyhive/models/operations/updateproject.py,sha256=Bf97UHs8gYm0IDr7xeX4t0ZaZ40P7fBlZXxfgImhH7o,755
 honeyhive/models/operations/updatetool.py,sha256=sg87lwZoj4oMQcD9D5RRG-QBiKqzuQyonNcGipQUF48,760
 honeyhive/utils/__init__.py,sha256=zLnrOfHSNt25T6bPV5Ejpkg_aqTozDDxvFG1IwS9Mdc,120
-honeyhive/utils/langchain_tracer.py,sha256=TfsnJ7mVc9T1q1CjCRB1vFN3WszulNrzq5ZT0eNeZNk,36037
-honeyhive/utils/llamaindex_tracer.py,sha256=n8nOxlvevHOvUh81V38XXmWMgt3cZ4nHUEMpEyNqjBY,26678
+honeyhive/utils/langchain_tracer.py,sha256=OEWl6jc2ZJlmzfW0qPOwLYGZJ4u0LILjOAol8-kjOrw,37534
+honeyhive/utils/llamaindex_tracer.py,sha256=tLwnknH3Xi3SZwo87tHQoGvc-E1S9IlgEBdkwUePeac,29985
 honeyhive/utils/retries.py,sha256=MYN9QqoPTQ8W4t7pP1E_vthvYymc8W43DUj-fXWToM4,3778
-honeyhive/utils/tracer.py,sha256=P8lJo7hb38nB-azKKQ2oElBticfPm3GQjlqgkj4AByc,24449
+honeyhive/utils/tracer.py,sha256=h5hZv3-V8Zqw2Brgh362Zu0xfAzRB7Uu8yOeyCMPZZ8,25540
 honeyhive/utils/utils.py,sha256=N98kWocluTimG5Jyju-DT_LjVV5ta8rJ1gGfz9O6_lU,29904
-honeyhive-0.1.92.dist-info/LICENSE.md,sha256=FiTUhGqAN9m3DxANtg3j_XrptaNYwWW8H_xkan403V4,1067
-honeyhive-0.1.92.dist-info/METADATA,sha256=flX1JkQ5P_SVPVXAl1CQ6DPaiWZJKc_XFF89VOVzyLw,10104
-honeyhive-0.1.92.dist-info/WHEEL,sha256=DZajD4pwLWue70CAfc7YaxT1wLUciNBvN_TTcvXpltE,110
-honeyhive-0.1.92.dist-info/entry_points.txt,sha256=CvgoR64OL75KOSpt7uSW2Fb5ZjWehBDTLGiy8-3Qiok,54
-honeyhive-0.1.92.dist-info/top_level.txt,sha256=EkTBKijxI-xSXEd6gSGJdgn5uHcJa4Yx7LBq5Z9hNZ0,10
-honeyhive-0.1.92.dist-info/RECORD,,
+honeyhive-0.1.93.dist-info/LICENSE.md,sha256=FiTUhGqAN9m3DxANtg3j_XrptaNYwWW8H_xkan403V4,1067
+honeyhive-0.1.93.dist-info/METADATA,sha256=8OHRJNj2QjgWJFxNlufxRx_mciz-KAdxrAhlpfn2DmU,10104
+honeyhive-0.1.93.dist-info/WHEEL,sha256=DZajD4pwLWue70CAfc7YaxT1wLUciNBvN_TTcvXpltE,110
+honeyhive-0.1.93.dist-info/entry_points.txt,sha256=CvgoR64OL75KOSpt7uSW2Fb5ZjWehBDTLGiy8-3Qiok,54
+honeyhive-0.1.93.dist-info/top_level.txt,sha256=EkTBKijxI-xSXEd6gSGJdgn5uHcJa4Yx7LBq5Z9hNZ0,10
+honeyhive-0.1.93.dist-info/RECORD,,
```

